{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aoun-CV-Assignment02.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YG6Nm2zuJMPA"
      },
      "source": [
        "#Question 1 - Part 1 - Loading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgWE_-JNJMiS"
      },
      "source": [
        "import os\n",
        "import gdown\n",
        "import tensorflow as tf\n",
        "from zipfile import ZipFile\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1F76-pILrS4"
      },
      "source": [
        "Downloading Stanford Cars Dataset from Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKmAfr3iLkuK",
        "outputId": "582c52e8-de90-4ffe-f3b1-9802d20c4c8f"
      },
      "source": [
        "!pip install -q kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!wget https://raw.githubusercontent.com/ms03831/cv_a2/main/kaggle.json\n",
        "!mv kaggle.json ~/.kaggle\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d jessicali9530/stanford-cars-dataset"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-29 18:28:07--  https://raw.githubusercontent.com/ms03831/cv_a2/main/kaggle.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 70 [text/plain]\n",
            "Saving to: ‘kaggle.json’\n",
            "\n",
            "kaggle.json         100%[===================>]      70  --.-KB/s    in 0s      \n",
            "\n",
            "2021-05-29 18:28:07 (4.31 MB/s) - ‘kaggle.json’ saved [70/70]\n",
            "\n",
            "Downloading stanford-cars-dataset.zip to /content\n",
            " 99% 1.81G/1.82G [00:16<00:00, 46.7MB/s]\n",
            "100% 1.82G/1.82G [00:16<00:00, 118MB/s] \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpQZHVKZL0zl"
      },
      "source": [
        "Unzipping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJjSNFQ6L10N"
      },
      "source": [
        "os.makedirs(\"images_cars\")\n",
        "with ZipFile(\"/content/stanford-cars-dataset.zip\", \"r\") as zipobj:\n",
        "    zipobj.extractall(\"images_cars\")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WotrcQSr_zUR"
      },
      "source": [
        "#Question 1 - Part 2 - Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYX9Mt_vLv7c"
      },
      "source": [
        "def define_discriminator(in_shape=(32,32,1)):\n",
        "  # weight initialization\n",
        "  init = RandomNormal(stddev=0.02)\n",
        "  # define model\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Conv2D(32, (4,4), strides=(2,2), padding='same', kernel_initializer=init, input_shape=in_shape))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "  model.add(Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "  model.add(Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "  # classifier\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  # compile model\n",
        "  opt = Adam(lr=0.00012, beta_1=0.5)\n",
        "  model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lanlzqQE1VA"
      },
      "source": [
        "The architecture has three Conv2D layers with LeakyReLU activation function and then outputs a single error between 0 to 1 using sigmoid. \n",
        "\n",
        "MaxPooling is not used because it is not preferable in GANs. Also, this is a very basic CNN which ensures fast training.\n",
        "\n",
        "When deciding an architecture for discriminator, a common convention is increasing filters as we go deeper into the network. The deeper layers in the network are responsible for learning the more complex patterns, shapes, or representations of the image. The more complex features mean that we need to capture more combinations, hence more filters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NU6uGXrXF8qL"
      },
      "source": [
        "#Question 1 - 3 - Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PK3enCm-F-kH"
      },
      "source": [
        "def define_generator(latent_dim):\n",
        "  # weight initialization\n",
        "  init = RandomNormal(stddev=0.02)\n",
        "  # define model\n",
        "  model = Sequential()\n",
        "\n",
        "  # foundation for 4x4 image\n",
        "  n_nodes = 128 * 4 * 4\n",
        "  model.add(Dense(n_nodes, kernel_initializer=init, input_dim=latent_dim))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "  model.add(Reshape((4, 4, 128)))\n",
        "   \n",
        "  #upsampling to 8x8 \n",
        "  model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "  #upsampling to 16x16 \n",
        "  model.add(Conv2DTranspose(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        " \n",
        "  #upsampling to 32x32  \n",
        "  model.add(Conv2DTranspose(32, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "  # output 32x32x1\n",
        "  model.add(Conv2D(1, (5,5), activation='tanh', padding='same', kernel_initializer=init))\n",
        "  return model"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuQ_K--1Hklf"
      },
      "source": [
        "#Implementing the Generator network to accept 100x1 noise vector and output 64x64x3 image\n",
        "latent_dim = 100"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-p3LDLaHcLr"
      },
      "source": [
        "The input noise vector dimension can certainly be changed. \n",
        "\n",
        "The vector is drawn randomly from a Gaussian distribution, and the vector is used to seed the generative process. After training, points in this multidimensional vector space will correspond to points in the problem domain, forming a compressed representation of the data distribution.\n",
        "\n",
        "The generator model applies meaning to points in a chosen latent space, such that new points drawn from the latent space can be provided to the generator model as input and used to generate new and different output examples. \n",
        "\n",
        "A large set of random numbers mean that more output images of different variety can be generated by the GAN. \n",
        "\n",
        "A very large number is not chosen because it can make the training very difficult and would require a much better discriminator as well as a generator. \n",
        "\n",
        "The number is not decreased too much because that would mean forcing the model to only generate a small subset of plausible outputs. This would eventually cause **Mode Collapse** failure in the GAN.\n",
        "\n",
        "A good starting point for generator in terms of deciding the number of filters could be reversing the order of the number of filters of the discriminator and that is what we did here. \n",
        "\n",
        "For example, if the discriminator starts from 32 filters, then 64, then 128. So, for generator, we went from 128 to 64 to 32. You can read the original DCGAN paper, and see their architecture. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrR5eQ2qIrI1"
      },
      "source": [
        "#Question 1 - 4 - Training Loop for GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5jkP17rKRoe"
      },
      "source": [
        "from os import makedirs\n",
        "from numpy import expand_dims\n",
        "from numpy import zeros\n",
        "from numpy import ones\n",
        "from numpy.random import randn\n",
        "from numpy.random import randint\n",
        "from keras.datasets.mnist import load_data\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.initializers import RandomNormal\n",
        "from matplotlib import pyplot\n",
        "from os import listdir\n",
        "from numpy import asarray\n",
        "from numpy import vstack\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import load_img\n",
        "from numpy import savez_compressed"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGliKhgZJ32C"
      },
      "source": [
        "Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcmt94RRIx-Q"
      },
      "source": [
        "EPOCHS = 50\n",
        "BATCH_SIZE = 128\n",
        "lr = 0.00012\n",
        "latent_dim = 100"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BUVXaSxKfjF"
      },
      "source": [
        "Sources Used: https://machinelearningmastery.com/how-to-develop-a-generative-adversarial-network-for-an-mnist-handwritten-digits-from-scratch-in-keras/\n",
        "\n",
        "https://machinelearningmastery.com/what-are-generative-adversarial-networks-gans/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylBlnJwTMU7q"
      },
      "source": [
        "# load images\n",
        "def load_real_samples():\n",
        "  data = list()\n",
        "  # load dataset\n",
        "  for filename in os.listdir('/content/images_cars/cars_train/cars_train/'):\n",
        "    pixels = load_img('/content/images_cars/cars_train/cars_train/'+str(filename), target_size = (32,32), grayscale=True)\n",
        "    pixels = img_to_array(pixels)\n",
        "    data.append(pixels)\n",
        "\n",
        "  X = asarray(data)\n",
        "  # convert from ints to floats\n",
        "  X = X.astype('float32')\n",
        "  # scale from [0,255] to [-1,1] to match the generator images\n",
        "  X = (X - 127.5) / 127.5\n",
        "  return X"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0kp7OWyMZr8",
        "outputId": "2a85a894-6826-4d2e-e685-719e1bdd2427"
      },
      "source": [
        "X = load_real_samples()\n",
        "print(X.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py:107: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
            "  warnings.warn('grayscale is deprecated. Please use '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(8144, 32, 32, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "9pvUcQLZMyFz",
        "outputId": "25ca8d93-e4fe-4b89-a89e-9ec392e652eb"
      },
      "source": [
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "\n",
        "print(X[0].shape) #converting for the sake of plotting\n",
        "backtorgb = cv2.cvtColor(X[0],cv2.COLOR_GRAY2RGB)\n",
        "print(backtorgb.shape)\n",
        "#pyplot.imshow(backtorgb)\n",
        "pyplot.imshow((backtorgb+1)/2) #we are actually using 1 channel image, this is just for plotting"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 32, 1)\n",
            "(32, 32, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa972133b50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEjpgfKrKhAx"
      },
      "source": [
        "# define the combined generator and discriminator model, for updating the generator\n",
        "def define_gan(generator, discriminator):\n",
        "  # make weights in the discriminator not trainable\n",
        "  discriminator.trainable = False\n",
        "  # connect them\n",
        "  model = Sequential()\n",
        "  # add generator\n",
        "  model.add(generator)\n",
        "  # add the discriminator\n",
        "  model.add(discriminator)\n",
        "  # compile model\n",
        "  opt = Adam(lr=0.00012, beta_1=0.5)\n",
        "  model.compile(loss='binary_crossentropy', optimizer=opt)\n",
        "  return model\n",
        "\n",
        "# select real samples\n",
        "def generate_real_samples(dataset, n_samples):\n",
        "  # choose random instances\n",
        "  ix = randint(0, dataset.shape[0], n_samples)\n",
        "  # select images\n",
        "  X = dataset[ix]\n",
        "  # generate class labels\n",
        "  y = ones((n_samples, 1))\n",
        "  return X, y\n",
        "\n",
        "# generate points in latent space as input for the generator\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "  # generate points in the latent space\n",
        "  x_input = randn(latent_dim * n_samples)\n",
        "  # reshape into a batch of inputs for the network\n",
        "  x_input = x_input.reshape(n_samples, latent_dim)\n",
        "  return x_input\n",
        "\n",
        "# use the generator to generate n fake examples, with class labels\n",
        "def generate_fake_samples(generator, latent_dim, n_samples):\n",
        "  # generate points in latent space\n",
        "  x_input = generate_latent_points(latent_dim, n_samples)\n",
        "  # predict outputs\n",
        "  X = generator.predict(x_input)\n",
        "  # create class labels\n",
        "  y = zeros((n_samples, 1))\n",
        "  return X, y\n",
        "\n",
        "# generate samples and save as a plot and save the model\n",
        "def summarize_performance(step, g_model, latent_dim, n_samples=16):\n",
        "  # prepare fake examples\n",
        "  X, _ = generate_fake_samples(g_model, latent_dim, n_samples)\n",
        "  # scale from [-1,1] to [0,1]\n",
        "  X = (X + 1) / 2.0\n",
        "  # plot images\n",
        "  for i in range(4 * 4):\n",
        "    # define subplot\n",
        "    pyplot.subplot(4, 4, 1 + i)\n",
        "    # turn off axis\n",
        "    pyplot.axis('off')\n",
        "    # plot raw pixel data\n",
        "    backtorgb = cv2.cvtColor(X[i, :, :, :],cv2.COLOR_GRAY2RGB)\n",
        "    pyplot.imshow((backtorgb+1)/2)\n",
        "  # save plot to file\n",
        "  pyplot.savefig('results_baseline/generated_plot_%03d.png' % (step+1))\n",
        "  pyplot.close()\n",
        "  # save the generator model\n",
        "  g_model.save('/content/drive/MyDrive/CV_Assignment_02/model_%03d.h5' % (step+1))\n",
        "\n",
        "# create a line plot of loss for the gan and save to file\n",
        "def plot_history(d1_hist, d2_hist, g_hist, a1_hist, a2_hist):\n",
        "  # plot loss\n",
        "  pyplot.subplot(2, 1, 1)\n",
        "  pyplot.plot(d1_hist, label='d-real')\n",
        "  pyplot.plot(d2_hist, label='d-fake')\n",
        "  pyplot.plot(g_hist, label='gen')\n",
        "  pyplot.legend()\n",
        "  # plot discriminator accuracy\n",
        "  pyplot.subplot(2, 1, 2)\n",
        "  pyplot.plot(a1_hist, label='acc-real')\n",
        "  pyplot.plot(a2_hist, label='acc-fake')\n",
        "  pyplot.legend()\n",
        "  # save plot to file\n",
        "  pyplot.savefig('results_baseline/plot_line_plot_loss.png')\n",
        "  pyplot.close()"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0ZjxT4-Qfki"
      },
      "source": [
        "# train the generator and discriminator\n",
        "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=EPOCHS, n_batch=BATCH_SIZE):\n",
        "  # calculate the number of batches per epoch\n",
        "  bat_per_epo = int(dataset.shape[0] / n_batch)\n",
        "  # calculate the total iterations based on batch and epoch\n",
        "  n_steps = bat_per_epo * n_epochs\n",
        "  # calculate the number of samples in half a batch\n",
        "  half_batch = int(n_batch / 2)\n",
        "  # prepare lists for storing stats each iteration\n",
        "  d1_hist, d2_hist, g_hist, a1_hist, a2_hist = list(), list(), list(), list(), list()\n",
        "  # manually enumerate epochs\n",
        "  for i in range(n_steps):\n",
        "    # get randomly selected 'real' samples\n",
        "    X_real, y_real = generate_real_samples(dataset, half_batch)\n",
        "    # update discriminator model weights\n",
        "    d_loss1, d_acc1 = d_model.train_on_batch(X_real, y_real)\n",
        "    # generate 'fake' examples\n",
        "    X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
        "    # update discriminator model weights\n",
        "    d_loss2, d_acc2 = d_model.train_on_batch(X_fake, y_fake)\n",
        "    # prepare points in latent space as input for the generator\n",
        "    X_gan = generate_latent_points(latent_dim, n_batch)\n",
        "    # create inverted labels for the fake samples\n",
        "    y_gan = ones((n_batch, 1))\n",
        "    # update the generator via the discriminator's error\n",
        "    g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
        "    # summarize loss on this batch\n",
        "    print('>%d, disc_1(Real)=%.3f, disc_2(Fake)=%.3f, gen_loss=%.3f, disc_1(Real)_a=%d, disc_2(Fake)_a=%d' %\n",
        "      (i+1, d_loss1, d_loss2, g_loss, int(100*d_acc1), int(100*d_acc2)))\n",
        "    # record history\n",
        "    d1_hist.append(d_loss1)\n",
        "    d2_hist.append(d_loss2)\n",
        "    g_hist.append(g_loss)\n",
        "    a1_hist.append(d_acc1)\n",
        "    a2_hist.append(d_acc2)\n",
        "    # evaluate the model performance every 'epoch'\n",
        "    if (i+1) % bat_per_epo == 0:\n",
        "      summarize_performance(i, g_model, latent_dim)\n",
        "  plot_history(d1_hist, d2_hist, g_hist, a1_hist, a2_hist)\n",
        "  return d1_hist, d2_hist, g_hist, a1_hist, a2_hist"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mC040Y53Qf-Y",
        "outputId": "6891f7cc-7a98-4db1-df24-cbf23256b691"
      },
      "source": [
        "makedirs('results_baseline', exist_ok=True)\n",
        "# size of the latent space\n",
        "latent_dim = 100\n",
        "# create the discriminator\n",
        "discriminator = define_discriminator()\n",
        "# create the generator\n",
        "generator = define_generator(latent_dim)\n",
        "# create the gan\n",
        "gan_model = define_gan(generator, discriminator)\n",
        "# load image data\n",
        "dataset = load_real_samples()\n",
        "print(dataset.shape)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py:107: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
            "  warnings.warn('grayscale is deprecated. Please use '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(8144, 32, 32, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhhCMUgjV6sm"
      },
      "source": [
        "Final training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duCzkqYOV8gH",
        "outputId": "d0e4de22-7d2c-4d34-e3f9-f3ed79c47435"
      },
      "source": [
        "d1_hist2, d2_hist2, g_hist2, a1_hist2, a2_hist2 = train(generator, discriminator, gan_model, dataset, latent_dim)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">1, disc_1(Real)=0.248, disc_2(Fake)=0.675, gen_loss=0.803, disc_1(Real)_a=100, disc_2(Fake)_a=92\n",
            ">2, disc_1(Real)=0.229, disc_2(Fake)=0.575, gen_loss=0.902, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">3, disc_1(Real)=0.233, disc_2(Fake)=0.502, gen_loss=1.008, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">4, disc_1(Real)=0.206, disc_2(Fake)=0.436, gen_loss=1.129, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">5, disc_1(Real)=0.197, disc_2(Fake)=0.385, gen_loss=1.234, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">6, disc_1(Real)=0.194, disc_2(Fake)=0.350, gen_loss=1.301, disc_1(Real)_a=96, disc_2(Fake)_a=100\n",
            ">7, disc_1(Real)=0.181, disc_2(Fake)=0.336, gen_loss=1.315, disc_1(Real)_a=93, disc_2(Fake)_a=100\n",
            ">8, disc_1(Real)=0.124, disc_2(Fake)=0.337, gen_loss=1.299, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">9, disc_1(Real)=0.142, disc_2(Fake)=0.352, gen_loss=1.264, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">10, disc_1(Real)=0.133, disc_2(Fake)=0.370, gen_loss=1.201, disc_1(Real)_a=96, disc_2(Fake)_a=100\n",
            ">11, disc_1(Real)=0.127, disc_2(Fake)=0.393, gen_loss=1.144, disc_1(Real)_a=96, disc_2(Fake)_a=100\n",
            ">12, disc_1(Real)=0.101, disc_2(Fake)=0.414, gen_loss=1.100, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">13, disc_1(Real)=0.127, disc_2(Fake)=0.433, gen_loss=1.060, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">14, disc_1(Real)=0.131, disc_2(Fake)=0.444, gen_loss=1.032, disc_1(Real)_a=96, disc_2(Fake)_a=100\n",
            ">15, disc_1(Real)=0.118, disc_2(Fake)=0.457, gen_loss=1.017, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">16, disc_1(Real)=0.070, disc_2(Fake)=0.460, gen_loss=1.004, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">17, disc_1(Real)=0.104, disc_2(Fake)=0.465, gen_loss=0.998, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">18, disc_1(Real)=0.064, disc_2(Fake)=0.466, gen_loss=0.994, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">19, disc_1(Real)=0.057, disc_2(Fake)=0.465, gen_loss=0.996, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">20, disc_1(Real)=0.036, disc_2(Fake)=0.466, gen_loss=0.998, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">21, disc_1(Real)=0.046, disc_2(Fake)=0.463, gen_loss=1.001, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">22, disc_1(Real)=0.065, disc_2(Fake)=0.461, gen_loss=1.004, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">23, disc_1(Real)=0.073, disc_2(Fake)=0.458, gen_loss=1.009, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">24, disc_1(Real)=0.057, disc_2(Fake)=0.455, gen_loss=1.015, disc_1(Real)_a=96, disc_2(Fake)_a=100\n",
            ">25, disc_1(Real)=0.078, disc_2(Fake)=0.451, gen_loss=1.020, disc_1(Real)_a=96, disc_2(Fake)_a=100\n",
            ">26, disc_1(Real)=0.058, disc_2(Fake)=0.449, gen_loss=1.029, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">27, disc_1(Real)=0.023, disc_2(Fake)=0.444, gen_loss=1.037, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">28, disc_1(Real)=0.035, disc_2(Fake)=0.439, gen_loss=1.046, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">29, disc_1(Real)=0.018, disc_2(Fake)=0.433, gen_loss=1.057, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">30, disc_1(Real)=0.014, disc_2(Fake)=0.427, gen_loss=1.068, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">31, disc_1(Real)=0.024, disc_2(Fake)=0.421, gen_loss=1.079, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">32, disc_1(Real)=0.034, disc_2(Fake)=0.415, gen_loss=1.090, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">33, disc_1(Real)=0.043, disc_2(Fake)=0.409, gen_loss=1.102, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">34, disc_1(Real)=0.011, disc_2(Fake)=0.404, gen_loss=1.114, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">35, disc_1(Real)=0.036, disc_2(Fake)=0.397, gen_loss=1.126, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">36, disc_1(Real)=0.019, disc_2(Fake)=0.391, gen_loss=1.140, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">37, disc_1(Real)=0.053, disc_2(Fake)=0.385, gen_loss=1.154, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">38, disc_1(Real)=0.028, disc_2(Fake)=0.378, gen_loss=1.168, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">39, disc_1(Real)=0.016, disc_2(Fake)=0.371, gen_loss=1.183, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">40, disc_1(Real)=0.019, disc_2(Fake)=0.365, gen_loss=1.199, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">41, disc_1(Real)=0.010, disc_2(Fake)=0.358, gen_loss=1.214, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">42, disc_1(Real)=0.025, disc_2(Fake)=0.352, gen_loss=1.230, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">43, disc_1(Real)=0.023, disc_2(Fake)=0.346, gen_loss=1.245, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">44, disc_1(Real)=0.018, disc_2(Fake)=0.340, gen_loss=1.260, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">45, disc_1(Real)=0.025, disc_2(Fake)=0.334, gen_loss=1.274, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">46, disc_1(Real)=0.018, disc_2(Fake)=0.330, gen_loss=1.287, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">47, disc_1(Real)=0.012, disc_2(Fake)=0.329, gen_loss=1.293, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">48, disc_1(Real)=0.014, disc_2(Fake)=0.345, gen_loss=1.261, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">49, disc_1(Real)=0.011, disc_2(Fake)=0.439, gen_loss=1.134, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">50, disc_1(Real)=0.015, disc_2(Fake)=0.795, gen_loss=0.781, disc_1(Real)_a=100, disc_2(Fake)_a=28\n",
            ">51, disc_1(Real)=0.021, disc_2(Fake)=1.489, gen_loss=0.392, disc_1(Real)_a=100, disc_2(Fake)_a=0\n",
            ">52, disc_1(Real)=0.028, disc_2(Fake)=2.081, gen_loss=0.268, disc_1(Real)_a=100, disc_2(Fake)_a=0\n",
            ">53, disc_1(Real)=0.042, disc_2(Fake)=2.209, gen_loss=0.263, disc_1(Real)_a=100, disc_2(Fake)_a=0\n",
            ">54, disc_1(Real)=0.094, disc_2(Fake)=1.807, gen_loss=0.324, disc_1(Real)_a=100, disc_2(Fake)_a=0\n",
            ">55, disc_1(Real)=0.149, disc_2(Fake)=1.480, gen_loss=0.423, disc_1(Real)_a=100, disc_2(Fake)_a=0\n",
            ">56, disc_1(Real)=0.239, disc_2(Fake)=1.166, gen_loss=0.549, disc_1(Real)_a=100, disc_2(Fake)_a=0\n",
            ">57, disc_1(Real)=0.266, disc_2(Fake)=0.905, gen_loss=0.739, disc_1(Real)_a=100, disc_2(Fake)_a=0\n",
            ">58, disc_1(Real)=0.352, disc_2(Fake)=0.651, gen_loss=1.059, disc_1(Real)_a=90, disc_2(Fake)_a=84\n",
            ">59, disc_1(Real)=0.403, disc_2(Fake)=0.395, gen_loss=1.409, disc_1(Real)_a=75, disc_2(Fake)_a=100\n",
            ">60, disc_1(Real)=0.370, disc_2(Fake)=0.257, gen_loss=1.702, disc_1(Real)_a=84, disc_2(Fake)_a=100\n",
            ">61, disc_1(Real)=0.443, disc_2(Fake)=0.199, gen_loss=1.858, disc_1(Real)_a=79, disc_2(Fake)_a=100\n",
            ">62, disc_1(Real)=0.546, disc_2(Fake)=0.178, gen_loss=1.920, disc_1(Real)_a=67, disc_2(Fake)_a=100\n",
            ">63, disc_1(Real)=0.415, disc_2(Fake)=0.171, gen_loss=1.946, disc_1(Real)_a=81, disc_2(Fake)_a=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">64, disc_1(Real)=0.334, disc_2(Fake)=0.168, gen_loss=1.963, disc_1(Real)_a=81, disc_2(Fake)_a=100\n",
            ">65, disc_1(Real)=0.475, disc_2(Fake)=0.174, gen_loss=1.907, disc_1(Real)_a=76, disc_2(Fake)_a=100\n",
            ">66, disc_1(Real)=0.401, disc_2(Fake)=0.180, gen_loss=1.861, disc_1(Real)_a=79, disc_2(Fake)_a=100\n",
            ">67, disc_1(Real)=0.504, disc_2(Fake)=0.193, gen_loss=1.790, disc_1(Real)_a=70, disc_2(Fake)_a=100\n",
            ">68, disc_1(Real)=0.334, disc_2(Fake)=0.204, gen_loss=1.745, disc_1(Real)_a=79, disc_2(Fake)_a=100\n",
            ">69, disc_1(Real)=0.395, disc_2(Fake)=0.213, gen_loss=1.702, disc_1(Real)_a=79, disc_2(Fake)_a=100\n",
            ">70, disc_1(Real)=0.339, disc_2(Fake)=0.223, gen_loss=1.665, disc_1(Real)_a=82, disc_2(Fake)_a=100\n",
            ">71, disc_1(Real)=0.368, disc_2(Fake)=0.232, gen_loss=1.624, disc_1(Real)_a=82, disc_2(Fake)_a=100\n",
            ">72, disc_1(Real)=0.221, disc_2(Fake)=0.239, gen_loss=1.614, disc_1(Real)_a=89, disc_2(Fake)_a=100\n",
            ">73, disc_1(Real)=0.165, disc_2(Fake)=0.243, gen_loss=1.606, disc_1(Real)_a=95, disc_2(Fake)_a=100\n",
            ">74, disc_1(Real)=0.276, disc_2(Fake)=0.255, gen_loss=1.570, disc_1(Real)_a=87, disc_2(Fake)_a=100\n",
            ">75, disc_1(Real)=0.287, disc_2(Fake)=0.282, gen_loss=1.540, disc_1(Real)_a=85, disc_2(Fake)_a=100\n",
            ">76, disc_1(Real)=0.271, disc_2(Fake)=0.310, gen_loss=1.541, disc_1(Real)_a=87, disc_2(Fake)_a=100\n",
            ">77, disc_1(Real)=0.252, disc_2(Fake)=0.359, gen_loss=1.562, disc_1(Real)_a=85, disc_2(Fake)_a=100\n",
            ">78, disc_1(Real)=0.280, disc_2(Fake)=0.355, gen_loss=1.591, disc_1(Real)_a=82, disc_2(Fake)_a=100\n",
            ">79, disc_1(Real)=0.266, disc_2(Fake)=0.386, gen_loss=1.641, disc_1(Real)_a=84, disc_2(Fake)_a=100\n",
            ">80, disc_1(Real)=0.145, disc_2(Fake)=0.354, gen_loss=1.732, disc_1(Real)_a=96, disc_2(Fake)_a=100\n",
            ">81, disc_1(Real)=0.137, disc_2(Fake)=0.304, gen_loss=1.821, disc_1(Real)_a=96, disc_2(Fake)_a=100\n",
            ">82, disc_1(Real)=0.149, disc_2(Fake)=0.333, gen_loss=1.907, disc_1(Real)_a=95, disc_2(Fake)_a=100\n",
            ">83, disc_1(Real)=0.095, disc_2(Fake)=0.419, gen_loss=1.902, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">84, disc_1(Real)=0.089, disc_2(Fake)=0.732, gen_loss=1.767, disc_1(Real)_a=100, disc_2(Fake)_a=28\n",
            ">85, disc_1(Real)=0.105, disc_2(Fake)=1.080, gen_loss=1.619, disc_1(Real)_a=100, disc_2(Fake)_a=0\n",
            ">86, disc_1(Real)=0.104, disc_2(Fake)=0.931, gen_loss=2.029, disc_1(Real)_a=100, disc_2(Fake)_a=1\n",
            ">87, disc_1(Real)=0.109, disc_2(Fake)=0.212, gen_loss=3.071, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">88, disc_1(Real)=0.160, disc_2(Fake)=0.048, gen_loss=3.699, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">89, disc_1(Real)=0.177, disc_2(Fake)=0.031, gen_loss=3.852, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">90, disc_1(Real)=0.184, disc_2(Fake)=0.033, gen_loss=3.806, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">91, disc_1(Real)=0.163, disc_2(Fake)=0.038, gen_loss=3.786, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">92, disc_1(Real)=0.123, disc_2(Fake)=0.027, gen_loss=4.126, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">93, disc_1(Real)=0.161, disc_2(Fake)=0.022, gen_loss=4.213, disc_1(Real)_a=95, disc_2(Fake)_a=100\n",
            ">94, disc_1(Real)=0.127, disc_2(Fake)=0.019, gen_loss=4.279, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">95, disc_1(Real)=0.167, disc_2(Fake)=0.024, gen_loss=3.988, disc_1(Real)_a=96, disc_2(Fake)_a=100\n",
            ">96, disc_1(Real)=0.151, disc_2(Fake)=0.029, gen_loss=4.029, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">97, disc_1(Real)=0.100, disc_2(Fake)=0.018, gen_loss=4.439, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">98, disc_1(Real)=0.105, disc_2(Fake)=0.015, gen_loss=4.502, disc_1(Real)_a=96, disc_2(Fake)_a=100\n",
            ">99, disc_1(Real)=0.095, disc_2(Fake)=0.013, gen_loss=4.590, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">100, disc_1(Real)=0.108, disc_2(Fake)=0.014, gen_loss=4.494, disc_1(Real)_a=96, disc_2(Fake)_a=100\n",
            ">101, disc_1(Real)=0.112, disc_2(Fake)=0.015, gen_loss=4.447, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">102, disc_1(Real)=0.136, disc_2(Fake)=0.020, gen_loss=4.192, disc_1(Real)_a=95, disc_2(Fake)_a=100\n",
            ">103, disc_1(Real)=0.064, disc_2(Fake)=0.017, gen_loss=4.470, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">104, disc_1(Real)=0.091, disc_2(Fake)=0.013, gen_loss=4.643, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">105, disc_1(Real)=0.129, disc_2(Fake)=0.015, gen_loss=4.391, disc_1(Real)_a=96, disc_2(Fake)_a=100\n",
            ">106, disc_1(Real)=0.072, disc_2(Fake)=0.014, gen_loss=4.570, disc_1(Real)_a=96, disc_2(Fake)_a=100\n",
            ">107, disc_1(Real)=0.085, disc_2(Fake)=0.011, gen_loss=4.733, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">108, disc_1(Real)=0.063, disc_2(Fake)=0.011, gen_loss=4.694, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">109, disc_1(Real)=0.081, disc_2(Fake)=0.011, gen_loss=4.684, disc_1(Real)_a=96, disc_2(Fake)_a=100\n",
            ">110, disc_1(Real)=0.052, disc_2(Fake)=0.010, gen_loss=4.791, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">111, disc_1(Real)=0.065, disc_2(Fake)=0.012, gen_loss=4.609, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">112, disc_1(Real)=0.060, disc_2(Fake)=0.013, gen_loss=4.611, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">113, disc_1(Real)=0.052, disc_2(Fake)=0.011, gen_loss=4.809, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">114, disc_1(Real)=0.065, disc_2(Fake)=0.011, gen_loss=4.711, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">115, disc_1(Real)=0.059, disc_2(Fake)=0.013, gen_loss=4.567, disc_1(Real)_a=96, disc_2(Fake)_a=100\n",
            ">116, disc_1(Real)=0.083, disc_2(Fake)=0.020, gen_loss=4.282, disc_1(Real)_a=96, disc_2(Fake)_a=100\n",
            ">117, disc_1(Real)=0.031, disc_2(Fake)=0.014, gen_loss=4.696, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">118, disc_1(Real)=0.050, disc_2(Fake)=0.010, gen_loss=4.838, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">119, disc_1(Real)=0.101, disc_2(Fake)=0.012, gen_loss=4.562, disc_1(Real)_a=96, disc_2(Fake)_a=100\n",
            ">120, disc_1(Real)=0.029, disc_2(Fake)=0.011, gen_loss=4.800, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">121, disc_1(Real)=0.104, disc_2(Fake)=0.012, gen_loss=4.603, disc_1(Real)_a=95, disc_2(Fake)_a=100\n",
            ">122, disc_1(Real)=0.060, disc_2(Fake)=0.013, gen_loss=4.660, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">123, disc_1(Real)=0.047, disc_2(Fake)=0.011, gen_loss=4.736, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">124, disc_1(Real)=0.036, disc_2(Fake)=0.009, gen_loss=4.944, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">125, disc_1(Real)=0.025, disc_2(Fake)=0.007, gen_loss=5.184, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">126, disc_1(Real)=0.015, disc_2(Fake)=0.005, gen_loss=5.417, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">127, disc_1(Real)=0.030, disc_2(Fake)=0.005, gen_loss=5.459, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">128, disc_1(Real)=0.045, disc_2(Fake)=0.005, gen_loss=5.357, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">129, disc_1(Real)=0.037, disc_2(Fake)=0.006, gen_loss=5.246, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">130, disc_1(Real)=0.020, disc_2(Fake)=0.006, gen_loss=5.336, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">131, disc_1(Real)=0.068, disc_2(Fake)=0.009, gen_loss=4.836, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">132, disc_1(Real)=0.032, disc_2(Fake)=0.009, gen_loss=4.962, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">133, disc_1(Real)=0.095, disc_2(Fake)=0.022, gen_loss=4.219, disc_1(Real)_a=93, disc_2(Fake)_a=100\n",
            ">134, disc_1(Real)=0.034, disc_2(Fake)=0.017, gen_loss=4.595, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">135, disc_1(Real)=0.062, disc_2(Fake)=0.014, gen_loss=4.557, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">136, disc_1(Real)=0.064, disc_2(Fake)=0.019, gen_loss=4.405, disc_1(Real)_a=96, disc_2(Fake)_a=100\n",
            ">137, disc_1(Real)=0.009, disc_2(Fake)=0.011, gen_loss=4.994, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">138, disc_1(Real)=0.010, disc_2(Fake)=0.006, gen_loss=5.428, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">139, disc_1(Real)=0.063, disc_2(Fake)=0.006, gen_loss=5.121, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">140, disc_1(Real)=0.032, disc_2(Fake)=0.007, gen_loss=5.072, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">141, disc_1(Real)=0.024, disc_2(Fake)=0.007, gen_loss=5.096, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">142, disc_1(Real)=0.029, disc_2(Fake)=0.007, gen_loss=5.172, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">143, disc_1(Real)=0.047, disc_2(Fake)=0.008, gen_loss=4.916, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">144, disc_1(Real)=0.039, disc_2(Fake)=0.008, gen_loss=5.069, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">145, disc_1(Real)=0.028, disc_2(Fake)=0.008, gen_loss=4.961, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">146, disc_1(Real)=0.015, disc_2(Fake)=0.007, gen_loss=5.218, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">147, disc_1(Real)=0.047, disc_2(Fake)=0.006, gen_loss=5.293, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">148, disc_1(Real)=0.038, disc_2(Fake)=0.008, gen_loss=5.023, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">149, disc_1(Real)=0.029, disc_2(Fake)=0.010, gen_loss=4.924, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">150, disc_1(Real)=0.025, disc_2(Fake)=0.008, gen_loss=5.109, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">151, disc_1(Real)=0.019, disc_2(Fake)=0.006, gen_loss=5.285, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">152, disc_1(Real)=0.012, disc_2(Fake)=0.005, gen_loss=5.517, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">153, disc_1(Real)=0.018, disc_2(Fake)=0.004, gen_loss=5.568, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">154, disc_1(Real)=0.009, disc_2(Fake)=0.004, gen_loss=5.723, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">155, disc_1(Real)=0.017, disc_2(Fake)=0.004, gen_loss=5.712, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">156, disc_1(Real)=0.014, disc_2(Fake)=0.004, gen_loss=5.721, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">157, disc_1(Real)=0.032, disc_2(Fake)=0.004, gen_loss=5.457, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">158, disc_1(Real)=0.016, disc_2(Fake)=0.005, gen_loss=5.379, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">159, disc_1(Real)=0.011, disc_2(Fake)=0.005, gen_loss=5.553, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">160, disc_1(Real)=0.004, disc_2(Fake)=0.004, gen_loss=5.789, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">161, disc_1(Real)=0.037, disc_2(Fake)=0.005, gen_loss=5.354, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">162, disc_1(Real)=0.014, disc_2(Fake)=0.006, gen_loss=5.402, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">163, disc_1(Real)=0.013, disc_2(Fake)=0.005, gen_loss=5.564, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">164, disc_1(Real)=0.057, disc_2(Fake)=0.007, gen_loss=5.112, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">165, disc_1(Real)=0.009, disc_2(Fake)=0.006, gen_loss=5.330, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">166, disc_1(Real)=0.008, disc_2(Fake)=0.005, gen_loss=5.589, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">167, disc_1(Real)=0.008, disc_2(Fake)=0.004, gen_loss=5.792, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">168, disc_1(Real)=0.014, disc_2(Fake)=0.003, gen_loss=5.769, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">169, disc_1(Real)=0.023, disc_2(Fake)=0.004, gen_loss=5.607, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">170, disc_1(Real)=0.042, disc_2(Fake)=0.006, gen_loss=5.248, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">171, disc_1(Real)=0.049, disc_2(Fake)=0.011, gen_loss=4.833, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">172, disc_1(Real)=0.008, disc_2(Fake)=0.007, gen_loss=5.338, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">173, disc_1(Real)=0.006, disc_2(Fake)=0.004, gen_loss=5.714, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">174, disc_1(Real)=0.005, disc_2(Fake)=0.003, gen_loss=5.957, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">175, disc_1(Real)=0.011, disc_2(Fake)=0.003, gen_loss=6.041, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">176, disc_1(Real)=0.024, disc_2(Fake)=0.003, gen_loss=5.821, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">177, disc_1(Real)=0.023, disc_2(Fake)=0.003, gen_loss=5.833, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">178, disc_1(Real)=0.012, disc_2(Fake)=0.003, gen_loss=5.879, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">179, disc_1(Real)=0.035, disc_2(Fake)=0.004, gen_loss=5.463, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">180, disc_1(Real)=0.009, disc_2(Fake)=0.005, gen_loss=5.561, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">181, disc_1(Real)=0.023, disc_2(Fake)=0.005, gen_loss=5.352, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">182, disc_1(Real)=0.006, disc_2(Fake)=0.005, gen_loss=5.565, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">183, disc_1(Real)=0.012, disc_2(Fake)=0.004, gen_loss=5.790, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">184, disc_1(Real)=0.014, disc_2(Fake)=0.003, gen_loss=5.826, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">185, disc_1(Real)=0.006, disc_2(Fake)=0.003, gen_loss=5.890, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">186, disc_1(Real)=0.003, disc_2(Fake)=0.003, gen_loss=6.051, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">187, disc_1(Real)=0.011, disc_2(Fake)=0.003, gen_loss=6.043, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">188, disc_1(Real)=0.020, disc_2(Fake)=0.003, gen_loss=5.938, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">189, disc_1(Real)=0.005, disc_2(Fake)=0.003, gen_loss=5.998, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">190, disc_1(Real)=0.009, disc_2(Fake)=0.003, gen_loss=6.079, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">191, disc_1(Real)=0.009, disc_2(Fake)=0.002, gen_loss=6.189, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">192, disc_1(Real)=0.027, disc_2(Fake)=0.003, gen_loss=5.835, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">193, disc_1(Real)=0.014, disc_2(Fake)=0.004, gen_loss=5.748, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">194, disc_1(Real)=0.001, disc_2(Fake)=0.003, gen_loss=5.961, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">195, disc_1(Real)=0.015, disc_2(Fake)=0.003, gen_loss=5.843, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">196, disc_1(Real)=0.030, disc_2(Fake)=0.004, gen_loss=5.729, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">197, disc_1(Real)=0.005, disc_2(Fake)=0.003, gen_loss=5.877, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">198, disc_1(Real)=0.012, disc_2(Fake)=0.003, gen_loss=5.975, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">199, disc_1(Real)=0.016, disc_2(Fake)=0.003, gen_loss=5.843, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">200, disc_1(Real)=0.008, disc_2(Fake)=0.003, gen_loss=5.807, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">201, disc_1(Real)=0.018, disc_2(Fake)=0.003, gen_loss=5.852, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">202, disc_1(Real)=0.012, disc_2(Fake)=0.003, gen_loss=5.832, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">203, disc_1(Real)=0.008, disc_2(Fake)=0.003, gen_loss=5.918, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">204, disc_1(Real)=0.016, disc_2(Fake)=0.003, gen_loss=5.933, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">205, disc_1(Real)=0.011, disc_2(Fake)=0.003, gen_loss=5.907, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">206, disc_1(Real)=0.021, disc_2(Fake)=0.003, gen_loss=5.847, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">207, disc_1(Real)=0.019, disc_2(Fake)=0.003, gen_loss=5.874, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">208, disc_1(Real)=0.002, disc_2(Fake)=0.003, gen_loss=6.059, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">209, disc_1(Real)=0.030, disc_2(Fake)=0.003, gen_loss=5.868, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">210, disc_1(Real)=0.005, disc_2(Fake)=0.003, gen_loss=5.983, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">211, disc_1(Real)=0.011, disc_2(Fake)=0.003, gen_loss=5.998, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">212, disc_1(Real)=0.013, disc_2(Fake)=0.003, gen_loss=5.884, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">213, disc_1(Real)=0.031, disc_2(Fake)=0.005, gen_loss=5.476, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">214, disc_1(Real)=0.001, disc_2(Fake)=0.004, gen_loss=5.761, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">215, disc_1(Real)=0.004, disc_2(Fake)=0.003, gen_loss=6.011, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">216, disc_1(Real)=0.051, disc_2(Fake)=0.005, gen_loss=5.189, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">217, disc_1(Real)=0.001, disc_2(Fake)=0.006, gen_loss=5.484, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">218, disc_1(Real)=0.005, disc_2(Fake)=0.004, gen_loss=5.825, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">219, disc_1(Real)=0.022, disc_2(Fake)=0.003, gen_loss=5.984, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">220, disc_1(Real)=0.013, disc_2(Fake)=0.003, gen_loss=5.863, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">221, disc_1(Real)=0.004, disc_2(Fake)=0.003, gen_loss=6.006, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">222, disc_1(Real)=0.017, disc_2(Fake)=0.003, gen_loss=5.997, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">223, disc_1(Real)=0.006, disc_2(Fake)=0.003, gen_loss=6.073, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">224, disc_1(Real)=0.005, disc_2(Fake)=0.002, gen_loss=6.201, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">225, disc_1(Real)=0.021, disc_2(Fake)=0.002, gen_loss=6.042, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">226, disc_1(Real)=0.012, disc_2(Fake)=0.003, gen_loss=5.830, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">227, disc_1(Real)=0.004, disc_2(Fake)=0.003, gen_loss=5.979, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">228, disc_1(Real)=0.011, disc_2(Fake)=0.003, gen_loss=5.888, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">229, disc_1(Real)=0.007, disc_2(Fake)=0.003, gen_loss=5.928, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">230, disc_1(Real)=0.019, disc_2(Fake)=0.003, gen_loss=5.839, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">231, disc_1(Real)=0.068, disc_2(Fake)=0.006, gen_loss=5.306, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">232, disc_1(Real)=0.026, disc_2(Fake)=0.009, gen_loss=5.156, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">233, disc_1(Real)=0.010, disc_2(Fake)=0.005, gen_loss=5.574, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">234, disc_1(Real)=0.003, disc_2(Fake)=0.003, gen_loss=5.950, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">235, disc_1(Real)=0.002, disc_2(Fake)=0.002, gen_loss=6.220, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">236, disc_1(Real)=0.018, disc_2(Fake)=0.003, gen_loss=5.964, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">237, disc_1(Real)=0.025, disc_2(Fake)=0.004, gen_loss=5.566, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">238, disc_1(Real)=0.002, disc_2(Fake)=0.004, gen_loss=5.763, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">239, disc_1(Real)=0.002, disc_2(Fake)=0.003, gen_loss=6.049, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">240, disc_1(Real)=0.008, disc_2(Fake)=0.002, gen_loss=6.210, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">241, disc_1(Real)=0.017, disc_2(Fake)=0.003, gen_loss=5.935, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">242, disc_1(Real)=0.026, disc_2(Fake)=0.005, gen_loss=5.291, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">243, disc_1(Real)=0.001, disc_2(Fake)=0.005, gen_loss=5.666, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">244, disc_1(Real)=0.001, disc_2(Fake)=0.003, gen_loss=6.035, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">245, disc_1(Real)=0.023, disc_2(Fake)=0.004, gen_loss=5.536, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">246, disc_1(Real)=0.012, disc_2(Fake)=0.005, gen_loss=5.533, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">247, disc_1(Real)=0.005, disc_2(Fake)=0.004, gen_loss=5.767, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">248, disc_1(Real)=0.090, disc_2(Fake)=0.007, gen_loss=5.065, disc_1(Real)_a=96, disc_2(Fake)_a=100\n",
            ">249, disc_1(Real)=0.005, disc_2(Fake)=0.007, gen_loss=5.351, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">250, disc_1(Real)=0.003, disc_2(Fake)=0.004, gen_loss=5.777, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">251, disc_1(Real)=0.006, disc_2(Fake)=0.003, gen_loss=6.009, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">252, disc_1(Real)=0.035, disc_2(Fake)=0.003, gen_loss=5.715, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">253, disc_1(Real)=0.040, disc_2(Fake)=0.009, gen_loss=4.954, disc_1(Real)_a=96, disc_2(Fake)_a=100\n",
            ">254, disc_1(Real)=0.001, disc_2(Fake)=0.007, gen_loss=5.447, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">255, disc_1(Real)=0.001, disc_2(Fake)=0.004, gen_loss=5.926, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">256, disc_1(Real)=0.001, disc_2(Fake)=0.002, gen_loss=6.236, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">257, disc_1(Real)=0.001, disc_2(Fake)=0.002, gen_loss=6.440, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">258, disc_1(Real)=0.002, disc_2(Fake)=0.002, gen_loss=6.586, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">259, disc_1(Real)=0.008, disc_2(Fake)=0.002, gen_loss=6.525, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">260, disc_1(Real)=0.004, disc_2(Fake)=0.002, gen_loss=6.469, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">261, disc_1(Real)=0.011, disc_2(Fake)=0.002, gen_loss=6.323, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">262, disc_1(Real)=0.006, disc_2(Fake)=0.002, gen_loss=6.312, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">263, disc_1(Real)=0.036, disc_2(Fake)=0.004, gen_loss=5.507, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">264, disc_1(Real)=0.019, disc_2(Fake)=0.007, gen_loss=5.367, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">265, disc_1(Real)=0.008, disc_2(Fake)=0.005, gen_loss=5.550, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">266, disc_1(Real)=0.012, disc_2(Fake)=0.004, gen_loss=5.788, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">267, disc_1(Real)=0.003, disc_2(Fake)=0.003, gen_loss=6.075, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">268, disc_1(Real)=0.025, disc_2(Fake)=0.003, gen_loss=5.759, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">269, disc_1(Real)=0.001, disc_2(Fake)=0.003, gen_loss=5.936, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">270, disc_1(Real)=0.003, disc_2(Fake)=0.003, gen_loss=6.132, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">271, disc_1(Real)=0.036, disc_2(Fake)=0.004, gen_loss=5.599, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">272, disc_1(Real)=0.003, disc_2(Fake)=0.004, gen_loss=5.781, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">273, disc_1(Real)=0.010, disc_2(Fake)=0.003, gen_loss=5.839, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">274, disc_1(Real)=0.003, disc_2(Fake)=0.003, gen_loss=6.058, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">275, disc_1(Real)=0.001, disc_2(Fake)=0.002, gen_loss=6.285, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">276, disc_1(Real)=0.001, disc_2(Fake)=0.002, gen_loss=6.484, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">277, disc_1(Real)=0.020, disc_2(Fake)=0.002, gen_loss=6.047, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">278, disc_1(Real)=0.012, disc_2(Fake)=0.003, gen_loss=5.816, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">279, disc_1(Real)=0.005, disc_2(Fake)=0.003, gen_loss=6.057, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">280, disc_1(Real)=0.003, disc_2(Fake)=0.002, gen_loss=6.292, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">281, disc_1(Real)=0.005, disc_2(Fake)=0.002, gen_loss=6.412, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">282, disc_1(Real)=0.009, disc_2(Fake)=0.002, gen_loss=6.386, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">283, disc_1(Real)=0.001, disc_2(Fake)=0.002, gen_loss=6.507, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">284, disc_1(Real)=0.002, disc_2(Fake)=0.001, gen_loss=6.617, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">285, disc_1(Real)=0.035, disc_2(Fake)=0.002, gen_loss=6.003, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">286, disc_1(Real)=0.005, disc_2(Fake)=0.003, gen_loss=5.886, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">287, disc_1(Real)=0.001, disc_2(Fake)=0.003, gen_loss=6.168, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">288, disc_1(Real)=0.001, disc_2(Fake)=0.002, gen_loss=6.421, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">289, disc_1(Real)=0.003, disc_2(Fake)=0.002, gen_loss=6.508, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">290, disc_1(Real)=0.002, disc_2(Fake)=0.002, gen_loss=6.555, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">291, disc_1(Real)=0.002, disc_2(Fake)=0.001, gen_loss=6.646, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">292, disc_1(Real)=0.004, disc_2(Fake)=0.001, gen_loss=6.723, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">293, disc_1(Real)=0.001, disc_2(Fake)=0.001, gen_loss=6.835, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">294, disc_1(Real)=0.002, disc_2(Fake)=0.001, gen_loss=6.923, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">295, disc_1(Real)=0.023, disc_2(Fake)=0.002, gen_loss=6.296, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">296, disc_1(Real)=0.016, disc_2(Fake)=0.004, gen_loss=5.676, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">297, disc_1(Real)=0.003, disc_2(Fake)=0.003, gen_loss=6.062, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">298, disc_1(Real)=0.007, disc_2(Fake)=0.003, gen_loss=6.169, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">299, disc_1(Real)=0.010, disc_2(Fake)=0.002, gen_loss=6.289, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">300, disc_1(Real)=0.004, disc_2(Fake)=0.002, gen_loss=6.396, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">301, disc_1(Real)=0.002, disc_2(Fake)=0.002, gen_loss=6.518, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">302, disc_1(Real)=0.001, disc_2(Fake)=0.001, gen_loss=6.667, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">303, disc_1(Real)=0.054, disc_2(Fake)=0.004, gen_loss=5.230, disc_1(Real)_a=95, disc_2(Fake)_a=100\n",
            ">304, disc_1(Real)=0.008, disc_2(Fake)=0.009, gen_loss=5.509, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">305, disc_1(Real)=0.012, disc_2(Fake)=0.005, gen_loss=5.761, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">306, disc_1(Real)=0.004, disc_2(Fake)=0.003, gen_loss=6.060, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">307, disc_1(Real)=0.004, disc_2(Fake)=0.002, gen_loss=6.240, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">308, disc_1(Real)=0.000, disc_2(Fake)=0.002, gen_loss=6.465, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">309, disc_1(Real)=0.022, disc_2(Fake)=0.002, gen_loss=5.949, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">310, disc_1(Real)=0.001, disc_2(Fake)=0.003, gen_loss=6.081, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">311, disc_1(Real)=0.003, disc_2(Fake)=0.002, gen_loss=6.239, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">312, disc_1(Real)=0.003, disc_2(Fake)=0.002, gen_loss=6.427, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">313, disc_1(Real)=0.002, disc_2(Fake)=0.002, gen_loss=6.597, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">314, disc_1(Real)=0.006, disc_2(Fake)=0.001, gen_loss=6.622, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">315, disc_1(Real)=0.002, disc_2(Fake)=0.001, gen_loss=6.655, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">316, disc_1(Real)=0.005, disc_2(Fake)=0.001, gen_loss=6.671, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">317, disc_1(Real)=0.030, disc_2(Fake)=0.003, gen_loss=5.640, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">318, disc_1(Real)=0.001, disc_2(Fake)=0.004, gen_loss=5.933, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">319, disc_1(Real)=0.001, disc_2(Fake)=0.002, gen_loss=6.302, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">320, disc_1(Real)=0.001, disc_2(Fake)=0.002, gen_loss=6.540, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">321, disc_1(Real)=0.002, disc_2(Fake)=0.001, gen_loss=6.698, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">322, disc_1(Real)=0.043, disc_2(Fake)=0.003, gen_loss=5.583, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">323, disc_1(Real)=0.001, disc_2(Fake)=0.004, gen_loss=5.839, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">324, disc_1(Real)=0.006, disc_2(Fake)=0.003, gen_loss=6.064, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">325, disc_1(Real)=0.001, disc_2(Fake)=0.002, gen_loss=6.307, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">326, disc_1(Real)=0.003, disc_2(Fake)=0.002, gen_loss=6.449, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">327, disc_1(Real)=0.000, disc_2(Fake)=0.001, gen_loss=6.643, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">328, disc_1(Real)=0.011, disc_2(Fake)=0.001, gen_loss=6.622, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">329, disc_1(Real)=0.014, disc_2(Fake)=0.002, gen_loss=6.213, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">330, disc_1(Real)=0.001, disc_2(Fake)=0.002, gen_loss=6.341, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">331, disc_1(Real)=0.000, disc_2(Fake)=0.002, gen_loss=6.541, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">332, disc_1(Real)=0.007, disc_2(Fake)=0.002, gen_loss=6.438, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">333, disc_1(Real)=0.005, disc_2(Fake)=0.002, gen_loss=6.508, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">334, disc_1(Real)=0.001, disc_2(Fake)=0.002, gen_loss=6.708, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">335, disc_1(Real)=0.004, disc_2(Fake)=0.002, gen_loss=6.764, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">336, disc_1(Real)=0.005, disc_2(Fake)=0.001, gen_loss=6.805, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">337, disc_1(Real)=0.001, disc_2(Fake)=0.001, gen_loss=6.904, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">338, disc_1(Real)=0.001, disc_2(Fake)=0.001, gen_loss=7.010, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">339, disc_1(Real)=0.002, disc_2(Fake)=0.001, gen_loss=6.965, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">340, disc_1(Real)=0.006, disc_2(Fake)=0.002, gen_loss=6.785, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">341, disc_1(Real)=0.001, disc_2(Fake)=0.001, gen_loss=6.903, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">342, disc_1(Real)=0.003, disc_2(Fake)=0.006, gen_loss=7.073, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">343, disc_1(Real)=0.000, disc_2(Fake)=0.002, gen_loss=7.370, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">344, disc_1(Real)=0.002, disc_2(Fake)=0.002, gen_loss=7.315, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">345, disc_1(Real)=0.004, disc_2(Fake)=0.005, gen_loss=7.325, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">346, disc_1(Real)=0.000, disc_2(Fake)=0.023, gen_loss=8.129, disc_1(Real)_a=100, disc_2(Fake)_a=98\n",
            ">347, disc_1(Real)=0.003, disc_2(Fake)=0.005, gen_loss=8.536, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">348, disc_1(Real)=0.033, disc_2(Fake)=0.050, gen_loss=8.819, disc_1(Real)_a=98, disc_2(Fake)_a=98\n",
            ">349, disc_1(Real)=0.001, disc_2(Fake)=0.001, gen_loss=8.746, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">350, disc_1(Real)=0.001, disc_2(Fake)=0.043, gen_loss=9.228, disc_1(Real)_a=100, disc_2(Fake)_a=98\n",
            ">351, disc_1(Real)=0.012, disc_2(Fake)=0.068, gen_loss=9.112, disc_1(Real)_a=100, disc_2(Fake)_a=95\n",
            ">352, disc_1(Real)=0.046, disc_2(Fake)=2.719, gen_loss=11.302, disc_1(Real)_a=98, disc_2(Fake)_a=1\n",
            ">353, disc_1(Real)=0.077, disc_2(Fake)=0.032, gen_loss=10.460, disc_1(Real)_a=96, disc_2(Fake)_a=100\n",
            ">354, disc_1(Real)=0.535, disc_2(Fake)=3.037, gen_loss=6.305, disc_1(Real)_a=89, disc_2(Fake)_a=1\n",
            ">355, disc_1(Real)=1.305, disc_2(Fake)=1.228, gen_loss=6.819, disc_1(Real)_a=84, disc_2(Fake)_a=28\n",
            ">356, disc_1(Real)=1.496, disc_2(Fake)=0.007, gen_loss=9.384, disc_1(Real)_a=65, disc_2(Fake)_a=100\n",
            ">357, disc_1(Real)=1.551, disc_2(Fake)=0.009, gen_loss=8.237, disc_1(Real)_a=68, disc_2(Fake)_a=100\n",
            ">358, disc_1(Real)=0.598, disc_2(Fake)=0.035, gen_loss=7.512, disc_1(Real)_a=82, disc_2(Fake)_a=100\n",
            ">359, disc_1(Real)=0.835, disc_2(Fake)=0.117, gen_loss=5.940, disc_1(Real)_a=79, disc_2(Fake)_a=95\n",
            ">360, disc_1(Real)=0.677, disc_2(Fake)=0.778, gen_loss=4.407, disc_1(Real)_a=81, disc_2(Fake)_a=59\n",
            ">361, disc_1(Real)=0.750, disc_2(Fake)=3.370, gen_loss=1.505, disc_1(Real)_a=81, disc_2(Fake)_a=26\n",
            ">362, disc_1(Real)=0.969, disc_2(Fake)=8.647, gen_loss=0.750, disc_1(Real)_a=73, disc_2(Fake)_a=0\n",
            ">363, disc_1(Real)=1.626, disc_2(Fake)=0.243, gen_loss=4.550, disc_1(Real)_a=43, disc_2(Fake)_a=100\n",
            ">364, disc_1(Real)=2.729, disc_2(Fake)=0.020, gen_loss=4.159, disc_1(Real)_a=1, disc_2(Fake)_a=100\n",
            ">365, disc_1(Real)=2.146, disc_2(Fake)=0.082, gen_loss=2.929, disc_1(Real)_a=15, disc_2(Fake)_a=100\n",
            ">366, disc_1(Real)=1.425, disc_2(Fake)=0.205, gen_loss=2.688, disc_1(Real)_a=23, disc_2(Fake)_a=100\n",
            ">367, disc_1(Real)=1.332, disc_2(Fake)=0.185, gen_loss=2.944, disc_1(Real)_a=32, disc_2(Fake)_a=100\n",
            ">368, disc_1(Real)=1.338, disc_2(Fake)=0.131, gen_loss=3.123, disc_1(Real)_a=42, disc_2(Fake)_a=100\n",
            ">369, disc_1(Real)=1.169, disc_2(Fake)=0.123, gen_loss=2.857, disc_1(Real)_a=37, disc_2(Fake)_a=100\n",
            ">370, disc_1(Real)=1.001, disc_2(Fake)=0.166, gen_loss=2.808, disc_1(Real)_a=56, disc_2(Fake)_a=100\n",
            ">371, disc_1(Real)=1.129, disc_2(Fake)=0.109, gen_loss=2.877, disc_1(Real)_a=48, disc_2(Fake)_a=100\n",
            ">372, disc_1(Real)=0.972, disc_2(Fake)=0.143, gen_loss=2.916, disc_1(Real)_a=57, disc_2(Fake)_a=100\n",
            ">373, disc_1(Real)=0.909, disc_2(Fake)=0.112, gen_loss=2.978, disc_1(Real)_a=57, disc_2(Fake)_a=100\n",
            ">374, disc_1(Real)=1.062, disc_2(Fake)=0.107, gen_loss=2.803, disc_1(Real)_a=45, disc_2(Fake)_a=100\n",
            ">375, disc_1(Real)=0.838, disc_2(Fake)=0.122, gen_loss=2.783, disc_1(Real)_a=56, disc_2(Fake)_a=100\n",
            ">376, disc_1(Real)=0.816, disc_2(Fake)=0.124, gen_loss=2.674, disc_1(Real)_a=57, disc_2(Fake)_a=100\n",
            ">377, disc_1(Real)=0.872, disc_2(Fake)=0.151, gen_loss=2.763, disc_1(Real)_a=62, disc_2(Fake)_a=98\n",
            ">378, disc_1(Real)=0.854, disc_2(Fake)=0.149, gen_loss=2.564, disc_1(Real)_a=57, disc_2(Fake)_a=98\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">379, disc_1(Real)=0.785, disc_2(Fake)=0.172, gen_loss=2.659, disc_1(Real)_a=60, disc_2(Fake)_a=96\n",
            ">380, disc_1(Real)=0.780, disc_2(Fake)=0.127, gen_loss=2.684, disc_1(Real)_a=67, disc_2(Fake)_a=100\n",
            ">381, disc_1(Real)=0.716, disc_2(Fake)=0.137, gen_loss=2.597, disc_1(Real)_a=68, disc_2(Fake)_a=98\n",
            ">382, disc_1(Real)=0.903, disc_2(Fake)=0.134, gen_loss=2.515, disc_1(Real)_a=57, disc_2(Fake)_a=100\n",
            ">383, disc_1(Real)=0.753, disc_2(Fake)=0.201, gen_loss=2.476, disc_1(Real)_a=54, disc_2(Fake)_a=95\n",
            ">384, disc_1(Real)=0.721, disc_2(Fake)=0.310, gen_loss=2.703, disc_1(Real)_a=64, disc_2(Fake)_a=84\n",
            ">385, disc_1(Real)=0.854, disc_2(Fake)=0.178, gen_loss=2.633, disc_1(Real)_a=65, disc_2(Fake)_a=95\n",
            ">386, disc_1(Real)=0.990, disc_2(Fake)=0.266, gen_loss=2.668, disc_1(Real)_a=50, disc_2(Fake)_a=90\n",
            ">387, disc_1(Real)=0.727, disc_2(Fake)=0.193, gen_loss=2.735, disc_1(Real)_a=64, disc_2(Fake)_a=93\n",
            ">388, disc_1(Real)=0.653, disc_2(Fake)=0.263, gen_loss=2.662, disc_1(Real)_a=71, disc_2(Fake)_a=85\n",
            ">389, disc_1(Real)=0.737, disc_2(Fake)=0.258, gen_loss=3.042, disc_1(Real)_a=62, disc_2(Fake)_a=87\n",
            ">390, disc_1(Real)=0.809, disc_2(Fake)=0.313, gen_loss=2.697, disc_1(Real)_a=57, disc_2(Fake)_a=79\n",
            ">391, disc_1(Real)=0.594, disc_2(Fake)=0.229, gen_loss=2.562, disc_1(Real)_a=68, disc_2(Fake)_a=89\n",
            ">392, disc_1(Real)=0.788, disc_2(Fake)=0.380, gen_loss=2.397, disc_1(Real)_a=57, disc_2(Fake)_a=76\n",
            ">393, disc_1(Real)=0.552, disc_2(Fake)=0.334, gen_loss=2.653, disc_1(Real)_a=75, disc_2(Fake)_a=78\n",
            ">394, disc_1(Real)=0.720, disc_2(Fake)=0.413, gen_loss=2.721, disc_1(Real)_a=65, disc_2(Fake)_a=73\n",
            ">395, disc_1(Real)=0.733, disc_2(Fake)=0.398, gen_loss=2.750, disc_1(Real)_a=60, disc_2(Fake)_a=78\n",
            ">396, disc_1(Real)=0.834, disc_2(Fake)=0.268, gen_loss=2.554, disc_1(Real)_a=57, disc_2(Fake)_a=87\n",
            ">397, disc_1(Real)=0.860, disc_2(Fake)=0.415, gen_loss=2.235, disc_1(Real)_a=54, disc_2(Fake)_a=75\n",
            ">398, disc_1(Real)=0.605, disc_2(Fake)=0.329, gen_loss=2.316, disc_1(Real)_a=67, disc_2(Fake)_a=81\n",
            ">399, disc_1(Real)=0.719, disc_2(Fake)=0.538, gen_loss=2.288, disc_1(Real)_a=65, disc_2(Fake)_a=62\n",
            ">400, disc_1(Real)=0.662, disc_2(Fake)=0.415, gen_loss=2.649, disc_1(Real)_a=64, disc_2(Fake)_a=68\n",
            ">401, disc_1(Real)=0.707, disc_2(Fake)=0.485, gen_loss=2.342, disc_1(Real)_a=64, disc_2(Fake)_a=73\n",
            ">402, disc_1(Real)=0.673, disc_2(Fake)=0.421, gen_loss=2.236, disc_1(Real)_a=67, disc_2(Fake)_a=76\n",
            ">403, disc_1(Real)=0.949, disc_2(Fake)=0.507, gen_loss=2.133, disc_1(Real)_a=56, disc_2(Fake)_a=67\n",
            ">404, disc_1(Real)=0.871, disc_2(Fake)=0.458, gen_loss=2.037, disc_1(Real)_a=57, disc_2(Fake)_a=70\n",
            ">405, disc_1(Real)=0.831, disc_2(Fake)=0.379, gen_loss=1.790, disc_1(Real)_a=67, disc_2(Fake)_a=79\n",
            ">406, disc_1(Real)=0.754, disc_2(Fake)=0.465, gen_loss=1.595, disc_1(Real)_a=56, disc_2(Fake)_a=75\n",
            ">407, disc_1(Real)=0.680, disc_2(Fake)=0.484, gen_loss=1.475, disc_1(Real)_a=68, disc_2(Fake)_a=73\n",
            ">408, disc_1(Real)=0.758, disc_2(Fake)=0.537, gen_loss=1.643, disc_1(Real)_a=54, disc_2(Fake)_a=70\n",
            ">409, disc_1(Real)=0.656, disc_2(Fake)=0.570, gen_loss=1.297, disc_1(Real)_a=64, disc_2(Fake)_a=57\n",
            ">410, disc_1(Real)=0.858, disc_2(Fake)=0.461, gen_loss=1.182, disc_1(Real)_a=57, disc_2(Fake)_a=76\n",
            ">411, disc_1(Real)=0.919, disc_2(Fake)=0.566, gen_loss=1.078, disc_1(Real)_a=51, disc_2(Fake)_a=68\n",
            ">412, disc_1(Real)=0.634, disc_2(Fake)=0.546, gen_loss=1.123, disc_1(Real)_a=70, disc_2(Fake)_a=70\n",
            ">413, disc_1(Real)=0.694, disc_2(Fake)=0.616, gen_loss=1.067, disc_1(Real)_a=70, disc_2(Fake)_a=67\n",
            ">414, disc_1(Real)=0.570, disc_2(Fake)=0.644, gen_loss=1.088, disc_1(Real)_a=81, disc_2(Fake)_a=56\n",
            ">415, disc_1(Real)=0.724, disc_2(Fake)=0.577, gen_loss=1.000, disc_1(Real)_a=62, disc_2(Fake)_a=65\n",
            ">416, disc_1(Real)=0.722, disc_2(Fake)=0.596, gen_loss=1.121, disc_1(Real)_a=62, disc_2(Fake)_a=64\n",
            ">417, disc_1(Real)=0.633, disc_2(Fake)=0.567, gen_loss=1.051, disc_1(Real)_a=71, disc_2(Fake)_a=67\n",
            ">418, disc_1(Real)=0.675, disc_2(Fake)=0.641, gen_loss=0.897, disc_1(Real)_a=68, disc_2(Fake)_a=51\n",
            ">419, disc_1(Real)=0.590, disc_2(Fake)=0.597, gen_loss=0.956, disc_1(Real)_a=71, disc_2(Fake)_a=67\n",
            ">420, disc_1(Real)=0.504, disc_2(Fake)=0.540, gen_loss=0.988, disc_1(Real)_a=84, disc_2(Fake)_a=78\n",
            ">421, disc_1(Real)=0.535, disc_2(Fake)=0.582, gen_loss=0.975, disc_1(Real)_a=81, disc_2(Fake)_a=70\n",
            ">422, disc_1(Real)=0.638, disc_2(Fake)=0.617, gen_loss=0.989, disc_1(Real)_a=65, disc_2(Fake)_a=68\n",
            ">423, disc_1(Real)=0.668, disc_2(Fake)=0.602, gen_loss=0.890, disc_1(Real)_a=65, disc_2(Fake)_a=68\n",
            ">424, disc_1(Real)=0.602, disc_2(Fake)=0.569, gen_loss=0.889, disc_1(Real)_a=71, disc_2(Fake)_a=76\n",
            ">425, disc_1(Real)=0.659, disc_2(Fake)=0.618, gen_loss=0.918, disc_1(Real)_a=70, disc_2(Fake)_a=68\n",
            ">426, disc_1(Real)=0.566, disc_2(Fake)=0.662, gen_loss=0.910, disc_1(Real)_a=67, disc_2(Fake)_a=56\n",
            ">427, disc_1(Real)=0.666, disc_2(Fake)=0.583, gen_loss=0.933, disc_1(Real)_a=67, disc_2(Fake)_a=81\n",
            ">428, disc_1(Real)=0.626, disc_2(Fake)=0.556, gen_loss=0.938, disc_1(Real)_a=65, disc_2(Fake)_a=81\n",
            ">429, disc_1(Real)=0.570, disc_2(Fake)=0.600, gen_loss=0.941, disc_1(Real)_a=73, disc_2(Fake)_a=71\n",
            ">430, disc_1(Real)=0.601, disc_2(Fake)=0.589, gen_loss=0.943, disc_1(Real)_a=71, disc_2(Fake)_a=76\n",
            ">431, disc_1(Real)=0.643, disc_2(Fake)=0.554, gen_loss=0.966, disc_1(Real)_a=70, disc_2(Fake)_a=84\n",
            ">432, disc_1(Real)=0.662, disc_2(Fake)=0.544, gen_loss=0.964, disc_1(Real)_a=67, disc_2(Fake)_a=93\n",
            ">433, disc_1(Real)=0.667, disc_2(Fake)=0.537, gen_loss=0.946, disc_1(Real)_a=62, disc_2(Fake)_a=90\n",
            ">434, disc_1(Real)=0.584, disc_2(Fake)=0.557, gen_loss=0.955, disc_1(Real)_a=70, disc_2(Fake)_a=87\n",
            ">435, disc_1(Real)=0.586, disc_2(Fake)=0.528, gen_loss=0.977, disc_1(Real)_a=73, disc_2(Fake)_a=92\n",
            ">436, disc_1(Real)=0.575, disc_2(Fake)=0.518, gen_loss=1.009, disc_1(Real)_a=70, disc_2(Fake)_a=95\n",
            ">437, disc_1(Real)=0.606, disc_2(Fake)=0.491, gen_loss=1.000, disc_1(Real)_a=65, disc_2(Fake)_a=100\n",
            ">438, disc_1(Real)=0.603, disc_2(Fake)=0.495, gen_loss=1.004, disc_1(Real)_a=68, disc_2(Fake)_a=100\n",
            ">439, disc_1(Real)=0.528, disc_2(Fake)=0.478, gen_loss=1.075, disc_1(Real)_a=87, disc_2(Fake)_a=98\n",
            ">440, disc_1(Real)=0.557, disc_2(Fake)=0.472, gen_loss=1.087, disc_1(Real)_a=75, disc_2(Fake)_a=100\n",
            ">441, disc_1(Real)=0.620, disc_2(Fake)=0.449, gen_loss=1.103, disc_1(Real)_a=68, disc_2(Fake)_a=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">442, disc_1(Real)=0.561, disc_2(Fake)=0.445, gen_loss=1.125, disc_1(Real)_a=75, disc_2(Fake)_a=100\n",
            ">443, disc_1(Real)=0.535, disc_2(Fake)=0.430, gen_loss=1.198, disc_1(Real)_a=82, disc_2(Fake)_a=100\n",
            ">444, disc_1(Real)=0.594, disc_2(Fake)=0.404, gen_loss=1.198, disc_1(Real)_a=65, disc_2(Fake)_a=100\n",
            ">445, disc_1(Real)=0.578, disc_2(Fake)=0.404, gen_loss=1.229, disc_1(Real)_a=75, disc_2(Fake)_a=100\n",
            ">446, disc_1(Real)=0.572, disc_2(Fake)=0.364, gen_loss=1.283, disc_1(Real)_a=71, disc_2(Fake)_a=100\n",
            ">447, disc_1(Real)=0.632, disc_2(Fake)=0.377, gen_loss=1.266, disc_1(Real)_a=60, disc_2(Fake)_a=100\n",
            ">448, disc_1(Real)=0.526, disc_2(Fake)=0.355, gen_loss=1.313, disc_1(Real)_a=84, disc_2(Fake)_a=100\n",
            ">449, disc_1(Real)=0.600, disc_2(Fake)=0.363, gen_loss=1.302, disc_1(Real)_a=68, disc_2(Fake)_a=100\n",
            ">450, disc_1(Real)=0.557, disc_2(Fake)=0.357, gen_loss=1.310, disc_1(Real)_a=78, disc_2(Fake)_a=100\n",
            ">451, disc_1(Real)=0.592, disc_2(Fake)=0.349, gen_loss=1.334, disc_1(Real)_a=73, disc_2(Fake)_a=100\n",
            ">452, disc_1(Real)=0.504, disc_2(Fake)=0.361, gen_loss=1.369, disc_1(Real)_a=87, disc_2(Fake)_a=100\n",
            ">453, disc_1(Real)=0.479, disc_2(Fake)=0.316, gen_loss=1.384, disc_1(Real)_a=85, disc_2(Fake)_a=100\n",
            ">454, disc_1(Real)=0.505, disc_2(Fake)=0.322, gen_loss=1.391, disc_1(Real)_a=90, disc_2(Fake)_a=100\n",
            ">455, disc_1(Real)=0.516, disc_2(Fake)=0.333, gen_loss=1.363, disc_1(Real)_a=85, disc_2(Fake)_a=100\n",
            ">456, disc_1(Real)=0.525, disc_2(Fake)=0.336, gen_loss=1.433, disc_1(Real)_a=81, disc_2(Fake)_a=100\n",
            ">457, disc_1(Real)=0.463, disc_2(Fake)=0.316, gen_loss=1.455, disc_1(Real)_a=90, disc_2(Fake)_a=100\n",
            ">458, disc_1(Real)=0.460, disc_2(Fake)=0.309, gen_loss=1.487, disc_1(Real)_a=90, disc_2(Fake)_a=100\n",
            ">459, disc_1(Real)=0.467, disc_2(Fake)=0.325, gen_loss=1.542, disc_1(Real)_a=87, disc_2(Fake)_a=98\n",
            ">460, disc_1(Real)=0.508, disc_2(Fake)=0.289, gen_loss=1.533, disc_1(Real)_a=84, disc_2(Fake)_a=100\n",
            ">461, disc_1(Real)=0.460, disc_2(Fake)=0.281, gen_loss=1.584, disc_1(Real)_a=89, disc_2(Fake)_a=100\n",
            ">462, disc_1(Real)=0.466, disc_2(Fake)=0.298, gen_loss=1.554, disc_1(Real)_a=90, disc_2(Fake)_a=100\n",
            ">463, disc_1(Real)=0.482, disc_2(Fake)=0.276, gen_loss=1.446, disc_1(Real)_a=85, disc_2(Fake)_a=100\n",
            ">464, disc_1(Real)=0.465, disc_2(Fake)=0.434, gen_loss=1.303, disc_1(Real)_a=82, disc_2(Fake)_a=92\n",
            ">465, disc_1(Real)=0.441, disc_2(Fake)=0.403, gen_loss=1.228, disc_1(Real)_a=90, disc_2(Fake)_a=92\n",
            ">466, disc_1(Real)=0.434, disc_2(Fake)=0.437, gen_loss=1.059, disc_1(Real)_a=93, disc_2(Fake)_a=90\n",
            ">467, disc_1(Real)=0.411, disc_2(Fake)=0.514, gen_loss=0.973, disc_1(Real)_a=93, disc_2(Fake)_a=85\n",
            ">468, disc_1(Real)=0.383, disc_2(Fake)=0.534, gen_loss=0.956, disc_1(Real)_a=95, disc_2(Fake)_a=81\n",
            ">469, disc_1(Real)=0.372, disc_2(Fake)=0.571, gen_loss=0.879, disc_1(Real)_a=98, disc_2(Fake)_a=71\n",
            ">470, disc_1(Real)=0.361, disc_2(Fake)=0.579, gen_loss=0.903, disc_1(Real)_a=96, disc_2(Fake)_a=70\n",
            ">471, disc_1(Real)=0.404, disc_2(Fake)=0.587, gen_loss=0.881, disc_1(Real)_a=90, disc_2(Fake)_a=71\n",
            ">472, disc_1(Real)=0.369, disc_2(Fake)=0.572, gen_loss=0.939, disc_1(Real)_a=95, disc_2(Fake)_a=75\n",
            ">473, disc_1(Real)=0.366, disc_2(Fake)=0.615, gen_loss=0.915, disc_1(Real)_a=96, disc_2(Fake)_a=68\n",
            ">474, disc_1(Real)=0.338, disc_2(Fake)=0.609, gen_loss=0.939, disc_1(Real)_a=100, disc_2(Fake)_a=60\n",
            ">475, disc_1(Real)=0.328, disc_2(Fake)=0.667, gen_loss=0.893, disc_1(Real)_a=98, disc_2(Fake)_a=56\n",
            ">476, disc_1(Real)=0.369, disc_2(Fake)=0.572, gen_loss=0.935, disc_1(Real)_a=98, disc_2(Fake)_a=76\n",
            ">477, disc_1(Real)=0.363, disc_2(Fake)=0.574, gen_loss=0.926, disc_1(Real)_a=96, disc_2(Fake)_a=76\n",
            ">478, disc_1(Real)=0.371, disc_2(Fake)=0.584, gen_loss=0.990, disc_1(Real)_a=96, disc_2(Fake)_a=73\n",
            ">479, disc_1(Real)=0.324, disc_2(Fake)=0.573, gen_loss=0.923, disc_1(Real)_a=98, disc_2(Fake)_a=78\n",
            ">480, disc_1(Real)=0.357, disc_2(Fake)=0.578, gen_loss=0.952, disc_1(Real)_a=98, disc_2(Fake)_a=76\n",
            ">481, disc_1(Real)=0.368, disc_2(Fake)=0.552, gen_loss=0.997, disc_1(Real)_a=93, disc_2(Fake)_a=82\n",
            ">482, disc_1(Real)=0.382, disc_2(Fake)=0.557, gen_loss=1.016, disc_1(Real)_a=95, disc_2(Fake)_a=81\n",
            ">483, disc_1(Real)=0.385, disc_2(Fake)=0.494, gen_loss=1.031, disc_1(Real)_a=96, disc_2(Fake)_a=82\n",
            ">484, disc_1(Real)=0.441, disc_2(Fake)=0.532, gen_loss=1.046, disc_1(Real)_a=87, disc_2(Fake)_a=81\n",
            ">485, disc_1(Real)=0.459, disc_2(Fake)=0.535, gen_loss=1.055, disc_1(Real)_a=82, disc_2(Fake)_a=79\n",
            ">486, disc_1(Real)=0.425, disc_2(Fake)=0.503, gen_loss=1.044, disc_1(Real)_a=90, disc_2(Fake)_a=90\n",
            ">487, disc_1(Real)=0.348, disc_2(Fake)=0.486, gen_loss=1.125, disc_1(Real)_a=93, disc_2(Fake)_a=85\n",
            ">488, disc_1(Real)=0.434, disc_2(Fake)=0.444, gen_loss=1.106, disc_1(Real)_a=85, disc_2(Fake)_a=90\n",
            ">489, disc_1(Real)=0.457, disc_2(Fake)=0.451, gen_loss=1.213, disc_1(Real)_a=82, disc_2(Fake)_a=89\n",
            ">490, disc_1(Real)=0.406, disc_2(Fake)=0.417, gen_loss=1.159, disc_1(Real)_a=84, disc_2(Fake)_a=93\n",
            ">491, disc_1(Real)=0.432, disc_2(Fake)=0.455, gen_loss=1.201, disc_1(Real)_a=82, disc_2(Fake)_a=93\n",
            ">492, disc_1(Real)=0.427, disc_2(Fake)=0.397, gen_loss=1.232, disc_1(Real)_a=82, disc_2(Fake)_a=93\n",
            ">493, disc_1(Real)=0.418, disc_2(Fake)=0.392, gen_loss=1.222, disc_1(Real)_a=78, disc_2(Fake)_a=95\n",
            ">494, disc_1(Real)=0.489, disc_2(Fake)=0.397, gen_loss=1.262, disc_1(Real)_a=78, disc_2(Fake)_a=95\n",
            ">495, disc_1(Real)=0.493, disc_2(Fake)=0.424, gen_loss=1.221, disc_1(Real)_a=70, disc_2(Fake)_a=93\n",
            ">496, disc_1(Real)=0.454, disc_2(Fake)=0.423, gen_loss=1.210, disc_1(Real)_a=78, disc_2(Fake)_a=95\n",
            ">497, disc_1(Real)=0.466, disc_2(Fake)=0.380, gen_loss=1.260, disc_1(Real)_a=79, disc_2(Fake)_a=98\n",
            ">498, disc_1(Real)=0.444, disc_2(Fake)=0.382, gen_loss=1.231, disc_1(Real)_a=76, disc_2(Fake)_a=96\n",
            ">499, disc_1(Real)=0.409, disc_2(Fake)=0.401, gen_loss=1.248, disc_1(Real)_a=78, disc_2(Fake)_a=95\n",
            ">500, disc_1(Real)=0.392, disc_2(Fake)=0.364, gen_loss=1.336, disc_1(Real)_a=79, disc_2(Fake)_a=95\n",
            ">501, disc_1(Real)=0.494, disc_2(Fake)=0.352, gen_loss=1.345, disc_1(Real)_a=78, disc_2(Fake)_a=95\n",
            ">502, disc_1(Real)=0.505, disc_2(Fake)=0.338, gen_loss=1.320, disc_1(Real)_a=75, disc_2(Fake)_a=95\n",
            ">503, disc_1(Real)=0.418, disc_2(Fake)=0.348, gen_loss=1.332, disc_1(Real)_a=81, disc_2(Fake)_a=95\n",
            ">504, disc_1(Real)=0.431, disc_2(Fake)=0.399, gen_loss=1.398, disc_1(Real)_a=71, disc_2(Fake)_a=95\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">505, disc_1(Real)=0.455, disc_2(Fake)=0.391, gen_loss=1.379, disc_1(Real)_a=70, disc_2(Fake)_a=96\n",
            ">506, disc_1(Real)=0.506, disc_2(Fake)=0.353, gen_loss=1.426, disc_1(Real)_a=70, disc_2(Fake)_a=96\n",
            ">507, disc_1(Real)=0.401, disc_2(Fake)=0.356, gen_loss=1.398, disc_1(Real)_a=84, disc_2(Fake)_a=93\n",
            ">508, disc_1(Real)=0.389, disc_2(Fake)=0.362, gen_loss=1.439, disc_1(Real)_a=82, disc_2(Fake)_a=95\n",
            ">509, disc_1(Real)=0.545, disc_2(Fake)=0.316, gen_loss=1.390, disc_1(Real)_a=62, disc_2(Fake)_a=93\n",
            ">510, disc_1(Real)=0.388, disc_2(Fake)=0.366, gen_loss=1.422, disc_1(Real)_a=82, disc_2(Fake)_a=93\n",
            ">511, disc_1(Real)=0.516, disc_2(Fake)=0.324, gen_loss=1.389, disc_1(Real)_a=68, disc_2(Fake)_a=98\n",
            ">512, disc_1(Real)=0.389, disc_2(Fake)=0.315, gen_loss=1.418, disc_1(Real)_a=82, disc_2(Fake)_a=96\n",
            ">513, disc_1(Real)=0.392, disc_2(Fake)=0.324, gen_loss=1.340, disc_1(Real)_a=81, disc_2(Fake)_a=98\n",
            ">514, disc_1(Real)=0.466, disc_2(Fake)=0.410, gen_loss=1.369, disc_1(Real)_a=76, disc_2(Fake)_a=90\n",
            ">515, disc_1(Real)=0.469, disc_2(Fake)=0.308, gen_loss=1.358, disc_1(Real)_a=75, disc_2(Fake)_a=98\n",
            ">516, disc_1(Real)=0.553, disc_2(Fake)=0.352, gen_loss=1.348, disc_1(Real)_a=67, disc_2(Fake)_a=95\n",
            ">517, disc_1(Real)=0.423, disc_2(Fake)=0.414, gen_loss=1.264, disc_1(Real)_a=75, disc_2(Fake)_a=89\n",
            ">518, disc_1(Real)=0.470, disc_2(Fake)=0.354, gen_loss=1.365, disc_1(Real)_a=73, disc_2(Fake)_a=96\n",
            ">519, disc_1(Real)=0.483, disc_2(Fake)=0.342, gen_loss=1.296, disc_1(Real)_a=78, disc_2(Fake)_a=96\n",
            ">520, disc_1(Real)=0.410, disc_2(Fake)=0.414, gen_loss=1.332, disc_1(Real)_a=81, disc_2(Fake)_a=87\n",
            ">521, disc_1(Real)=0.428, disc_2(Fake)=0.425, gen_loss=1.391, disc_1(Real)_a=79, disc_2(Fake)_a=87\n",
            ">522, disc_1(Real)=0.445, disc_2(Fake)=0.409, gen_loss=1.442, disc_1(Real)_a=76, disc_2(Fake)_a=92\n",
            ">523, disc_1(Real)=0.464, disc_2(Fake)=0.282, gen_loss=1.421, disc_1(Real)_a=68, disc_2(Fake)_a=100\n",
            ">524, disc_1(Real)=0.544, disc_2(Fake)=0.334, gen_loss=1.353, disc_1(Real)_a=65, disc_2(Fake)_a=95\n",
            ">525, disc_1(Real)=0.469, disc_2(Fake)=0.346, gen_loss=1.419, disc_1(Real)_a=75, disc_2(Fake)_a=95\n",
            ">526, disc_1(Real)=0.422, disc_2(Fake)=0.356, gen_loss=1.367, disc_1(Real)_a=81, disc_2(Fake)_a=92\n",
            ">527, disc_1(Real)=0.386, disc_2(Fake)=0.347, gen_loss=1.434, disc_1(Real)_a=85, disc_2(Fake)_a=93\n",
            ">528, disc_1(Real)=0.356, disc_2(Fake)=0.346, gen_loss=1.377, disc_1(Real)_a=84, disc_2(Fake)_a=93\n",
            ">529, disc_1(Real)=0.426, disc_2(Fake)=0.284, gen_loss=1.452, disc_1(Real)_a=81, disc_2(Fake)_a=98\n",
            ">530, disc_1(Real)=0.470, disc_2(Fake)=0.314, gen_loss=1.348, disc_1(Real)_a=71, disc_2(Fake)_a=98\n",
            ">531, disc_1(Real)=0.432, disc_2(Fake)=0.396, gen_loss=1.436, disc_1(Real)_a=79, disc_2(Fake)_a=87\n",
            ">532, disc_1(Real)=0.469, disc_2(Fake)=0.415, gen_loss=1.450, disc_1(Real)_a=73, disc_2(Fake)_a=84\n",
            ">533, disc_1(Real)=0.552, disc_2(Fake)=0.326, gen_loss=1.436, disc_1(Real)_a=67, disc_2(Fake)_a=93\n",
            ">534, disc_1(Real)=0.435, disc_2(Fake)=0.338, gen_loss=1.433, disc_1(Real)_a=79, disc_2(Fake)_a=93\n",
            ">535, disc_1(Real)=0.412, disc_2(Fake)=0.387, gen_loss=1.405, disc_1(Real)_a=79, disc_2(Fake)_a=90\n",
            ">536, disc_1(Real)=0.526, disc_2(Fake)=0.417, gen_loss=1.433, disc_1(Real)_a=67, disc_2(Fake)_a=82\n",
            ">537, disc_1(Real)=0.452, disc_2(Fake)=0.375, gen_loss=1.369, disc_1(Real)_a=71, disc_2(Fake)_a=90\n",
            ">538, disc_1(Real)=0.440, disc_2(Fake)=0.367, gen_loss=1.389, disc_1(Real)_a=75, disc_2(Fake)_a=89\n",
            ">539, disc_1(Real)=0.426, disc_2(Fake)=0.424, gen_loss=1.338, disc_1(Real)_a=78, disc_2(Fake)_a=85\n",
            ">540, disc_1(Real)=0.462, disc_2(Fake)=0.438, gen_loss=1.293, disc_1(Real)_a=75, disc_2(Fake)_a=81\n",
            ">541, disc_1(Real)=0.549, disc_2(Fake)=0.444, gen_loss=1.258, disc_1(Real)_a=67, disc_2(Fake)_a=87\n",
            ">542, disc_1(Real)=0.357, disc_2(Fake)=0.606, gen_loss=1.281, disc_1(Real)_a=79, disc_2(Fake)_a=67\n",
            ">543, disc_1(Real)=0.472, disc_2(Fake)=0.642, gen_loss=1.301, disc_1(Real)_a=76, disc_2(Fake)_a=60\n",
            ">544, disc_1(Real)=0.466, disc_2(Fake)=0.569, gen_loss=1.415, disc_1(Real)_a=79, disc_2(Fake)_a=79\n",
            ">545, disc_1(Real)=0.496, disc_2(Fake)=0.494, gen_loss=1.573, disc_1(Real)_a=71, disc_2(Fake)_a=76\n",
            ">546, disc_1(Real)=0.645, disc_2(Fake)=0.484, gen_loss=1.430, disc_1(Real)_a=62, disc_2(Fake)_a=81\n",
            ">547, disc_1(Real)=0.615, disc_2(Fake)=0.435, gen_loss=1.330, disc_1(Real)_a=60, disc_2(Fake)_a=84\n",
            ">548, disc_1(Real)=0.704, disc_2(Fake)=0.506, gen_loss=1.265, disc_1(Real)_a=53, disc_2(Fake)_a=73\n",
            ">549, disc_1(Real)=0.619, disc_2(Fake)=0.562, gen_loss=1.208, disc_1(Real)_a=67, disc_2(Fake)_a=73\n",
            ">550, disc_1(Real)=0.596, disc_2(Fake)=0.740, gen_loss=1.253, disc_1(Real)_a=64, disc_2(Fake)_a=65\n",
            ">551, disc_1(Real)=0.614, disc_2(Fake)=0.546, gen_loss=1.381, disc_1(Real)_a=64, disc_2(Fake)_a=78\n",
            ">552, disc_1(Real)=0.641, disc_2(Fake)=0.549, gen_loss=1.247, disc_1(Real)_a=65, disc_2(Fake)_a=71\n",
            ">553, disc_1(Real)=0.665, disc_2(Fake)=0.576, gen_loss=1.266, disc_1(Real)_a=56, disc_2(Fake)_a=68\n",
            ">554, disc_1(Real)=0.767, disc_2(Fake)=0.475, gen_loss=1.342, disc_1(Real)_a=45, disc_2(Fake)_a=76\n",
            ">555, disc_1(Real)=0.700, disc_2(Fake)=0.484, gen_loss=1.232, disc_1(Real)_a=56, disc_2(Fake)_a=81\n",
            ">556, disc_1(Real)=0.743, disc_2(Fake)=0.667, gen_loss=1.155, disc_1(Real)_a=53, disc_2(Fake)_a=60\n",
            ">557, disc_1(Real)=0.602, disc_2(Fake)=0.492, gen_loss=1.298, disc_1(Real)_a=62, disc_2(Fake)_a=73\n",
            ">558, disc_1(Real)=0.635, disc_2(Fake)=0.502, gen_loss=1.320, disc_1(Real)_a=60, disc_2(Fake)_a=81\n",
            ">559, disc_1(Real)=0.665, disc_2(Fake)=0.414, gen_loss=1.374, disc_1(Real)_a=59, disc_2(Fake)_a=85\n",
            ">560, disc_1(Real)=0.755, disc_2(Fake)=0.540, gen_loss=1.199, disc_1(Real)_a=50, disc_2(Fake)_a=71\n",
            ">561, disc_1(Real)=0.585, disc_2(Fake)=0.507, gen_loss=1.301, disc_1(Real)_a=67, disc_2(Fake)_a=79\n",
            ">562, disc_1(Real)=0.712, disc_2(Fake)=0.452, gen_loss=1.307, disc_1(Real)_a=51, disc_2(Fake)_a=85\n",
            ">563, disc_1(Real)=0.645, disc_2(Fake)=0.435, gen_loss=1.272, disc_1(Real)_a=64, disc_2(Fake)_a=85\n",
            ">564, disc_1(Real)=0.699, disc_2(Fake)=0.463, gen_loss=1.327, disc_1(Real)_a=51, disc_2(Fake)_a=82\n",
            ">565, disc_1(Real)=0.590, disc_2(Fake)=0.435, gen_loss=1.322, disc_1(Real)_a=65, disc_2(Fake)_a=82\n",
            ">566, disc_1(Real)=0.690, disc_2(Fake)=0.467, gen_loss=1.265, disc_1(Real)_a=54, disc_2(Fake)_a=79\n",
            ">567, disc_1(Real)=0.558, disc_2(Fake)=0.467, gen_loss=1.293, disc_1(Real)_a=70, disc_2(Fake)_a=85\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">568, disc_1(Real)=0.628, disc_2(Fake)=0.404, gen_loss=1.260, disc_1(Real)_a=62, disc_2(Fake)_a=89\n",
            ">569, disc_1(Real)=0.631, disc_2(Fake)=0.427, gen_loss=1.284, disc_1(Real)_a=56, disc_2(Fake)_a=82\n",
            ">570, disc_1(Real)=0.600, disc_2(Fake)=0.452, gen_loss=1.201, disc_1(Real)_a=71, disc_2(Fake)_a=85\n",
            ">571, disc_1(Real)=0.611, disc_2(Fake)=0.437, gen_loss=1.233, disc_1(Real)_a=70, disc_2(Fake)_a=84\n",
            ">572, disc_1(Real)=0.519, disc_2(Fake)=0.550, gen_loss=1.170, disc_1(Real)_a=79, disc_2(Fake)_a=71\n",
            ">573, disc_1(Real)=0.546, disc_2(Fake)=0.443, gen_loss=1.168, disc_1(Real)_a=71, disc_2(Fake)_a=90\n",
            ">574, disc_1(Real)=0.512, disc_2(Fake)=0.552, gen_loss=1.100, disc_1(Real)_a=81, disc_2(Fake)_a=79\n",
            ">575, disc_1(Real)=0.582, disc_2(Fake)=0.497, gen_loss=1.099, disc_1(Real)_a=70, disc_2(Fake)_a=85\n",
            ">576, disc_1(Real)=0.583, disc_2(Fake)=0.560, gen_loss=1.083, disc_1(Real)_a=71, disc_2(Fake)_a=78\n",
            ">577, disc_1(Real)=0.533, disc_2(Fake)=0.504, gen_loss=1.059, disc_1(Real)_a=76, disc_2(Fake)_a=79\n",
            ">578, disc_1(Real)=0.524, disc_2(Fake)=0.567, gen_loss=1.056, disc_1(Real)_a=76, disc_2(Fake)_a=70\n",
            ">579, disc_1(Real)=0.605, disc_2(Fake)=0.628, gen_loss=1.000, disc_1(Real)_a=60, disc_2(Fake)_a=53\n",
            ">580, disc_1(Real)=0.619, disc_2(Fake)=0.580, gen_loss=0.963, disc_1(Real)_a=67, disc_2(Fake)_a=73\n",
            ">581, disc_1(Real)=0.629, disc_2(Fake)=0.647, gen_loss=0.941, disc_1(Real)_a=64, disc_2(Fake)_a=57\n",
            ">582, disc_1(Real)=0.575, disc_2(Fake)=0.696, gen_loss=0.891, disc_1(Real)_a=75, disc_2(Fake)_a=53\n",
            ">583, disc_1(Real)=0.608, disc_2(Fake)=0.590, gen_loss=0.915, disc_1(Real)_a=68, disc_2(Fake)_a=70\n",
            ">584, disc_1(Real)=0.513, disc_2(Fake)=0.675, gen_loss=0.880, disc_1(Real)_a=87, disc_2(Fake)_a=56\n",
            ">585, disc_1(Real)=0.542, disc_2(Fake)=0.683, gen_loss=0.912, disc_1(Real)_a=76, disc_2(Fake)_a=64\n",
            ">586, disc_1(Real)=0.517, disc_2(Fake)=0.660, gen_loss=0.955, disc_1(Real)_a=76, disc_2(Fake)_a=62\n",
            ">587, disc_1(Real)=0.593, disc_2(Fake)=0.609, gen_loss=0.990, disc_1(Real)_a=71, disc_2(Fake)_a=75\n",
            ">588, disc_1(Real)=0.641, disc_2(Fake)=0.571, gen_loss=0.967, disc_1(Real)_a=68, disc_2(Fake)_a=78\n",
            ">589, disc_1(Real)=0.604, disc_2(Fake)=0.607, gen_loss=1.013, disc_1(Real)_a=75, disc_2(Fake)_a=76\n",
            ">590, disc_1(Real)=0.768, disc_2(Fake)=0.550, gen_loss=1.082, disc_1(Real)_a=53, disc_2(Fake)_a=89\n",
            ">591, disc_1(Real)=0.640, disc_2(Fake)=0.551, gen_loss=1.098, disc_1(Real)_a=64, disc_2(Fake)_a=84\n",
            ">592, disc_1(Real)=0.571, disc_2(Fake)=0.529, gen_loss=1.144, disc_1(Real)_a=65, disc_2(Fake)_a=84\n",
            ">593, disc_1(Real)=0.616, disc_2(Fake)=0.481, gen_loss=1.160, disc_1(Real)_a=68, disc_2(Fake)_a=90\n",
            ">594, disc_1(Real)=0.575, disc_2(Fake)=0.476, gen_loss=1.284, disc_1(Real)_a=67, disc_2(Fake)_a=89\n",
            ">595, disc_1(Real)=0.541, disc_2(Fake)=0.475, gen_loss=1.298, disc_1(Real)_a=71, disc_2(Fake)_a=87\n",
            ">596, disc_1(Real)=0.559, disc_2(Fake)=0.400, gen_loss=1.302, disc_1(Real)_a=78, disc_2(Fake)_a=92\n",
            ">597, disc_1(Real)=0.559, disc_2(Fake)=0.376, gen_loss=1.316, disc_1(Real)_a=71, disc_2(Fake)_a=96\n",
            ">598, disc_1(Real)=0.504, disc_2(Fake)=0.402, gen_loss=1.366, disc_1(Real)_a=81, disc_2(Fake)_a=89\n",
            ">599, disc_1(Real)=0.459, disc_2(Fake)=0.381, gen_loss=1.387, disc_1(Real)_a=85, disc_2(Fake)_a=95\n",
            ">600, disc_1(Real)=0.491, disc_2(Fake)=0.406, gen_loss=1.446, disc_1(Real)_a=84, disc_2(Fake)_a=87\n",
            ">601, disc_1(Real)=0.482, disc_2(Fake)=0.423, gen_loss=1.433, disc_1(Real)_a=79, disc_2(Fake)_a=87\n",
            ">602, disc_1(Real)=0.401, disc_2(Fake)=0.388, gen_loss=1.464, disc_1(Real)_a=90, disc_2(Fake)_a=90\n",
            ">603, disc_1(Real)=0.478, disc_2(Fake)=0.401, gen_loss=1.395, disc_1(Real)_a=89, disc_2(Fake)_a=93\n",
            ">604, disc_1(Real)=0.474, disc_2(Fake)=0.452, gen_loss=1.382, disc_1(Real)_a=87, disc_2(Fake)_a=90\n",
            ">605, disc_1(Real)=0.507, disc_2(Fake)=0.492, gen_loss=1.278, disc_1(Real)_a=82, disc_2(Fake)_a=89\n",
            ">606, disc_1(Real)=0.494, disc_2(Fake)=0.630, gen_loss=1.171, disc_1(Real)_a=79, disc_2(Fake)_a=67\n",
            ">607, disc_1(Real)=0.574, disc_2(Fake)=0.739, gen_loss=0.958, disc_1(Real)_a=70, disc_2(Fake)_a=51\n",
            ">608, disc_1(Real)=0.643, disc_2(Fake)=0.874, gen_loss=0.806, disc_1(Real)_a=62, disc_2(Fake)_a=32\n",
            ">609, disc_1(Real)=0.630, disc_2(Fake)=0.987, gen_loss=0.802, disc_1(Real)_a=60, disc_2(Fake)_a=28\n",
            ">610, disc_1(Real)=0.636, disc_2(Fake)=0.913, gen_loss=0.819, disc_1(Real)_a=65, disc_2(Fake)_a=21\n",
            ">611, disc_1(Real)=0.667, disc_2(Fake)=0.786, gen_loss=0.882, disc_1(Real)_a=64, disc_2(Fake)_a=39\n",
            ">612, disc_1(Real)=0.589, disc_2(Fake)=0.671, gen_loss=0.963, disc_1(Real)_a=68, disc_2(Fake)_a=51\n",
            ">613, disc_1(Real)=0.579, disc_2(Fake)=0.580, gen_loss=1.109, disc_1(Real)_a=70, disc_2(Fake)_a=87\n",
            ">614, disc_1(Real)=0.610, disc_2(Fake)=0.497, gen_loss=1.182, disc_1(Real)_a=67, disc_2(Fake)_a=85\n",
            ">615, disc_1(Real)=0.478, disc_2(Fake)=0.478, gen_loss=1.219, disc_1(Real)_a=85, disc_2(Fake)_a=89\n",
            ">616, disc_1(Real)=0.497, disc_2(Fake)=0.551, gen_loss=1.227, disc_1(Real)_a=76, disc_2(Fake)_a=79\n",
            ">617, disc_1(Real)=0.573, disc_2(Fake)=0.442, gen_loss=1.293, disc_1(Real)_a=71, disc_2(Fake)_a=85\n",
            ">618, disc_1(Real)=0.512, disc_2(Fake)=0.451, gen_loss=1.239, disc_1(Real)_a=73, disc_2(Fake)_a=92\n",
            ">619, disc_1(Real)=0.536, disc_2(Fake)=0.484, gen_loss=1.188, disc_1(Real)_a=79, disc_2(Fake)_a=92\n",
            ">620, disc_1(Real)=0.429, disc_2(Fake)=0.560, gen_loss=1.171, disc_1(Real)_a=85, disc_2(Fake)_a=89\n",
            ">621, disc_1(Real)=0.528, disc_2(Fake)=0.590, gen_loss=1.059, disc_1(Real)_a=73, disc_2(Fake)_a=84\n",
            ">622, disc_1(Real)=0.492, disc_2(Fake)=0.705, gen_loss=0.985, disc_1(Real)_a=75, disc_2(Fake)_a=51\n",
            ">623, disc_1(Real)=0.583, disc_2(Fake)=0.875, gen_loss=0.833, disc_1(Real)_a=65, disc_2(Fake)_a=18\n",
            ">624, disc_1(Real)=0.553, disc_2(Fake)=0.873, gen_loss=0.793, disc_1(Real)_a=73, disc_2(Fake)_a=23\n",
            ">625, disc_1(Real)=0.637, disc_2(Fake)=0.763, gen_loss=0.862, disc_1(Real)_a=68, disc_2(Fake)_a=43\n",
            ">626, disc_1(Real)=0.626, disc_2(Fake)=0.684, gen_loss=0.980, disc_1(Real)_a=64, disc_2(Fake)_a=51\n",
            ">627, disc_1(Real)=0.702, disc_2(Fake)=0.600, gen_loss=1.100, disc_1(Real)_a=57, disc_2(Fake)_a=79\n",
            ">628, disc_1(Real)=0.538, disc_2(Fake)=0.527, gen_loss=1.317, disc_1(Real)_a=73, disc_2(Fake)_a=79\n",
            ">629, disc_1(Real)=0.635, disc_2(Fake)=0.467, gen_loss=1.299, disc_1(Real)_a=59, disc_2(Fake)_a=90\n",
            ">630, disc_1(Real)=0.593, disc_2(Fake)=0.515, gen_loss=1.277, disc_1(Real)_a=70, disc_2(Fake)_a=79\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">631, disc_1(Real)=0.608, disc_2(Fake)=0.528, gen_loss=1.284, disc_1(Real)_a=67, disc_2(Fake)_a=87\n",
            ">632, disc_1(Real)=0.610, disc_2(Fake)=0.525, gen_loss=1.276, disc_1(Real)_a=64, disc_2(Fake)_a=79\n",
            ">633, disc_1(Real)=0.589, disc_2(Fake)=0.578, gen_loss=1.335, disc_1(Real)_a=70, disc_2(Fake)_a=81\n",
            ">634, disc_1(Real)=0.690, disc_2(Fake)=0.419, gen_loss=1.532, disc_1(Real)_a=62, disc_2(Fake)_a=93\n",
            ">635, disc_1(Real)=0.584, disc_2(Fake)=0.351, gen_loss=1.713, disc_1(Real)_a=68, disc_2(Fake)_a=93\n",
            ">636, disc_1(Real)=0.544, disc_2(Fake)=0.347, gen_loss=1.666, disc_1(Real)_a=76, disc_2(Fake)_a=95\n",
            ">637, disc_1(Real)=0.546, disc_2(Fake)=0.341, gen_loss=1.669, disc_1(Real)_a=82, disc_2(Fake)_a=96\n",
            ">638, disc_1(Real)=0.748, disc_2(Fake)=0.401, gen_loss=1.658, disc_1(Real)_a=56, disc_2(Fake)_a=95\n",
            ">639, disc_1(Real)=0.671, disc_2(Fake)=0.345, gen_loss=1.704, disc_1(Real)_a=57, disc_2(Fake)_a=96\n",
            ">640, disc_1(Real)=0.579, disc_2(Fake)=0.290, gen_loss=1.863, disc_1(Real)_a=70, disc_2(Fake)_a=98\n",
            ">641, disc_1(Real)=0.622, disc_2(Fake)=0.237, gen_loss=1.944, disc_1(Real)_a=71, disc_2(Fake)_a=98\n",
            ">642, disc_1(Real)=0.580, disc_2(Fake)=0.226, gen_loss=2.007, disc_1(Real)_a=71, disc_2(Fake)_a=98\n",
            ">643, disc_1(Real)=0.564, disc_2(Fake)=0.246, gen_loss=2.114, disc_1(Real)_a=73, disc_2(Fake)_a=95\n",
            ">644, disc_1(Real)=0.588, disc_2(Fake)=0.202, gen_loss=2.142, disc_1(Real)_a=68, disc_2(Fake)_a=98\n",
            ">645, disc_1(Real)=0.573, disc_2(Fake)=0.202, gen_loss=2.118, disc_1(Real)_a=70, disc_2(Fake)_a=100\n",
            ">646, disc_1(Real)=0.505, disc_2(Fake)=0.220, gen_loss=2.398, disc_1(Real)_a=79, disc_2(Fake)_a=98\n",
            ">647, disc_1(Real)=0.535, disc_2(Fake)=0.215, gen_loss=2.469, disc_1(Real)_a=73, disc_2(Fake)_a=100\n",
            ">648, disc_1(Real)=0.501, disc_2(Fake)=0.205, gen_loss=2.334, disc_1(Real)_a=81, disc_2(Fake)_a=98\n",
            ">649, disc_1(Real)=0.567, disc_2(Fake)=0.249, gen_loss=2.415, disc_1(Real)_a=67, disc_2(Fake)_a=98\n",
            ">650, disc_1(Real)=0.618, disc_2(Fake)=0.210, gen_loss=2.594, disc_1(Real)_a=68, disc_2(Fake)_a=100\n",
            ">651, disc_1(Real)=0.571, disc_2(Fake)=0.153, gen_loss=2.594, disc_1(Real)_a=71, disc_2(Fake)_a=100\n",
            ">652, disc_1(Real)=0.624, disc_2(Fake)=0.199, gen_loss=2.723, disc_1(Real)_a=64, disc_2(Fake)_a=100\n",
            ">653, disc_1(Real)=0.630, disc_2(Fake)=0.170, gen_loss=2.662, disc_1(Real)_a=62, disc_2(Fake)_a=98\n",
            ">654, disc_1(Real)=0.591, disc_2(Fake)=0.147, gen_loss=2.678, disc_1(Real)_a=67, disc_2(Fake)_a=100\n",
            ">655, disc_1(Real)=0.557, disc_2(Fake)=0.132, gen_loss=2.643, disc_1(Real)_a=70, disc_2(Fake)_a=100\n",
            ">656, disc_1(Real)=0.496, disc_2(Fake)=0.162, gen_loss=2.716, disc_1(Real)_a=78, disc_2(Fake)_a=100\n",
            ">657, disc_1(Real)=0.582, disc_2(Fake)=0.129, gen_loss=2.687, disc_1(Real)_a=71, disc_2(Fake)_a=98\n",
            ">658, disc_1(Real)=0.511, disc_2(Fake)=0.154, gen_loss=2.800, disc_1(Real)_a=76, disc_2(Fake)_a=98\n",
            ">659, disc_1(Real)=0.579, disc_2(Fake)=0.152, gen_loss=2.747, disc_1(Real)_a=68, disc_2(Fake)_a=100\n",
            ">660, disc_1(Real)=0.513, disc_2(Fake)=0.159, gen_loss=2.759, disc_1(Real)_a=78, disc_2(Fake)_a=100\n",
            ">661, disc_1(Real)=0.546, disc_2(Fake)=0.187, gen_loss=2.628, disc_1(Real)_a=70, disc_2(Fake)_a=98\n",
            ">662, disc_1(Real)=0.719, disc_2(Fake)=0.252, gen_loss=2.318, disc_1(Real)_a=64, disc_2(Fake)_a=93\n",
            ">663, disc_1(Real)=0.551, disc_2(Fake)=0.211, gen_loss=2.460, disc_1(Real)_a=75, disc_2(Fake)_a=95\n",
            ">664, disc_1(Real)=0.344, disc_2(Fake)=0.186, gen_loss=2.870, disc_1(Real)_a=90, disc_2(Fake)_a=93\n",
            ">665, disc_1(Real)=0.403, disc_2(Fake)=0.173, gen_loss=2.932, disc_1(Real)_a=84, disc_2(Fake)_a=96\n",
            ">666, disc_1(Real)=0.522, disc_2(Fake)=0.184, gen_loss=2.597, disc_1(Real)_a=75, disc_2(Fake)_a=96\n",
            ">667, disc_1(Real)=0.432, disc_2(Fake)=0.216, gen_loss=2.443, disc_1(Real)_a=81, disc_2(Fake)_a=95\n",
            ">668, disc_1(Real)=0.416, disc_2(Fake)=0.242, gen_loss=2.626, disc_1(Real)_a=87, disc_2(Fake)_a=95\n",
            ">669, disc_1(Real)=0.571, disc_2(Fake)=0.316, gen_loss=2.075, disc_1(Real)_a=73, disc_2(Fake)_a=89\n",
            ">670, disc_1(Real)=0.504, disc_2(Fake)=0.731, gen_loss=1.672, disc_1(Real)_a=76, disc_2(Fake)_a=48\n",
            ">671, disc_1(Real)=0.951, disc_2(Fake)=1.570, gen_loss=1.133, disc_1(Real)_a=56, disc_2(Fake)_a=12\n",
            ">672, disc_1(Real)=0.978, disc_2(Fake)=0.703, gen_loss=1.506, disc_1(Real)_a=57, disc_2(Fake)_a=51\n",
            ">673, disc_1(Real)=1.491, disc_2(Fake)=0.393, gen_loss=1.613, disc_1(Real)_a=35, disc_2(Fake)_a=89\n",
            ">674, disc_1(Real)=1.019, disc_2(Fake)=0.334, gen_loss=1.646, disc_1(Real)_a=51, disc_2(Fake)_a=89\n",
            ">675, disc_1(Real)=0.730, disc_2(Fake)=0.339, gen_loss=1.742, disc_1(Real)_a=60, disc_2(Fake)_a=81\n",
            ">676, disc_1(Real)=0.794, disc_2(Fake)=0.350, gen_loss=1.776, disc_1(Real)_a=67, disc_2(Fake)_a=85\n",
            ">677, disc_1(Real)=0.575, disc_2(Fake)=0.449, gen_loss=1.588, disc_1(Real)_a=73, disc_2(Fake)_a=75\n",
            ">678, disc_1(Real)=0.633, disc_2(Fake)=0.507, gen_loss=1.568, disc_1(Real)_a=70, disc_2(Fake)_a=78\n",
            ">679, disc_1(Real)=0.509, disc_2(Fake)=0.469, gen_loss=1.479, disc_1(Real)_a=75, disc_2(Fake)_a=79\n",
            ">680, disc_1(Real)=0.423, disc_2(Fake)=0.421, gen_loss=1.519, disc_1(Real)_a=82, disc_2(Fake)_a=84\n",
            ">681, disc_1(Real)=0.398, disc_2(Fake)=0.405, gen_loss=1.511, disc_1(Real)_a=84, disc_2(Fake)_a=90\n",
            ">682, disc_1(Real)=0.355, disc_2(Fake)=0.371, gen_loss=1.650, disc_1(Real)_a=85, disc_2(Fake)_a=100\n",
            ">683, disc_1(Real)=0.569, disc_2(Fake)=0.297, gen_loss=1.712, disc_1(Real)_a=68, disc_2(Fake)_a=100\n",
            ">684, disc_1(Real)=0.440, disc_2(Fake)=0.286, gen_loss=1.731, disc_1(Real)_a=78, disc_2(Fake)_a=100\n",
            ">685, disc_1(Real)=0.327, disc_2(Fake)=0.214, gen_loss=1.960, disc_1(Real)_a=92, disc_2(Fake)_a=98\n",
            ">686, disc_1(Real)=0.329, disc_2(Fake)=0.209, gen_loss=2.006, disc_1(Real)_a=87, disc_2(Fake)_a=100\n",
            ">687, disc_1(Real)=0.364, disc_2(Fake)=0.164, gen_loss=2.090, disc_1(Real)_a=87, disc_2(Fake)_a=100\n",
            ">688, disc_1(Real)=0.231, disc_2(Fake)=0.225, gen_loss=2.062, disc_1(Real)_a=98, disc_2(Fake)_a=98\n",
            ">689, disc_1(Real)=0.208, disc_2(Fake)=0.171, gen_loss=2.160, disc_1(Real)_a=96, disc_2(Fake)_a=98\n",
            ">690, disc_1(Real)=0.276, disc_2(Fake)=0.185, gen_loss=2.088, disc_1(Real)_a=93, disc_2(Fake)_a=98\n",
            ">691, disc_1(Real)=0.265, disc_2(Fake)=0.241, gen_loss=1.946, disc_1(Real)_a=92, disc_2(Fake)_a=95\n",
            ">692, disc_1(Real)=0.245, disc_2(Fake)=0.376, gen_loss=1.688, disc_1(Real)_a=93, disc_2(Fake)_a=79\n",
            ">693, disc_1(Real)=0.267, disc_2(Fake)=0.380, gen_loss=1.650, disc_1(Real)_a=90, disc_2(Fake)_a=79\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">694, disc_1(Real)=0.243, disc_2(Fake)=0.418, gen_loss=1.895, disc_1(Real)_a=95, disc_2(Fake)_a=71\n",
            ">695, disc_1(Real)=0.316, disc_2(Fake)=0.279, gen_loss=1.857, disc_1(Real)_a=93, disc_2(Fake)_a=90\n",
            ">696, disc_1(Real)=0.262, disc_2(Fake)=0.328, gen_loss=1.794, disc_1(Real)_a=93, disc_2(Fake)_a=81\n",
            ">697, disc_1(Real)=0.224, disc_2(Fake)=0.344, gen_loss=2.107, disc_1(Real)_a=96, disc_2(Fake)_a=82\n",
            ">698, disc_1(Real)=0.340, disc_2(Fake)=0.369, gen_loss=1.924, disc_1(Real)_a=87, disc_2(Fake)_a=79\n",
            ">699, disc_1(Real)=0.349, disc_2(Fake)=0.328, gen_loss=1.687, disc_1(Real)_a=87, disc_2(Fake)_a=85\n",
            ">700, disc_1(Real)=0.318, disc_2(Fake)=0.348, gen_loss=1.537, disc_1(Real)_a=89, disc_2(Fake)_a=90\n",
            ">701, disc_1(Real)=0.326, disc_2(Fake)=0.419, gen_loss=1.375, disc_1(Real)_a=90, disc_2(Fake)_a=84\n",
            ">702, disc_1(Real)=0.358, disc_2(Fake)=0.416, gen_loss=1.315, disc_1(Real)_a=85, disc_2(Fake)_a=95\n",
            ">703, disc_1(Real)=0.410, disc_2(Fake)=0.414, gen_loss=1.408, disc_1(Real)_a=82, disc_2(Fake)_a=96\n",
            ">704, disc_1(Real)=0.443, disc_2(Fake)=0.430, gen_loss=1.430, disc_1(Real)_a=76, disc_2(Fake)_a=98\n",
            ">705, disc_1(Real)=0.332, disc_2(Fake)=0.395, gen_loss=1.429, disc_1(Real)_a=90, disc_2(Fake)_a=100\n",
            ">706, disc_1(Real)=0.427, disc_2(Fake)=0.365, gen_loss=1.487, disc_1(Real)_a=84, disc_2(Fake)_a=100\n",
            ">707, disc_1(Real)=0.391, disc_2(Fake)=0.302, gen_loss=1.587, disc_1(Real)_a=84, disc_2(Fake)_a=100\n",
            ">708, disc_1(Real)=0.319, disc_2(Fake)=0.270, gen_loss=1.722, disc_1(Real)_a=84, disc_2(Fake)_a=100\n",
            ">709, disc_1(Real)=0.259, disc_2(Fake)=0.229, gen_loss=1.826, disc_1(Real)_a=92, disc_2(Fake)_a=100\n",
            ">710, disc_1(Real)=0.257, disc_2(Fake)=0.201, gen_loss=1.929, disc_1(Real)_a=95, disc_2(Fake)_a=100\n",
            ">711, disc_1(Real)=0.242, disc_2(Fake)=0.214, gen_loss=1.902, disc_1(Real)_a=95, disc_2(Fake)_a=100\n",
            ">712, disc_1(Real)=0.254, disc_2(Fake)=0.221, gen_loss=1.863, disc_1(Real)_a=95, disc_2(Fake)_a=100\n",
            ">713, disc_1(Real)=0.245, disc_2(Fake)=0.258, gen_loss=1.692, disc_1(Real)_a=92, disc_2(Fake)_a=100\n",
            ">714, disc_1(Real)=0.194, disc_2(Fake)=0.283, gen_loss=1.625, disc_1(Real)_a=96, disc_2(Fake)_a=100\n",
            ">715, disc_1(Real)=0.153, disc_2(Fake)=0.321, gen_loss=1.465, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">716, disc_1(Real)=0.174, disc_2(Fake)=0.381, gen_loss=1.330, disc_1(Real)_a=96, disc_2(Fake)_a=98\n",
            ">717, disc_1(Real)=0.161, disc_2(Fake)=0.428, gen_loss=1.218, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">718, disc_1(Real)=0.179, disc_2(Fake)=0.483, gen_loss=1.093, disc_1(Real)_a=96, disc_2(Fake)_a=98\n",
            ">719, disc_1(Real)=0.203, disc_2(Fake)=0.488, gen_loss=1.065, disc_1(Real)_a=95, disc_2(Fake)_a=93\n",
            ">720, disc_1(Real)=0.158, disc_2(Fake)=0.602, gen_loss=1.033, disc_1(Real)_a=98, disc_2(Fake)_a=73\n",
            ">721, disc_1(Real)=0.154, disc_2(Fake)=0.603, gen_loss=1.023, disc_1(Real)_a=100, disc_2(Fake)_a=78\n",
            ">722, disc_1(Real)=0.139, disc_2(Fake)=0.605, gen_loss=1.022, disc_1(Real)_a=98, disc_2(Fake)_a=79\n",
            ">723, disc_1(Real)=0.194, disc_2(Fake)=0.535, gen_loss=1.094, disc_1(Real)_a=100, disc_2(Fake)_a=81\n",
            ">724, disc_1(Real)=0.158, disc_2(Fake)=0.486, gen_loss=1.188, disc_1(Real)_a=96, disc_2(Fake)_a=82\n",
            ">725, disc_1(Real)=0.207, disc_2(Fake)=0.457, gen_loss=1.320, disc_1(Real)_a=98, disc_2(Fake)_a=84\n",
            ">726, disc_1(Real)=0.255, disc_2(Fake)=0.543, gen_loss=1.384, disc_1(Real)_a=92, disc_2(Fake)_a=68\n",
            ">727, disc_1(Real)=0.248, disc_2(Fake)=0.401, gen_loss=1.332, disc_1(Real)_a=95, disc_2(Fake)_a=84\n",
            ">728, disc_1(Real)=0.258, disc_2(Fake)=0.453, gen_loss=1.468, disc_1(Real)_a=92, disc_2(Fake)_a=79\n",
            ">729, disc_1(Real)=0.262, disc_2(Fake)=0.438, gen_loss=1.579, disc_1(Real)_a=92, disc_2(Fake)_a=79\n",
            ">730, disc_1(Real)=0.383, disc_2(Fake)=0.344, gen_loss=1.504, disc_1(Real)_a=87, disc_2(Fake)_a=89\n",
            ">731, disc_1(Real)=0.369, disc_2(Fake)=0.358, gen_loss=1.534, disc_1(Real)_a=90, disc_2(Fake)_a=82\n",
            ">732, disc_1(Real)=0.263, disc_2(Fake)=0.350, gen_loss=1.619, disc_1(Real)_a=96, disc_2(Fake)_a=84\n",
            ">733, disc_1(Real)=0.285, disc_2(Fake)=0.422, gen_loss=1.688, disc_1(Real)_a=93, disc_2(Fake)_a=76\n",
            ">734, disc_1(Real)=0.302, disc_2(Fake)=0.347, gen_loss=1.664, disc_1(Real)_a=89, disc_2(Fake)_a=85\n",
            ">735, disc_1(Real)=0.339, disc_2(Fake)=0.437, gen_loss=1.647, disc_1(Real)_a=93, disc_2(Fake)_a=76\n",
            ">736, disc_1(Real)=0.389, disc_2(Fake)=0.305, gen_loss=1.492, disc_1(Real)_a=84, disc_2(Fake)_a=92\n",
            ">737, disc_1(Real)=0.323, disc_2(Fake)=0.376, gen_loss=1.628, disc_1(Real)_a=95, disc_2(Fake)_a=82\n",
            ">738, disc_1(Real)=0.366, disc_2(Fake)=0.349, gen_loss=1.496, disc_1(Real)_a=92, disc_2(Fake)_a=87\n",
            ">739, disc_1(Real)=0.357, disc_2(Fake)=0.341, gen_loss=1.479, disc_1(Real)_a=89, disc_2(Fake)_a=85\n",
            ">740, disc_1(Real)=0.379, disc_2(Fake)=0.396, gen_loss=1.404, disc_1(Real)_a=89, disc_2(Fake)_a=82\n",
            ">741, disc_1(Real)=0.363, disc_2(Fake)=0.415, gen_loss=1.363, disc_1(Real)_a=90, disc_2(Fake)_a=85\n",
            ">742, disc_1(Real)=0.273, disc_2(Fake)=0.443, gen_loss=1.348, disc_1(Real)_a=93, disc_2(Fake)_a=81\n",
            ">743, disc_1(Real)=0.437, disc_2(Fake)=0.398, gen_loss=1.301, disc_1(Real)_a=84, disc_2(Fake)_a=89\n",
            ">744, disc_1(Real)=0.340, disc_2(Fake)=0.468, gen_loss=1.343, disc_1(Real)_a=89, disc_2(Fake)_a=84\n",
            ">745, disc_1(Real)=0.379, disc_2(Fake)=0.440, gen_loss=1.294, disc_1(Real)_a=90, disc_2(Fake)_a=84\n",
            ">746, disc_1(Real)=0.357, disc_2(Fake)=0.416, gen_loss=1.459, disc_1(Real)_a=89, disc_2(Fake)_a=84\n",
            ">747, disc_1(Real)=0.365, disc_2(Fake)=0.390, gen_loss=1.453, disc_1(Real)_a=89, disc_2(Fake)_a=87\n",
            ">748, disc_1(Real)=0.355, disc_2(Fake)=0.383, gen_loss=1.520, disc_1(Real)_a=82, disc_2(Fake)_a=85\n",
            ">749, disc_1(Real)=0.369, disc_2(Fake)=0.386, gen_loss=1.438, disc_1(Real)_a=84, disc_2(Fake)_a=85\n",
            ">750, disc_1(Real)=0.360, disc_2(Fake)=0.372, gen_loss=1.603, disc_1(Real)_a=87, disc_2(Fake)_a=87\n",
            ">751, disc_1(Real)=0.314, disc_2(Fake)=0.354, gen_loss=1.711, disc_1(Real)_a=89, disc_2(Fake)_a=87\n",
            ">752, disc_1(Real)=0.438, disc_2(Fake)=0.312, gen_loss=1.728, disc_1(Real)_a=84, disc_2(Fake)_a=90\n",
            ">753, disc_1(Real)=0.462, disc_2(Fake)=0.274, gen_loss=1.691, disc_1(Real)_a=79, disc_2(Fake)_a=96\n",
            ">754, disc_1(Real)=0.375, disc_2(Fake)=0.239, gen_loss=1.751, disc_1(Real)_a=95, disc_2(Fake)_a=96\n",
            ">755, disc_1(Real)=0.341, disc_2(Fake)=0.231, gen_loss=1.801, disc_1(Real)_a=92, disc_2(Fake)_a=96\n",
            ">756, disc_1(Real)=0.290, disc_2(Fake)=0.331, gen_loss=1.867, disc_1(Real)_a=92, disc_2(Fake)_a=85\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">757, disc_1(Real)=0.288, disc_2(Fake)=0.184, gen_loss=1.850, disc_1(Real)_a=93, disc_2(Fake)_a=98\n",
            ">758, disc_1(Real)=0.307, disc_2(Fake)=0.289, gen_loss=1.999, disc_1(Real)_a=93, disc_2(Fake)_a=85\n",
            ">759, disc_1(Real)=0.227, disc_2(Fake)=0.301, gen_loss=2.031, disc_1(Real)_a=96, disc_2(Fake)_a=87\n",
            ">760, disc_1(Real)=0.273, disc_2(Fake)=0.191, gen_loss=2.022, disc_1(Real)_a=93, disc_2(Fake)_a=96\n",
            ">761, disc_1(Real)=0.311, disc_2(Fake)=0.271, gen_loss=1.970, disc_1(Real)_a=93, disc_2(Fake)_a=89\n",
            ">762, disc_1(Real)=0.399, disc_2(Fake)=0.199, gen_loss=2.057, disc_1(Real)_a=82, disc_2(Fake)_a=96\n",
            ">763, disc_1(Real)=0.290, disc_2(Fake)=0.272, gen_loss=1.962, disc_1(Real)_a=90, disc_2(Fake)_a=89\n",
            ">764, disc_1(Real)=0.258, disc_2(Fake)=0.280, gen_loss=2.076, disc_1(Real)_a=95, disc_2(Fake)_a=89\n",
            ">765, disc_1(Real)=0.348, disc_2(Fake)=0.230, gen_loss=2.061, disc_1(Real)_a=87, disc_2(Fake)_a=93\n",
            ">766, disc_1(Real)=0.290, disc_2(Fake)=0.292, gen_loss=2.015, disc_1(Real)_a=93, disc_2(Fake)_a=89\n",
            ">767, disc_1(Real)=0.305, disc_2(Fake)=0.271, gen_loss=1.944, disc_1(Real)_a=93, disc_2(Fake)_a=92\n",
            ">768, disc_1(Real)=0.259, disc_2(Fake)=0.284, gen_loss=1.902, disc_1(Real)_a=95, disc_2(Fake)_a=90\n",
            ">769, disc_1(Real)=0.310, disc_2(Fake)=0.280, gen_loss=1.907, disc_1(Real)_a=92, disc_2(Fake)_a=93\n",
            ">770, disc_1(Real)=0.266, disc_2(Fake)=0.275, gen_loss=1.816, disc_1(Real)_a=96, disc_2(Fake)_a=89\n",
            ">771, disc_1(Real)=0.322, disc_2(Fake)=0.359, gen_loss=1.744, disc_1(Real)_a=92, disc_2(Fake)_a=82\n",
            ">772, disc_1(Real)=0.291, disc_2(Fake)=0.484, gen_loss=1.551, disc_1(Real)_a=95, disc_2(Fake)_a=71\n",
            ">773, disc_1(Real)=0.303, disc_2(Fake)=0.420, gen_loss=1.234, disc_1(Real)_a=89, disc_2(Fake)_a=89\n",
            ">774, disc_1(Real)=0.426, disc_2(Fake)=0.850, gen_loss=0.873, disc_1(Real)_a=79, disc_2(Fake)_a=29\n",
            ">775, disc_1(Real)=0.364, disc_2(Fake)=1.421, gen_loss=0.579, disc_1(Real)_a=84, disc_2(Fake)_a=12\n",
            ">776, disc_1(Real)=0.391, disc_2(Fake)=1.665, gen_loss=0.587, disc_1(Real)_a=78, disc_2(Fake)_a=12\n",
            ">777, disc_1(Real)=0.448, disc_2(Fake)=1.939, gen_loss=0.743, disc_1(Real)_a=78, disc_2(Fake)_a=14\n",
            ">778, disc_1(Real)=0.480, disc_2(Fake)=1.249, gen_loss=0.837, disc_1(Real)_a=73, disc_2(Fake)_a=29\n",
            ">779, disc_1(Real)=0.704, disc_2(Fake)=0.996, gen_loss=1.020, disc_1(Real)_a=65, disc_2(Fake)_a=40\n",
            ">780, disc_1(Real)=0.677, disc_2(Fake)=0.584, gen_loss=1.327, disc_1(Real)_a=64, disc_2(Fake)_a=73\n",
            ">781, disc_1(Real)=0.488, disc_2(Fake)=0.371, gen_loss=1.774, disc_1(Real)_a=76, disc_2(Fake)_a=96\n",
            ">782, disc_1(Real)=0.405, disc_2(Fake)=0.219, gen_loss=2.004, disc_1(Real)_a=85, disc_2(Fake)_a=100\n",
            ">783, disc_1(Real)=0.436, disc_2(Fake)=0.222, gen_loss=2.132, disc_1(Real)_a=78, disc_2(Fake)_a=98\n",
            ">784, disc_1(Real)=0.371, disc_2(Fake)=0.201, gen_loss=2.293, disc_1(Real)_a=84, disc_2(Fake)_a=100\n",
            ">785, disc_1(Real)=0.322, disc_2(Fake)=0.192, gen_loss=2.387, disc_1(Real)_a=90, disc_2(Fake)_a=100\n",
            ">786, disc_1(Real)=0.278, disc_2(Fake)=0.199, gen_loss=2.321, disc_1(Real)_a=95, disc_2(Fake)_a=100\n",
            ">787, disc_1(Real)=0.363, disc_2(Fake)=0.196, gen_loss=2.230, disc_1(Real)_a=90, disc_2(Fake)_a=100\n",
            ">788, disc_1(Real)=0.353, disc_2(Fake)=0.259, gen_loss=2.011, disc_1(Real)_a=90, disc_2(Fake)_a=100\n",
            ">789, disc_1(Real)=0.349, disc_2(Fake)=0.280, gen_loss=2.071, disc_1(Real)_a=93, disc_2(Fake)_a=100\n",
            ">790, disc_1(Real)=0.380, disc_2(Fake)=0.333, gen_loss=2.353, disc_1(Real)_a=89, disc_2(Fake)_a=93\n",
            ">791, disc_1(Real)=0.499, disc_2(Fake)=0.208, gen_loss=2.417, disc_1(Real)_a=78, disc_2(Fake)_a=98\n",
            ">792, disc_1(Real)=0.567, disc_2(Fake)=0.228, gen_loss=2.298, disc_1(Real)_a=75, disc_2(Fake)_a=96\n",
            ">793, disc_1(Real)=0.462, disc_2(Fake)=0.219, gen_loss=2.434, disc_1(Real)_a=84, disc_2(Fake)_a=96\n",
            ">794, disc_1(Real)=0.503, disc_2(Fake)=0.242, gen_loss=2.544, disc_1(Real)_a=79, disc_2(Fake)_a=92\n",
            ">795, disc_1(Real)=0.571, disc_2(Fake)=0.217, gen_loss=2.795, disc_1(Real)_a=73, disc_2(Fake)_a=90\n",
            ">796, disc_1(Real)=0.552, disc_2(Fake)=0.199, gen_loss=2.831, disc_1(Real)_a=76, disc_2(Fake)_a=93\n",
            ">797, disc_1(Real)=0.493, disc_2(Fake)=0.140, gen_loss=2.863, disc_1(Real)_a=79, disc_2(Fake)_a=98\n",
            ">798, disc_1(Real)=0.555, disc_2(Fake)=0.129, gen_loss=2.600, disc_1(Real)_a=67, disc_2(Fake)_a=100\n",
            ">799, disc_1(Real)=0.445, disc_2(Fake)=0.177, gen_loss=2.489, disc_1(Real)_a=81, disc_2(Fake)_a=100\n",
            ">800, disc_1(Real)=0.413, disc_2(Fake)=0.218, gen_loss=2.521, disc_1(Real)_a=81, disc_2(Fake)_a=100\n",
            ">801, disc_1(Real)=0.291, disc_2(Fake)=0.124, gen_loss=2.686, disc_1(Real)_a=92, disc_2(Fake)_a=100\n",
            ">802, disc_1(Real)=0.432, disc_2(Fake)=0.128, gen_loss=2.440, disc_1(Real)_a=82, disc_2(Fake)_a=100\n",
            ">803, disc_1(Real)=0.382, disc_2(Fake)=0.198, gen_loss=2.324, disc_1(Real)_a=82, disc_2(Fake)_a=100\n",
            ">804, disc_1(Real)=0.341, disc_2(Fake)=0.203, gen_loss=2.446, disc_1(Real)_a=85, disc_2(Fake)_a=100\n",
            ">805, disc_1(Real)=0.403, disc_2(Fake)=0.213, gen_loss=2.303, disc_1(Real)_a=82, disc_2(Fake)_a=100\n",
            ">806, disc_1(Real)=0.534, disc_2(Fake)=0.314, gen_loss=2.010, disc_1(Real)_a=73, disc_2(Fake)_a=100\n",
            ">807, disc_1(Real)=0.359, disc_2(Fake)=0.351, gen_loss=2.075, disc_1(Real)_a=85, disc_2(Fake)_a=95\n",
            ">808, disc_1(Real)=0.735, disc_2(Fake)=0.504, gen_loss=1.795, disc_1(Real)_a=70, disc_2(Fake)_a=82\n",
            ">809, disc_1(Real)=0.875, disc_2(Fake)=0.573, gen_loss=1.548, disc_1(Real)_a=59, disc_2(Fake)_a=81\n",
            ">810, disc_1(Real)=0.771, disc_2(Fake)=0.632, gen_loss=1.417, disc_1(Real)_a=70, disc_2(Fake)_a=62\n",
            ">811, disc_1(Real)=1.220, disc_2(Fake)=0.679, gen_loss=1.353, disc_1(Real)_a=60, disc_2(Fake)_a=57\n",
            ">812, disc_1(Real)=0.734, disc_2(Fake)=0.479, gen_loss=1.442, disc_1(Real)_a=75, disc_2(Fake)_a=95\n",
            ">813, disc_1(Real)=1.114, disc_2(Fake)=0.525, gen_loss=1.260, disc_1(Real)_a=51, disc_2(Fake)_a=89\n",
            ">814, disc_1(Real)=0.813, disc_2(Fake)=0.571, gen_loss=1.241, disc_1(Real)_a=62, disc_2(Fake)_a=79\n",
            ">815, disc_1(Real)=0.407, disc_2(Fake)=0.573, gen_loss=1.378, disc_1(Real)_a=81, disc_2(Fake)_a=73\n",
            ">816, disc_1(Real)=0.522, disc_2(Fake)=0.529, gen_loss=1.494, disc_1(Real)_a=78, disc_2(Fake)_a=81\n",
            ">817, disc_1(Real)=0.408, disc_2(Fake)=0.423, gen_loss=1.570, disc_1(Real)_a=85, disc_2(Fake)_a=100\n",
            ">818, disc_1(Real)=0.467, disc_2(Fake)=0.334, gen_loss=1.610, disc_1(Real)_a=81, disc_2(Fake)_a=100\n",
            ">819, disc_1(Real)=0.410, disc_2(Fake)=0.370, gen_loss=1.510, disc_1(Real)_a=82, disc_2(Fake)_a=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">820, disc_1(Real)=0.357, disc_2(Fake)=0.391, gen_loss=1.564, disc_1(Real)_a=87, disc_2(Fake)_a=96\n",
            ">821, disc_1(Real)=0.260, disc_2(Fake)=0.383, gen_loss=1.595, disc_1(Real)_a=95, disc_2(Fake)_a=98\n",
            ">822, disc_1(Real)=0.268, disc_2(Fake)=0.331, gen_loss=1.680, disc_1(Real)_a=90, disc_2(Fake)_a=100\n",
            ">823, disc_1(Real)=0.244, disc_2(Fake)=0.286, gen_loss=1.788, disc_1(Real)_a=93, disc_2(Fake)_a=100\n",
            ">824, disc_1(Real)=0.174, disc_2(Fake)=0.226, gen_loss=1.914, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">825, disc_1(Real)=0.165, disc_2(Fake)=0.193, gen_loss=1.964, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">826, disc_1(Real)=0.202, disc_2(Fake)=0.199, gen_loss=1.955, disc_1(Real)_a=95, disc_2(Fake)_a=100\n",
            ">827, disc_1(Real)=0.193, disc_2(Fake)=0.200, gen_loss=1.957, disc_1(Real)_a=96, disc_2(Fake)_a=100\n",
            ">828, disc_1(Real)=0.109, disc_2(Fake)=0.185, gen_loss=2.009, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">829, disc_1(Real)=0.134, disc_2(Fake)=0.155, gen_loss=2.161, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">830, disc_1(Real)=0.153, disc_2(Fake)=0.139, gen_loss=2.247, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">831, disc_1(Real)=0.110, disc_2(Fake)=0.114, gen_loss=2.387, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">832, disc_1(Real)=0.116, disc_2(Fake)=0.102, gen_loss=2.557, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">833, disc_1(Real)=0.072, disc_2(Fake)=0.094, gen_loss=2.645, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">834, disc_1(Real)=0.120, disc_2(Fake)=0.083, gen_loss=2.932, disc_1(Real)_a=96, disc_2(Fake)_a=100\n",
            ">835, disc_1(Real)=0.140, disc_2(Fake)=0.068, gen_loss=3.005, disc_1(Real)_a=92, disc_2(Fake)_a=100\n",
            ">836, disc_1(Real)=0.108, disc_2(Fake)=0.068, gen_loss=3.016, disc_1(Real)_a=96, disc_2(Fake)_a=100\n",
            ">837, disc_1(Real)=0.103, disc_2(Fake)=0.075, gen_loss=3.012, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">838, disc_1(Real)=0.110, disc_2(Fake)=0.069, gen_loss=3.155, disc_1(Real)_a=96, disc_2(Fake)_a=100\n",
            ">839, disc_1(Real)=0.110, disc_2(Fake)=0.079, gen_loss=3.070, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">840, disc_1(Real)=0.142, disc_2(Fake)=0.059, gen_loss=2.925, disc_1(Real)_a=95, disc_2(Fake)_a=100\n",
            ">841, disc_1(Real)=0.089, disc_2(Fake)=0.077, gen_loss=2.994, disc_1(Real)_a=96, disc_2(Fake)_a=100\n",
            ">842, disc_1(Real)=0.111, disc_2(Fake)=0.076, gen_loss=2.924, disc_1(Real)_a=95, disc_2(Fake)_a=100\n",
            ">843, disc_1(Real)=0.084, disc_2(Fake)=0.075, gen_loss=3.107, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">844, disc_1(Real)=0.108, disc_2(Fake)=0.068, gen_loss=3.128, disc_1(Real)_a=96, disc_2(Fake)_a=100\n",
            ">845, disc_1(Real)=0.077, disc_2(Fake)=0.078, gen_loss=3.225, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">846, disc_1(Real)=0.095, disc_2(Fake)=0.077, gen_loss=3.226, disc_1(Real)_a=96, disc_2(Fake)_a=100\n",
            ">847, disc_1(Real)=0.092, disc_2(Fake)=0.074, gen_loss=3.127, disc_1(Real)_a=96, disc_2(Fake)_a=100\n",
            ">848, disc_1(Real)=0.101, disc_2(Fake)=0.083, gen_loss=3.191, disc_1(Real)_a=96, disc_2(Fake)_a=100\n",
            ">849, disc_1(Real)=0.040, disc_2(Fake)=0.074, gen_loss=3.157, disc_1(Real)_a=100, disc_2(Fake)_a=100\n",
            ">850, disc_1(Real)=0.061, disc_2(Fake)=0.085, gen_loss=3.330, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">851, disc_1(Real)=0.069, disc_2(Fake)=0.119, gen_loss=3.432, disc_1(Real)_a=98, disc_2(Fake)_a=100\n",
            ">852, disc_1(Real)=0.078, disc_2(Fake)=0.119, gen_loss=3.376, disc_1(Real)_a=96, disc_2(Fake)_a=96\n",
            ">853, disc_1(Real)=0.093, disc_2(Fake)=0.127, gen_loss=3.549, disc_1(Real)_a=96, disc_2(Fake)_a=100\n",
            ">854, disc_1(Real)=0.081, disc_2(Fake)=0.153, gen_loss=3.381, disc_1(Real)_a=98, disc_2(Fake)_a=93\n",
            ">855, disc_1(Real)=0.124, disc_2(Fake)=0.145, gen_loss=3.285, disc_1(Real)_a=96, disc_2(Fake)_a=96\n",
            ">856, disc_1(Real)=0.089, disc_2(Fake)=0.179, gen_loss=2.926, disc_1(Real)_a=98, disc_2(Fake)_a=93\n",
            ">857, disc_1(Real)=0.149, disc_2(Fake)=0.272, gen_loss=2.975, disc_1(Real)_a=93, disc_2(Fake)_a=81\n",
            ">858, disc_1(Real)=0.093, disc_2(Fake)=0.192, gen_loss=2.769, disc_1(Real)_a=98, disc_2(Fake)_a=93\n",
            ">859, disc_1(Real)=0.121, disc_2(Fake)=0.225, gen_loss=2.445, disc_1(Real)_a=95, disc_2(Fake)_a=89\n",
            ">860, disc_1(Real)=0.134, disc_2(Fake)=0.236, gen_loss=2.537, disc_1(Real)_a=96, disc_2(Fake)_a=90\n",
            ">861, disc_1(Real)=0.079, disc_2(Fake)=0.313, gen_loss=2.159, disc_1(Real)_a=98, disc_2(Fake)_a=87\n",
            ">862, disc_1(Real)=0.066, disc_2(Fake)=0.257, gen_loss=2.193, disc_1(Real)_a=100, disc_2(Fake)_a=89\n",
            ">863, disc_1(Real)=0.167, disc_2(Fake)=0.367, gen_loss=2.121, disc_1(Real)_a=92, disc_2(Fake)_a=78\n",
            ">864, disc_1(Real)=0.133, disc_2(Fake)=0.329, gen_loss=2.086, disc_1(Real)_a=95, disc_2(Fake)_a=82\n",
            ">865, disc_1(Real)=0.108, disc_2(Fake)=0.385, gen_loss=2.206, disc_1(Real)_a=96, disc_2(Fake)_a=79\n",
            ">866, disc_1(Real)=0.140, disc_2(Fake)=0.377, gen_loss=2.003, disc_1(Real)_a=95, disc_2(Fake)_a=81\n",
            ">867, disc_1(Real)=0.207, disc_2(Fake)=0.483, gen_loss=1.985, disc_1(Real)_a=93, disc_2(Fake)_a=78\n",
            ">868, disc_1(Real)=0.163, disc_2(Fake)=0.415, gen_loss=2.115, disc_1(Real)_a=93, disc_2(Fake)_a=78\n",
            ">869, disc_1(Real)=0.182, disc_2(Fake)=0.313, gen_loss=1.882, disc_1(Real)_a=93, disc_2(Fake)_a=85\n",
            ">870, disc_1(Real)=0.212, disc_2(Fake)=0.415, gen_loss=1.758, disc_1(Real)_a=93, disc_2(Fake)_a=78\n",
            ">871, disc_1(Real)=0.161, disc_2(Fake)=0.421, gen_loss=1.510, disc_1(Real)_a=96, disc_2(Fake)_a=81\n",
            ">872, disc_1(Real)=0.250, disc_2(Fake)=0.475, gen_loss=1.404, disc_1(Real)_a=89, disc_2(Fake)_a=79\n",
            ">873, disc_1(Real)=0.331, disc_2(Fake)=0.728, gen_loss=1.035, disc_1(Real)_a=90, disc_2(Fake)_a=56\n",
            ">874, disc_1(Real)=0.500, disc_2(Fake)=0.864, gen_loss=1.026, disc_1(Real)_a=76, disc_2(Fake)_a=48\n",
            ">875, disc_1(Real)=0.624, disc_2(Fake)=0.777, gen_loss=1.361, disc_1(Real)_a=65, disc_2(Fake)_a=65\n",
            ">876, disc_1(Real)=0.767, disc_2(Fake)=0.932, gen_loss=1.808, disc_1(Real)_a=53, disc_2(Fake)_a=59\n",
            ">877, disc_1(Real)=0.967, disc_2(Fake)=0.357, gen_loss=1.862, disc_1(Real)_a=29, disc_2(Fake)_a=85\n",
            ">878, disc_1(Real)=1.024, disc_2(Fake)=0.501, gen_loss=1.624, disc_1(Real)_a=26, disc_2(Fake)_a=76\n",
            ">879, disc_1(Real)=0.912, disc_2(Fake)=0.748, gen_loss=1.363, disc_1(Real)_a=39, disc_2(Fake)_a=50\n",
            ">880, disc_1(Real)=0.791, disc_2(Fake)=0.653, gen_loss=1.080, disc_1(Real)_a=48, disc_2(Fake)_a=59\n",
            ">881, disc_1(Real)=0.779, disc_2(Fake)=0.780, gen_loss=1.061, disc_1(Real)_a=56, disc_2(Fake)_a=54\n",
            ">882, disc_1(Real)=0.646, disc_2(Fake)=0.814, gen_loss=1.051, disc_1(Real)_a=59, disc_2(Fake)_a=56\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">883, disc_1(Real)=0.733, disc_2(Fake)=0.921, gen_loss=1.105, disc_1(Real)_a=50, disc_2(Fake)_a=48\n",
            ">884, disc_1(Real)=0.676, disc_2(Fake)=0.684, gen_loss=1.159, disc_1(Real)_a=64, disc_2(Fake)_a=65\n",
            ">885, disc_1(Real)=0.698, disc_2(Fake)=0.672, gen_loss=1.256, disc_1(Real)_a=60, disc_2(Fake)_a=65\n",
            ">886, disc_1(Real)=0.738, disc_2(Fake)=0.619, gen_loss=1.138, disc_1(Real)_a=53, disc_2(Fake)_a=75\n",
            ">887, disc_1(Real)=0.530, disc_2(Fake)=0.638, gen_loss=1.338, disc_1(Real)_a=73, disc_2(Fake)_a=67\n",
            ">888, disc_1(Real)=0.570, disc_2(Fake)=0.648, gen_loss=1.403, disc_1(Real)_a=67, disc_2(Fake)_a=59\n",
            ">889, disc_1(Real)=0.713, disc_2(Fake)=0.405, gen_loss=1.498, disc_1(Real)_a=54, disc_2(Fake)_a=78\n",
            ">890, disc_1(Real)=0.676, disc_2(Fake)=0.449, gen_loss=1.411, disc_1(Real)_a=62, disc_2(Fake)_a=81\n",
            ">891, disc_1(Real)=0.697, disc_2(Fake)=0.424, gen_loss=1.378, disc_1(Real)_a=64, disc_2(Fake)_a=85\n",
            ">892, disc_1(Real)=0.601, disc_2(Fake)=0.487, gen_loss=1.533, disc_1(Real)_a=65, disc_2(Fake)_a=85\n",
            ">893, disc_1(Real)=0.595, disc_2(Fake)=0.419, gen_loss=1.663, disc_1(Real)_a=68, disc_2(Fake)_a=98\n",
            ">894, disc_1(Real)=0.666, disc_2(Fake)=0.326, gen_loss=1.650, disc_1(Real)_a=50, disc_2(Fake)_a=100\n",
            ">895, disc_1(Real)=0.499, disc_2(Fake)=0.331, gen_loss=1.536, disc_1(Real)_a=84, disc_2(Fake)_a=100\n",
            ">896, disc_1(Real)=0.468, disc_2(Fake)=0.357, gen_loss=1.460, disc_1(Real)_a=82, disc_2(Fake)_a=98\n",
            ">897, disc_1(Real)=0.550, disc_2(Fake)=0.410, gen_loss=1.354, disc_1(Real)_a=76, disc_2(Fake)_a=98\n",
            ">898, disc_1(Real)=0.434, disc_2(Fake)=0.407, gen_loss=1.398, disc_1(Real)_a=87, disc_2(Fake)_a=100\n",
            ">899, disc_1(Real)=0.460, disc_2(Fake)=0.429, gen_loss=1.445, disc_1(Real)_a=85, disc_2(Fake)_a=96\n",
            ">900, disc_1(Real)=0.548, disc_2(Fake)=0.412, gen_loss=1.463, disc_1(Real)_a=71, disc_2(Fake)_a=98\n",
            ">901, disc_1(Real)=0.531, disc_2(Fake)=0.415, gen_loss=1.448, disc_1(Real)_a=76, disc_2(Fake)_a=96\n",
            ">902, disc_1(Real)=0.449, disc_2(Fake)=0.346, gen_loss=1.478, disc_1(Real)_a=81, disc_2(Fake)_a=100\n",
            ">903, disc_1(Real)=0.370, disc_2(Fake)=0.347, gen_loss=1.529, disc_1(Real)_a=82, disc_2(Fake)_a=96\n",
            ">904, disc_1(Real)=0.444, disc_2(Fake)=0.356, gen_loss=1.577, disc_1(Real)_a=84, disc_2(Fake)_a=92\n",
            ">905, disc_1(Real)=0.552, disc_2(Fake)=0.332, gen_loss=1.534, disc_1(Real)_a=76, disc_2(Fake)_a=98\n",
            ">906, disc_1(Real)=0.472, disc_2(Fake)=0.389, gen_loss=1.612, disc_1(Real)_a=76, disc_2(Fake)_a=89\n",
            ">907, disc_1(Real)=0.516, disc_2(Fake)=0.395, gen_loss=1.554, disc_1(Real)_a=79, disc_2(Fake)_a=95\n",
            ">908, disc_1(Real)=0.443, disc_2(Fake)=0.418, gen_loss=1.552, disc_1(Real)_a=82, disc_2(Fake)_a=92\n",
            ">909, disc_1(Real)=0.473, disc_2(Fake)=0.395, gen_loss=1.562, disc_1(Real)_a=82, disc_2(Fake)_a=92\n",
            ">910, disc_1(Real)=0.565, disc_2(Fake)=0.423, gen_loss=1.366, disc_1(Real)_a=68, disc_2(Fake)_a=95\n",
            ">911, disc_1(Real)=0.560, disc_2(Fake)=0.432, gen_loss=1.316, disc_1(Real)_a=71, disc_2(Fake)_a=89\n",
            ">912, disc_1(Real)=0.442, disc_2(Fake)=0.490, gen_loss=1.348, disc_1(Real)_a=78, disc_2(Fake)_a=81\n",
            ">913, disc_1(Real)=0.656, disc_2(Fake)=0.461, gen_loss=1.328, disc_1(Real)_a=60, disc_2(Fake)_a=85\n",
            ">914, disc_1(Real)=0.529, disc_2(Fake)=0.478, gen_loss=1.355, disc_1(Real)_a=76, disc_2(Fake)_a=82\n",
            ">915, disc_1(Real)=0.481, disc_2(Fake)=0.546, gen_loss=1.374, disc_1(Real)_a=79, disc_2(Fake)_a=68\n",
            ">916, disc_1(Real)=0.724, disc_2(Fake)=0.525, gen_loss=1.334, disc_1(Real)_a=53, disc_2(Fake)_a=78\n",
            ">917, disc_1(Real)=0.639, disc_2(Fake)=0.586, gen_loss=1.363, disc_1(Real)_a=68, disc_2(Fake)_a=67\n",
            ">918, disc_1(Real)=0.610, disc_2(Fake)=0.501, gen_loss=1.518, disc_1(Real)_a=67, disc_2(Fake)_a=78\n",
            ">919, disc_1(Real)=0.774, disc_2(Fake)=0.491, gen_loss=1.375, disc_1(Real)_a=59, disc_2(Fake)_a=81\n",
            ">920, disc_1(Real)=0.580, disc_2(Fake)=0.491, gen_loss=1.385, disc_1(Real)_a=67, disc_2(Fake)_a=81\n",
            ">921, disc_1(Real)=0.640, disc_2(Fake)=0.444, gen_loss=1.558, disc_1(Real)_a=65, disc_2(Fake)_a=84\n",
            ">922, disc_1(Real)=0.627, disc_2(Fake)=0.431, gen_loss=1.487, disc_1(Real)_a=67, disc_2(Fake)_a=87\n",
            ">923, disc_1(Real)=0.664, disc_2(Fake)=0.432, gen_loss=1.482, disc_1(Real)_a=59, disc_2(Fake)_a=84\n",
            ">924, disc_1(Real)=0.552, disc_2(Fake)=0.431, gen_loss=1.465, disc_1(Real)_a=73, disc_2(Fake)_a=89\n",
            ">925, disc_1(Real)=0.557, disc_2(Fake)=0.414, gen_loss=1.578, disc_1(Real)_a=73, disc_2(Fake)_a=89\n",
            ">926, disc_1(Real)=0.643, disc_2(Fake)=0.364, gen_loss=1.496, disc_1(Real)_a=67, disc_2(Fake)_a=95\n",
            ">927, disc_1(Real)=0.403, disc_2(Fake)=0.419, gen_loss=1.609, disc_1(Real)_a=85, disc_2(Fake)_a=89\n",
            ">928, disc_1(Real)=0.593, disc_2(Fake)=0.459, gen_loss=1.515, disc_1(Real)_a=67, disc_2(Fake)_a=84\n",
            ">929, disc_1(Real)=0.538, disc_2(Fake)=0.473, gen_loss=1.603, disc_1(Real)_a=62, disc_2(Fake)_a=71\n",
            ">930, disc_1(Real)=0.558, disc_2(Fake)=0.453, gen_loss=1.427, disc_1(Real)_a=73, disc_2(Fake)_a=82\n",
            ">931, disc_1(Real)=0.605, disc_2(Fake)=0.485, gen_loss=1.335, disc_1(Real)_a=64, disc_2(Fake)_a=73\n",
            ">932, disc_1(Real)=0.503, disc_2(Fake)=0.502, gen_loss=1.476, disc_1(Real)_a=78, disc_2(Fake)_a=76\n",
            ">933, disc_1(Real)=0.589, disc_2(Fake)=0.526, gen_loss=1.532, disc_1(Real)_a=70, disc_2(Fake)_a=73\n",
            ">934, disc_1(Real)=0.508, disc_2(Fake)=0.489, gen_loss=1.579, disc_1(Real)_a=75, disc_2(Fake)_a=78\n",
            ">935, disc_1(Real)=0.585, disc_2(Fake)=0.483, gen_loss=1.605, disc_1(Real)_a=71, disc_2(Fake)_a=82\n",
            ">936, disc_1(Real)=0.518, disc_2(Fake)=0.406, gen_loss=1.469, disc_1(Real)_a=73, disc_2(Fake)_a=89\n",
            ">937, disc_1(Real)=0.692, disc_2(Fake)=0.505, gen_loss=1.411, disc_1(Real)_a=67, disc_2(Fake)_a=76\n",
            ">938, disc_1(Real)=0.551, disc_2(Fake)=0.616, gen_loss=1.491, disc_1(Real)_a=75, disc_2(Fake)_a=57\n",
            ">939, disc_1(Real)=0.688, disc_2(Fake)=0.528, gen_loss=1.481, disc_1(Real)_a=51, disc_2(Fake)_a=71\n",
            ">940, disc_1(Real)=0.570, disc_2(Fake)=0.519, gen_loss=1.616, disc_1(Real)_a=68, disc_2(Fake)_a=76\n",
            ">941, disc_1(Real)=0.727, disc_2(Fake)=0.523, gen_loss=1.589, disc_1(Real)_a=50, disc_2(Fake)_a=73\n",
            ">942, disc_1(Real)=0.713, disc_2(Fake)=0.507, gen_loss=1.546, disc_1(Real)_a=51, disc_2(Fake)_a=75\n",
            ">943, disc_1(Real)=0.680, disc_2(Fake)=0.549, gen_loss=1.661, disc_1(Real)_a=60, disc_2(Fake)_a=68\n",
            ">944, disc_1(Real)=0.623, disc_2(Fake)=0.369, gen_loss=1.763, disc_1(Real)_a=67, disc_2(Fake)_a=92\n",
            ">945, disc_1(Real)=0.736, disc_2(Fake)=0.451, gen_loss=1.466, disc_1(Real)_a=56, disc_2(Fake)_a=85\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">946, disc_1(Real)=0.622, disc_2(Fake)=0.521, gen_loss=1.486, disc_1(Real)_a=65, disc_2(Fake)_a=82\n",
            ">947, disc_1(Real)=0.723, disc_2(Fake)=0.527, gen_loss=1.487, disc_1(Real)_a=50, disc_2(Fake)_a=81\n",
            ">948, disc_1(Real)=0.736, disc_2(Fake)=0.519, gen_loss=1.477, disc_1(Real)_a=53, disc_2(Fake)_a=85\n",
            ">949, disc_1(Real)=0.663, disc_2(Fake)=0.490, gen_loss=1.480, disc_1(Real)_a=57, disc_2(Fake)_a=93\n",
            ">950, disc_1(Real)=0.710, disc_2(Fake)=0.537, gen_loss=1.396, disc_1(Real)_a=53, disc_2(Fake)_a=89\n",
            ">951, disc_1(Real)=0.651, disc_2(Fake)=0.588, gen_loss=1.348, disc_1(Real)_a=64, disc_2(Fake)_a=81\n",
            ">952, disc_1(Real)=0.692, disc_2(Fake)=0.727, gen_loss=1.107, disc_1(Real)_a=68, disc_2(Fake)_a=43\n",
            ">953, disc_1(Real)=0.654, disc_2(Fake)=0.933, gen_loss=0.900, disc_1(Real)_a=67, disc_2(Fake)_a=23\n",
            ">954, disc_1(Real)=0.670, disc_2(Fake)=0.911, gen_loss=0.859, disc_1(Real)_a=56, disc_2(Fake)_a=28\n",
            ">955, disc_1(Real)=0.753, disc_2(Fake)=0.848, gen_loss=0.819, disc_1(Real)_a=51, disc_2(Fake)_a=28\n",
            ">956, disc_1(Real)=0.706, disc_2(Fake)=0.783, gen_loss=0.921, disc_1(Real)_a=57, disc_2(Fake)_a=35\n",
            ">957, disc_1(Real)=0.663, disc_2(Fake)=0.659, gen_loss=1.083, disc_1(Real)_a=57, disc_2(Fake)_a=75\n",
            ">958, disc_1(Real)=0.598, disc_2(Fake)=0.599, gen_loss=1.242, disc_1(Real)_a=62, disc_2(Fake)_a=81\n",
            ">959, disc_1(Real)=0.630, disc_2(Fake)=0.623, gen_loss=1.265, disc_1(Real)_a=64, disc_2(Fake)_a=73\n",
            ">960, disc_1(Real)=0.655, disc_2(Fake)=0.553, gen_loss=1.396, disc_1(Real)_a=56, disc_2(Fake)_a=73\n",
            ">961, disc_1(Real)=0.647, disc_2(Fake)=0.632, gen_loss=1.267, disc_1(Real)_a=62, disc_2(Fake)_a=71\n",
            ">962, disc_1(Real)=0.574, disc_2(Fake)=0.654, gen_loss=1.219, disc_1(Real)_a=75, disc_2(Fake)_a=73\n",
            ">963, disc_1(Real)=0.621, disc_2(Fake)=0.691, gen_loss=1.288, disc_1(Real)_a=70, disc_2(Fake)_a=62\n",
            ">964, disc_1(Real)=0.711, disc_2(Fake)=0.785, gen_loss=1.297, disc_1(Real)_a=53, disc_2(Fake)_a=54\n",
            ">965, disc_1(Real)=0.804, disc_2(Fake)=0.674, gen_loss=1.271, disc_1(Real)_a=51, disc_2(Fake)_a=68\n",
            ">966, disc_1(Real)=1.031, disc_2(Fake)=0.581, gen_loss=1.284, disc_1(Real)_a=42, disc_2(Fake)_a=76\n",
            ">967, disc_1(Real)=1.059, disc_2(Fake)=0.516, gen_loss=1.353, disc_1(Real)_a=35, disc_2(Fake)_a=87\n",
            ">968, disc_1(Real)=0.899, disc_2(Fake)=0.506, gen_loss=1.322, disc_1(Real)_a=32, disc_2(Fake)_a=87\n",
            ">969, disc_1(Real)=0.939, disc_2(Fake)=0.520, gen_loss=1.369, disc_1(Real)_a=39, disc_2(Fake)_a=89\n",
            ">970, disc_1(Real)=1.015, disc_2(Fake)=0.553, gen_loss=1.368, disc_1(Real)_a=34, disc_2(Fake)_a=75\n",
            ">971, disc_1(Real)=0.902, disc_2(Fake)=0.563, gen_loss=1.274, disc_1(Real)_a=35, disc_2(Fake)_a=75\n",
            ">972, disc_1(Real)=0.936, disc_2(Fake)=0.566, gen_loss=1.258, disc_1(Real)_a=40, disc_2(Fake)_a=75\n",
            ">973, disc_1(Real)=0.998, disc_2(Fake)=0.565, gen_loss=1.219, disc_1(Real)_a=29, disc_2(Fake)_a=82\n",
            ">974, disc_1(Real)=0.846, disc_2(Fake)=0.530, gen_loss=1.178, disc_1(Real)_a=43, disc_2(Fake)_a=87\n",
            ">975, disc_1(Real)=0.773, disc_2(Fake)=0.650, gen_loss=1.218, disc_1(Real)_a=40, disc_2(Fake)_a=76\n",
            ">976, disc_1(Real)=0.751, disc_2(Fake)=0.647, gen_loss=1.411, disc_1(Real)_a=50, disc_2(Fake)_a=68\n",
            ">977, disc_1(Real)=0.814, disc_2(Fake)=0.503, gen_loss=1.358, disc_1(Real)_a=48, disc_2(Fake)_a=82\n",
            ">978, disc_1(Real)=0.817, disc_2(Fake)=0.523, gen_loss=1.381, disc_1(Real)_a=34, disc_2(Fake)_a=84\n",
            ">979, disc_1(Real)=0.643, disc_2(Fake)=0.541, gen_loss=1.324, disc_1(Real)_a=60, disc_2(Fake)_a=76\n",
            ">980, disc_1(Real)=0.647, disc_2(Fake)=0.568, gen_loss=1.331, disc_1(Real)_a=57, disc_2(Fake)_a=75\n",
            ">981, disc_1(Real)=0.769, disc_2(Fake)=0.535, gen_loss=1.312, disc_1(Real)_a=50, disc_2(Fake)_a=79\n",
            ">982, disc_1(Real)=0.748, disc_2(Fake)=0.601, gen_loss=1.424, disc_1(Real)_a=45, disc_2(Fake)_a=79\n",
            ">983, disc_1(Real)=0.783, disc_2(Fake)=0.462, gen_loss=1.469, disc_1(Real)_a=43, disc_2(Fake)_a=87\n",
            ">984, disc_1(Real)=0.823, disc_2(Fake)=0.532, gen_loss=1.526, disc_1(Real)_a=42, disc_2(Fake)_a=79\n",
            ">985, disc_1(Real)=0.771, disc_2(Fake)=0.514, gen_loss=1.446, disc_1(Real)_a=45, disc_2(Fake)_a=81\n",
            ">986, disc_1(Real)=0.776, disc_2(Fake)=0.493, gen_loss=1.506, disc_1(Real)_a=39, disc_2(Fake)_a=82\n",
            ">987, disc_1(Real)=0.762, disc_2(Fake)=0.490, gen_loss=1.522, disc_1(Real)_a=48, disc_2(Fake)_a=79\n",
            ">988, disc_1(Real)=0.699, disc_2(Fake)=0.441, gen_loss=1.437, disc_1(Real)_a=53, disc_2(Fake)_a=84\n",
            ">989, disc_1(Real)=0.678, disc_2(Fake)=0.469, gen_loss=1.499, disc_1(Real)_a=56, disc_2(Fake)_a=81\n",
            ">990, disc_1(Real)=0.664, disc_2(Fake)=0.470, gen_loss=1.498, disc_1(Real)_a=60, disc_2(Fake)_a=84\n",
            ">991, disc_1(Real)=0.619, disc_2(Fake)=0.499, gen_loss=1.504, disc_1(Real)_a=70, disc_2(Fake)_a=78\n",
            ">992, disc_1(Real)=0.574, disc_2(Fake)=0.536, gen_loss=1.507, disc_1(Real)_a=68, disc_2(Fake)_a=75\n",
            ">993, disc_1(Real)=0.651, disc_2(Fake)=0.452, gen_loss=1.489, disc_1(Real)_a=57, disc_2(Fake)_a=75\n",
            ">994, disc_1(Real)=0.612, disc_2(Fake)=0.518, gen_loss=1.472, disc_1(Real)_a=68, disc_2(Fake)_a=76\n",
            ">995, disc_1(Real)=0.612, disc_2(Fake)=0.647, gen_loss=1.255, disc_1(Real)_a=60, disc_2(Fake)_a=65\n",
            ">996, disc_1(Real)=0.611, disc_2(Fake)=0.697, gen_loss=1.370, disc_1(Real)_a=65, disc_2(Fake)_a=54\n",
            ">997, disc_1(Real)=0.612, disc_2(Fake)=0.523, gen_loss=1.310, disc_1(Real)_a=67, disc_2(Fake)_a=76\n",
            ">998, disc_1(Real)=0.672, disc_2(Fake)=0.518, gen_loss=1.341, disc_1(Real)_a=59, disc_2(Fake)_a=79\n",
            ">999, disc_1(Real)=0.648, disc_2(Fake)=0.575, gen_loss=1.364, disc_1(Real)_a=57, disc_2(Fake)_a=73\n",
            ">1000, disc_1(Real)=0.559, disc_2(Fake)=0.494, gen_loss=1.423, disc_1(Real)_a=75, disc_2(Fake)_a=76\n",
            ">1001, disc_1(Real)=0.557, disc_2(Fake)=0.399, gen_loss=1.415, disc_1(Real)_a=81, disc_2(Fake)_a=84\n",
            ">1002, disc_1(Real)=0.526, disc_2(Fake)=0.481, gen_loss=1.487, disc_1(Real)_a=79, disc_2(Fake)_a=81\n",
            ">1003, disc_1(Real)=0.449, disc_2(Fake)=0.468, gen_loss=1.437, disc_1(Real)_a=89, disc_2(Fake)_a=71\n",
            ">1004, disc_1(Real)=0.463, disc_2(Fake)=0.445, gen_loss=1.518, disc_1(Real)_a=84, disc_2(Fake)_a=78\n",
            ">1005, disc_1(Real)=0.432, disc_2(Fake)=0.405, gen_loss=1.759, disc_1(Real)_a=87, disc_2(Fake)_a=76\n",
            ">1006, disc_1(Real)=0.451, disc_2(Fake)=0.342, gen_loss=1.863, disc_1(Real)_a=81, disc_2(Fake)_a=85\n",
            ">1007, disc_1(Real)=0.398, disc_2(Fake)=0.411, gen_loss=1.628, disc_1(Real)_a=85, disc_2(Fake)_a=75\n",
            ">1008, disc_1(Real)=0.400, disc_2(Fake)=0.419, gen_loss=1.691, disc_1(Real)_a=90, disc_2(Fake)_a=71\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">1009, disc_1(Real)=0.376, disc_2(Fake)=0.483, gen_loss=1.720, disc_1(Real)_a=95, disc_2(Fake)_a=71\n",
            ">1010, disc_1(Real)=0.370, disc_2(Fake)=0.445, gen_loss=1.908, disc_1(Real)_a=95, disc_2(Fake)_a=79\n",
            ">1011, disc_1(Real)=0.442, disc_2(Fake)=0.399, gen_loss=1.833, disc_1(Real)_a=85, disc_2(Fake)_a=81\n",
            ">1012, disc_1(Real)=0.445, disc_2(Fake)=0.364, gen_loss=1.742, disc_1(Real)_a=84, disc_2(Fake)_a=85\n",
            ">1013, disc_1(Real)=0.339, disc_2(Fake)=0.526, gen_loss=1.704, disc_1(Real)_a=90, disc_2(Fake)_a=68\n",
            ">1014, disc_1(Real)=0.390, disc_2(Fake)=0.457, gen_loss=1.638, disc_1(Real)_a=89, disc_2(Fake)_a=75\n",
            ">1015, disc_1(Real)=0.383, disc_2(Fake)=0.500, gen_loss=1.524, disc_1(Real)_a=92, disc_2(Fake)_a=68\n",
            ">1016, disc_1(Real)=0.462, disc_2(Fake)=0.541, gen_loss=1.327, disc_1(Real)_a=82, disc_2(Fake)_a=71\n",
            ">1017, disc_1(Real)=0.425, disc_2(Fake)=0.558, gen_loss=1.301, disc_1(Real)_a=89, disc_2(Fake)_a=68\n",
            ">1018, disc_1(Real)=0.420, disc_2(Fake)=0.518, gen_loss=1.339, disc_1(Real)_a=87, disc_2(Fake)_a=76\n",
            ">1019, disc_1(Real)=0.445, disc_2(Fake)=0.543, gen_loss=1.325, disc_1(Real)_a=90, disc_2(Fake)_a=75\n",
            ">1020, disc_1(Real)=0.508, disc_2(Fake)=0.454, gen_loss=1.412, disc_1(Real)_a=78, disc_2(Fake)_a=92\n",
            ">1021, disc_1(Real)=0.481, disc_2(Fake)=0.467, gen_loss=1.462, disc_1(Real)_a=89, disc_2(Fake)_a=85\n",
            ">1022, disc_1(Real)=0.482, disc_2(Fake)=0.427, gen_loss=1.624, disc_1(Real)_a=85, disc_2(Fake)_a=87\n",
            ">1023, disc_1(Real)=0.471, disc_2(Fake)=0.370, gen_loss=1.686, disc_1(Real)_a=82, disc_2(Fake)_a=90\n",
            ">1024, disc_1(Real)=0.433, disc_2(Fake)=0.406, gen_loss=1.698, disc_1(Real)_a=84, disc_2(Fake)_a=84\n",
            ">1025, disc_1(Real)=0.522, disc_2(Fake)=0.356, gen_loss=1.564, disc_1(Real)_a=75, disc_2(Fake)_a=93\n",
            ">1026, disc_1(Real)=0.498, disc_2(Fake)=0.506, gen_loss=1.383, disc_1(Real)_a=71, disc_2(Fake)_a=82\n",
            ">1027, disc_1(Real)=0.479, disc_2(Fake)=0.555, gen_loss=1.440, disc_1(Real)_a=79, disc_2(Fake)_a=71\n",
            ">1028, disc_1(Real)=0.574, disc_2(Fake)=0.601, gen_loss=1.378, disc_1(Real)_a=68, disc_2(Fake)_a=64\n",
            ">1029, disc_1(Real)=0.639, disc_2(Fake)=0.637, gen_loss=1.383, disc_1(Real)_a=73, disc_2(Fake)_a=62\n",
            ">1030, disc_1(Real)=0.601, disc_2(Fake)=0.560, gen_loss=1.398, disc_1(Real)_a=68, disc_2(Fake)_a=68\n",
            ">1031, disc_1(Real)=0.709, disc_2(Fake)=0.616, gen_loss=1.425, disc_1(Real)_a=64, disc_2(Fake)_a=67\n",
            ">1032, disc_1(Real)=0.795, disc_2(Fake)=0.444, gen_loss=1.452, disc_1(Real)_a=50, disc_2(Fake)_a=87\n",
            ">1033, disc_1(Real)=0.784, disc_2(Fake)=0.560, gen_loss=1.394, disc_1(Real)_a=50, disc_2(Fake)_a=70\n",
            ">1034, disc_1(Real)=0.762, disc_2(Fake)=0.538, gen_loss=1.268, disc_1(Real)_a=48, disc_2(Fake)_a=75\n",
            ">1035, disc_1(Real)=0.759, disc_2(Fake)=0.606, gen_loss=1.272, disc_1(Real)_a=48, disc_2(Fake)_a=65\n",
            ">1036, disc_1(Real)=0.812, disc_2(Fake)=0.615, gen_loss=1.218, disc_1(Real)_a=40, disc_2(Fake)_a=64\n",
            ">1037, disc_1(Real)=0.778, disc_2(Fake)=0.522, gen_loss=1.142, disc_1(Real)_a=54, disc_2(Fake)_a=82\n",
            ">1038, disc_1(Real)=0.670, disc_2(Fake)=0.561, gen_loss=1.193, disc_1(Real)_a=57, disc_2(Fake)_a=76\n",
            ">1039, disc_1(Real)=0.815, disc_2(Fake)=0.577, gen_loss=1.191, disc_1(Real)_a=46, disc_2(Fake)_a=70\n",
            ">1040, disc_1(Real)=0.682, disc_2(Fake)=0.698, gen_loss=1.230, disc_1(Real)_a=64, disc_2(Fake)_a=56\n",
            ">1041, disc_1(Real)=0.768, disc_2(Fake)=0.502, gen_loss=1.252, disc_1(Real)_a=45, disc_2(Fake)_a=76\n",
            ">1042, disc_1(Real)=0.751, disc_2(Fake)=0.494, gen_loss=1.268, disc_1(Real)_a=56, disc_2(Fake)_a=81\n",
            ">1043, disc_1(Real)=0.834, disc_2(Fake)=0.580, gen_loss=1.172, disc_1(Real)_a=45, disc_2(Fake)_a=67\n",
            ">1044, disc_1(Real)=0.657, disc_2(Fake)=0.567, gen_loss=1.194, disc_1(Real)_a=59, disc_2(Fake)_a=71\n",
            ">1045, disc_1(Real)=0.673, disc_2(Fake)=0.496, gen_loss=1.201, disc_1(Real)_a=65, disc_2(Fake)_a=81\n",
            ">1046, disc_1(Real)=0.742, disc_2(Fake)=0.521, gen_loss=1.227, disc_1(Real)_a=56, disc_2(Fake)_a=78\n",
            ">1047, disc_1(Real)=0.664, disc_2(Fake)=0.493, gen_loss=1.215, disc_1(Real)_a=62, disc_2(Fake)_a=79\n",
            ">1048, disc_1(Real)=0.723, disc_2(Fake)=0.530, gen_loss=1.201, disc_1(Real)_a=57, disc_2(Fake)_a=75\n",
            ">1049, disc_1(Real)=0.661, disc_2(Fake)=0.504, gen_loss=1.245, disc_1(Real)_a=62, disc_2(Fake)_a=85\n",
            ">1050, disc_1(Real)=0.708, disc_2(Fake)=0.531, gen_loss=1.255, disc_1(Real)_a=56, disc_2(Fake)_a=81\n",
            ">1051, disc_1(Real)=0.828, disc_2(Fake)=0.472, gen_loss=1.226, disc_1(Real)_a=35, disc_2(Fake)_a=90\n",
            ">1052, disc_1(Real)=0.742, disc_2(Fake)=0.591, gen_loss=1.224, disc_1(Real)_a=57, disc_2(Fake)_a=71\n",
            ">1053, disc_1(Real)=0.790, disc_2(Fake)=0.597, gen_loss=1.261, disc_1(Real)_a=48, disc_2(Fake)_a=70\n",
            ">1054, disc_1(Real)=0.756, disc_2(Fake)=0.497, gen_loss=1.258, disc_1(Real)_a=54, disc_2(Fake)_a=90\n",
            ">1055, disc_1(Real)=0.714, disc_2(Fake)=0.525, gen_loss=1.273, disc_1(Real)_a=56, disc_2(Fake)_a=82\n",
            ">1056, disc_1(Real)=0.904, disc_2(Fake)=0.515, gen_loss=1.164, disc_1(Real)_a=43, disc_2(Fake)_a=82\n",
            ">1057, disc_1(Real)=0.861, disc_2(Fake)=0.623, gen_loss=1.074, disc_1(Real)_a=48, disc_2(Fake)_a=65\n",
            ">1058, disc_1(Real)=0.801, disc_2(Fake)=0.688, gen_loss=1.052, disc_1(Real)_a=57, disc_2(Fake)_a=54\n",
            ">1059, disc_1(Real)=0.804, disc_2(Fake)=0.717, gen_loss=1.113, disc_1(Real)_a=46, disc_2(Fake)_a=48\n",
            ">1060, disc_1(Real)=0.862, disc_2(Fake)=0.628, gen_loss=1.125, disc_1(Real)_a=50, disc_2(Fake)_a=65\n",
            ">1061, disc_1(Real)=0.816, disc_2(Fake)=0.583, gen_loss=1.106, disc_1(Real)_a=50, disc_2(Fake)_a=71\n",
            ">1062, disc_1(Real)=0.940, disc_2(Fake)=0.657, gen_loss=0.966, disc_1(Real)_a=37, disc_2(Fake)_a=60\n",
            ">1063, disc_1(Real)=0.883, disc_2(Fake)=0.703, gen_loss=0.922, disc_1(Real)_a=46, disc_2(Fake)_a=51\n",
            ">1064, disc_1(Real)=0.891, disc_2(Fake)=0.744, gen_loss=0.946, disc_1(Real)_a=40, disc_2(Fake)_a=43\n",
            ">1065, disc_1(Real)=0.962, disc_2(Fake)=0.711, gen_loss=0.988, disc_1(Real)_a=25, disc_2(Fake)_a=53\n",
            ">1066, disc_1(Real)=1.010, disc_2(Fake)=0.701, gen_loss=0.934, disc_1(Real)_a=35, disc_2(Fake)_a=57\n",
            ">1067, disc_1(Real)=0.869, disc_2(Fake)=0.637, gen_loss=0.882, disc_1(Real)_a=45, disc_2(Fake)_a=64\n",
            ">1068, disc_1(Real)=0.914, disc_2(Fake)=0.663, gen_loss=0.885, disc_1(Real)_a=53, disc_2(Fake)_a=57\n",
            ">1069, disc_1(Real)=0.788, disc_2(Fake)=0.724, gen_loss=0.931, disc_1(Real)_a=46, disc_2(Fake)_a=53\n",
            ">1070, disc_1(Real)=0.841, disc_2(Fake)=0.683, gen_loss=0.971, disc_1(Real)_a=35, disc_2(Fake)_a=57\n",
            ">1071, disc_1(Real)=0.853, disc_2(Fake)=0.624, gen_loss=0.996, disc_1(Real)_a=46, disc_2(Fake)_a=71\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">1072, disc_1(Real)=0.759, disc_2(Fake)=0.575, gen_loss=1.038, disc_1(Real)_a=54, disc_2(Fake)_a=82\n",
            ">1073, disc_1(Real)=0.808, disc_2(Fake)=0.570, gen_loss=1.072, disc_1(Real)_a=48, disc_2(Fake)_a=87\n",
            ">1074, disc_1(Real)=0.828, disc_2(Fake)=0.571, gen_loss=1.031, disc_1(Real)_a=51, disc_2(Fake)_a=78\n",
            ">1075, disc_1(Real)=0.824, disc_2(Fake)=0.571, gen_loss=1.035, disc_1(Real)_a=51, disc_2(Fake)_a=84\n",
            ">1076, disc_1(Real)=0.689, disc_2(Fake)=0.562, gen_loss=1.050, disc_1(Real)_a=62, disc_2(Fake)_a=76\n",
            ">1077, disc_1(Real)=0.757, disc_2(Fake)=0.566, gen_loss=0.968, disc_1(Real)_a=51, disc_2(Fake)_a=76\n",
            ">1078, disc_1(Real)=0.768, disc_2(Fake)=0.581, gen_loss=1.004, disc_1(Real)_a=57, disc_2(Fake)_a=73\n",
            ">1079, disc_1(Real)=0.687, disc_2(Fake)=0.614, gen_loss=1.021, disc_1(Real)_a=57, disc_2(Fake)_a=64\n",
            ">1080, disc_1(Real)=0.582, disc_2(Fake)=0.565, gen_loss=1.011, disc_1(Real)_a=78, disc_2(Fake)_a=67\n",
            ">1081, disc_1(Real)=0.555, disc_2(Fake)=0.553, gen_loss=1.062, disc_1(Real)_a=76, disc_2(Fake)_a=75\n",
            ">1082, disc_1(Real)=0.642, disc_2(Fake)=0.565, gen_loss=1.115, disc_1(Real)_a=64, disc_2(Fake)_a=68\n",
            ">1083, disc_1(Real)=0.617, disc_2(Fake)=0.574, gen_loss=1.057, disc_1(Real)_a=71, disc_2(Fake)_a=67\n",
            ">1084, disc_1(Real)=0.594, disc_2(Fake)=0.549, gen_loss=1.098, disc_1(Real)_a=75, disc_2(Fake)_a=71\n",
            ">1085, disc_1(Real)=0.559, disc_2(Fake)=0.544, gen_loss=1.104, disc_1(Real)_a=75, disc_2(Fake)_a=71\n",
            ">1086, disc_1(Real)=0.542, disc_2(Fake)=0.453, gen_loss=1.192, disc_1(Real)_a=73, disc_2(Fake)_a=81\n",
            ">1087, disc_1(Real)=0.520, disc_2(Fake)=0.487, gen_loss=1.177, disc_1(Real)_a=79, disc_2(Fake)_a=76\n",
            ">1088, disc_1(Real)=0.597, disc_2(Fake)=0.505, gen_loss=1.133, disc_1(Real)_a=71, disc_2(Fake)_a=78\n",
            ">1089, disc_1(Real)=0.556, disc_2(Fake)=0.536, gen_loss=1.154, disc_1(Real)_a=78, disc_2(Fake)_a=73\n",
            ">1090, disc_1(Real)=0.505, disc_2(Fake)=0.497, gen_loss=1.187, disc_1(Real)_a=81, disc_2(Fake)_a=82\n",
            ">1091, disc_1(Real)=0.503, disc_2(Fake)=0.481, gen_loss=1.214, disc_1(Real)_a=82, disc_2(Fake)_a=79\n",
            ">1092, disc_1(Real)=0.583, disc_2(Fake)=0.550, gen_loss=1.108, disc_1(Real)_a=78, disc_2(Fake)_a=73\n",
            ">1093, disc_1(Real)=0.488, disc_2(Fake)=0.522, gen_loss=1.081, disc_1(Real)_a=81, disc_2(Fake)_a=75\n",
            ">1094, disc_1(Real)=0.577, disc_2(Fake)=0.521, gen_loss=1.097, disc_1(Real)_a=75, disc_2(Fake)_a=76\n",
            ">1095, disc_1(Real)=0.615, disc_2(Fake)=0.556, gen_loss=1.008, disc_1(Real)_a=67, disc_2(Fake)_a=71\n",
            ">1096, disc_1(Real)=0.514, disc_2(Fake)=0.606, gen_loss=0.978, disc_1(Real)_a=82, disc_2(Fake)_a=62\n",
            ">1097, disc_1(Real)=0.508, disc_2(Fake)=0.568, gen_loss=1.024, disc_1(Real)_a=82, disc_2(Fake)_a=79\n",
            ">1098, disc_1(Real)=0.500, disc_2(Fake)=0.609, gen_loss=1.005, disc_1(Real)_a=82, disc_2(Fake)_a=70\n",
            ">1099, disc_1(Real)=0.518, disc_2(Fake)=0.584, gen_loss=1.033, disc_1(Real)_a=84, disc_2(Fake)_a=67\n",
            ">1100, disc_1(Real)=0.563, disc_2(Fake)=0.527, gen_loss=1.039, disc_1(Real)_a=78, disc_2(Fake)_a=87\n",
            ">1101, disc_1(Real)=0.563, disc_2(Fake)=0.576, gen_loss=1.026, disc_1(Real)_a=76, disc_2(Fake)_a=75\n",
            ">1102, disc_1(Real)=0.526, disc_2(Fake)=0.534, gen_loss=1.047, disc_1(Real)_a=81, disc_2(Fake)_a=79\n",
            ">1103, disc_1(Real)=0.490, disc_2(Fake)=0.573, gen_loss=1.010, disc_1(Real)_a=84, disc_2(Fake)_a=78\n",
            ">1104, disc_1(Real)=0.523, disc_2(Fake)=0.571, gen_loss=0.986, disc_1(Real)_a=73, disc_2(Fake)_a=79\n",
            ">1105, disc_1(Real)=0.600, disc_2(Fake)=0.594, gen_loss=1.003, disc_1(Real)_a=73, disc_2(Fake)_a=62\n",
            ">1106, disc_1(Real)=0.547, disc_2(Fake)=0.567, gen_loss=0.980, disc_1(Real)_a=79, disc_2(Fake)_a=78\n",
            ">1107, disc_1(Real)=0.578, disc_2(Fake)=0.593, gen_loss=0.944, disc_1(Real)_a=68, disc_2(Fake)_a=73\n",
            ">1108, disc_1(Real)=0.550, disc_2(Fake)=0.586, gen_loss=0.921, disc_1(Real)_a=79, disc_2(Fake)_a=75\n",
            ">1109, disc_1(Real)=0.554, disc_2(Fake)=0.632, gen_loss=0.893, disc_1(Real)_a=76, disc_2(Fake)_a=65\n",
            ">1110, disc_1(Real)=0.446, disc_2(Fake)=0.626, gen_loss=0.899, disc_1(Real)_a=90, disc_2(Fake)_a=71\n",
            ">1111, disc_1(Real)=0.485, disc_2(Fake)=0.610, gen_loss=0.921, disc_1(Real)_a=87, disc_2(Fake)_a=65\n",
            ">1112, disc_1(Real)=0.550, disc_2(Fake)=0.594, gen_loss=0.919, disc_1(Real)_a=76, disc_2(Fake)_a=71\n",
            ">1113, disc_1(Real)=0.505, disc_2(Fake)=0.613, gen_loss=0.860, disc_1(Real)_a=81, disc_2(Fake)_a=70\n",
            ">1114, disc_1(Real)=0.568, disc_2(Fake)=0.607, gen_loss=0.918, disc_1(Real)_a=75, disc_2(Fake)_a=71\n",
            ">1115, disc_1(Real)=0.585, disc_2(Fake)=0.651, gen_loss=0.900, disc_1(Real)_a=75, disc_2(Fake)_a=67\n",
            ">1116, disc_1(Real)=0.541, disc_2(Fake)=0.631, gen_loss=0.885, disc_1(Real)_a=79, disc_2(Fake)_a=67\n",
            ">1117, disc_1(Real)=0.522, disc_2(Fake)=0.614, gen_loss=0.906, disc_1(Real)_a=84, disc_2(Fake)_a=70\n",
            ">1118, disc_1(Real)=0.550, disc_2(Fake)=0.644, gen_loss=0.881, disc_1(Real)_a=76, disc_2(Fake)_a=65\n",
            ">1119, disc_1(Real)=0.519, disc_2(Fake)=0.603, gen_loss=0.957, disc_1(Real)_a=84, disc_2(Fake)_a=76\n",
            ">1120, disc_1(Real)=0.524, disc_2(Fake)=0.585, gen_loss=0.931, disc_1(Real)_a=76, disc_2(Fake)_a=75\n",
            ">1121, disc_1(Real)=0.524, disc_2(Fake)=0.553, gen_loss=0.956, disc_1(Real)_a=82, disc_2(Fake)_a=89\n",
            ">1122, disc_1(Real)=0.532, disc_2(Fake)=0.544, gen_loss=0.960, disc_1(Real)_a=78, disc_2(Fake)_a=85\n",
            ">1123, disc_1(Real)=0.577, disc_2(Fake)=0.571, gen_loss=0.977, disc_1(Real)_a=75, disc_2(Fake)_a=89\n",
            ">1124, disc_1(Real)=0.568, disc_2(Fake)=0.559, gen_loss=0.925, disc_1(Real)_a=75, disc_2(Fake)_a=84\n",
            ">1125, disc_1(Real)=0.526, disc_2(Fake)=0.558, gen_loss=0.936, disc_1(Real)_a=82, disc_2(Fake)_a=85\n",
            ">1126, disc_1(Real)=0.463, disc_2(Fake)=0.565, gen_loss=0.965, disc_1(Real)_a=90, disc_2(Fake)_a=87\n",
            ">1127, disc_1(Real)=0.507, disc_2(Fake)=0.558, gen_loss=0.976, disc_1(Real)_a=85, disc_2(Fake)_a=89\n",
            ">1128, disc_1(Real)=0.493, disc_2(Fake)=0.544, gen_loss=0.967, disc_1(Real)_a=82, disc_2(Fake)_a=92\n",
            ">1129, disc_1(Real)=0.506, disc_2(Fake)=0.543, gen_loss=0.976, disc_1(Real)_a=89, disc_2(Fake)_a=90\n",
            ">1130, disc_1(Real)=0.471, disc_2(Fake)=0.555, gen_loss=0.980, disc_1(Real)_a=90, disc_2(Fake)_a=87\n",
            ">1131, disc_1(Real)=0.488, disc_2(Fake)=0.551, gen_loss=0.982, disc_1(Real)_a=87, disc_2(Fake)_a=84\n",
            ">1132, disc_1(Real)=0.496, disc_2(Fake)=0.516, gen_loss=0.978, disc_1(Real)_a=81, disc_2(Fake)_a=92\n",
            ">1133, disc_1(Real)=0.533, disc_2(Fake)=0.548, gen_loss=1.010, disc_1(Real)_a=79, disc_2(Fake)_a=84\n",
            ">1134, disc_1(Real)=0.506, disc_2(Fake)=0.510, gen_loss=0.970, disc_1(Real)_a=82, disc_2(Fake)_a=90\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">1135, disc_1(Real)=0.481, disc_2(Fake)=0.570, gen_loss=0.983, disc_1(Real)_a=84, disc_2(Fake)_a=85\n",
            ">1136, disc_1(Real)=0.496, disc_2(Fake)=0.556, gen_loss=0.978, disc_1(Real)_a=81, disc_2(Fake)_a=89\n",
            ">1137, disc_1(Real)=0.512, disc_2(Fake)=0.557, gen_loss=0.992, disc_1(Real)_a=89, disc_2(Fake)_a=93\n",
            ">1138, disc_1(Real)=0.498, disc_2(Fake)=0.546, gen_loss=1.032, disc_1(Real)_a=79, disc_2(Fake)_a=92\n",
            ">1139, disc_1(Real)=0.532, disc_2(Fake)=0.565, gen_loss=0.999, disc_1(Real)_a=82, disc_2(Fake)_a=79\n",
            ">1140, disc_1(Real)=0.531, disc_2(Fake)=0.541, gen_loss=0.967, disc_1(Real)_a=84, disc_2(Fake)_a=89\n",
            ">1141, disc_1(Real)=0.478, disc_2(Fake)=0.595, gen_loss=0.995, disc_1(Real)_a=90, disc_2(Fake)_a=68\n",
            ">1142, disc_1(Real)=0.501, disc_2(Fake)=0.592, gen_loss=0.959, disc_1(Real)_a=81, disc_2(Fake)_a=67\n",
            ">1143, disc_1(Real)=0.513, disc_2(Fake)=0.572, gen_loss=0.944, disc_1(Real)_a=85, disc_2(Fake)_a=78\n",
            ">1144, disc_1(Real)=0.542, disc_2(Fake)=0.602, gen_loss=0.888, disc_1(Real)_a=76, disc_2(Fake)_a=67\n",
            ">1145, disc_1(Real)=0.551, disc_2(Fake)=0.638, gen_loss=0.891, disc_1(Real)_a=78, disc_2(Fake)_a=57\n",
            ">1146, disc_1(Real)=0.522, disc_2(Fake)=0.636, gen_loss=0.892, disc_1(Real)_a=81, disc_2(Fake)_a=64\n",
            ">1147, disc_1(Real)=0.587, disc_2(Fake)=0.620, gen_loss=0.860, disc_1(Real)_a=75, disc_2(Fake)_a=64\n",
            ">1148, disc_1(Real)=0.555, disc_2(Fake)=0.689, gen_loss=0.854, disc_1(Real)_a=75, disc_2(Fake)_a=54\n",
            ">1149, disc_1(Real)=0.576, disc_2(Fake)=0.724, gen_loss=0.830, disc_1(Real)_a=73, disc_2(Fake)_a=50\n",
            ">1150, disc_1(Real)=0.580, disc_2(Fake)=0.735, gen_loss=0.791, disc_1(Real)_a=73, disc_2(Fake)_a=57\n",
            ">1151, disc_1(Real)=0.538, disc_2(Fake)=0.713, gen_loss=0.810, disc_1(Real)_a=76, disc_2(Fake)_a=57\n",
            ">1152, disc_1(Real)=0.559, disc_2(Fake)=0.779, gen_loss=0.781, disc_1(Real)_a=75, disc_2(Fake)_a=48\n",
            ">1153, disc_1(Real)=0.510, disc_2(Fake)=0.763, gen_loss=0.797, disc_1(Real)_a=81, disc_2(Fake)_a=50\n",
            ">1154, disc_1(Real)=0.549, disc_2(Fake)=0.764, gen_loss=0.792, disc_1(Real)_a=75, disc_2(Fake)_a=56\n",
            ">1155, disc_1(Real)=0.606, disc_2(Fake)=0.791, gen_loss=0.811, disc_1(Real)_a=65, disc_2(Fake)_a=48\n",
            ">1156, disc_1(Real)=0.629, disc_2(Fake)=0.796, gen_loss=0.846, disc_1(Real)_a=65, disc_2(Fake)_a=46\n",
            ">1157, disc_1(Real)=0.635, disc_2(Fake)=0.797, gen_loss=0.783, disc_1(Real)_a=64, disc_2(Fake)_a=40\n",
            ">1158, disc_1(Real)=0.609, disc_2(Fake)=0.718, gen_loss=0.771, disc_1(Real)_a=70, disc_2(Fake)_a=51\n",
            ">1159, disc_1(Real)=0.608, disc_2(Fake)=0.721, gen_loss=0.770, disc_1(Real)_a=71, disc_2(Fake)_a=51\n",
            ">1160, disc_1(Real)=0.570, disc_2(Fake)=0.787, gen_loss=0.807, disc_1(Real)_a=73, disc_2(Fake)_a=37\n",
            ">1161, disc_1(Real)=0.570, disc_2(Fake)=0.752, gen_loss=0.881, disc_1(Real)_a=78, disc_2(Fake)_a=40\n",
            ">1162, disc_1(Real)=0.614, disc_2(Fake)=0.636, gen_loss=0.889, disc_1(Real)_a=65, disc_2(Fake)_a=65\n",
            ">1163, disc_1(Real)=0.565, disc_2(Fake)=0.657, gen_loss=0.860, disc_1(Real)_a=68, disc_2(Fake)_a=59\n",
            ">1164, disc_1(Real)=0.546, disc_2(Fake)=0.657, gen_loss=0.885, disc_1(Real)_a=73, disc_2(Fake)_a=59\n",
            ">1165, disc_1(Real)=0.575, disc_2(Fake)=0.700, gen_loss=0.909, disc_1(Real)_a=70, disc_2(Fake)_a=50\n",
            ">1166, disc_1(Real)=0.560, disc_2(Fake)=0.576, gen_loss=0.914, disc_1(Real)_a=76, disc_2(Fake)_a=73\n",
            ">1167, disc_1(Real)=0.580, disc_2(Fake)=0.625, gen_loss=0.975, disc_1(Real)_a=67, disc_2(Fake)_a=65\n",
            ">1168, disc_1(Real)=0.582, disc_2(Fake)=0.630, gen_loss=0.957, disc_1(Real)_a=71, disc_2(Fake)_a=67\n",
            ">1169, disc_1(Real)=0.635, disc_2(Fake)=0.590, gen_loss=0.974, disc_1(Real)_a=59, disc_2(Fake)_a=75\n",
            ">1170, disc_1(Real)=0.567, disc_2(Fake)=0.588, gen_loss=1.018, disc_1(Real)_a=76, disc_2(Fake)_a=75\n",
            ">1171, disc_1(Real)=0.534, disc_2(Fake)=0.586, gen_loss=0.979, disc_1(Real)_a=75, disc_2(Fake)_a=78\n",
            ">1172, disc_1(Real)=0.572, disc_2(Fake)=0.563, gen_loss=1.046, disc_1(Real)_a=68, disc_2(Fake)_a=84\n",
            ">1173, disc_1(Real)=0.537, disc_2(Fake)=0.592, gen_loss=0.974, disc_1(Real)_a=76, disc_2(Fake)_a=73\n",
            ">1174, disc_1(Real)=0.585, disc_2(Fake)=0.566, gen_loss=0.968, disc_1(Real)_a=68, disc_2(Fake)_a=78\n",
            ">1175, disc_1(Real)=0.529, disc_2(Fake)=0.616, gen_loss=0.955, disc_1(Real)_a=82, disc_2(Fake)_a=68\n",
            ">1176, disc_1(Real)=0.594, disc_2(Fake)=0.582, gen_loss=0.974, disc_1(Real)_a=67, disc_2(Fake)_a=70\n",
            ">1177, disc_1(Real)=0.553, disc_2(Fake)=0.624, gen_loss=0.932, disc_1(Real)_a=78, disc_2(Fake)_a=62\n",
            ">1178, disc_1(Real)=0.529, disc_2(Fake)=0.614, gen_loss=0.931, disc_1(Real)_a=81, disc_2(Fake)_a=70\n",
            ">1179, disc_1(Real)=0.571, disc_2(Fake)=0.633, gen_loss=0.923, disc_1(Real)_a=75, disc_2(Fake)_a=62\n",
            ">1180, disc_1(Real)=0.593, disc_2(Fake)=0.631, gen_loss=0.915, disc_1(Real)_a=70, disc_2(Fake)_a=65\n",
            ">1181, disc_1(Real)=0.589, disc_2(Fake)=0.675, gen_loss=0.925, disc_1(Real)_a=75, disc_2(Fake)_a=51\n",
            ">1182, disc_1(Real)=0.522, disc_2(Fake)=0.625, gen_loss=0.924, disc_1(Real)_a=81, disc_2(Fake)_a=67\n",
            ">1183, disc_1(Real)=0.528, disc_2(Fake)=0.639, gen_loss=0.886, disc_1(Real)_a=76, disc_2(Fake)_a=67\n",
            ">1184, disc_1(Real)=0.596, disc_2(Fake)=0.661, gen_loss=0.914, disc_1(Real)_a=68, disc_2(Fake)_a=54\n",
            ">1185, disc_1(Real)=0.594, disc_2(Fake)=0.619, gen_loss=0.937, disc_1(Real)_a=60, disc_2(Fake)_a=67\n",
            ">1186, disc_1(Real)=0.599, disc_2(Fake)=0.615, gen_loss=0.947, disc_1(Real)_a=75, disc_2(Fake)_a=73\n",
            ">1187, disc_1(Real)=0.612, disc_2(Fake)=0.587, gen_loss=0.956, disc_1(Real)_a=67, disc_2(Fake)_a=82\n",
            ">1188, disc_1(Real)=0.602, disc_2(Fake)=0.615, gen_loss=0.962, disc_1(Real)_a=65, disc_2(Fake)_a=67\n",
            ">1189, disc_1(Real)=0.609, disc_2(Fake)=0.565, gen_loss=1.014, disc_1(Real)_a=73, disc_2(Fake)_a=81\n",
            ">1190, disc_1(Real)=0.584, disc_2(Fake)=0.543, gen_loss=1.056, disc_1(Real)_a=73, disc_2(Fake)_a=87\n",
            ">1191, disc_1(Real)=0.603, disc_2(Fake)=0.506, gen_loss=1.089, disc_1(Real)_a=71, disc_2(Fake)_a=95\n",
            ">1192, disc_1(Real)=0.551, disc_2(Fake)=0.485, gen_loss=1.166, disc_1(Real)_a=71, disc_2(Fake)_a=92\n",
            ">1193, disc_1(Real)=0.511, disc_2(Fake)=0.487, gen_loss=1.188, disc_1(Real)_a=85, disc_2(Fake)_a=95\n",
            ">1194, disc_1(Real)=0.545, disc_2(Fake)=0.448, gen_loss=1.168, disc_1(Real)_a=78, disc_2(Fake)_a=95\n",
            ">1195, disc_1(Real)=0.521, disc_2(Fake)=0.442, gen_loss=1.155, disc_1(Real)_a=76, disc_2(Fake)_a=96\n",
            ">1196, disc_1(Real)=0.496, disc_2(Fake)=0.472, gen_loss=1.217, disc_1(Real)_a=81, disc_2(Fake)_a=92\n",
            ">1197, disc_1(Real)=0.455, disc_2(Fake)=0.448, gen_loss=1.228, disc_1(Real)_a=87, disc_2(Fake)_a=96\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">1198, disc_1(Real)=0.447, disc_2(Fake)=0.413, gen_loss=1.225, disc_1(Real)_a=85, disc_2(Fake)_a=98\n",
            ">1199, disc_1(Real)=0.442, disc_2(Fake)=0.410, gen_loss=1.209, disc_1(Real)_a=89, disc_2(Fake)_a=92\n",
            ">1200, disc_1(Real)=0.448, disc_2(Fake)=0.441, gen_loss=1.292, disc_1(Real)_a=92, disc_2(Fake)_a=93\n",
            ">1201, disc_1(Real)=0.484, disc_2(Fake)=0.437, gen_loss=1.241, disc_1(Real)_a=85, disc_2(Fake)_a=95\n",
            ">1202, disc_1(Real)=0.438, disc_2(Fake)=0.450, gen_loss=1.202, disc_1(Real)_a=90, disc_2(Fake)_a=95\n",
            ">1203, disc_1(Real)=0.457, disc_2(Fake)=0.419, gen_loss=1.176, disc_1(Real)_a=85, disc_2(Fake)_a=100\n",
            ">1204, disc_1(Real)=0.504, disc_2(Fake)=0.482, gen_loss=1.131, disc_1(Real)_a=84, disc_2(Fake)_a=95\n",
            ">1205, disc_1(Real)=0.486, disc_2(Fake)=0.470, gen_loss=1.152, disc_1(Real)_a=90, disc_2(Fake)_a=96\n",
            ">1206, disc_1(Real)=0.498, disc_2(Fake)=0.459, gen_loss=1.107, disc_1(Real)_a=79, disc_2(Fake)_a=98\n",
            ">1207, disc_1(Real)=0.469, disc_2(Fake)=0.498, gen_loss=1.120, disc_1(Real)_a=82, disc_2(Fake)_a=89\n",
            ">1208, disc_1(Real)=0.564, disc_2(Fake)=0.474, gen_loss=1.122, disc_1(Real)_a=73, disc_2(Fake)_a=98\n",
            ">1209, disc_1(Real)=0.487, disc_2(Fake)=0.473, gen_loss=1.113, disc_1(Real)_a=82, disc_2(Fake)_a=96\n",
            ">1210, disc_1(Real)=0.532, disc_2(Fake)=0.489, gen_loss=1.039, disc_1(Real)_a=78, disc_2(Fake)_a=95\n",
            ">1211, disc_1(Real)=0.486, disc_2(Fake)=0.522, gen_loss=1.021, disc_1(Real)_a=82, disc_2(Fake)_a=90\n",
            ">1212, disc_1(Real)=0.480, disc_2(Fake)=0.546, gen_loss=1.102, disc_1(Real)_a=87, disc_2(Fake)_a=89\n",
            ">1213, disc_1(Real)=0.437, disc_2(Fake)=0.498, gen_loss=1.145, disc_1(Real)_a=84, disc_2(Fake)_a=93\n",
            ">1214, disc_1(Real)=0.495, disc_2(Fake)=0.483, gen_loss=1.185, disc_1(Real)_a=78, disc_2(Fake)_a=90\n",
            ">1215, disc_1(Real)=0.482, disc_2(Fake)=0.436, gen_loss=1.213, disc_1(Real)_a=79, disc_2(Fake)_a=95\n",
            ">1216, disc_1(Real)=0.493, disc_2(Fake)=0.467, gen_loss=1.217, disc_1(Real)_a=82, disc_2(Fake)_a=87\n",
            ">1217, disc_1(Real)=0.545, disc_2(Fake)=0.473, gen_loss=1.178, disc_1(Real)_a=73, disc_2(Fake)_a=93\n",
            ">1218, disc_1(Real)=0.519, disc_2(Fake)=0.453, gen_loss=1.261, disc_1(Real)_a=84, disc_2(Fake)_a=93\n",
            ">1219, disc_1(Real)=0.537, disc_2(Fake)=0.449, gen_loss=1.194, disc_1(Real)_a=73, disc_2(Fake)_a=93\n",
            ">1220, disc_1(Real)=0.498, disc_2(Fake)=0.469, gen_loss=1.163, disc_1(Real)_a=82, disc_2(Fake)_a=87\n",
            ">1221, disc_1(Real)=0.603, disc_2(Fake)=0.492, gen_loss=1.173, disc_1(Real)_a=64, disc_2(Fake)_a=81\n",
            ">1222, disc_1(Real)=0.528, disc_2(Fake)=0.497, gen_loss=1.150, disc_1(Real)_a=75, disc_2(Fake)_a=85\n",
            ">1223, disc_1(Real)=0.573, disc_2(Fake)=0.572, gen_loss=1.116, disc_1(Real)_a=75, disc_2(Fake)_a=75\n",
            ">1224, disc_1(Real)=0.619, disc_2(Fake)=0.501, gen_loss=1.150, disc_1(Real)_a=62, disc_2(Fake)_a=89\n",
            ">1225, disc_1(Real)=0.643, disc_2(Fake)=0.513, gen_loss=1.167, disc_1(Real)_a=59, disc_2(Fake)_a=89\n",
            ">1226, disc_1(Real)=0.706, disc_2(Fake)=0.492, gen_loss=1.193, disc_1(Real)_a=45, disc_2(Fake)_a=90\n",
            ">1227, disc_1(Real)=0.694, disc_2(Fake)=0.491, gen_loss=1.276, disc_1(Real)_a=57, disc_2(Fake)_a=96\n",
            ">1228, disc_1(Real)=0.733, disc_2(Fake)=0.450, gen_loss=1.249, disc_1(Real)_a=45, disc_2(Fake)_a=95\n",
            ">1229, disc_1(Real)=0.737, disc_2(Fake)=0.504, gen_loss=1.265, disc_1(Real)_a=46, disc_2(Fake)_a=82\n",
            ">1230, disc_1(Real)=0.719, disc_2(Fake)=0.488, gen_loss=1.323, disc_1(Real)_a=51, disc_2(Fake)_a=84\n",
            ">1231, disc_1(Real)=0.775, disc_2(Fake)=0.496, gen_loss=1.224, disc_1(Real)_a=43, disc_2(Fake)_a=79\n",
            ">1232, disc_1(Real)=0.749, disc_2(Fake)=0.595, gen_loss=1.128, disc_1(Real)_a=46, disc_2(Fake)_a=64\n",
            ">1233, disc_1(Real)=0.784, disc_2(Fake)=0.585, gen_loss=1.065, disc_1(Real)_a=35, disc_2(Fake)_a=67\n",
            ">1234, disc_1(Real)=0.699, disc_2(Fake)=0.605, gen_loss=1.022, disc_1(Real)_a=56, disc_2(Fake)_a=60\n",
            ">1235, disc_1(Real)=0.706, disc_2(Fake)=0.605, gen_loss=0.871, disc_1(Real)_a=54, disc_2(Fake)_a=73\n",
            ">1236, disc_1(Real)=0.691, disc_2(Fake)=0.768, gen_loss=0.829, disc_1(Real)_a=56, disc_2(Fake)_a=42\n",
            ">1237, disc_1(Real)=0.682, disc_2(Fake)=0.775, gen_loss=0.854, disc_1(Real)_a=56, disc_2(Fake)_a=42\n",
            ">1238, disc_1(Real)=0.750, disc_2(Fake)=0.861, gen_loss=0.820, disc_1(Real)_a=46, disc_2(Fake)_a=37\n",
            ">1239, disc_1(Real)=0.718, disc_2(Fake)=0.900, gen_loss=0.826, disc_1(Real)_a=51, disc_2(Fake)_a=43\n",
            ">1240, disc_1(Real)=0.788, disc_2(Fake)=0.943, gen_loss=0.796, disc_1(Real)_a=43, disc_2(Fake)_a=42\n",
            ">1241, disc_1(Real)=0.821, disc_2(Fake)=1.021, gen_loss=0.728, disc_1(Real)_a=40, disc_2(Fake)_a=35\n",
            ">1242, disc_1(Real)=0.830, disc_2(Fake)=1.092, gen_loss=0.682, disc_1(Real)_a=37, disc_2(Fake)_a=39\n",
            ">1243, disc_1(Real)=0.850, disc_2(Fake)=0.997, gen_loss=0.695, disc_1(Real)_a=31, disc_2(Fake)_a=48\n",
            ">1244, disc_1(Real)=0.891, disc_2(Fake)=1.287, gen_loss=0.590, disc_1(Real)_a=28, disc_2(Fake)_a=26\n",
            ">1245, disc_1(Real)=0.820, disc_2(Fake)=1.109, gen_loss=0.620, disc_1(Real)_a=37, disc_2(Fake)_a=45\n",
            ">1246, disc_1(Real)=0.893, disc_2(Fake)=1.287, gen_loss=0.551, disc_1(Real)_a=28, disc_2(Fake)_a=29\n",
            ">1247, disc_1(Real)=0.816, disc_2(Fake)=1.380, gen_loss=0.573, disc_1(Real)_a=42, disc_2(Fake)_a=32\n",
            ">1248, disc_1(Real)=0.908, disc_2(Fake)=1.279, gen_loss=0.565, disc_1(Real)_a=18, disc_2(Fake)_a=35\n",
            ">1249, disc_1(Real)=0.921, disc_2(Fake)=1.187, gen_loss=0.539, disc_1(Real)_a=31, disc_2(Fake)_a=32\n",
            ">1250, disc_1(Real)=0.868, disc_2(Fake)=1.374, gen_loss=0.550, disc_1(Real)_a=32, disc_2(Fake)_a=20\n",
            ">1251, disc_1(Real)=0.836, disc_2(Fake)=1.273, gen_loss=0.492, disc_1(Real)_a=37, disc_2(Fake)_a=17\n",
            ">1252, disc_1(Real)=0.881, disc_2(Fake)=1.322, gen_loss=0.515, disc_1(Real)_a=29, disc_2(Fake)_a=15\n",
            ">1253, disc_1(Real)=0.875, disc_2(Fake)=1.153, gen_loss=0.484, disc_1(Real)_a=29, disc_2(Fake)_a=21\n",
            ">1254, disc_1(Real)=0.825, disc_2(Fake)=1.204, gen_loss=0.476, disc_1(Real)_a=34, disc_2(Fake)_a=21\n",
            ">1255, disc_1(Real)=0.937, disc_2(Fake)=1.272, gen_loss=0.481, disc_1(Real)_a=21, disc_2(Fake)_a=6\n",
            ">1256, disc_1(Real)=0.866, disc_2(Fake)=1.228, gen_loss=0.482, disc_1(Real)_a=26, disc_2(Fake)_a=7\n",
            ">1257, disc_1(Real)=0.856, disc_2(Fake)=1.320, gen_loss=0.456, disc_1(Real)_a=21, disc_2(Fake)_a=6\n",
            ">1258, disc_1(Real)=0.810, disc_2(Fake)=1.166, gen_loss=0.451, disc_1(Real)_a=35, disc_2(Fake)_a=0\n",
            ">1259, disc_1(Real)=0.787, disc_2(Fake)=1.131, gen_loss=0.479, disc_1(Real)_a=42, disc_2(Fake)_a=0\n",
            ">1260, disc_1(Real)=0.726, disc_2(Fake)=1.037, gen_loss=0.471, disc_1(Real)_a=46, disc_2(Fake)_a=1\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">1261, disc_1(Real)=0.763, disc_2(Fake)=1.110, gen_loss=0.494, disc_1(Real)_a=43, disc_2(Fake)_a=0\n",
            ">1262, disc_1(Real)=0.730, disc_2(Fake)=1.112, gen_loss=0.489, disc_1(Real)_a=45, disc_2(Fake)_a=1\n",
            ">1263, disc_1(Real)=0.715, disc_2(Fake)=1.038, gen_loss=0.532, disc_1(Real)_a=54, disc_2(Fake)_a=1\n",
            ">1264, disc_1(Real)=0.722, disc_2(Fake)=0.999, gen_loss=0.540, disc_1(Real)_a=50, disc_2(Fake)_a=3\n",
            ">1265, disc_1(Real)=0.740, disc_2(Fake)=0.981, gen_loss=0.578, disc_1(Real)_a=46, disc_2(Fake)_a=0\n",
            ">1266, disc_1(Real)=0.691, disc_2(Fake)=0.887, gen_loss=0.603, disc_1(Real)_a=53, disc_2(Fake)_a=12\n",
            ">1267, disc_1(Real)=0.700, disc_2(Fake)=0.846, gen_loss=0.613, disc_1(Real)_a=51, disc_2(Fake)_a=17\n",
            ">1268, disc_1(Real)=0.723, disc_2(Fake)=0.848, gen_loss=0.629, disc_1(Real)_a=54, disc_2(Fake)_a=15\n",
            ">1269, disc_1(Real)=0.685, disc_2(Fake)=0.837, gen_loss=0.669, disc_1(Real)_a=56, disc_2(Fake)_a=17\n",
            ">1270, disc_1(Real)=0.622, disc_2(Fake)=0.778, gen_loss=0.694, disc_1(Real)_a=70, disc_2(Fake)_a=28\n",
            ">1271, disc_1(Real)=0.689, disc_2(Fake)=0.765, gen_loss=0.742, disc_1(Real)_a=48, disc_2(Fake)_a=28\n",
            ">1272, disc_1(Real)=0.741, disc_2(Fake)=0.752, gen_loss=0.765, disc_1(Real)_a=60, disc_2(Fake)_a=35\n",
            ">1273, disc_1(Real)=0.707, disc_2(Fake)=0.683, gen_loss=0.787, disc_1(Real)_a=54, disc_2(Fake)_a=53\n",
            ">1274, disc_1(Real)=0.626, disc_2(Fake)=0.650, gen_loss=0.820, disc_1(Real)_a=62, disc_2(Fake)_a=65\n",
            ">1275, disc_1(Real)=0.630, disc_2(Fake)=0.624, gen_loss=0.833, disc_1(Real)_a=62, disc_2(Fake)_a=79\n",
            ">1276, disc_1(Real)=0.607, disc_2(Fake)=0.631, gen_loss=0.900, disc_1(Real)_a=70, disc_2(Fake)_a=65\n",
            ">1277, disc_1(Real)=0.579, disc_2(Fake)=0.618, gen_loss=0.930, disc_1(Real)_a=68, disc_2(Fake)_a=75\n",
            ">1278, disc_1(Real)=0.572, disc_2(Fake)=0.610, gen_loss=0.901, disc_1(Real)_a=68, disc_2(Fake)_a=70\n",
            ">1279, disc_1(Real)=0.637, disc_2(Fake)=0.582, gen_loss=0.916, disc_1(Real)_a=60, disc_2(Fake)_a=76\n",
            ">1280, disc_1(Real)=0.528, disc_2(Fake)=0.626, gen_loss=0.911, disc_1(Real)_a=75, disc_2(Fake)_a=68\n",
            ">1281, disc_1(Real)=0.529, disc_2(Fake)=0.620, gen_loss=0.918, disc_1(Real)_a=81, disc_2(Fake)_a=68\n",
            ">1282, disc_1(Real)=0.523, disc_2(Fake)=0.673, gen_loss=0.808, disc_1(Real)_a=81, disc_2(Fake)_a=48\n",
            ">1283, disc_1(Real)=0.516, disc_2(Fake)=0.739, gen_loss=0.717, disc_1(Real)_a=84, disc_2(Fake)_a=39\n",
            ">1284, disc_1(Real)=0.555, disc_2(Fake)=0.888, gen_loss=0.662, disc_1(Real)_a=75, disc_2(Fake)_a=18\n",
            ">1285, disc_1(Real)=0.626, disc_2(Fake)=0.912, gen_loss=0.653, disc_1(Real)_a=67, disc_2(Fake)_a=15\n",
            ">1286, disc_1(Real)=0.638, disc_2(Fake)=0.888, gen_loss=0.683, disc_1(Real)_a=64, disc_2(Fake)_a=21\n",
            ">1287, disc_1(Real)=0.632, disc_2(Fake)=0.819, gen_loss=0.804, disc_1(Real)_a=65, disc_2(Fake)_a=20\n",
            ">1288, disc_1(Real)=0.616, disc_2(Fake)=0.638, gen_loss=0.973, disc_1(Real)_a=73, disc_2(Fake)_a=73\n",
            ">1289, disc_1(Real)=0.718, disc_2(Fake)=0.518, gen_loss=1.104, disc_1(Real)_a=53, disc_2(Fake)_a=98\n",
            ">1290, disc_1(Real)=0.714, disc_2(Fake)=0.446, gen_loss=1.232, disc_1(Real)_a=53, disc_2(Fake)_a=100\n",
            ">1291, disc_1(Real)=0.722, disc_2(Fake)=0.381, gen_loss=1.270, disc_1(Real)_a=46, disc_2(Fake)_a=100\n",
            ">1292, disc_1(Real)=0.689, disc_2(Fake)=0.396, gen_loss=1.315, disc_1(Real)_a=59, disc_2(Fake)_a=98\n",
            ">1293, disc_1(Real)=0.777, disc_2(Fake)=0.379, gen_loss=1.324, disc_1(Real)_a=46, disc_2(Fake)_a=98\n",
            ">1294, disc_1(Real)=0.709, disc_2(Fake)=0.375, gen_loss=1.278, disc_1(Real)_a=48, disc_2(Fake)_a=100\n",
            ">1295, disc_1(Real)=0.681, disc_2(Fake)=0.405, gen_loss=1.230, disc_1(Real)_a=62, disc_2(Fake)_a=96\n",
            ">1296, disc_1(Real)=0.765, disc_2(Fake)=0.417, gen_loss=1.170, disc_1(Real)_a=48, disc_2(Fake)_a=98\n",
            ">1297, disc_1(Real)=0.696, disc_2(Fake)=0.421, gen_loss=1.211, disc_1(Real)_a=53, disc_2(Fake)_a=93\n",
            ">1298, disc_1(Real)=0.676, disc_2(Fake)=0.451, gen_loss=1.140, disc_1(Real)_a=60, disc_2(Fake)_a=92\n",
            ">1299, disc_1(Real)=0.662, disc_2(Fake)=0.499, gen_loss=1.114, disc_1(Real)_a=65, disc_2(Fake)_a=87\n",
            ">1300, disc_1(Real)=0.558, disc_2(Fake)=0.498, gen_loss=1.098, disc_1(Real)_a=73, disc_2(Fake)_a=82\n",
            ">1301, disc_1(Real)=0.644, disc_2(Fake)=0.531, gen_loss=1.058, disc_1(Real)_a=60, disc_2(Fake)_a=85\n",
            ">1302, disc_1(Real)=0.728, disc_2(Fake)=0.532, gen_loss=1.001, disc_1(Real)_a=46, disc_2(Fake)_a=85\n",
            ">1303, disc_1(Real)=0.577, disc_2(Fake)=0.561, gen_loss=1.009, disc_1(Real)_a=73, disc_2(Fake)_a=76\n",
            ">1304, disc_1(Real)=0.614, disc_2(Fake)=0.562, gen_loss=0.977, disc_1(Real)_a=68, disc_2(Fake)_a=78\n",
            ">1305, disc_1(Real)=0.565, disc_2(Fake)=0.541, gen_loss=0.922, disc_1(Real)_a=70, disc_2(Fake)_a=89\n",
            ">1306, disc_1(Real)=0.615, disc_2(Fake)=0.582, gen_loss=0.936, disc_1(Real)_a=62, disc_2(Fake)_a=76\n",
            ">1307, disc_1(Real)=0.596, disc_2(Fake)=0.600, gen_loss=0.969, disc_1(Real)_a=70, disc_2(Fake)_a=68\n",
            ">1308, disc_1(Real)=0.523, disc_2(Fake)=0.593, gen_loss=0.868, disc_1(Real)_a=84, disc_2(Fake)_a=73\n",
            ">1309, disc_1(Real)=0.547, disc_2(Fake)=0.666, gen_loss=0.851, disc_1(Real)_a=76, disc_2(Fake)_a=56\n",
            ">1310, disc_1(Real)=0.531, disc_2(Fake)=0.701, gen_loss=0.818, disc_1(Real)_a=73, disc_2(Fake)_a=51\n",
            ">1311, disc_1(Real)=0.543, disc_2(Fake)=0.673, gen_loss=0.809, disc_1(Real)_a=71, disc_2(Fake)_a=53\n",
            ">1312, disc_1(Real)=0.554, disc_2(Fake)=0.706, gen_loss=0.830, disc_1(Real)_a=75, disc_2(Fake)_a=46\n",
            ">1313, disc_1(Real)=0.580, disc_2(Fake)=0.636, gen_loss=0.825, disc_1(Real)_a=68, disc_2(Fake)_a=70\n",
            ">1314, disc_1(Real)=0.627, disc_2(Fake)=0.644, gen_loss=0.898, disc_1(Real)_a=67, disc_2(Fake)_a=60\n",
            ">1315, disc_1(Real)=0.576, disc_2(Fake)=0.597, gen_loss=0.906, disc_1(Real)_a=79, disc_2(Fake)_a=85\n",
            ">1316, disc_1(Real)=0.545, disc_2(Fake)=0.546, gen_loss=1.011, disc_1(Real)_a=85, disc_2(Fake)_a=95\n",
            ">1317, disc_1(Real)=0.604, disc_2(Fake)=0.495, gen_loss=1.091, disc_1(Real)_a=75, disc_2(Fake)_a=98\n",
            ">1318, disc_1(Real)=0.582, disc_2(Fake)=0.460, gen_loss=1.174, disc_1(Real)_a=73, disc_2(Fake)_a=100\n",
            ">1319, disc_1(Real)=0.527, disc_2(Fake)=0.408, gen_loss=1.267, disc_1(Real)_a=87, disc_2(Fake)_a=100\n",
            ">1320, disc_1(Real)=0.519, disc_2(Fake)=0.353, gen_loss=1.393, disc_1(Real)_a=76, disc_2(Fake)_a=100\n",
            ">1321, disc_1(Real)=0.618, disc_2(Fake)=0.340, gen_loss=1.430, disc_1(Real)_a=64, disc_2(Fake)_a=100\n",
            ">1322, disc_1(Real)=0.548, disc_2(Fake)=0.316, gen_loss=1.443, disc_1(Real)_a=68, disc_2(Fake)_a=100\n",
            ">1323, disc_1(Real)=0.631, disc_2(Fake)=0.334, gen_loss=1.354, disc_1(Real)_a=62, disc_2(Fake)_a=98\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">1324, disc_1(Real)=0.508, disc_2(Fake)=0.334, gen_loss=1.388, disc_1(Real)_a=78, disc_2(Fake)_a=100\n",
            ">1325, disc_1(Real)=0.507, disc_2(Fake)=0.317, gen_loss=1.456, disc_1(Real)_a=79, disc_2(Fake)_a=100\n",
            ">1326, disc_1(Real)=0.524, disc_2(Fake)=0.372, gen_loss=1.415, disc_1(Real)_a=76, disc_2(Fake)_a=96\n",
            ">1327, disc_1(Real)=0.471, disc_2(Fake)=0.389, gen_loss=1.391, disc_1(Real)_a=85, disc_2(Fake)_a=96\n",
            ">1328, disc_1(Real)=0.542, disc_2(Fake)=0.364, gen_loss=1.262, disc_1(Real)_a=78, disc_2(Fake)_a=93\n",
            ">1329, disc_1(Real)=0.474, disc_2(Fake)=0.441, gen_loss=1.181, disc_1(Real)_a=75, disc_2(Fake)_a=87\n",
            ">1330, disc_1(Real)=0.507, disc_2(Fake)=0.503, gen_loss=1.097, disc_1(Real)_a=76, disc_2(Fake)_a=78\n",
            ">1331, disc_1(Real)=0.540, disc_2(Fake)=0.495, gen_loss=0.963, disc_1(Real)_a=70, disc_2(Fake)_a=89\n",
            ">1332, disc_1(Real)=0.478, disc_2(Fake)=0.689, gen_loss=0.863, disc_1(Real)_a=76, disc_2(Fake)_a=60\n",
            ">1333, disc_1(Real)=0.459, disc_2(Fake)=0.862, gen_loss=0.767, disc_1(Real)_a=84, disc_2(Fake)_a=34\n",
            ">1334, disc_1(Real)=0.476, disc_2(Fake)=0.977, gen_loss=0.670, disc_1(Real)_a=78, disc_2(Fake)_a=17\n",
            ">1335, disc_1(Real)=0.485, disc_2(Fake)=1.041, gen_loss=0.628, disc_1(Real)_a=82, disc_2(Fake)_a=14\n",
            ">1336, disc_1(Real)=0.575, disc_2(Fake)=0.918, gen_loss=0.687, disc_1(Real)_a=71, disc_2(Fake)_a=17\n",
            ">1337, disc_1(Real)=0.580, disc_2(Fake)=0.776, gen_loss=0.816, disc_1(Real)_a=75, disc_2(Fake)_a=40\n",
            ">1338, disc_1(Real)=0.612, disc_2(Fake)=0.667, gen_loss=0.972, disc_1(Real)_a=68, disc_2(Fake)_a=56\n",
            ">1339, disc_1(Real)=0.723, disc_2(Fake)=0.504, gen_loss=1.161, disc_1(Real)_a=48, disc_2(Fake)_a=96\n",
            ">1340, disc_1(Real)=0.685, disc_2(Fake)=0.439, gen_loss=1.247, disc_1(Real)_a=56, disc_2(Fake)_a=98\n",
            ">1341, disc_1(Real)=0.704, disc_2(Fake)=0.419, gen_loss=1.319, disc_1(Real)_a=50, disc_2(Fake)_a=100\n",
            ">1342, disc_1(Real)=0.778, disc_2(Fake)=0.405, gen_loss=1.286, disc_1(Real)_a=46, disc_2(Fake)_a=100\n",
            ">1343, disc_1(Real)=0.812, disc_2(Fake)=0.442, gen_loss=1.223, disc_1(Real)_a=42, disc_2(Fake)_a=93\n",
            ">1344, disc_1(Real)=0.643, disc_2(Fake)=0.423, gen_loss=1.223, disc_1(Real)_a=60, disc_2(Fake)_a=100\n",
            ">1345, disc_1(Real)=0.831, disc_2(Fake)=0.510, gen_loss=1.093, disc_1(Real)_a=48, disc_2(Fake)_a=85\n",
            ">1346, disc_1(Real)=0.761, disc_2(Fake)=0.601, gen_loss=0.971, disc_1(Real)_a=46, disc_2(Fake)_a=78\n",
            ">1347, disc_1(Real)=0.696, disc_2(Fake)=0.615, gen_loss=0.878, disc_1(Real)_a=60, disc_2(Fake)_a=65\n",
            ">1348, disc_1(Real)=0.776, disc_2(Fake)=0.689, gen_loss=0.799, disc_1(Real)_a=48, disc_2(Fake)_a=59\n",
            ">1349, disc_1(Real)=0.672, disc_2(Fake)=0.769, gen_loss=0.729, disc_1(Real)_a=57, disc_2(Fake)_a=45\n",
            ">1350, disc_1(Real)=0.836, disc_2(Fake)=0.900, gen_loss=0.661, disc_1(Real)_a=43, disc_2(Fake)_a=35\n",
            ">1351, disc_1(Real)=0.676, disc_2(Fake)=1.103, gen_loss=0.646, disc_1(Real)_a=54, disc_2(Fake)_a=25\n",
            ">1352, disc_1(Real)=0.765, disc_2(Fake)=1.002, gen_loss=0.547, disc_1(Real)_a=45, disc_2(Fake)_a=34\n",
            ">1353, disc_1(Real)=0.775, disc_2(Fake)=1.126, gen_loss=0.511, disc_1(Real)_a=51, disc_2(Fake)_a=21\n",
            ">1354, disc_1(Real)=0.713, disc_2(Fake)=1.166, gen_loss=0.548, disc_1(Real)_a=51, disc_2(Fake)_a=23\n",
            ">1355, disc_1(Real)=0.716, disc_2(Fake)=1.087, gen_loss=0.551, disc_1(Real)_a=51, disc_2(Fake)_a=29\n",
            ">1356, disc_1(Real)=0.749, disc_2(Fake)=1.001, gen_loss=0.592, disc_1(Real)_a=43, disc_2(Fake)_a=35\n",
            ">1357, disc_1(Real)=0.742, disc_2(Fake)=0.961, gen_loss=0.617, disc_1(Real)_a=50, disc_2(Fake)_a=32\n",
            ">1358, disc_1(Real)=0.722, disc_2(Fake)=0.835, gen_loss=0.656, disc_1(Real)_a=50, disc_2(Fake)_a=37\n",
            ">1359, disc_1(Real)=0.720, disc_2(Fake)=0.845, gen_loss=0.686, disc_1(Real)_a=46, disc_2(Fake)_a=34\n",
            ">1360, disc_1(Real)=0.724, disc_2(Fake)=0.837, gen_loss=0.693, disc_1(Real)_a=34, disc_2(Fake)_a=42\n",
            ">1361, disc_1(Real)=0.721, disc_2(Fake)=0.731, gen_loss=0.733, disc_1(Real)_a=48, disc_2(Fake)_a=40\n",
            ">1362, disc_1(Real)=0.788, disc_2(Fake)=0.683, gen_loss=0.704, disc_1(Real)_a=40, disc_2(Fake)_a=64\n",
            ">1363, disc_1(Real)=0.723, disc_2(Fake)=0.803, gen_loss=0.733, disc_1(Real)_a=51, disc_2(Fake)_a=34\n",
            ">1364, disc_1(Real)=0.665, disc_2(Fake)=0.738, gen_loss=0.734, disc_1(Real)_a=59, disc_2(Fake)_a=48\n",
            ">1365, disc_1(Real)=0.769, disc_2(Fake)=0.718, gen_loss=0.723, disc_1(Real)_a=35, disc_2(Fake)_a=53\n",
            ">1366, disc_1(Real)=0.737, disc_2(Fake)=0.747, gen_loss=0.726, disc_1(Real)_a=45, disc_2(Fake)_a=48\n",
            ">1367, disc_1(Real)=0.706, disc_2(Fake)=0.781, gen_loss=0.714, disc_1(Real)_a=45, disc_2(Fake)_a=40\n",
            ">1368, disc_1(Real)=0.732, disc_2(Fake)=0.746, gen_loss=0.751, disc_1(Real)_a=40, disc_2(Fake)_a=50\n",
            ">1369, disc_1(Real)=0.790, disc_2(Fake)=0.717, gen_loss=0.750, disc_1(Real)_a=35, disc_2(Fake)_a=56\n",
            ">1370, disc_1(Real)=0.712, disc_2(Fake)=0.747, gen_loss=0.699, disc_1(Real)_a=51, disc_2(Fake)_a=40\n",
            ">1371, disc_1(Real)=0.785, disc_2(Fake)=0.810, gen_loss=0.718, disc_1(Real)_a=43, disc_2(Fake)_a=32\n",
            ">1372, disc_1(Real)=0.730, disc_2(Fake)=0.772, gen_loss=0.738, disc_1(Real)_a=45, disc_2(Fake)_a=34\n",
            ">1373, disc_1(Real)=0.737, disc_2(Fake)=0.744, gen_loss=0.726, disc_1(Real)_a=43, disc_2(Fake)_a=40\n",
            ">1374, disc_1(Real)=0.779, disc_2(Fake)=0.687, gen_loss=0.737, disc_1(Real)_a=39, disc_2(Fake)_a=50\n",
            ">1375, disc_1(Real)=0.739, disc_2(Fake)=0.711, gen_loss=0.756, disc_1(Real)_a=35, disc_2(Fake)_a=42\n",
            ">1376, disc_1(Real)=0.738, disc_2(Fake)=0.651, gen_loss=0.810, disc_1(Real)_a=40, disc_2(Fake)_a=65\n",
            ">1377, disc_1(Real)=0.673, disc_2(Fake)=0.649, gen_loss=0.831, disc_1(Real)_a=60, disc_2(Fake)_a=73\n",
            ">1378, disc_1(Real)=0.792, disc_2(Fake)=0.598, gen_loss=0.862, disc_1(Real)_a=32, disc_2(Fake)_a=87\n",
            ">1379, disc_1(Real)=0.800, disc_2(Fake)=0.574, gen_loss=0.910, disc_1(Real)_a=37, disc_2(Fake)_a=84\n",
            ">1380, disc_1(Real)=0.814, disc_2(Fake)=0.562, gen_loss=0.908, disc_1(Real)_a=28, disc_2(Fake)_a=96\n",
            ">1381, disc_1(Real)=0.704, disc_2(Fake)=0.537, gen_loss=0.920, disc_1(Real)_a=51, disc_2(Fake)_a=98\n",
            ">1382, disc_1(Real)=0.711, disc_2(Fake)=0.525, gen_loss=0.954, disc_1(Real)_a=43, disc_2(Fake)_a=95\n",
            ">1383, disc_1(Real)=0.735, disc_2(Fake)=0.515, gen_loss=0.987, disc_1(Real)_a=42, disc_2(Fake)_a=95\n",
            ">1384, disc_1(Real)=0.731, disc_2(Fake)=0.527, gen_loss=0.994, disc_1(Real)_a=40, disc_2(Fake)_a=92\n",
            ">1385, disc_1(Real)=0.734, disc_2(Fake)=0.515, gen_loss=1.014, disc_1(Real)_a=40, disc_2(Fake)_a=95\n",
            ">1386, disc_1(Real)=0.770, disc_2(Fake)=0.496, gen_loss=1.069, disc_1(Real)_a=42, disc_2(Fake)_a=93\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">1387, disc_1(Real)=0.681, disc_2(Fake)=0.467, gen_loss=1.026, disc_1(Real)_a=51, disc_2(Fake)_a=96\n",
            ">1388, disc_1(Real)=0.674, disc_2(Fake)=0.472, gen_loss=1.051, disc_1(Real)_a=57, disc_2(Fake)_a=95\n",
            ">1389, disc_1(Real)=0.719, disc_2(Fake)=0.493, gen_loss=1.057, disc_1(Real)_a=46, disc_2(Fake)_a=92\n",
            ">1390, disc_1(Real)=0.756, disc_2(Fake)=0.490, gen_loss=1.022, disc_1(Real)_a=51, disc_2(Fake)_a=93\n",
            ">1391, disc_1(Real)=0.689, disc_2(Fake)=0.505, gen_loss=1.043, disc_1(Real)_a=50, disc_2(Fake)_a=89\n",
            ">1392, disc_1(Real)=0.642, disc_2(Fake)=0.481, gen_loss=1.058, disc_1(Real)_a=62, disc_2(Fake)_a=90\n",
            ">1393, disc_1(Real)=0.729, disc_2(Fake)=0.505, gen_loss=1.057, disc_1(Real)_a=57, disc_2(Fake)_a=87\n",
            ">1394, disc_1(Real)=0.634, disc_2(Fake)=0.516, gen_loss=1.029, disc_1(Real)_a=65, disc_2(Fake)_a=87\n",
            ">1395, disc_1(Real)=0.639, disc_2(Fake)=0.477, gen_loss=1.012, disc_1(Real)_a=60, disc_2(Fake)_a=93\n",
            ">1396, disc_1(Real)=0.630, disc_2(Fake)=0.503, gen_loss=1.032, disc_1(Real)_a=64, disc_2(Fake)_a=89\n",
            ">1397, disc_1(Real)=0.620, disc_2(Fake)=0.480, gen_loss=1.015, disc_1(Real)_a=57, disc_2(Fake)_a=89\n",
            ">1398, disc_1(Real)=0.630, disc_2(Fake)=0.510, gen_loss=0.996, disc_1(Real)_a=60, disc_2(Fake)_a=90\n",
            ">1399, disc_1(Real)=0.536, disc_2(Fake)=0.478, gen_loss=1.045, disc_1(Real)_a=70, disc_2(Fake)_a=90\n",
            ">1400, disc_1(Real)=0.649, disc_2(Fake)=0.461, gen_loss=1.030, disc_1(Real)_a=60, disc_2(Fake)_a=92\n",
            ">1401, disc_1(Real)=0.636, disc_2(Fake)=0.493, gen_loss=1.019, disc_1(Real)_a=59, disc_2(Fake)_a=87\n",
            ">1402, disc_1(Real)=0.569, disc_2(Fake)=0.463, gen_loss=1.042, disc_1(Real)_a=65, disc_2(Fake)_a=96\n",
            ">1403, disc_1(Real)=0.553, disc_2(Fake)=0.487, gen_loss=1.059, disc_1(Real)_a=65, disc_2(Fake)_a=90\n",
            ">1404, disc_1(Real)=0.516, disc_2(Fake)=0.497, gen_loss=1.064, disc_1(Real)_a=79, disc_2(Fake)_a=92\n",
            ">1405, disc_1(Real)=0.522, disc_2(Fake)=0.519, gen_loss=1.024, disc_1(Real)_a=71, disc_2(Fake)_a=81\n",
            ">1406, disc_1(Real)=0.593, disc_2(Fake)=0.496, gen_loss=1.048, disc_1(Real)_a=64, disc_2(Fake)_a=84\n",
            ">1407, disc_1(Real)=0.549, disc_2(Fake)=0.507, gen_loss=1.021, disc_1(Real)_a=71, disc_2(Fake)_a=89\n",
            ">1408, disc_1(Real)=0.512, disc_2(Fake)=0.495, gen_loss=1.044, disc_1(Real)_a=79, disc_2(Fake)_a=92\n",
            ">1409, disc_1(Real)=0.533, disc_2(Fake)=0.473, gen_loss=1.060, disc_1(Real)_a=76, disc_2(Fake)_a=92\n",
            ">1410, disc_1(Real)=0.560, disc_2(Fake)=0.504, gen_loss=1.059, disc_1(Real)_a=67, disc_2(Fake)_a=89\n",
            ">1411, disc_1(Real)=0.549, disc_2(Fake)=0.489, gen_loss=1.039, disc_1(Real)_a=82, disc_2(Fake)_a=92\n",
            ">1412, disc_1(Real)=0.523, disc_2(Fake)=0.507, gen_loss=1.064, disc_1(Real)_a=79, disc_2(Fake)_a=85\n",
            ">1413, disc_1(Real)=0.537, disc_2(Fake)=0.455, gen_loss=1.041, disc_1(Real)_a=81, disc_2(Fake)_a=96\n",
            ">1414, disc_1(Real)=0.518, disc_2(Fake)=0.472, gen_loss=1.059, disc_1(Real)_a=85, disc_2(Fake)_a=93\n",
            ">1415, disc_1(Real)=0.521, disc_2(Fake)=0.480, gen_loss=1.074, disc_1(Real)_a=79, disc_2(Fake)_a=90\n",
            ">1416, disc_1(Real)=0.520, disc_2(Fake)=0.452, gen_loss=1.055, disc_1(Real)_a=78, disc_2(Fake)_a=98\n",
            ">1417, disc_1(Real)=0.524, disc_2(Fake)=0.476, gen_loss=1.054, disc_1(Real)_a=75, disc_2(Fake)_a=95\n",
            ">1418, disc_1(Real)=0.508, disc_2(Fake)=0.478, gen_loss=1.085, disc_1(Real)_a=84, disc_2(Fake)_a=96\n",
            ">1419, disc_1(Real)=0.525, disc_2(Fake)=0.467, gen_loss=1.054, disc_1(Real)_a=84, disc_2(Fake)_a=96\n",
            ">1420, disc_1(Real)=0.539, disc_2(Fake)=0.494, gen_loss=1.072, disc_1(Real)_a=75, disc_2(Fake)_a=93\n",
            ">1421, disc_1(Real)=0.507, disc_2(Fake)=0.498, gen_loss=1.088, disc_1(Real)_a=81, disc_2(Fake)_a=96\n",
            ">1422, disc_1(Real)=0.540, disc_2(Fake)=0.483, gen_loss=1.064, disc_1(Real)_a=79, disc_2(Fake)_a=93\n",
            ">1423, disc_1(Real)=0.600, disc_2(Fake)=0.458, gen_loss=1.046, disc_1(Real)_a=67, disc_2(Fake)_a=98\n",
            ">1424, disc_1(Real)=0.560, disc_2(Fake)=0.486, gen_loss=1.034, disc_1(Real)_a=73, disc_2(Fake)_a=100\n",
            ">1425, disc_1(Real)=0.548, disc_2(Fake)=0.503, gen_loss=0.989, disc_1(Real)_a=76, disc_2(Fake)_a=98\n",
            ">1426, disc_1(Real)=0.527, disc_2(Fake)=0.493, gen_loss=1.026, disc_1(Real)_a=87, disc_2(Fake)_a=95\n",
            ">1427, disc_1(Real)=0.563, disc_2(Fake)=0.485, gen_loss=1.017, disc_1(Real)_a=78, disc_2(Fake)_a=100\n",
            ">1428, disc_1(Real)=0.555, disc_2(Fake)=0.496, gen_loss=1.021, disc_1(Real)_a=75, disc_2(Fake)_a=92\n",
            ">1429, disc_1(Real)=0.613, disc_2(Fake)=0.498, gen_loss=1.018, disc_1(Real)_a=60, disc_2(Fake)_a=95\n",
            ">1430, disc_1(Real)=0.524, disc_2(Fake)=0.487, gen_loss=1.022, disc_1(Real)_a=82, disc_2(Fake)_a=92\n",
            ">1431, disc_1(Real)=0.599, disc_2(Fake)=0.526, gen_loss=1.027, disc_1(Real)_a=65, disc_2(Fake)_a=92\n",
            ">1432, disc_1(Real)=0.576, disc_2(Fake)=0.476, gen_loss=1.062, disc_1(Real)_a=73, disc_2(Fake)_a=100\n",
            ">1433, disc_1(Real)=0.543, disc_2(Fake)=0.478, gen_loss=1.027, disc_1(Real)_a=79, disc_2(Fake)_a=98\n",
            ">1434, disc_1(Real)=0.608, disc_2(Fake)=0.486, gen_loss=1.040, disc_1(Real)_a=64, disc_2(Fake)_a=95\n",
            ">1435, disc_1(Real)=0.565, disc_2(Fake)=0.470, gen_loss=1.035, disc_1(Real)_a=78, disc_2(Fake)_a=96\n",
            ">1436, disc_1(Real)=0.607, disc_2(Fake)=0.482, gen_loss=1.053, disc_1(Real)_a=62, disc_2(Fake)_a=96\n",
            ">1437, disc_1(Real)=0.584, disc_2(Fake)=0.496, gen_loss=1.014, disc_1(Real)_a=76, disc_2(Fake)_a=90\n",
            ">1438, disc_1(Real)=0.597, disc_2(Fake)=0.500, gen_loss=1.017, disc_1(Real)_a=68, disc_2(Fake)_a=90\n",
            ">1439, disc_1(Real)=0.565, disc_2(Fake)=0.520, gen_loss=0.997, disc_1(Real)_a=68, disc_2(Fake)_a=87\n",
            ">1440, disc_1(Real)=0.608, disc_2(Fake)=0.506, gen_loss=0.983, disc_1(Real)_a=62, disc_2(Fake)_a=92\n",
            ">1441, disc_1(Real)=0.669, disc_2(Fake)=0.534, gen_loss=0.997, disc_1(Real)_a=59, disc_2(Fake)_a=82\n",
            ">1442, disc_1(Real)=0.626, disc_2(Fake)=0.534, gen_loss=1.023, disc_1(Real)_a=64, disc_2(Fake)_a=79\n",
            ">1443, disc_1(Real)=0.632, disc_2(Fake)=0.562, gen_loss=1.018, disc_1(Real)_a=64, disc_2(Fake)_a=71\n",
            ">1444, disc_1(Real)=0.622, disc_2(Fake)=0.559, gen_loss=1.047, disc_1(Real)_a=65, disc_2(Fake)_a=75\n",
            ">1445, disc_1(Real)=0.633, disc_2(Fake)=0.554, gen_loss=1.060, disc_1(Real)_a=64, disc_2(Fake)_a=73\n",
            ">1446, disc_1(Real)=0.639, disc_2(Fake)=0.556, gen_loss=1.129, disc_1(Real)_a=59, disc_2(Fake)_a=78\n",
            ">1447, disc_1(Real)=0.637, disc_2(Fake)=0.547, gen_loss=1.102, disc_1(Real)_a=60, disc_2(Fake)_a=73\n",
            ">1448, disc_1(Real)=0.686, disc_2(Fake)=0.506, gen_loss=1.094, disc_1(Real)_a=57, disc_2(Fake)_a=78\n",
            ">1449, disc_1(Real)=0.660, disc_2(Fake)=0.533, gen_loss=1.196, disc_1(Real)_a=60, disc_2(Fake)_a=76\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">1450, disc_1(Real)=0.666, disc_2(Fake)=0.488, gen_loss=1.135, disc_1(Real)_a=57, disc_2(Fake)_a=79\n",
            ">1451, disc_1(Real)=0.630, disc_2(Fake)=0.523, gen_loss=1.030, disc_1(Real)_a=59, disc_2(Fake)_a=84\n",
            ">1452, disc_1(Real)=0.625, disc_2(Fake)=0.511, gen_loss=1.087, disc_1(Real)_a=70, disc_2(Fake)_a=82\n",
            ">1453, disc_1(Real)=0.627, disc_2(Fake)=0.524, gen_loss=1.074, disc_1(Real)_a=62, disc_2(Fake)_a=78\n",
            ">1454, disc_1(Real)=0.582, disc_2(Fake)=0.525, gen_loss=1.048, disc_1(Real)_a=76, disc_2(Fake)_a=81\n",
            ">1455, disc_1(Real)=0.636, disc_2(Fake)=0.534, gen_loss=1.064, disc_1(Real)_a=65, disc_2(Fake)_a=68\n",
            ">1456, disc_1(Real)=0.671, disc_2(Fake)=0.561, gen_loss=1.009, disc_1(Real)_a=62, disc_2(Fake)_a=71\n",
            ">1457, disc_1(Real)=0.594, disc_2(Fake)=0.544, gen_loss=1.016, disc_1(Real)_a=73, disc_2(Fake)_a=81\n",
            ">1458, disc_1(Real)=0.632, disc_2(Fake)=0.548, gen_loss=1.051, disc_1(Real)_a=60, disc_2(Fake)_a=75\n",
            ">1459, disc_1(Real)=0.609, disc_2(Fake)=0.520, gen_loss=0.985, disc_1(Real)_a=73, disc_2(Fake)_a=85\n",
            ">1460, disc_1(Real)=0.666, disc_2(Fake)=0.544, gen_loss=0.989, disc_1(Real)_a=60, disc_2(Fake)_a=76\n",
            ">1461, disc_1(Real)=0.596, disc_2(Fake)=0.563, gen_loss=1.004, disc_1(Real)_a=75, disc_2(Fake)_a=79\n",
            ">1462, disc_1(Real)=0.644, disc_2(Fake)=0.620, gen_loss=0.934, disc_1(Real)_a=70, disc_2(Fake)_a=64\n",
            ">1463, disc_1(Real)=0.659, disc_2(Fake)=0.605, gen_loss=0.891, disc_1(Real)_a=64, disc_2(Fake)_a=64\n",
            ">1464, disc_1(Real)=0.575, disc_2(Fake)=0.596, gen_loss=0.913, disc_1(Real)_a=76, disc_2(Fake)_a=70\n",
            ">1465, disc_1(Real)=0.648, disc_2(Fake)=0.538, gen_loss=0.921, disc_1(Real)_a=60, disc_2(Fake)_a=76\n",
            ">1466, disc_1(Real)=0.636, disc_2(Fake)=0.677, gen_loss=0.909, disc_1(Real)_a=73, disc_2(Fake)_a=65\n",
            ">1467, disc_1(Real)=0.648, disc_2(Fake)=0.622, gen_loss=0.912, disc_1(Real)_a=56, disc_2(Fake)_a=67\n",
            ">1468, disc_1(Real)=0.613, disc_2(Fake)=0.610, gen_loss=0.987, disc_1(Real)_a=75, disc_2(Fake)_a=68\n",
            ">1469, disc_1(Real)=0.675, disc_2(Fake)=0.573, gen_loss=0.989, disc_1(Real)_a=64, disc_2(Fake)_a=67\n",
            ">1470, disc_1(Real)=0.648, disc_2(Fake)=0.612, gen_loss=0.959, disc_1(Real)_a=65, disc_2(Fake)_a=67\n",
            ">1471, disc_1(Real)=0.684, disc_2(Fake)=0.566, gen_loss=0.953, disc_1(Real)_a=54, disc_2(Fake)_a=73\n",
            ">1472, disc_1(Real)=0.603, disc_2(Fake)=0.613, gen_loss=0.942, disc_1(Real)_a=76, disc_2(Fake)_a=65\n",
            ">1473, disc_1(Real)=0.632, disc_2(Fake)=0.641, gen_loss=0.900, disc_1(Real)_a=65, disc_2(Fake)_a=62\n",
            ">1474, disc_1(Real)=0.660, disc_2(Fake)=0.693, gen_loss=0.885, disc_1(Real)_a=59, disc_2(Fake)_a=54\n",
            ">1475, disc_1(Real)=0.626, disc_2(Fake)=0.700, gen_loss=0.903, disc_1(Real)_a=73, disc_2(Fake)_a=60\n",
            ">1476, disc_1(Real)=0.693, disc_2(Fake)=0.595, gen_loss=0.897, disc_1(Real)_a=70, disc_2(Fake)_a=75\n",
            ">1477, disc_1(Real)=0.667, disc_2(Fake)=0.585, gen_loss=0.913, disc_1(Real)_a=57, disc_2(Fake)_a=71\n",
            ">1478, disc_1(Real)=0.606, disc_2(Fake)=0.689, gen_loss=0.862, disc_1(Real)_a=78, disc_2(Fake)_a=62\n",
            ">1479, disc_1(Real)=0.687, disc_2(Fake)=0.705, gen_loss=0.911, disc_1(Real)_a=51, disc_2(Fake)_a=53\n",
            ">1480, disc_1(Real)=0.669, disc_2(Fake)=0.661, gen_loss=0.953, disc_1(Real)_a=62, disc_2(Fake)_a=62\n",
            ">1481, disc_1(Real)=0.633, disc_2(Fake)=0.676, gen_loss=0.921, disc_1(Real)_a=62, disc_2(Fake)_a=54\n",
            ">1482, disc_1(Real)=0.717, disc_2(Fake)=0.663, gen_loss=0.874, disc_1(Real)_a=56, disc_2(Fake)_a=60\n",
            ">1483, disc_1(Real)=0.656, disc_2(Fake)=0.660, gen_loss=0.934, disc_1(Real)_a=59, disc_2(Fake)_a=62\n",
            ">1484, disc_1(Real)=0.648, disc_2(Fake)=0.599, gen_loss=0.870, disc_1(Real)_a=64, disc_2(Fake)_a=67\n",
            ">1485, disc_1(Real)=0.680, disc_2(Fake)=0.697, gen_loss=0.910, disc_1(Real)_a=62, disc_2(Fake)_a=53\n",
            ">1486, disc_1(Real)=0.689, disc_2(Fake)=0.672, gen_loss=0.902, disc_1(Real)_a=57, disc_2(Fake)_a=56\n",
            ">1487, disc_1(Real)=0.625, disc_2(Fake)=0.667, gen_loss=0.892, disc_1(Real)_a=67, disc_2(Fake)_a=62\n",
            ">1488, disc_1(Real)=0.662, disc_2(Fake)=0.665, gen_loss=0.874, disc_1(Real)_a=53, disc_2(Fake)_a=59\n",
            ">1489, disc_1(Real)=0.750, disc_2(Fake)=0.709, gen_loss=0.910, disc_1(Real)_a=50, disc_2(Fake)_a=56\n",
            ">1490, disc_1(Real)=0.658, disc_2(Fake)=0.632, gen_loss=0.857, disc_1(Real)_a=64, disc_2(Fake)_a=68\n",
            ">1491, disc_1(Real)=0.674, disc_2(Fake)=0.647, gen_loss=0.874, disc_1(Real)_a=62, disc_2(Fake)_a=67\n",
            ">1492, disc_1(Real)=0.684, disc_2(Fake)=0.668, gen_loss=0.814, disc_1(Real)_a=57, disc_2(Fake)_a=67\n",
            ">1493, disc_1(Real)=0.757, disc_2(Fake)=0.719, gen_loss=0.824, disc_1(Real)_a=54, disc_2(Fake)_a=48\n",
            ">1494, disc_1(Real)=0.655, disc_2(Fake)=0.639, gen_loss=0.843, disc_1(Real)_a=56, disc_2(Fake)_a=62\n",
            ">1495, disc_1(Real)=0.650, disc_2(Fake)=0.674, gen_loss=0.829, disc_1(Real)_a=57, disc_2(Fake)_a=65\n",
            ">1496, disc_1(Real)=0.603, disc_2(Fake)=0.695, gen_loss=0.829, disc_1(Real)_a=75, disc_2(Fake)_a=60\n",
            ">1497, disc_1(Real)=0.691, disc_2(Fake)=0.614, gen_loss=0.841, disc_1(Real)_a=62, disc_2(Fake)_a=71\n",
            ">1498, disc_1(Real)=0.637, disc_2(Fake)=0.664, gen_loss=0.876, disc_1(Real)_a=57, disc_2(Fake)_a=62\n",
            ">1499, disc_1(Real)=0.654, disc_2(Fake)=0.709, gen_loss=0.879, disc_1(Real)_a=65, disc_2(Fake)_a=60\n",
            ">1500, disc_1(Real)=0.689, disc_2(Fake)=0.747, gen_loss=0.852, disc_1(Real)_a=59, disc_2(Fake)_a=46\n",
            ">1501, disc_1(Real)=0.616, disc_2(Fake)=0.630, gen_loss=0.846, disc_1(Real)_a=68, disc_2(Fake)_a=62\n",
            ">1502, disc_1(Real)=0.720, disc_2(Fake)=0.631, gen_loss=0.899, disc_1(Real)_a=45, disc_2(Fake)_a=68\n",
            ">1503, disc_1(Real)=0.650, disc_2(Fake)=0.583, gen_loss=0.888, disc_1(Real)_a=54, disc_2(Fake)_a=76\n",
            ">1504, disc_1(Real)=0.621, disc_2(Fake)=0.639, gen_loss=0.901, disc_1(Real)_a=71, disc_2(Fake)_a=59\n",
            ">1505, disc_1(Real)=0.644, disc_2(Fake)=0.568, gen_loss=0.914, disc_1(Real)_a=64, disc_2(Fake)_a=76\n",
            ">1506, disc_1(Real)=0.755, disc_2(Fake)=0.556, gen_loss=0.902, disc_1(Real)_a=53, disc_2(Fake)_a=85\n",
            ">1507, disc_1(Real)=0.636, disc_2(Fake)=0.561, gen_loss=0.929, disc_1(Real)_a=65, disc_2(Fake)_a=78\n",
            ">1508, disc_1(Real)=0.688, disc_2(Fake)=0.576, gen_loss=0.930, disc_1(Real)_a=60, disc_2(Fake)_a=81\n",
            ">1509, disc_1(Real)=0.670, disc_2(Fake)=0.578, gen_loss=0.901, disc_1(Real)_a=59, disc_2(Fake)_a=78\n",
            ">1510, disc_1(Real)=0.597, disc_2(Fake)=0.517, gen_loss=0.920, disc_1(Real)_a=71, disc_2(Fake)_a=90\n",
            ">1511, disc_1(Real)=0.606, disc_2(Fake)=0.587, gen_loss=0.914, disc_1(Real)_a=70, disc_2(Fake)_a=78\n",
            ">1512, disc_1(Real)=0.642, disc_2(Fake)=0.551, gen_loss=0.941, disc_1(Real)_a=68, disc_2(Fake)_a=85\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">1513, disc_1(Real)=0.607, disc_2(Fake)=0.517, gen_loss=0.974, disc_1(Real)_a=71, disc_2(Fake)_a=90\n",
            ">1514, disc_1(Real)=0.566, disc_2(Fake)=0.546, gen_loss=1.005, disc_1(Real)_a=76, disc_2(Fake)_a=81\n",
            ">1515, disc_1(Real)=0.586, disc_2(Fake)=0.504, gen_loss=1.029, disc_1(Real)_a=78, disc_2(Fake)_a=93\n",
            ">1516, disc_1(Real)=0.596, disc_2(Fake)=0.458, gen_loss=1.076, disc_1(Real)_a=70, disc_2(Fake)_a=93\n",
            ">1517, disc_1(Real)=0.644, disc_2(Fake)=0.477, gen_loss=1.057, disc_1(Real)_a=64, disc_2(Fake)_a=95\n",
            ">1518, disc_1(Real)=0.616, disc_2(Fake)=0.476, gen_loss=1.076, disc_1(Real)_a=67, disc_2(Fake)_a=100\n",
            ">1519, disc_1(Real)=0.593, disc_2(Fake)=0.480, gen_loss=1.055, disc_1(Real)_a=70, disc_2(Fake)_a=96\n",
            ">1520, disc_1(Real)=0.534, disc_2(Fake)=0.461, gen_loss=1.096, disc_1(Real)_a=82, disc_2(Fake)_a=98\n",
            ">1521, disc_1(Real)=0.591, disc_2(Fake)=0.466, gen_loss=1.119, disc_1(Real)_a=70, disc_2(Fake)_a=98\n",
            ">1522, disc_1(Real)=0.583, disc_2(Fake)=0.459, gen_loss=1.098, disc_1(Real)_a=73, disc_2(Fake)_a=98\n",
            ">1523, disc_1(Real)=0.591, disc_2(Fake)=0.450, gen_loss=1.138, disc_1(Real)_a=75, disc_2(Fake)_a=100\n",
            ">1524, disc_1(Real)=0.603, disc_2(Fake)=0.442, gen_loss=1.132, disc_1(Real)_a=67, disc_2(Fake)_a=100\n",
            ">1525, disc_1(Real)=0.545, disc_2(Fake)=0.432, gen_loss=1.150, disc_1(Real)_a=76, disc_2(Fake)_a=100\n",
            ">1526, disc_1(Real)=0.589, disc_2(Fake)=0.433, gen_loss=1.158, disc_1(Real)_a=73, disc_2(Fake)_a=100\n",
            ">1527, disc_1(Real)=0.556, disc_2(Fake)=0.425, gen_loss=1.164, disc_1(Real)_a=81, disc_2(Fake)_a=100\n",
            ">1528, disc_1(Real)=0.503, disc_2(Fake)=0.404, gen_loss=1.192, disc_1(Real)_a=78, disc_2(Fake)_a=100\n",
            ">1529, disc_1(Real)=0.603, disc_2(Fake)=0.420, gen_loss=1.177, disc_1(Real)_a=65, disc_2(Fake)_a=100\n",
            ">1530, disc_1(Real)=0.544, disc_2(Fake)=0.428, gen_loss=1.218, disc_1(Real)_a=78, disc_2(Fake)_a=100\n",
            ">1531, disc_1(Real)=0.576, disc_2(Fake)=0.410, gen_loss=1.216, disc_1(Real)_a=70, disc_2(Fake)_a=100\n",
            ">1532, disc_1(Real)=0.570, disc_2(Fake)=0.391, gen_loss=1.242, disc_1(Real)_a=75, disc_2(Fake)_a=100\n",
            ">1533, disc_1(Real)=0.604, disc_2(Fake)=0.391, gen_loss=1.236, disc_1(Real)_a=73, disc_2(Fake)_a=100\n",
            ">1534, disc_1(Real)=0.552, disc_2(Fake)=0.392, gen_loss=1.208, disc_1(Real)_a=76, disc_2(Fake)_a=100\n",
            ">1535, disc_1(Real)=0.563, disc_2(Fake)=0.413, gen_loss=1.211, disc_1(Real)_a=81, disc_2(Fake)_a=100\n",
            ">1536, disc_1(Real)=0.594, disc_2(Fake)=0.407, gen_loss=1.231, disc_1(Real)_a=67, disc_2(Fake)_a=100\n",
            ">1537, disc_1(Real)=0.528, disc_2(Fake)=0.403, gen_loss=1.246, disc_1(Real)_a=81, disc_2(Fake)_a=100\n",
            ">1538, disc_1(Real)=0.619, disc_2(Fake)=0.390, gen_loss=1.225, disc_1(Real)_a=70, disc_2(Fake)_a=100\n",
            ">1539, disc_1(Real)=0.575, disc_2(Fake)=0.408, gen_loss=1.249, disc_1(Real)_a=79, disc_2(Fake)_a=100\n",
            ">1540, disc_1(Real)=0.582, disc_2(Fake)=0.406, gen_loss=1.256, disc_1(Real)_a=78, disc_2(Fake)_a=98\n",
            ">1541, disc_1(Real)=0.571, disc_2(Fake)=0.403, gen_loss=1.277, disc_1(Real)_a=73, disc_2(Fake)_a=100\n",
            ">1542, disc_1(Real)=0.559, disc_2(Fake)=0.401, gen_loss=1.283, disc_1(Real)_a=76, disc_2(Fake)_a=98\n",
            ">1543, disc_1(Real)=0.625, disc_2(Fake)=0.377, gen_loss=1.269, disc_1(Real)_a=68, disc_2(Fake)_a=100\n",
            ">1544, disc_1(Real)=0.630, disc_2(Fake)=0.397, gen_loss=1.239, disc_1(Real)_a=60, disc_2(Fake)_a=100\n",
            ">1545, disc_1(Real)=0.599, disc_2(Fake)=0.412, gen_loss=1.242, disc_1(Real)_a=75, disc_2(Fake)_a=100\n",
            ">1546, disc_1(Real)=0.585, disc_2(Fake)=0.412, gen_loss=1.228, disc_1(Real)_a=73, disc_2(Fake)_a=100\n",
            ">1547, disc_1(Real)=0.632, disc_2(Fake)=0.424, gen_loss=1.228, disc_1(Real)_a=67, disc_2(Fake)_a=98\n",
            ">1548, disc_1(Real)=0.558, disc_2(Fake)=0.398, gen_loss=1.232, disc_1(Real)_a=75, disc_2(Fake)_a=100\n",
            ">1549, disc_1(Real)=0.567, disc_2(Fake)=0.424, gen_loss=1.260, disc_1(Real)_a=68, disc_2(Fake)_a=100\n",
            ">1550, disc_1(Real)=0.559, disc_2(Fake)=0.403, gen_loss=1.267, disc_1(Real)_a=78, disc_2(Fake)_a=100\n",
            ">1551, disc_1(Real)=0.564, disc_2(Fake)=0.399, gen_loss=1.303, disc_1(Real)_a=79, disc_2(Fake)_a=98\n",
            ">1552, disc_1(Real)=0.614, disc_2(Fake)=0.410, gen_loss=1.249, disc_1(Real)_a=71, disc_2(Fake)_a=96\n",
            ">1553, disc_1(Real)=0.613, disc_2(Fake)=0.422, gen_loss=1.253, disc_1(Real)_a=65, disc_2(Fake)_a=96\n",
            ">1554, disc_1(Real)=0.671, disc_2(Fake)=0.469, gen_loss=1.191, disc_1(Real)_a=57, disc_2(Fake)_a=93\n",
            ">1555, disc_1(Real)=0.658, disc_2(Fake)=0.449, gen_loss=1.202, disc_1(Real)_a=67, disc_2(Fake)_a=96\n",
            ">1556, disc_1(Real)=0.636, disc_2(Fake)=0.474, gen_loss=1.241, disc_1(Real)_a=57, disc_2(Fake)_a=89\n",
            ">1557, disc_1(Real)=0.614, disc_2(Fake)=0.408, gen_loss=1.183, disc_1(Real)_a=70, disc_2(Fake)_a=98\n",
            ">1558, disc_1(Real)=0.671, disc_2(Fake)=0.461, gen_loss=1.219, disc_1(Real)_a=60, disc_2(Fake)_a=92\n",
            ">1559, disc_1(Real)=0.647, disc_2(Fake)=0.462, gen_loss=1.143, disc_1(Real)_a=65, disc_2(Fake)_a=90\n",
            ">1560, disc_1(Real)=0.679, disc_2(Fake)=0.487, gen_loss=1.159, disc_1(Real)_a=64, disc_2(Fake)_a=90\n",
            ">1561, disc_1(Real)=0.700, disc_2(Fake)=0.498, gen_loss=1.168, disc_1(Real)_a=60, disc_2(Fake)_a=85\n",
            ">1562, disc_1(Real)=0.661, disc_2(Fake)=0.472, gen_loss=1.098, disc_1(Real)_a=65, disc_2(Fake)_a=84\n",
            ">1563, disc_1(Real)=0.686, disc_2(Fake)=0.539, gen_loss=1.155, disc_1(Real)_a=54, disc_2(Fake)_a=78\n",
            ">1564, disc_1(Real)=0.698, disc_2(Fake)=0.574, gen_loss=1.084, disc_1(Real)_a=51, disc_2(Fake)_a=71\n",
            ">1565, disc_1(Real)=0.715, disc_2(Fake)=0.626, gen_loss=1.135, disc_1(Real)_a=56, disc_2(Fake)_a=68\n",
            ">1566, disc_1(Real)=0.720, disc_2(Fake)=0.576, gen_loss=1.118, disc_1(Real)_a=53, disc_2(Fake)_a=76\n",
            ">1567, disc_1(Real)=0.716, disc_2(Fake)=0.569, gen_loss=1.137, disc_1(Real)_a=51, disc_2(Fake)_a=75\n",
            ">1568, disc_1(Real)=0.802, disc_2(Fake)=0.555, gen_loss=1.049, disc_1(Real)_a=48, disc_2(Fake)_a=73\n",
            ">1569, disc_1(Real)=0.767, disc_2(Fake)=0.576, gen_loss=1.041, disc_1(Real)_a=53, disc_2(Fake)_a=78\n",
            ">1570, disc_1(Real)=0.813, disc_2(Fake)=0.626, gen_loss=0.969, disc_1(Real)_a=50, disc_2(Fake)_a=67\n",
            ">1571, disc_1(Real)=0.746, disc_2(Fake)=0.604, gen_loss=0.963, disc_1(Real)_a=53, disc_2(Fake)_a=70\n",
            ">1572, disc_1(Real)=0.652, disc_2(Fake)=0.605, gen_loss=1.038, disc_1(Real)_a=53, disc_2(Fake)_a=68\n",
            ">1573, disc_1(Real)=0.638, disc_2(Fake)=0.599, gen_loss=1.065, disc_1(Real)_a=68, disc_2(Fake)_a=75\n",
            ">1574, disc_1(Real)=0.716, disc_2(Fake)=0.507, gen_loss=1.086, disc_1(Real)_a=53, disc_2(Fake)_a=95\n",
            ">1575, disc_1(Real)=0.677, disc_2(Fake)=0.537, gen_loss=1.083, disc_1(Real)_a=54, disc_2(Fake)_a=82\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">1576, disc_1(Real)=0.687, disc_2(Fake)=0.520, gen_loss=1.069, disc_1(Real)_a=62, disc_2(Fake)_a=93\n",
            ">1577, disc_1(Real)=0.652, disc_2(Fake)=0.484, gen_loss=1.152, disc_1(Real)_a=65, disc_2(Fake)_a=95\n",
            ">1578, disc_1(Real)=0.715, disc_2(Fake)=0.476, gen_loss=1.161, disc_1(Real)_a=51, disc_2(Fake)_a=95\n",
            ">1579, disc_1(Real)=0.678, disc_2(Fake)=0.482, gen_loss=1.165, disc_1(Real)_a=59, disc_2(Fake)_a=95\n",
            ">1580, disc_1(Real)=0.565, disc_2(Fake)=0.442, gen_loss=1.178, disc_1(Real)_a=76, disc_2(Fake)_a=96\n",
            ">1581, disc_1(Real)=0.656, disc_2(Fake)=0.458, gen_loss=1.155, disc_1(Real)_a=60, disc_2(Fake)_a=93\n",
            ">1582, disc_1(Real)=0.585, disc_2(Fake)=0.475, gen_loss=1.187, disc_1(Real)_a=75, disc_2(Fake)_a=89\n",
            ">1583, disc_1(Real)=0.576, disc_2(Fake)=0.480, gen_loss=1.204, disc_1(Real)_a=71, disc_2(Fake)_a=92\n",
            ">1584, disc_1(Real)=0.615, disc_2(Fake)=0.509, gen_loss=1.167, disc_1(Real)_a=65, disc_2(Fake)_a=89\n",
            ">1585, disc_1(Real)=0.547, disc_2(Fake)=0.462, gen_loss=1.199, disc_1(Real)_a=79, disc_2(Fake)_a=93\n",
            ">1586, disc_1(Real)=0.580, disc_2(Fake)=0.477, gen_loss=1.153, disc_1(Real)_a=73, disc_2(Fake)_a=92\n",
            ">1587, disc_1(Real)=0.585, disc_2(Fake)=0.488, gen_loss=1.178, disc_1(Real)_a=73, disc_2(Fake)_a=93\n",
            ">1588, disc_1(Real)=0.542, disc_2(Fake)=0.515, gen_loss=1.169, disc_1(Real)_a=79, disc_2(Fake)_a=90\n",
            ">1589, disc_1(Real)=0.574, disc_2(Fake)=0.496, gen_loss=1.207, disc_1(Real)_a=70, disc_2(Fake)_a=90\n",
            ">1590, disc_1(Real)=0.603, disc_2(Fake)=0.534, gen_loss=1.159, disc_1(Real)_a=73, disc_2(Fake)_a=84\n",
            ">1591, disc_1(Real)=0.638, disc_2(Fake)=0.558, gen_loss=1.140, disc_1(Real)_a=59, disc_2(Fake)_a=84\n",
            ">1592, disc_1(Real)=0.674, disc_2(Fake)=0.550, gen_loss=1.108, disc_1(Real)_a=60, disc_2(Fake)_a=76\n",
            ">1593, disc_1(Real)=0.595, disc_2(Fake)=0.545, gen_loss=1.053, disc_1(Real)_a=65, disc_2(Fake)_a=79\n",
            ">1594, disc_1(Real)=0.624, disc_2(Fake)=0.651, gen_loss=0.997, disc_1(Real)_a=64, disc_2(Fake)_a=62\n",
            ">1595, disc_1(Real)=0.635, disc_2(Fake)=0.656, gen_loss=0.927, disc_1(Real)_a=65, disc_2(Fake)_a=54\n",
            ">1596, disc_1(Real)=0.637, disc_2(Fake)=0.638, gen_loss=0.934, disc_1(Real)_a=64, disc_2(Fake)_a=64\n",
            ">1597, disc_1(Real)=0.731, disc_2(Fake)=0.676, gen_loss=0.916, disc_1(Real)_a=53, disc_2(Fake)_a=59\n",
            ">1598, disc_1(Real)=0.710, disc_2(Fake)=0.674, gen_loss=0.877, disc_1(Real)_a=53, disc_2(Fake)_a=57\n",
            ">1599, disc_1(Real)=0.689, disc_2(Fake)=0.614, gen_loss=0.962, disc_1(Real)_a=51, disc_2(Fake)_a=79\n",
            ">1600, disc_1(Real)=0.694, disc_2(Fake)=0.646, gen_loss=0.935, disc_1(Real)_a=60, disc_2(Fake)_a=64\n",
            ">1601, disc_1(Real)=0.667, disc_2(Fake)=0.667, gen_loss=0.961, disc_1(Real)_a=59, disc_2(Fake)_a=59\n",
            ">1602, disc_1(Real)=0.766, disc_2(Fake)=0.671, gen_loss=0.952, disc_1(Real)_a=53, disc_2(Fake)_a=64\n",
            ">1603, disc_1(Real)=0.748, disc_2(Fake)=0.661, gen_loss=0.883, disc_1(Real)_a=48, disc_2(Fake)_a=56\n",
            ">1604, disc_1(Real)=0.682, disc_2(Fake)=0.672, gen_loss=0.914, disc_1(Real)_a=60, disc_2(Fake)_a=60\n",
            ">1605, disc_1(Real)=0.794, disc_2(Fake)=0.728, gen_loss=0.824, disc_1(Real)_a=50, disc_2(Fake)_a=51\n",
            ">1606, disc_1(Real)=0.661, disc_2(Fake)=0.732, gen_loss=0.865, disc_1(Real)_a=62, disc_2(Fake)_a=50\n",
            ">1607, disc_1(Real)=0.737, disc_2(Fake)=0.716, gen_loss=0.828, disc_1(Real)_a=46, disc_2(Fake)_a=54\n",
            ">1608, disc_1(Real)=0.686, disc_2(Fake)=0.765, gen_loss=0.830, disc_1(Real)_a=56, disc_2(Fake)_a=39\n",
            ">1609, disc_1(Real)=0.665, disc_2(Fake)=0.757, gen_loss=0.776, disc_1(Real)_a=59, disc_2(Fake)_a=39\n",
            ">1610, disc_1(Real)=0.659, disc_2(Fake)=0.735, gen_loss=0.808, disc_1(Real)_a=65, disc_2(Fake)_a=43\n",
            ">1611, disc_1(Real)=0.806, disc_2(Fake)=0.801, gen_loss=0.768, disc_1(Real)_a=48, disc_2(Fake)_a=31\n",
            ">1612, disc_1(Real)=0.747, disc_2(Fake)=0.821, gen_loss=0.732, disc_1(Real)_a=54, disc_2(Fake)_a=40\n",
            ">1613, disc_1(Real)=0.666, disc_2(Fake)=0.819, gen_loss=0.742, disc_1(Real)_a=60, disc_2(Fake)_a=34\n",
            ">1614, disc_1(Real)=0.776, disc_2(Fake)=0.764, gen_loss=0.719, disc_1(Real)_a=43, disc_2(Fake)_a=46\n",
            ">1615, disc_1(Real)=0.690, disc_2(Fake)=0.838, gen_loss=0.747, disc_1(Real)_a=59, disc_2(Fake)_a=31\n",
            ">1616, disc_1(Real)=0.674, disc_2(Fake)=0.768, gen_loss=0.769, disc_1(Real)_a=60, disc_2(Fake)_a=46\n",
            ">1617, disc_1(Real)=0.755, disc_2(Fake)=0.721, gen_loss=0.802, disc_1(Real)_a=43, disc_2(Fake)_a=54\n",
            ">1618, disc_1(Real)=0.631, disc_2(Fake)=0.726, gen_loss=0.832, disc_1(Real)_a=65, disc_2(Fake)_a=51\n",
            ">1619, disc_1(Real)=0.669, disc_2(Fake)=0.693, gen_loss=0.864, disc_1(Real)_a=62, disc_2(Fake)_a=60\n",
            ">1620, disc_1(Real)=0.635, disc_2(Fake)=0.656, gen_loss=0.889, disc_1(Real)_a=67, disc_2(Fake)_a=64\n",
            ">1621, disc_1(Real)=0.667, disc_2(Fake)=0.620, gen_loss=0.931, disc_1(Real)_a=57, disc_2(Fake)_a=73\n",
            ">1622, disc_1(Real)=0.627, disc_2(Fake)=0.564, gen_loss=0.960, disc_1(Real)_a=67, disc_2(Fake)_a=85\n",
            ">1623, disc_1(Real)=0.628, disc_2(Fake)=0.535, gen_loss=0.954, disc_1(Real)_a=67, disc_2(Fake)_a=84\n",
            ">1624, disc_1(Real)=0.636, disc_2(Fake)=0.537, gen_loss=1.009, disc_1(Real)_a=65, disc_2(Fake)_a=92\n",
            ">1625, disc_1(Real)=0.585, disc_2(Fake)=0.555, gen_loss=1.018, disc_1(Real)_a=68, disc_2(Fake)_a=92\n",
            ">1626, disc_1(Real)=0.557, disc_2(Fake)=0.507, gen_loss=1.020, disc_1(Real)_a=79, disc_2(Fake)_a=92\n",
            ">1627, disc_1(Real)=0.570, disc_2(Fake)=0.495, gen_loss=1.069, disc_1(Real)_a=76, disc_2(Fake)_a=93\n",
            ">1628, disc_1(Real)=0.525, disc_2(Fake)=0.489, gen_loss=1.130, disc_1(Real)_a=85, disc_2(Fake)_a=95\n",
            ">1629, disc_1(Real)=0.544, disc_2(Fake)=0.471, gen_loss=1.096, disc_1(Real)_a=79, disc_2(Fake)_a=96\n",
            ">1630, disc_1(Real)=0.554, disc_2(Fake)=0.470, gen_loss=1.080, disc_1(Real)_a=76, disc_2(Fake)_a=96\n",
            ">1631, disc_1(Real)=0.493, disc_2(Fake)=0.504, gen_loss=1.149, disc_1(Real)_a=89, disc_2(Fake)_a=92\n",
            ">1632, disc_1(Real)=0.509, disc_2(Fake)=0.481, gen_loss=1.083, disc_1(Real)_a=90, disc_2(Fake)_a=98\n",
            ">1633, disc_1(Real)=0.521, disc_2(Fake)=0.477, gen_loss=1.128, disc_1(Real)_a=84, disc_2(Fake)_a=100\n",
            ">1634, disc_1(Real)=0.511, disc_2(Fake)=0.489, gen_loss=1.135, disc_1(Real)_a=89, disc_2(Fake)_a=93\n",
            ">1635, disc_1(Real)=0.520, disc_2(Fake)=0.450, gen_loss=1.141, disc_1(Real)_a=85, disc_2(Fake)_a=98\n",
            ">1636, disc_1(Real)=0.534, disc_2(Fake)=0.470, gen_loss=1.127, disc_1(Real)_a=85, disc_2(Fake)_a=100\n",
            ">1637, disc_1(Real)=0.526, disc_2(Fake)=0.494, gen_loss=1.070, disc_1(Real)_a=79, disc_2(Fake)_a=98\n",
            ">1638, disc_1(Real)=0.526, disc_2(Fake)=0.528, gen_loss=1.038, disc_1(Real)_a=79, disc_2(Fake)_a=98\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">1639, disc_1(Real)=0.507, disc_2(Fake)=0.540, gen_loss=0.996, disc_1(Real)_a=82, disc_2(Fake)_a=92\n",
            ">1640, disc_1(Real)=0.525, disc_2(Fake)=0.555, gen_loss=0.981, disc_1(Real)_a=81, disc_2(Fake)_a=93\n",
            ">1641, disc_1(Real)=0.534, disc_2(Fake)=0.572, gen_loss=0.946, disc_1(Real)_a=85, disc_2(Fake)_a=84\n",
            ">1642, disc_1(Real)=0.554, disc_2(Fake)=0.607, gen_loss=0.931, disc_1(Real)_a=79, disc_2(Fake)_a=81\n",
            ">1643, disc_1(Real)=0.531, disc_2(Fake)=0.608, gen_loss=0.933, disc_1(Real)_a=78, disc_2(Fake)_a=71\n",
            ">1644, disc_1(Real)=0.550, disc_2(Fake)=0.598, gen_loss=0.910, disc_1(Real)_a=76, disc_2(Fake)_a=76\n",
            ">1645, disc_1(Real)=0.626, disc_2(Fake)=0.634, gen_loss=0.840, disc_1(Real)_a=68, disc_2(Fake)_a=68\n",
            ">1646, disc_1(Real)=0.574, disc_2(Fake)=0.627, gen_loss=0.870, disc_1(Real)_a=76, disc_2(Fake)_a=60\n",
            ">1647, disc_1(Real)=0.508, disc_2(Fake)=0.725, gen_loss=0.854, disc_1(Real)_a=89, disc_2(Fake)_a=50\n",
            ">1648, disc_1(Real)=0.622, disc_2(Fake)=0.626, gen_loss=0.838, disc_1(Real)_a=70, disc_2(Fake)_a=59\n",
            ">1649, disc_1(Real)=0.620, disc_2(Fake)=0.661, gen_loss=0.879, disc_1(Real)_a=70, disc_2(Fake)_a=60\n",
            ">1650, disc_1(Real)=0.593, disc_2(Fake)=0.690, gen_loss=0.857, disc_1(Real)_a=76, disc_2(Fake)_a=48\n",
            ">1651, disc_1(Real)=0.587, disc_2(Fake)=0.674, gen_loss=0.787, disc_1(Real)_a=75, disc_2(Fake)_a=53\n",
            ">1652, disc_1(Real)=0.569, disc_2(Fake)=0.723, gen_loss=0.828, disc_1(Real)_a=79, disc_2(Fake)_a=45\n",
            ">1653, disc_1(Real)=0.602, disc_2(Fake)=0.710, gen_loss=0.847, disc_1(Real)_a=70, disc_2(Fake)_a=45\n",
            ">1654, disc_1(Real)=0.632, disc_2(Fake)=0.792, gen_loss=0.818, disc_1(Real)_a=60, disc_2(Fake)_a=35\n",
            ">1655, disc_1(Real)=0.570, disc_2(Fake)=0.737, gen_loss=0.780, disc_1(Real)_a=79, disc_2(Fake)_a=43\n",
            ">1656, disc_1(Real)=0.619, disc_2(Fake)=0.795, gen_loss=0.776, disc_1(Real)_a=65, disc_2(Fake)_a=29\n",
            ">1657, disc_1(Real)=0.584, disc_2(Fake)=0.764, gen_loss=0.747, disc_1(Real)_a=71, disc_2(Fake)_a=37\n",
            ">1658, disc_1(Real)=0.632, disc_2(Fake)=0.748, gen_loss=0.744, disc_1(Real)_a=68, disc_2(Fake)_a=39\n",
            ">1659, disc_1(Real)=0.582, disc_2(Fake)=0.797, gen_loss=0.719, disc_1(Real)_a=75, disc_2(Fake)_a=35\n",
            ">1660, disc_1(Real)=0.548, disc_2(Fake)=0.763, gen_loss=0.730, disc_1(Real)_a=81, disc_2(Fake)_a=35\n",
            ">1661, disc_1(Real)=0.561, disc_2(Fake)=0.756, gen_loss=0.706, disc_1(Real)_a=78, disc_2(Fake)_a=37\n",
            ">1662, disc_1(Real)=0.600, disc_2(Fake)=0.769, gen_loss=0.707, disc_1(Real)_a=76, disc_2(Fake)_a=35\n",
            ">1663, disc_1(Real)=0.523, disc_2(Fake)=0.774, gen_loss=0.703, disc_1(Real)_a=92, disc_2(Fake)_a=31\n",
            ">1664, disc_1(Real)=0.581, disc_2(Fake)=0.752, gen_loss=0.718, disc_1(Real)_a=78, disc_2(Fake)_a=37\n",
            ">1665, disc_1(Real)=0.577, disc_2(Fake)=0.770, gen_loss=0.726, disc_1(Real)_a=81, disc_2(Fake)_a=34\n",
            ">1666, disc_1(Real)=0.593, disc_2(Fake)=0.782, gen_loss=0.713, disc_1(Real)_a=76, disc_2(Fake)_a=35\n",
            ">1667, disc_1(Real)=0.614, disc_2(Fake)=0.758, gen_loss=0.725, disc_1(Real)_a=73, disc_2(Fake)_a=39\n",
            ">1668, disc_1(Real)=0.579, disc_2(Fake)=0.747, gen_loss=0.763, disc_1(Real)_a=78, disc_2(Fake)_a=46\n",
            ">1669, disc_1(Real)=0.632, disc_2(Fake)=0.741, gen_loss=0.754, disc_1(Real)_a=68, disc_2(Fake)_a=40\n",
            ">1670, disc_1(Real)=0.608, disc_2(Fake)=0.750, gen_loss=0.772, disc_1(Real)_a=79, disc_2(Fake)_a=34\n",
            ">1671, disc_1(Real)=0.622, disc_2(Fake)=0.694, gen_loss=0.770, disc_1(Real)_a=67, disc_2(Fake)_a=56\n",
            ">1672, disc_1(Real)=0.547, disc_2(Fake)=0.702, gen_loss=0.776, disc_1(Real)_a=81, disc_2(Fake)_a=45\n",
            ">1673, disc_1(Real)=0.609, disc_2(Fake)=0.728, gen_loss=0.783, disc_1(Real)_a=67, disc_2(Fake)_a=40\n",
            ">1674, disc_1(Real)=0.593, disc_2(Fake)=0.680, gen_loss=0.837, disc_1(Real)_a=67, disc_2(Fake)_a=54\n",
            ">1675, disc_1(Real)=0.583, disc_2(Fake)=0.684, gen_loss=0.833, disc_1(Real)_a=71, disc_2(Fake)_a=53\n",
            ">1676, disc_1(Real)=0.576, disc_2(Fake)=0.618, gen_loss=0.872, disc_1(Real)_a=81, disc_2(Fake)_a=73\n",
            ">1677, disc_1(Real)=0.574, disc_2(Fake)=0.614, gen_loss=0.891, disc_1(Real)_a=76, disc_2(Fake)_a=73\n",
            ">1678, disc_1(Real)=0.561, disc_2(Fake)=0.578, gen_loss=0.880, disc_1(Real)_a=78, disc_2(Fake)_a=81\n",
            ">1679, disc_1(Real)=0.575, disc_2(Fake)=0.589, gen_loss=0.924, disc_1(Real)_a=68, disc_2(Fake)_a=81\n",
            ">1680, disc_1(Real)=0.559, disc_2(Fake)=0.606, gen_loss=0.927, disc_1(Real)_a=89, disc_2(Fake)_a=65\n",
            ">1681, disc_1(Real)=0.579, disc_2(Fake)=0.571, gen_loss=0.944, disc_1(Real)_a=76, disc_2(Fake)_a=79\n",
            ">1682, disc_1(Real)=0.526, disc_2(Fake)=0.589, gen_loss=0.969, disc_1(Real)_a=85, disc_2(Fake)_a=81\n",
            ">1683, disc_1(Real)=0.549, disc_2(Fake)=0.555, gen_loss=1.008, disc_1(Real)_a=87, disc_2(Fake)_a=89\n",
            ">1684, disc_1(Real)=0.540, disc_2(Fake)=0.533, gen_loss=1.023, disc_1(Real)_a=90, disc_2(Fake)_a=92\n",
            ">1685, disc_1(Real)=0.531, disc_2(Fake)=0.523, gen_loss=1.021, disc_1(Real)_a=82, disc_2(Fake)_a=92\n",
            ">1686, disc_1(Real)=0.507, disc_2(Fake)=0.509, gen_loss=1.049, disc_1(Real)_a=84, disc_2(Fake)_a=96\n",
            ">1687, disc_1(Real)=0.532, disc_2(Fake)=0.495, gen_loss=1.044, disc_1(Real)_a=82, disc_2(Fake)_a=98\n",
            ">1688, disc_1(Real)=0.507, disc_2(Fake)=0.508, gen_loss=1.084, disc_1(Real)_a=87, disc_2(Fake)_a=89\n",
            ">1689, disc_1(Real)=0.527, disc_2(Fake)=0.484, gen_loss=1.160, disc_1(Real)_a=79, disc_2(Fake)_a=93\n",
            ">1690, disc_1(Real)=0.516, disc_2(Fake)=0.489, gen_loss=1.188, disc_1(Real)_a=82, disc_2(Fake)_a=93\n",
            ">1691, disc_1(Real)=0.477, disc_2(Fake)=0.456, gen_loss=1.147, disc_1(Real)_a=81, disc_2(Fake)_a=95\n",
            ">1692, disc_1(Real)=0.462, disc_2(Fake)=0.471, gen_loss=1.130, disc_1(Real)_a=89, disc_2(Fake)_a=90\n",
            ">1693, disc_1(Real)=0.545, disc_2(Fake)=0.480, gen_loss=1.134, disc_1(Real)_a=71, disc_2(Fake)_a=85\n",
            ">1694, disc_1(Real)=0.504, disc_2(Fake)=0.514, gen_loss=1.066, disc_1(Real)_a=82, disc_2(Fake)_a=84\n",
            ">1695, disc_1(Real)=0.509, disc_2(Fake)=0.494, gen_loss=1.043, disc_1(Real)_a=85, disc_2(Fake)_a=89\n",
            ">1696, disc_1(Real)=0.550, disc_2(Fake)=0.566, gen_loss=1.005, disc_1(Real)_a=76, disc_2(Fake)_a=82\n",
            ">1697, disc_1(Real)=0.468, disc_2(Fake)=0.530, gen_loss=1.075, disc_1(Real)_a=92, disc_2(Fake)_a=84\n",
            ">1698, disc_1(Real)=0.522, disc_2(Fake)=0.528, gen_loss=1.072, disc_1(Real)_a=81, disc_2(Fake)_a=89\n",
            ">1699, disc_1(Real)=0.597, disc_2(Fake)=0.527, gen_loss=1.039, disc_1(Real)_a=68, disc_2(Fake)_a=89\n",
            ">1700, disc_1(Real)=0.528, disc_2(Fake)=0.558, gen_loss=1.078, disc_1(Real)_a=75, disc_2(Fake)_a=82\n",
            ">1701, disc_1(Real)=0.559, disc_2(Fake)=0.534, gen_loss=1.050, disc_1(Real)_a=75, disc_2(Fake)_a=85\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">1702, disc_1(Real)=0.572, disc_2(Fake)=0.566, gen_loss=0.993, disc_1(Real)_a=75, disc_2(Fake)_a=89\n",
            ">1703, disc_1(Real)=0.562, disc_2(Fake)=0.602, gen_loss=0.961, disc_1(Real)_a=76, disc_2(Fake)_a=82\n",
            ">1704, disc_1(Real)=0.596, disc_2(Fake)=0.653, gen_loss=0.899, disc_1(Real)_a=70, disc_2(Fake)_a=65\n",
            ">1705, disc_1(Real)=0.525, disc_2(Fake)=0.675, gen_loss=0.924, disc_1(Real)_a=78, disc_2(Fake)_a=62\n",
            ">1706, disc_1(Real)=0.588, disc_2(Fake)=0.712, gen_loss=0.922, disc_1(Real)_a=76, disc_2(Fake)_a=42\n",
            ">1707, disc_1(Real)=0.642, disc_2(Fake)=0.743, gen_loss=0.917, disc_1(Real)_a=62, disc_2(Fake)_a=48\n",
            ">1708, disc_1(Real)=0.682, disc_2(Fake)=0.771, gen_loss=0.888, disc_1(Real)_a=50, disc_2(Fake)_a=43\n",
            ">1709, disc_1(Real)=0.643, disc_2(Fake)=0.777, gen_loss=0.898, disc_1(Real)_a=57, disc_2(Fake)_a=40\n",
            ">1710, disc_1(Real)=0.667, disc_2(Fake)=0.795, gen_loss=0.916, disc_1(Real)_a=59, disc_2(Fake)_a=39\n",
            ">1711, disc_1(Real)=0.676, disc_2(Fake)=0.721, gen_loss=0.952, disc_1(Real)_a=60, disc_2(Fake)_a=48\n",
            ">1712, disc_1(Real)=0.739, disc_2(Fake)=0.687, gen_loss=0.952, disc_1(Real)_a=43, disc_2(Fake)_a=48\n",
            ">1713, disc_1(Real)=0.770, disc_2(Fake)=0.601, gen_loss=0.987, disc_1(Real)_a=45, disc_2(Fake)_a=64\n",
            ">1714, disc_1(Real)=0.660, disc_2(Fake)=0.564, gen_loss=1.120, disc_1(Real)_a=62, disc_2(Fake)_a=75\n",
            ">1715, disc_1(Real)=0.586, disc_2(Fake)=0.475, gen_loss=1.233, disc_1(Real)_a=70, disc_2(Fake)_a=96\n",
            ">1716, disc_1(Real)=0.733, disc_2(Fake)=0.426, gen_loss=1.213, disc_1(Real)_a=42, disc_2(Fake)_a=100\n",
            ">1717, disc_1(Real)=0.575, disc_2(Fake)=0.446, gen_loss=1.229, disc_1(Real)_a=78, disc_2(Fake)_a=98\n",
            ">1718, disc_1(Real)=0.590, disc_2(Fake)=0.427, gen_loss=1.178, disc_1(Real)_a=67, disc_2(Fake)_a=100\n",
            ">1719, disc_1(Real)=0.569, disc_2(Fake)=0.495, gen_loss=1.166, disc_1(Real)_a=75, disc_2(Fake)_a=92\n",
            ">1720, disc_1(Real)=0.528, disc_2(Fake)=0.506, gen_loss=1.135, disc_1(Real)_a=78, disc_2(Fake)_a=95\n",
            ">1721, disc_1(Real)=0.583, disc_2(Fake)=0.518, gen_loss=1.044, disc_1(Real)_a=70, disc_2(Fake)_a=92\n",
            ">1722, disc_1(Real)=0.519, disc_2(Fake)=0.550, gen_loss=1.017, disc_1(Real)_a=82, disc_2(Fake)_a=85\n",
            ">1723, disc_1(Real)=0.507, disc_2(Fake)=0.572, gen_loss=0.978, disc_1(Real)_a=85, disc_2(Fake)_a=89\n",
            ">1724, disc_1(Real)=0.461, disc_2(Fake)=0.574, gen_loss=1.049, disc_1(Real)_a=87, disc_2(Fake)_a=82\n",
            ">1725, disc_1(Real)=0.496, disc_2(Fake)=0.560, gen_loss=1.058, disc_1(Real)_a=81, disc_2(Fake)_a=81\n",
            ">1726, disc_1(Real)=0.491, disc_2(Fake)=0.512, gen_loss=1.130, disc_1(Real)_a=87, disc_2(Fake)_a=85\n",
            ">1727, disc_1(Real)=0.483, disc_2(Fake)=0.598, gen_loss=1.022, disc_1(Real)_a=93, disc_2(Fake)_a=79\n",
            ">1728, disc_1(Real)=0.471, disc_2(Fake)=0.675, gen_loss=0.990, disc_1(Real)_a=87, disc_2(Fake)_a=70\n",
            ">1729, disc_1(Real)=0.481, disc_2(Fake)=0.758, gen_loss=0.860, disc_1(Real)_a=87, disc_2(Fake)_a=57\n",
            ">1730, disc_1(Real)=0.524, disc_2(Fake)=0.877, gen_loss=0.771, disc_1(Real)_a=84, disc_2(Fake)_a=32\n",
            ">1731, disc_1(Real)=0.529, disc_2(Fake)=0.781, gen_loss=0.718, disc_1(Real)_a=79, disc_2(Fake)_a=35\n",
            ">1732, disc_1(Real)=0.581, disc_2(Fake)=0.850, gen_loss=0.673, disc_1(Real)_a=71, disc_2(Fake)_a=35\n",
            ">1733, disc_1(Real)=0.610, disc_2(Fake)=0.906, gen_loss=0.649, disc_1(Real)_a=70, disc_2(Fake)_a=34\n",
            ">1734, disc_1(Real)=0.640, disc_2(Fake)=0.818, gen_loss=0.678, disc_1(Real)_a=64, disc_2(Fake)_a=39\n",
            ">1735, disc_1(Real)=0.652, disc_2(Fake)=0.939, gen_loss=0.703, disc_1(Real)_a=56, disc_2(Fake)_a=37\n",
            ">1736, disc_1(Real)=0.619, disc_2(Fake)=0.839, gen_loss=0.719, disc_1(Real)_a=65, disc_2(Fake)_a=53\n",
            ">1737, disc_1(Real)=0.674, disc_2(Fake)=0.876, gen_loss=0.763, disc_1(Real)_a=54, disc_2(Fake)_a=50\n",
            ">1738, disc_1(Real)=0.671, disc_2(Fake)=0.873, gen_loss=0.758, disc_1(Real)_a=56, disc_2(Fake)_a=45\n",
            ">1739, disc_1(Real)=0.658, disc_2(Fake)=0.887, gen_loss=0.695, disc_1(Real)_a=56, disc_2(Fake)_a=40\n",
            ">1740, disc_1(Real)=0.617, disc_2(Fake)=0.816, gen_loss=0.686, disc_1(Real)_a=64, disc_2(Fake)_a=50\n",
            ">1741, disc_1(Real)=0.648, disc_2(Fake)=0.827, gen_loss=0.708, disc_1(Real)_a=57, disc_2(Fake)_a=43\n",
            ">1742, disc_1(Real)=0.678, disc_2(Fake)=0.838, gen_loss=0.728, disc_1(Real)_a=54, disc_2(Fake)_a=43\n",
            ">1743, disc_1(Real)=0.599, disc_2(Fake)=0.781, gen_loss=0.746, disc_1(Real)_a=67, disc_2(Fake)_a=45\n",
            ">1744, disc_1(Real)=0.647, disc_2(Fake)=0.795, gen_loss=0.747, disc_1(Real)_a=60, disc_2(Fake)_a=34\n",
            ">1745, disc_1(Real)=0.677, disc_2(Fake)=0.792, gen_loss=0.734, disc_1(Real)_a=50, disc_2(Fake)_a=34\n",
            ">1746, disc_1(Real)=0.624, disc_2(Fake)=0.749, gen_loss=0.763, disc_1(Real)_a=71, disc_2(Fake)_a=42\n",
            ">1747, disc_1(Real)=0.661, disc_2(Fake)=0.710, gen_loss=0.813, disc_1(Real)_a=57, disc_2(Fake)_a=45\n",
            ">1748, disc_1(Real)=0.572, disc_2(Fake)=0.682, gen_loss=0.815, disc_1(Real)_a=75, disc_2(Fake)_a=56\n",
            ">1749, disc_1(Real)=0.646, disc_2(Fake)=0.664, gen_loss=0.832, disc_1(Real)_a=59, disc_2(Fake)_a=62\n",
            ">1750, disc_1(Real)=0.577, disc_2(Fake)=0.644, gen_loss=0.894, disc_1(Real)_a=76, disc_2(Fake)_a=65\n",
            ">1751, disc_1(Real)=0.592, disc_2(Fake)=0.608, gen_loss=0.929, disc_1(Real)_a=68, disc_2(Fake)_a=76\n",
            ">1752, disc_1(Real)=0.553, disc_2(Fake)=0.590, gen_loss=0.941, disc_1(Real)_a=84, disc_2(Fake)_a=85\n",
            ">1753, disc_1(Real)=0.561, disc_2(Fake)=0.565, gen_loss=0.965, disc_1(Real)_a=79, disc_2(Fake)_a=89\n",
            ">1754, disc_1(Real)=0.503, disc_2(Fake)=0.585, gen_loss=0.997, disc_1(Real)_a=89, disc_2(Fake)_a=82\n",
            ">1755, disc_1(Real)=0.516, disc_2(Fake)=0.556, gen_loss=1.022, disc_1(Real)_a=90, disc_2(Fake)_a=92\n",
            ">1756, disc_1(Real)=0.551, disc_2(Fake)=0.511, gen_loss=1.068, disc_1(Real)_a=81, disc_2(Fake)_a=100\n",
            ">1757, disc_1(Real)=0.521, disc_2(Fake)=0.488, gen_loss=1.121, disc_1(Real)_a=82, disc_2(Fake)_a=96\n",
            ">1758, disc_1(Real)=0.512, disc_2(Fake)=0.470, gen_loss=1.142, disc_1(Real)_a=84, disc_2(Fake)_a=98\n",
            ">1759, disc_1(Real)=0.491, disc_2(Fake)=0.432, gen_loss=1.163, disc_1(Real)_a=87, disc_2(Fake)_a=100\n",
            ">1760, disc_1(Real)=0.486, disc_2(Fake)=0.447, gen_loss=1.154, disc_1(Real)_a=89, disc_2(Fake)_a=96\n",
            ">1761, disc_1(Real)=0.460, disc_2(Fake)=0.438, gen_loss=1.221, disc_1(Real)_a=92, disc_2(Fake)_a=96\n",
            ">1762, disc_1(Real)=0.474, disc_2(Fake)=0.445, gen_loss=1.202, disc_1(Real)_a=87, disc_2(Fake)_a=96\n",
            ">1763, disc_1(Real)=0.479, disc_2(Fake)=0.486, gen_loss=1.132, disc_1(Real)_a=92, disc_2(Fake)_a=95\n",
            ">1764, disc_1(Real)=0.473, disc_2(Fake)=0.491, gen_loss=1.133, disc_1(Real)_a=89, disc_2(Fake)_a=92\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">1765, disc_1(Real)=0.505, disc_2(Fake)=0.539, gen_loss=1.062, disc_1(Real)_a=89, disc_2(Fake)_a=87\n",
            ">1766, disc_1(Real)=0.463, disc_2(Fake)=0.575, gen_loss=1.023, disc_1(Real)_a=90, disc_2(Fake)_a=82\n",
            ">1767, disc_1(Real)=0.457, disc_2(Fake)=0.563, gen_loss=1.001, disc_1(Real)_a=85, disc_2(Fake)_a=79\n",
            ">1768, disc_1(Real)=0.508, disc_2(Fake)=0.580, gen_loss=1.033, disc_1(Real)_a=81, disc_2(Fake)_a=76\n",
            ">1769, disc_1(Real)=0.532, disc_2(Fake)=0.555, gen_loss=1.081, disc_1(Real)_a=75, disc_2(Fake)_a=85\n",
            ">1770, disc_1(Real)=0.484, disc_2(Fake)=0.511, gen_loss=1.148, disc_1(Real)_a=84, disc_2(Fake)_a=82\n",
            ">1771, disc_1(Real)=0.552, disc_2(Fake)=0.509, gen_loss=1.169, disc_1(Real)_a=78, disc_2(Fake)_a=81\n",
            ">1772, disc_1(Real)=0.567, disc_2(Fake)=0.467, gen_loss=1.176, disc_1(Real)_a=71, disc_2(Fake)_a=89\n",
            ">1773, disc_1(Real)=0.537, disc_2(Fake)=0.445, gen_loss=1.249, disc_1(Real)_a=78, disc_2(Fake)_a=89\n",
            ">1774, disc_1(Real)=0.529, disc_2(Fake)=0.488, gen_loss=1.164, disc_1(Real)_a=78, disc_2(Fake)_a=79\n",
            ">1775, disc_1(Real)=0.585, disc_2(Fake)=0.479, gen_loss=1.175, disc_1(Real)_a=70, disc_2(Fake)_a=82\n",
            ">1776, disc_1(Real)=0.529, disc_2(Fake)=0.491, gen_loss=1.103, disc_1(Real)_a=79, disc_2(Fake)_a=87\n",
            ">1777, disc_1(Real)=0.549, disc_2(Fake)=0.540, gen_loss=1.088, disc_1(Real)_a=78, disc_2(Fake)_a=76\n",
            ">1778, disc_1(Real)=0.553, disc_2(Fake)=0.482, gen_loss=1.030, disc_1(Real)_a=78, disc_2(Fake)_a=92\n",
            ">1779, disc_1(Real)=0.580, disc_2(Fake)=0.528, gen_loss=1.056, disc_1(Real)_a=82, disc_2(Fake)_a=79\n",
            ">1780, disc_1(Real)=0.591, disc_2(Fake)=0.519, gen_loss=1.119, disc_1(Real)_a=75, disc_2(Fake)_a=87\n",
            ">1781, disc_1(Real)=0.557, disc_2(Fake)=0.488, gen_loss=1.122, disc_1(Real)_a=79, disc_2(Fake)_a=100\n",
            ">1782, disc_1(Real)=0.568, disc_2(Fake)=0.488, gen_loss=1.145, disc_1(Real)_a=76, disc_2(Fake)_a=100\n",
            ">1783, disc_1(Real)=0.560, disc_2(Fake)=0.478, gen_loss=1.175, disc_1(Real)_a=79, disc_2(Fake)_a=100\n",
            ">1784, disc_1(Real)=0.594, disc_2(Fake)=0.462, gen_loss=1.180, disc_1(Real)_a=65, disc_2(Fake)_a=98\n",
            ">1785, disc_1(Real)=0.541, disc_2(Fake)=0.437, gen_loss=1.179, disc_1(Real)_a=79, disc_2(Fake)_a=98\n",
            ">1786, disc_1(Real)=0.562, disc_2(Fake)=0.443, gen_loss=1.232, disc_1(Real)_a=73, disc_2(Fake)_a=98\n",
            ">1787, disc_1(Real)=0.588, disc_2(Fake)=0.458, gen_loss=1.219, disc_1(Real)_a=65, disc_2(Fake)_a=93\n",
            ">1788, disc_1(Real)=0.534, disc_2(Fake)=0.411, gen_loss=1.184, disc_1(Real)_a=75, disc_2(Fake)_a=98\n",
            ">1789, disc_1(Real)=0.625, disc_2(Fake)=0.443, gen_loss=1.206, disc_1(Real)_a=68, disc_2(Fake)_a=93\n",
            ">1790, disc_1(Real)=0.643, disc_2(Fake)=0.446, gen_loss=1.178, disc_1(Real)_a=67, disc_2(Fake)_a=95\n",
            ">1791, disc_1(Real)=0.544, disc_2(Fake)=0.493, gen_loss=1.175, disc_1(Real)_a=78, disc_2(Fake)_a=92\n",
            ">1792, disc_1(Real)=0.583, disc_2(Fake)=0.466, gen_loss=1.127, disc_1(Real)_a=76, disc_2(Fake)_a=95\n",
            ">1793, disc_1(Real)=0.582, disc_2(Fake)=0.459, gen_loss=1.143, disc_1(Real)_a=65, disc_2(Fake)_a=98\n",
            ">1794, disc_1(Real)=0.664, disc_2(Fake)=0.501, gen_loss=1.126, disc_1(Real)_a=60, disc_2(Fake)_a=90\n",
            ">1795, disc_1(Real)=0.584, disc_2(Fake)=0.496, gen_loss=1.078, disc_1(Real)_a=70, disc_2(Fake)_a=98\n",
            ">1796, disc_1(Real)=0.597, disc_2(Fake)=0.511, gen_loss=1.111, disc_1(Real)_a=64, disc_2(Fake)_a=92\n",
            ">1797, disc_1(Real)=0.644, disc_2(Fake)=0.508, gen_loss=1.044, disc_1(Real)_a=62, disc_2(Fake)_a=93\n",
            ">1798, disc_1(Real)=0.660, disc_2(Fake)=0.503, gen_loss=1.048, disc_1(Real)_a=60, disc_2(Fake)_a=92\n",
            ">1799, disc_1(Real)=0.603, disc_2(Fake)=0.536, gen_loss=1.021, disc_1(Real)_a=68, disc_2(Fake)_a=87\n",
            ">1800, disc_1(Real)=0.652, disc_2(Fake)=0.563, gen_loss=1.055, disc_1(Real)_a=65, disc_2(Fake)_a=76\n",
            ">1801, disc_1(Real)=0.625, disc_2(Fake)=0.590, gen_loss=1.013, disc_1(Real)_a=62, disc_2(Fake)_a=73\n",
            ">1802, disc_1(Real)=0.605, disc_2(Fake)=0.590, gen_loss=1.016, disc_1(Real)_a=64, disc_2(Fake)_a=79\n",
            ">1803, disc_1(Real)=0.579, disc_2(Fake)=0.590, gen_loss=0.965, disc_1(Real)_a=68, disc_2(Fake)_a=70\n",
            ">1804, disc_1(Real)=0.613, disc_2(Fake)=0.601, gen_loss=1.000, disc_1(Real)_a=71, disc_2(Fake)_a=70\n",
            ">1805, disc_1(Real)=0.674, disc_2(Fake)=0.617, gen_loss=1.020, disc_1(Real)_a=60, disc_2(Fake)_a=68\n",
            ">1806, disc_1(Real)=0.725, disc_2(Fake)=0.560, gen_loss=1.045, disc_1(Real)_a=51, disc_2(Fake)_a=79\n",
            ">1807, disc_1(Real)=0.696, disc_2(Fake)=0.571, gen_loss=1.034, disc_1(Real)_a=56, disc_2(Fake)_a=73\n",
            ">1808, disc_1(Real)=0.703, disc_2(Fake)=0.611, gen_loss=0.958, disc_1(Real)_a=48, disc_2(Fake)_a=75\n",
            ">1809, disc_1(Real)=0.825, disc_2(Fake)=0.680, gen_loss=0.913, disc_1(Real)_a=45, disc_2(Fake)_a=71\n",
            ">1810, disc_1(Real)=0.756, disc_2(Fake)=0.732, gen_loss=0.943, disc_1(Real)_a=42, disc_2(Fake)_a=64\n",
            ">1811, disc_1(Real)=0.681, disc_2(Fake)=0.719, gen_loss=0.848, disc_1(Real)_a=57, disc_2(Fake)_a=60\n",
            ">1812, disc_1(Real)=0.708, disc_2(Fake)=0.769, gen_loss=0.823, disc_1(Real)_a=53, disc_2(Fake)_a=53\n",
            ">1813, disc_1(Real)=0.729, disc_2(Fake)=0.773, gen_loss=0.877, disc_1(Real)_a=46, disc_2(Fake)_a=57\n",
            ">1814, disc_1(Real)=0.689, disc_2(Fake)=0.708, gen_loss=0.819, disc_1(Real)_a=45, disc_2(Fake)_a=60\n",
            ">1815, disc_1(Real)=0.734, disc_2(Fake)=0.737, gen_loss=0.800, disc_1(Real)_a=46, disc_2(Fake)_a=60\n",
            ">1816, disc_1(Real)=0.664, disc_2(Fake)=0.729, gen_loss=0.829, disc_1(Real)_a=53, disc_2(Fake)_a=53\n",
            ">1817, disc_1(Real)=0.666, disc_2(Fake)=0.745, gen_loss=0.790, disc_1(Real)_a=60, disc_2(Fake)_a=45\n",
            ">1818, disc_1(Real)=0.640, disc_2(Fake)=0.734, gen_loss=0.789, disc_1(Real)_a=64, disc_2(Fake)_a=50\n",
            ">1819, disc_1(Real)=0.709, disc_2(Fake)=0.779, gen_loss=0.829, disc_1(Real)_a=51, disc_2(Fake)_a=45\n",
            ">1820, disc_1(Real)=0.678, disc_2(Fake)=0.718, gen_loss=0.880, disc_1(Real)_a=62, disc_2(Fake)_a=51\n",
            ">1821, disc_1(Real)=0.699, disc_2(Fake)=0.703, gen_loss=0.827, disc_1(Real)_a=54, disc_2(Fake)_a=56\n",
            ">1822, disc_1(Real)=0.694, disc_2(Fake)=0.680, gen_loss=0.858, disc_1(Real)_a=59, disc_2(Fake)_a=54\n",
            ">1823, disc_1(Real)=0.698, disc_2(Fake)=0.697, gen_loss=0.863, disc_1(Real)_a=57, disc_2(Fake)_a=53\n",
            ">1824, disc_1(Real)=0.676, disc_2(Fake)=0.674, gen_loss=0.892, disc_1(Real)_a=62, disc_2(Fake)_a=53\n",
            ">1825, disc_1(Real)=0.643, disc_2(Fake)=0.686, gen_loss=0.913, disc_1(Real)_a=56, disc_2(Fake)_a=53\n",
            ">1826, disc_1(Real)=0.658, disc_2(Fake)=0.622, gen_loss=0.899, disc_1(Real)_a=62, disc_2(Fake)_a=62\n",
            ">1827, disc_1(Real)=0.657, disc_2(Fake)=0.658, gen_loss=0.904, disc_1(Real)_a=59, disc_2(Fake)_a=59\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">1828, disc_1(Real)=0.675, disc_2(Fake)=0.598, gen_loss=0.892, disc_1(Real)_a=57, disc_2(Fake)_a=76\n",
            ">1829, disc_1(Real)=0.658, disc_2(Fake)=0.666, gen_loss=0.978, disc_1(Real)_a=54, disc_2(Fake)_a=64\n",
            ">1830, disc_1(Real)=0.597, disc_2(Fake)=0.581, gen_loss=1.008, disc_1(Real)_a=67, disc_2(Fake)_a=78\n",
            ">1831, disc_1(Real)=0.685, disc_2(Fake)=0.550, gen_loss=1.046, disc_1(Real)_a=50, disc_2(Fake)_a=82\n",
            ">1832, disc_1(Real)=0.625, disc_2(Fake)=0.543, gen_loss=0.986, disc_1(Real)_a=65, disc_2(Fake)_a=84\n",
            ">1833, disc_1(Real)=0.667, disc_2(Fake)=0.556, gen_loss=1.044, disc_1(Real)_a=62, disc_2(Fake)_a=79\n",
            ">1834, disc_1(Real)=0.614, disc_2(Fake)=0.566, gen_loss=0.993, disc_1(Real)_a=67, disc_2(Fake)_a=79\n",
            ">1835, disc_1(Real)=0.639, disc_2(Fake)=0.575, gen_loss=1.026, disc_1(Real)_a=57, disc_2(Fake)_a=84\n",
            ">1836, disc_1(Real)=0.636, disc_2(Fake)=0.535, gen_loss=1.051, disc_1(Real)_a=60, disc_2(Fake)_a=82\n",
            ">1837, disc_1(Real)=0.571, disc_2(Fake)=0.506, gen_loss=1.051, disc_1(Real)_a=68, disc_2(Fake)_a=89\n",
            ">1838, disc_1(Real)=0.568, disc_2(Fake)=0.538, gen_loss=1.084, disc_1(Real)_a=73, disc_2(Fake)_a=84\n",
            ">1839, disc_1(Real)=0.550, disc_2(Fake)=0.507, gen_loss=1.135, disc_1(Real)_a=76, disc_2(Fake)_a=92\n",
            ">1840, disc_1(Real)=0.582, disc_2(Fake)=0.513, gen_loss=1.093, disc_1(Real)_a=73, disc_2(Fake)_a=85\n",
            ">1841, disc_1(Real)=0.624, disc_2(Fake)=0.550, gen_loss=1.095, disc_1(Real)_a=71, disc_2(Fake)_a=84\n",
            ">1842, disc_1(Real)=0.650, disc_2(Fake)=0.522, gen_loss=1.089, disc_1(Real)_a=64, disc_2(Fake)_a=89\n",
            ">1843, disc_1(Real)=0.598, disc_2(Fake)=0.517, gen_loss=1.083, disc_1(Real)_a=73, disc_2(Fake)_a=84\n",
            ">1844, disc_1(Real)=0.575, disc_2(Fake)=0.485, gen_loss=1.136, disc_1(Real)_a=67, disc_2(Fake)_a=95\n",
            ">1845, disc_1(Real)=0.606, disc_2(Fake)=0.492, gen_loss=1.155, disc_1(Real)_a=65, disc_2(Fake)_a=85\n",
            ">1846, disc_1(Real)=0.641, disc_2(Fake)=0.465, gen_loss=1.135, disc_1(Real)_a=67, disc_2(Fake)_a=87\n",
            ">1847, disc_1(Real)=0.579, disc_2(Fake)=0.509, gen_loss=1.203, disc_1(Real)_a=71, disc_2(Fake)_a=85\n",
            ">1848, disc_1(Real)=0.579, disc_2(Fake)=0.479, gen_loss=1.186, disc_1(Real)_a=71, disc_2(Fake)_a=92\n",
            ">1849, disc_1(Real)=0.674, disc_2(Fake)=0.453, gen_loss=1.188, disc_1(Real)_a=56, disc_2(Fake)_a=92\n",
            ">1850, disc_1(Real)=0.626, disc_2(Fake)=0.475, gen_loss=1.171, disc_1(Real)_a=65, disc_2(Fake)_a=90\n",
            ">1851, disc_1(Real)=0.526, disc_2(Fake)=0.425, gen_loss=1.143, disc_1(Real)_a=82, disc_2(Fake)_a=96\n",
            ">1852, disc_1(Real)=0.608, disc_2(Fake)=0.467, gen_loss=1.139, disc_1(Real)_a=60, disc_2(Fake)_a=90\n",
            ">1853, disc_1(Real)=0.546, disc_2(Fake)=0.491, gen_loss=1.136, disc_1(Real)_a=78, disc_2(Fake)_a=90\n",
            ">1854, disc_1(Real)=0.549, disc_2(Fake)=0.485, gen_loss=1.094, disc_1(Real)_a=81, disc_2(Fake)_a=95\n",
            ">1855, disc_1(Real)=0.556, disc_2(Fake)=0.473, gen_loss=1.151, disc_1(Real)_a=78, disc_2(Fake)_a=90\n",
            ">1856, disc_1(Real)=0.578, disc_2(Fake)=0.484, gen_loss=1.110, disc_1(Real)_a=70, disc_2(Fake)_a=90\n",
            ">1857, disc_1(Real)=0.560, disc_2(Fake)=0.479, gen_loss=1.122, disc_1(Real)_a=78, disc_2(Fake)_a=93\n",
            ">1858, disc_1(Real)=0.533, disc_2(Fake)=0.505, gen_loss=1.095, disc_1(Real)_a=85, disc_2(Fake)_a=96\n",
            ">1859, disc_1(Real)=0.625, disc_2(Fake)=0.517, gen_loss=1.060, disc_1(Real)_a=75, disc_2(Fake)_a=90\n",
            ">1860, disc_1(Real)=0.569, disc_2(Fake)=0.536, gen_loss=1.065, disc_1(Real)_a=76, disc_2(Fake)_a=90\n",
            ">1861, disc_1(Real)=0.594, disc_2(Fake)=0.551, gen_loss=1.003, disc_1(Real)_a=73, disc_2(Fake)_a=84\n",
            ">1862, disc_1(Real)=0.560, disc_2(Fake)=0.538, gen_loss=1.033, disc_1(Real)_a=79, disc_2(Fake)_a=89\n",
            ">1863, disc_1(Real)=0.612, disc_2(Fake)=0.546, gen_loss=1.094, disc_1(Real)_a=68, disc_2(Fake)_a=90\n",
            ">1864, disc_1(Real)=0.627, disc_2(Fake)=0.498, gen_loss=1.102, disc_1(Real)_a=65, disc_2(Fake)_a=93\n",
            ">1865, disc_1(Real)=0.672, disc_2(Fake)=0.518, gen_loss=1.041, disc_1(Real)_a=64, disc_2(Fake)_a=92\n",
            ">1866, disc_1(Real)=0.649, disc_2(Fake)=0.555, gen_loss=1.022, disc_1(Real)_a=68, disc_2(Fake)_a=85\n",
            ">1867, disc_1(Real)=0.569, disc_2(Fake)=0.514, gen_loss=1.028, disc_1(Real)_a=71, disc_2(Fake)_a=90\n",
            ">1868, disc_1(Real)=0.624, disc_2(Fake)=0.583, gen_loss=1.027, disc_1(Real)_a=67, disc_2(Fake)_a=76\n",
            ">1869, disc_1(Real)=0.619, disc_2(Fake)=0.549, gen_loss=0.982, disc_1(Real)_a=67, disc_2(Fake)_a=78\n",
            ">1870, disc_1(Real)=0.663, disc_2(Fake)=0.593, gen_loss=0.985, disc_1(Real)_a=60, disc_2(Fake)_a=70\n",
            ">1871, disc_1(Real)=0.615, disc_2(Fake)=0.607, gen_loss=0.900, disc_1(Real)_a=67, disc_2(Fake)_a=75\n",
            ">1872, disc_1(Real)=0.639, disc_2(Fake)=0.634, gen_loss=0.961, disc_1(Real)_a=70, disc_2(Fake)_a=75\n",
            ">1873, disc_1(Real)=0.660, disc_2(Fake)=0.596, gen_loss=0.946, disc_1(Real)_a=65, disc_2(Fake)_a=73\n",
            ">1874, disc_1(Real)=0.665, disc_2(Fake)=0.564, gen_loss=0.958, disc_1(Real)_a=64, disc_2(Fake)_a=79\n",
            ">1875, disc_1(Real)=0.706, disc_2(Fake)=0.604, gen_loss=0.901, disc_1(Real)_a=57, disc_2(Fake)_a=73\n",
            ">1876, disc_1(Real)=0.660, disc_2(Fake)=0.650, gen_loss=0.831, disc_1(Real)_a=62, disc_2(Fake)_a=56\n",
            ">1877, disc_1(Real)=0.595, disc_2(Fake)=0.654, gen_loss=0.872, disc_1(Real)_a=76, disc_2(Fake)_a=62\n",
            ">1878, disc_1(Real)=0.615, disc_2(Fake)=0.654, gen_loss=0.879, disc_1(Real)_a=65, disc_2(Fake)_a=62\n",
            ">1879, disc_1(Real)=0.621, disc_2(Fake)=0.663, gen_loss=0.861, disc_1(Real)_a=67, disc_2(Fake)_a=56\n",
            ">1880, disc_1(Real)=0.632, disc_2(Fake)=0.630, gen_loss=0.926, disc_1(Real)_a=64, disc_2(Fake)_a=70\n",
            ">1881, disc_1(Real)=0.657, disc_2(Fake)=0.624, gen_loss=0.878, disc_1(Real)_a=64, disc_2(Fake)_a=70\n",
            ">1882, disc_1(Real)=0.626, disc_2(Fake)=0.637, gen_loss=0.912, disc_1(Real)_a=71, disc_2(Fake)_a=62\n",
            ">1883, disc_1(Real)=0.650, disc_2(Fake)=0.639, gen_loss=0.913, disc_1(Real)_a=68, disc_2(Fake)_a=75\n",
            ">1884, disc_1(Real)=0.618, disc_2(Fake)=0.687, gen_loss=0.910, disc_1(Real)_a=68, disc_2(Fake)_a=70\n",
            ">1885, disc_1(Real)=0.587, disc_2(Fake)=0.615, gen_loss=0.954, disc_1(Real)_a=73, disc_2(Fake)_a=78\n",
            ">1886, disc_1(Real)=0.563, disc_2(Fake)=0.576, gen_loss=0.958, disc_1(Real)_a=71, disc_2(Fake)_a=79\n",
            ">1887, disc_1(Real)=0.679, disc_2(Fake)=0.659, gen_loss=0.918, disc_1(Real)_a=57, disc_2(Fake)_a=65\n",
            ">1888, disc_1(Real)=0.573, disc_2(Fake)=0.608, gen_loss=0.954, disc_1(Real)_a=68, disc_2(Fake)_a=78\n",
            ">1889, disc_1(Real)=0.627, disc_2(Fake)=0.638, gen_loss=0.951, disc_1(Real)_a=64, disc_2(Fake)_a=70\n",
            ">1890, disc_1(Real)=0.634, disc_2(Fake)=0.628, gen_loss=0.889, disc_1(Real)_a=64, disc_2(Fake)_a=76\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">1891, disc_1(Real)=0.631, disc_2(Fake)=0.598, gen_loss=0.960, disc_1(Real)_a=67, disc_2(Fake)_a=73\n",
            ">1892, disc_1(Real)=0.566, disc_2(Fake)=0.630, gen_loss=0.905, disc_1(Real)_a=75, disc_2(Fake)_a=67\n",
            ">1893, disc_1(Real)=0.565, disc_2(Fake)=0.658, gen_loss=0.906, disc_1(Real)_a=70, disc_2(Fake)_a=65\n",
            ">1894, disc_1(Real)=0.587, disc_2(Fake)=0.569, gen_loss=0.935, disc_1(Real)_a=71, disc_2(Fake)_a=78\n",
            ">1895, disc_1(Real)=0.533, disc_2(Fake)=0.656, gen_loss=0.974, disc_1(Real)_a=75, disc_2(Fake)_a=70\n",
            ">1896, disc_1(Real)=0.564, disc_2(Fake)=0.659, gen_loss=0.951, disc_1(Real)_a=75, disc_2(Fake)_a=68\n",
            ">1897, disc_1(Real)=0.583, disc_2(Fake)=0.598, gen_loss=0.940, disc_1(Real)_a=65, disc_2(Fake)_a=75\n",
            ">1898, disc_1(Real)=0.572, disc_2(Fake)=0.550, gen_loss=0.954, disc_1(Real)_a=70, disc_2(Fake)_a=81\n",
            ">1899, disc_1(Real)=0.617, disc_2(Fake)=0.630, gen_loss=0.922, disc_1(Real)_a=68, disc_2(Fake)_a=64\n",
            ">1900, disc_1(Real)=0.558, disc_2(Fake)=0.547, gen_loss=1.013, disc_1(Real)_a=73, disc_2(Fake)_a=81\n",
            ">1901, disc_1(Real)=0.616, disc_2(Fake)=0.664, gen_loss=0.991, disc_1(Real)_a=59, disc_2(Fake)_a=68\n",
            ">1902, disc_1(Real)=0.519, disc_2(Fake)=0.569, gen_loss=1.050, disc_1(Real)_a=78, disc_2(Fake)_a=76\n",
            ">1903, disc_1(Real)=0.582, disc_2(Fake)=0.578, gen_loss=1.017, disc_1(Real)_a=65, disc_2(Fake)_a=71\n",
            ">1904, disc_1(Real)=0.544, disc_2(Fake)=0.636, gen_loss=0.963, disc_1(Real)_a=73, disc_2(Fake)_a=75\n",
            ">1905, disc_1(Real)=0.598, disc_2(Fake)=0.605, gen_loss=0.994, disc_1(Real)_a=64, disc_2(Fake)_a=76\n",
            ">1906, disc_1(Real)=0.578, disc_2(Fake)=0.554, gen_loss=0.943, disc_1(Real)_a=68, disc_2(Fake)_a=73\n",
            ">1907, disc_1(Real)=0.673, disc_2(Fake)=0.691, gen_loss=0.971, disc_1(Real)_a=56, disc_2(Fake)_a=60\n",
            ">1908, disc_1(Real)=0.536, disc_2(Fake)=0.541, gen_loss=0.988, disc_1(Real)_a=78, disc_2(Fake)_a=76\n",
            ">1909, disc_1(Real)=0.591, disc_2(Fake)=0.594, gen_loss=0.957, disc_1(Real)_a=68, disc_2(Fake)_a=71\n",
            ">1910, disc_1(Real)=0.543, disc_2(Fake)=0.573, gen_loss=0.987, disc_1(Real)_a=76, disc_2(Fake)_a=75\n",
            ">1911, disc_1(Real)=0.560, disc_2(Fake)=0.590, gen_loss=0.966, disc_1(Real)_a=65, disc_2(Fake)_a=71\n",
            ">1912, disc_1(Real)=0.535, disc_2(Fake)=0.582, gen_loss=0.967, disc_1(Real)_a=75, disc_2(Fake)_a=73\n",
            ">1913, disc_1(Real)=0.566, disc_2(Fake)=0.571, gen_loss=0.964, disc_1(Real)_a=79, disc_2(Fake)_a=78\n",
            ">1914, disc_1(Real)=0.542, disc_2(Fake)=0.598, gen_loss=0.995, disc_1(Real)_a=78, disc_2(Fake)_a=75\n",
            ">1915, disc_1(Real)=0.572, disc_2(Fake)=0.524, gen_loss=0.981, disc_1(Real)_a=67, disc_2(Fake)_a=87\n",
            ">1916, disc_1(Real)=0.474, disc_2(Fake)=0.542, gen_loss=1.033, disc_1(Real)_a=82, disc_2(Fake)_a=84\n",
            ">1917, disc_1(Real)=0.565, disc_2(Fake)=0.499, gen_loss=1.030, disc_1(Real)_a=65, disc_2(Fake)_a=89\n",
            ">1918, disc_1(Real)=0.533, disc_2(Fake)=0.569, gen_loss=1.002, disc_1(Real)_a=68, disc_2(Fake)_a=75\n",
            ">1919, disc_1(Real)=0.600, disc_2(Fake)=0.549, gen_loss=1.028, disc_1(Real)_a=59, disc_2(Fake)_a=79\n",
            ">1920, disc_1(Real)=0.596, disc_2(Fake)=0.543, gen_loss=1.009, disc_1(Real)_a=62, disc_2(Fake)_a=81\n",
            ">1921, disc_1(Real)=0.581, disc_2(Fake)=0.520, gen_loss=0.947, disc_1(Real)_a=65, disc_2(Fake)_a=92\n",
            ">1922, disc_1(Real)=0.518, disc_2(Fake)=0.549, gen_loss=0.993, disc_1(Real)_a=73, disc_2(Fake)_a=82\n",
            ">1923, disc_1(Real)=0.563, disc_2(Fake)=0.529, gen_loss=0.976, disc_1(Real)_a=67, disc_2(Fake)_a=87\n",
            ">1924, disc_1(Real)=0.592, disc_2(Fake)=0.559, gen_loss=0.946, disc_1(Real)_a=68, disc_2(Fake)_a=78\n",
            ">1925, disc_1(Real)=0.532, disc_2(Fake)=0.575, gen_loss=0.989, disc_1(Real)_a=78, disc_2(Fake)_a=71\n",
            ">1926, disc_1(Real)=0.575, disc_2(Fake)=0.537, gen_loss=1.015, disc_1(Real)_a=68, disc_2(Fake)_a=89\n",
            ">1927, disc_1(Real)=0.626, disc_2(Fake)=0.524, gen_loss=0.965, disc_1(Real)_a=68, disc_2(Fake)_a=89\n",
            ">1928, disc_1(Real)=0.483, disc_2(Fake)=0.586, gen_loss=0.971, disc_1(Real)_a=84, disc_2(Fake)_a=81\n",
            ">1929, disc_1(Real)=0.582, disc_2(Fake)=0.546, gen_loss=0.989, disc_1(Real)_a=64, disc_2(Fake)_a=87\n",
            ">1930, disc_1(Real)=0.600, disc_2(Fake)=0.544, gen_loss=0.962, disc_1(Real)_a=75, disc_2(Fake)_a=81\n",
            ">1931, disc_1(Real)=0.593, disc_2(Fake)=0.576, gen_loss=1.021, disc_1(Real)_a=70, disc_2(Fake)_a=78\n",
            ">1932, disc_1(Real)=0.637, disc_2(Fake)=0.572, gen_loss=0.927, disc_1(Real)_a=65, disc_2(Fake)_a=75\n",
            ">1933, disc_1(Real)=0.638, disc_2(Fake)=0.584, gen_loss=0.888, disc_1(Real)_a=67, disc_2(Fake)_a=76\n",
            ">1934, disc_1(Real)=0.627, disc_2(Fake)=0.581, gen_loss=0.929, disc_1(Real)_a=65, disc_2(Fake)_a=79\n",
            ">1935, disc_1(Real)=0.652, disc_2(Fake)=0.630, gen_loss=0.867, disc_1(Real)_a=57, disc_2(Fake)_a=65\n",
            ">1936, disc_1(Real)=0.589, disc_2(Fake)=0.639, gen_loss=0.903, disc_1(Real)_a=70, disc_2(Fake)_a=67\n",
            ">1937, disc_1(Real)=0.604, disc_2(Fake)=0.623, gen_loss=0.884, disc_1(Real)_a=62, disc_2(Fake)_a=71\n",
            ">1938, disc_1(Real)=0.593, disc_2(Fake)=0.698, gen_loss=0.876, disc_1(Real)_a=71, disc_2(Fake)_a=57\n",
            ">1939, disc_1(Real)=0.569, disc_2(Fake)=0.617, gen_loss=0.917, disc_1(Real)_a=71, disc_2(Fake)_a=73\n",
            ">1940, disc_1(Real)=0.609, disc_2(Fake)=0.599, gen_loss=0.944, disc_1(Real)_a=71, disc_2(Fake)_a=75\n",
            ">1941, disc_1(Real)=0.656, disc_2(Fake)=0.674, gen_loss=0.932, disc_1(Real)_a=60, disc_2(Fake)_a=65\n",
            ">1942, disc_1(Real)=0.692, disc_2(Fake)=0.693, gen_loss=0.858, disc_1(Real)_a=51, disc_2(Fake)_a=64\n",
            ">1943, disc_1(Real)=0.655, disc_2(Fake)=0.777, gen_loss=0.901, disc_1(Real)_a=64, disc_2(Fake)_a=53\n",
            ">1944, disc_1(Real)=0.677, disc_2(Fake)=0.770, gen_loss=0.956, disc_1(Real)_a=60, disc_2(Fake)_a=50\n",
            ">1945, disc_1(Real)=0.679, disc_2(Fake)=0.654, gen_loss=0.921, disc_1(Real)_a=53, disc_2(Fake)_a=60\n",
            ">1946, disc_1(Real)=0.625, disc_2(Fake)=0.611, gen_loss=0.954, disc_1(Real)_a=60, disc_2(Fake)_a=67\n",
            ">1947, disc_1(Real)=0.707, disc_2(Fake)=0.584, gen_loss=0.918, disc_1(Real)_a=50, disc_2(Fake)_a=73\n",
            ">1948, disc_1(Real)=0.644, disc_2(Fake)=0.596, gen_loss=0.972, disc_1(Real)_a=60, disc_2(Fake)_a=68\n",
            ">1949, disc_1(Real)=0.623, disc_2(Fake)=0.599, gen_loss=0.927, disc_1(Real)_a=65, disc_2(Fake)_a=68\n",
            ">1950, disc_1(Real)=0.676, disc_2(Fake)=0.593, gen_loss=0.957, disc_1(Real)_a=54, disc_2(Fake)_a=75\n",
            ">1951, disc_1(Real)=0.636, disc_2(Fake)=0.556, gen_loss=1.002, disc_1(Real)_a=65, disc_2(Fake)_a=76\n",
            ">1952, disc_1(Real)=0.652, disc_2(Fake)=0.550, gen_loss=0.992, disc_1(Real)_a=59, disc_2(Fake)_a=75\n",
            ">1953, disc_1(Real)=0.643, disc_2(Fake)=0.535, gen_loss=0.987, disc_1(Real)_a=70, disc_2(Fake)_a=84\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">1954, disc_1(Real)=0.640, disc_2(Fake)=0.532, gen_loss=1.018, disc_1(Real)_a=68, disc_2(Fake)_a=87\n",
            ">1955, disc_1(Real)=0.640, disc_2(Fake)=0.535, gen_loss=1.041, disc_1(Real)_a=60, disc_2(Fake)_a=85\n",
            ">1956, disc_1(Real)=0.636, disc_2(Fake)=0.565, gen_loss=1.047, disc_1(Real)_a=60, disc_2(Fake)_a=78\n",
            ">1957, disc_1(Real)=0.551, disc_2(Fake)=0.498, gen_loss=1.085, disc_1(Real)_a=76, disc_2(Fake)_a=93\n",
            ">1958, disc_1(Real)=0.600, disc_2(Fake)=0.511, gen_loss=1.083, disc_1(Real)_a=71, disc_2(Fake)_a=92\n",
            ">1959, disc_1(Real)=0.643, disc_2(Fake)=0.507, gen_loss=1.010, disc_1(Real)_a=64, disc_2(Fake)_a=87\n",
            ">1960, disc_1(Real)=0.637, disc_2(Fake)=0.543, gen_loss=1.068, disc_1(Real)_a=64, disc_2(Fake)_a=90\n",
            ">1961, disc_1(Real)=0.586, disc_2(Fake)=0.513, gen_loss=1.100, disc_1(Real)_a=73, disc_2(Fake)_a=95\n",
            ">1962, disc_1(Real)=0.624, disc_2(Fake)=0.484, gen_loss=1.121, disc_1(Real)_a=60, disc_2(Fake)_a=95\n",
            ">1963, disc_1(Real)=0.582, disc_2(Fake)=0.530, gen_loss=1.103, disc_1(Real)_a=73, disc_2(Fake)_a=82\n",
            ">1964, disc_1(Real)=0.541, disc_2(Fake)=0.497, gen_loss=1.133, disc_1(Real)_a=75, disc_2(Fake)_a=92\n",
            ">1965, disc_1(Real)=0.566, disc_2(Fake)=0.496, gen_loss=1.109, disc_1(Real)_a=71, disc_2(Fake)_a=87\n",
            ">1966, disc_1(Real)=0.594, disc_2(Fake)=0.525, gen_loss=1.089, disc_1(Real)_a=67, disc_2(Fake)_a=89\n",
            ">1967, disc_1(Real)=0.603, disc_2(Fake)=0.558, gen_loss=1.098, disc_1(Real)_a=76, disc_2(Fake)_a=70\n",
            ">1968, disc_1(Real)=0.609, disc_2(Fake)=0.552, gen_loss=1.011, disc_1(Real)_a=71, disc_2(Fake)_a=75\n",
            ">1969, disc_1(Real)=0.609, disc_2(Fake)=0.526, gen_loss=1.037, disc_1(Real)_a=70, disc_2(Fake)_a=84\n",
            ">1970, disc_1(Real)=0.556, disc_2(Fake)=0.553, gen_loss=0.995, disc_1(Real)_a=78, disc_2(Fake)_a=79\n",
            ">1971, disc_1(Real)=0.615, disc_2(Fake)=0.568, gen_loss=0.976, disc_1(Real)_a=65, disc_2(Fake)_a=76\n",
            ">1972, disc_1(Real)=0.601, disc_2(Fake)=0.581, gen_loss=1.051, disc_1(Real)_a=68, disc_2(Fake)_a=73\n",
            ">1973, disc_1(Real)=0.632, disc_2(Fake)=0.554, gen_loss=1.002, disc_1(Real)_a=64, disc_2(Fake)_a=75\n",
            ">1974, disc_1(Real)=0.640, disc_2(Fake)=0.542, gen_loss=1.013, disc_1(Real)_a=60, disc_2(Fake)_a=79\n",
            ">1975, disc_1(Real)=0.646, disc_2(Fake)=0.536, gen_loss=0.990, disc_1(Real)_a=59, disc_2(Fake)_a=84\n",
            ">1976, disc_1(Real)=0.645, disc_2(Fake)=0.553, gen_loss=0.961, disc_1(Real)_a=54, disc_2(Fake)_a=82\n",
            ">1977, disc_1(Real)=0.668, disc_2(Fake)=0.620, gen_loss=0.990, disc_1(Real)_a=54, disc_2(Fake)_a=65\n",
            ">1978, disc_1(Real)=0.644, disc_2(Fake)=0.572, gen_loss=0.979, disc_1(Real)_a=62, disc_2(Fake)_a=76\n",
            ">1979, disc_1(Real)=0.588, disc_2(Fake)=0.562, gen_loss=0.996, disc_1(Real)_a=75, disc_2(Fake)_a=78\n",
            ">1980, disc_1(Real)=0.632, disc_2(Fake)=0.545, gen_loss=1.021, disc_1(Real)_a=64, disc_2(Fake)_a=76\n",
            ">1981, disc_1(Real)=0.621, disc_2(Fake)=0.547, gen_loss=0.971, disc_1(Real)_a=67, disc_2(Fake)_a=84\n",
            ">1982, disc_1(Real)=0.568, disc_2(Fake)=0.560, gen_loss=1.017, disc_1(Real)_a=78, disc_2(Fake)_a=76\n",
            ">1983, disc_1(Real)=0.617, disc_2(Fake)=0.522, gen_loss=1.062, disc_1(Real)_a=67, disc_2(Fake)_a=85\n",
            ">1984, disc_1(Real)=0.549, disc_2(Fake)=0.508, gen_loss=1.083, disc_1(Real)_a=76, disc_2(Fake)_a=82\n",
            ">1985, disc_1(Real)=0.592, disc_2(Fake)=0.530, gen_loss=1.082, disc_1(Real)_a=70, disc_2(Fake)_a=85\n",
            ">1986, disc_1(Real)=0.616, disc_2(Fake)=0.567, gen_loss=1.115, disc_1(Real)_a=64, disc_2(Fake)_a=75\n",
            ">1987, disc_1(Real)=0.619, disc_2(Fake)=0.566, gen_loss=1.154, disc_1(Real)_a=64, disc_2(Fake)_a=79\n",
            ">1988, disc_1(Real)=0.652, disc_2(Fake)=0.484, gen_loss=1.119, disc_1(Real)_a=60, disc_2(Fake)_a=87\n",
            ">1989, disc_1(Real)=0.619, disc_2(Fake)=0.455, gen_loss=1.110, disc_1(Real)_a=67, disc_2(Fake)_a=85\n",
            ">1990, disc_1(Real)=0.578, disc_2(Fake)=0.506, gen_loss=1.119, disc_1(Real)_a=71, disc_2(Fake)_a=84\n",
            ">1991, disc_1(Real)=0.566, disc_2(Fake)=0.503, gen_loss=1.147, disc_1(Real)_a=76, disc_2(Fake)_a=87\n",
            ">1992, disc_1(Real)=0.537, disc_2(Fake)=0.475, gen_loss=1.138, disc_1(Real)_a=82, disc_2(Fake)_a=93\n",
            ">1993, disc_1(Real)=0.576, disc_2(Fake)=0.456, gen_loss=1.154, disc_1(Real)_a=79, disc_2(Fake)_a=89\n",
            ">1994, disc_1(Real)=0.582, disc_2(Fake)=0.474, gen_loss=1.125, disc_1(Real)_a=70, disc_2(Fake)_a=92\n",
            ">1995, disc_1(Real)=0.585, disc_2(Fake)=0.478, gen_loss=1.148, disc_1(Real)_a=70, disc_2(Fake)_a=85\n",
            ">1996, disc_1(Real)=0.577, disc_2(Fake)=0.483, gen_loss=1.156, disc_1(Real)_a=68, disc_2(Fake)_a=90\n",
            ">1997, disc_1(Real)=0.549, disc_2(Fake)=0.496, gen_loss=1.194, disc_1(Real)_a=78, disc_2(Fake)_a=81\n",
            ">1998, disc_1(Real)=0.615, disc_2(Fake)=0.424, gen_loss=1.164, disc_1(Real)_a=64, disc_2(Fake)_a=95\n",
            ">1999, disc_1(Real)=0.611, disc_2(Fake)=0.468, gen_loss=1.095, disc_1(Real)_a=67, disc_2(Fake)_a=98\n",
            ">2000, disc_1(Real)=0.616, disc_2(Fake)=0.482, gen_loss=1.092, disc_1(Real)_a=68, disc_2(Fake)_a=93\n",
            ">2001, disc_1(Real)=0.592, disc_2(Fake)=0.505, gen_loss=1.100, disc_1(Real)_a=65, disc_2(Fake)_a=90\n",
            ">2002, disc_1(Real)=0.613, disc_2(Fake)=0.483, gen_loss=1.140, disc_1(Real)_a=71, disc_2(Fake)_a=95\n",
            ">2003, disc_1(Real)=0.642, disc_2(Fake)=0.483, gen_loss=1.078, disc_1(Real)_a=57, disc_2(Fake)_a=93\n",
            ">2004, disc_1(Real)=0.573, disc_2(Fake)=0.457, gen_loss=1.070, disc_1(Real)_a=70, disc_2(Fake)_a=93\n",
            ">2005, disc_1(Real)=0.577, disc_2(Fake)=0.510, gen_loss=1.060, disc_1(Real)_a=75, disc_2(Fake)_a=90\n",
            ">2006, disc_1(Real)=0.612, disc_2(Fake)=0.501, gen_loss=1.053, disc_1(Real)_a=65, disc_2(Fake)_a=85\n",
            ">2007, disc_1(Real)=0.591, disc_2(Fake)=0.524, gen_loss=1.079, disc_1(Real)_a=78, disc_2(Fake)_a=85\n",
            ">2008, disc_1(Real)=0.598, disc_2(Fake)=0.527, gen_loss=1.056, disc_1(Real)_a=68, disc_2(Fake)_a=84\n",
            ">2009, disc_1(Real)=0.589, disc_2(Fake)=0.516, gen_loss=1.041, disc_1(Real)_a=67, disc_2(Fake)_a=82\n",
            ">2010, disc_1(Real)=0.625, disc_2(Fake)=0.555, gen_loss=1.038, disc_1(Real)_a=65, disc_2(Fake)_a=79\n",
            ">2011, disc_1(Real)=0.661, disc_2(Fake)=0.532, gen_loss=1.000, disc_1(Real)_a=59, disc_2(Fake)_a=89\n",
            ">2012, disc_1(Real)=0.631, disc_2(Fake)=0.541, gen_loss=1.013, disc_1(Real)_a=68, disc_2(Fake)_a=84\n",
            ">2013, disc_1(Real)=0.617, disc_2(Fake)=0.534, gen_loss=1.006, disc_1(Real)_a=64, disc_2(Fake)_a=85\n",
            ">2014, disc_1(Real)=0.685, disc_2(Fake)=0.572, gen_loss=0.991, disc_1(Real)_a=53, disc_2(Fake)_a=81\n",
            ">2015, disc_1(Real)=0.626, disc_2(Fake)=0.535, gen_loss=0.988, disc_1(Real)_a=64, disc_2(Fake)_a=87\n",
            ">2016, disc_1(Real)=0.669, disc_2(Fake)=0.574, gen_loss=0.980, disc_1(Real)_a=64, disc_2(Fake)_a=87\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">2017, disc_1(Real)=0.612, disc_2(Fake)=0.588, gen_loss=0.978, disc_1(Real)_a=67, disc_2(Fake)_a=82\n",
            ">2018, disc_1(Real)=0.692, disc_2(Fake)=0.563, gen_loss=0.941, disc_1(Real)_a=56, disc_2(Fake)_a=78\n",
            ">2019, disc_1(Real)=0.718, disc_2(Fake)=0.603, gen_loss=0.910, disc_1(Real)_a=56, disc_2(Fake)_a=75\n",
            ">2020, disc_1(Real)=0.692, disc_2(Fake)=0.665, gen_loss=0.905, disc_1(Real)_a=54, disc_2(Fake)_a=62\n",
            ">2021, disc_1(Real)=0.648, disc_2(Fake)=0.631, gen_loss=0.907, disc_1(Real)_a=60, disc_2(Fake)_a=73\n",
            ">2022, disc_1(Real)=0.678, disc_2(Fake)=0.646, gen_loss=0.872, disc_1(Real)_a=53, disc_2(Fake)_a=71\n",
            ">2023, disc_1(Real)=0.668, disc_2(Fake)=0.634, gen_loss=0.925, disc_1(Real)_a=56, disc_2(Fake)_a=70\n",
            ">2024, disc_1(Real)=0.721, disc_2(Fake)=0.616, gen_loss=0.844, disc_1(Real)_a=50, disc_2(Fake)_a=71\n",
            ">2025, disc_1(Real)=0.717, disc_2(Fake)=0.642, gen_loss=0.829, disc_1(Real)_a=57, disc_2(Fake)_a=68\n",
            ">2026, disc_1(Real)=0.783, disc_2(Fake)=0.732, gen_loss=0.813, disc_1(Real)_a=43, disc_2(Fake)_a=48\n",
            ">2027, disc_1(Real)=0.694, disc_2(Fake)=0.770, gen_loss=0.792, disc_1(Real)_a=57, disc_2(Fake)_a=35\n",
            ">2028, disc_1(Real)=0.685, disc_2(Fake)=0.766, gen_loss=0.827, disc_1(Real)_a=57, disc_2(Fake)_a=50\n",
            ">2029, disc_1(Real)=0.693, disc_2(Fake)=0.691, gen_loss=0.791, disc_1(Real)_a=53, disc_2(Fake)_a=60\n",
            ">2030, disc_1(Real)=0.637, disc_2(Fake)=0.709, gen_loss=0.836, disc_1(Real)_a=64, disc_2(Fake)_a=53\n",
            ">2031, disc_1(Real)=0.671, disc_2(Fake)=0.715, gen_loss=0.820, disc_1(Real)_a=56, disc_2(Fake)_a=60\n",
            ">2032, disc_1(Real)=0.678, disc_2(Fake)=0.718, gen_loss=0.796, disc_1(Real)_a=53, disc_2(Fake)_a=54\n",
            ">2033, disc_1(Real)=0.646, disc_2(Fake)=0.775, gen_loss=0.817, disc_1(Real)_a=64, disc_2(Fake)_a=45\n",
            ">2034, disc_1(Real)=0.747, disc_2(Fake)=0.709, gen_loss=0.786, disc_1(Real)_a=42, disc_2(Fake)_a=51\n",
            ">2035, disc_1(Real)=0.698, disc_2(Fake)=0.761, gen_loss=0.776, disc_1(Real)_a=57, disc_2(Fake)_a=43\n",
            ">2036, disc_1(Real)=0.688, disc_2(Fake)=0.751, gen_loss=0.782, disc_1(Real)_a=51, disc_2(Fake)_a=48\n",
            ">2037, disc_1(Real)=0.697, disc_2(Fake)=0.752, gen_loss=0.758, disc_1(Real)_a=51, disc_2(Fake)_a=45\n",
            ">2038, disc_1(Real)=0.693, disc_2(Fake)=0.704, gen_loss=0.772, disc_1(Real)_a=53, disc_2(Fake)_a=57\n",
            ">2039, disc_1(Real)=0.709, disc_2(Fake)=0.759, gen_loss=0.771, disc_1(Real)_a=59, disc_2(Fake)_a=48\n",
            ">2040, disc_1(Real)=0.656, disc_2(Fake)=0.714, gen_loss=0.810, disc_1(Real)_a=62, disc_2(Fake)_a=59\n",
            ">2041, disc_1(Real)=0.742, disc_2(Fake)=0.709, gen_loss=0.791, disc_1(Real)_a=51, disc_2(Fake)_a=57\n",
            ">2042, disc_1(Real)=0.711, disc_2(Fake)=0.682, gen_loss=0.797, disc_1(Real)_a=56, disc_2(Fake)_a=59\n",
            ">2043, disc_1(Real)=0.695, disc_2(Fake)=0.682, gen_loss=0.775, disc_1(Real)_a=60, disc_2(Fake)_a=60\n",
            ">2044, disc_1(Real)=0.636, disc_2(Fake)=0.782, gen_loss=0.832, disc_1(Real)_a=67, disc_2(Fake)_a=46\n",
            ">2045, disc_1(Real)=0.752, disc_2(Fake)=0.701, gen_loss=0.836, disc_1(Real)_a=42, disc_2(Fake)_a=60\n",
            ">2046, disc_1(Real)=0.595, disc_2(Fake)=0.635, gen_loss=0.847, disc_1(Real)_a=71, disc_2(Fake)_a=64\n",
            ">2047, disc_1(Real)=0.697, disc_2(Fake)=0.629, gen_loss=0.875, disc_1(Real)_a=59, disc_2(Fake)_a=73\n",
            ">2048, disc_1(Real)=0.703, disc_2(Fake)=0.653, gen_loss=0.885, disc_1(Real)_a=51, disc_2(Fake)_a=60\n",
            ">2049, disc_1(Real)=0.674, disc_2(Fake)=0.640, gen_loss=0.857, disc_1(Real)_a=56, disc_2(Fake)_a=64\n",
            ">2050, disc_1(Real)=0.624, disc_2(Fake)=0.625, gen_loss=0.871, disc_1(Real)_a=65, disc_2(Fake)_a=67\n",
            ">2051, disc_1(Real)=0.659, disc_2(Fake)=0.637, gen_loss=0.889, disc_1(Real)_a=50, disc_2(Fake)_a=65\n",
            ">2052, disc_1(Real)=0.638, disc_2(Fake)=0.588, gen_loss=0.913, disc_1(Real)_a=71, disc_2(Fake)_a=79\n",
            ">2053, disc_1(Real)=0.664, disc_2(Fake)=0.597, gen_loss=0.934, disc_1(Real)_a=64, disc_2(Fake)_a=75\n",
            ">2054, disc_1(Real)=0.637, disc_2(Fake)=0.618, gen_loss=0.897, disc_1(Real)_a=59, disc_2(Fake)_a=68\n",
            ">2055, disc_1(Real)=0.603, disc_2(Fake)=0.631, gen_loss=0.876, disc_1(Real)_a=70, disc_2(Fake)_a=67\n",
            ">2056, disc_1(Real)=0.642, disc_2(Fake)=0.631, gen_loss=0.906, disc_1(Real)_a=60, disc_2(Fake)_a=68\n",
            ">2057, disc_1(Real)=0.580, disc_2(Fake)=0.597, gen_loss=0.883, disc_1(Real)_a=76, disc_2(Fake)_a=79\n",
            ">2058, disc_1(Real)=0.615, disc_2(Fake)=0.616, gen_loss=0.919, disc_1(Real)_a=65, disc_2(Fake)_a=70\n",
            ">2059, disc_1(Real)=0.645, disc_2(Fake)=0.610, gen_loss=0.915, disc_1(Real)_a=70, disc_2(Fake)_a=73\n",
            ">2060, disc_1(Real)=0.636, disc_2(Fake)=0.570, gen_loss=0.917, disc_1(Real)_a=64, disc_2(Fake)_a=75\n",
            ">2061, disc_1(Real)=0.675, disc_2(Fake)=0.603, gen_loss=0.934, disc_1(Real)_a=57, disc_2(Fake)_a=65\n",
            ">2062, disc_1(Real)=0.677, disc_2(Fake)=0.617, gen_loss=0.858, disc_1(Real)_a=56, disc_2(Fake)_a=68\n",
            ">2063, disc_1(Real)=0.598, disc_2(Fake)=0.632, gen_loss=0.859, disc_1(Real)_a=73, disc_2(Fake)_a=62\n",
            ">2064, disc_1(Real)=0.576, disc_2(Fake)=0.629, gen_loss=0.881, disc_1(Real)_a=71, disc_2(Fake)_a=67\n",
            ">2065, disc_1(Real)=0.681, disc_2(Fake)=0.631, gen_loss=0.849, disc_1(Real)_a=48, disc_2(Fake)_a=59\n",
            ">2066, disc_1(Real)=0.591, disc_2(Fake)=0.668, gen_loss=0.904, disc_1(Real)_a=70, disc_2(Fake)_a=64\n",
            ">2067, disc_1(Real)=0.596, disc_2(Fake)=0.656, gen_loss=0.863, disc_1(Real)_a=68, disc_2(Fake)_a=67\n",
            ">2068, disc_1(Real)=0.574, disc_2(Fake)=0.624, gen_loss=0.863, disc_1(Real)_a=71, disc_2(Fake)_a=68\n",
            ">2069, disc_1(Real)=0.641, disc_2(Fake)=0.664, gen_loss=0.844, disc_1(Real)_a=64, disc_2(Fake)_a=59\n",
            ">2070, disc_1(Real)=0.616, disc_2(Fake)=0.659, gen_loss=0.844, disc_1(Real)_a=62, disc_2(Fake)_a=70\n",
            ">2071, disc_1(Real)=0.603, disc_2(Fake)=0.642, gen_loss=0.829, disc_1(Real)_a=68, disc_2(Fake)_a=65\n",
            ">2072, disc_1(Real)=0.673, disc_2(Fake)=0.698, gen_loss=0.840, disc_1(Real)_a=54, disc_2(Fake)_a=54\n",
            ">2073, disc_1(Real)=0.613, disc_2(Fake)=0.661, gen_loss=0.841, disc_1(Real)_a=71, disc_2(Fake)_a=60\n",
            ">2074, disc_1(Real)=0.614, disc_2(Fake)=0.690, gen_loss=0.830, disc_1(Real)_a=56, disc_2(Fake)_a=67\n",
            ">2075, disc_1(Real)=0.613, disc_2(Fake)=0.724, gen_loss=0.776, disc_1(Real)_a=68, disc_2(Fake)_a=57\n",
            ">2076, disc_1(Real)=0.606, disc_2(Fake)=0.701, gen_loss=0.806, disc_1(Real)_a=71, disc_2(Fake)_a=57\n",
            ">2077, disc_1(Real)=0.577, disc_2(Fake)=0.738, gen_loss=0.785, disc_1(Real)_a=75, disc_2(Fake)_a=48\n",
            ">2078, disc_1(Real)=0.629, disc_2(Fake)=0.706, gen_loss=0.777, disc_1(Real)_a=65, disc_2(Fake)_a=51\n",
            ">2079, disc_1(Real)=0.635, disc_2(Fake)=0.709, gen_loss=0.736, disc_1(Real)_a=62, disc_2(Fake)_a=48\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">2080, disc_1(Real)=0.602, disc_2(Fake)=0.708, gen_loss=0.809, disc_1(Real)_a=73, disc_2(Fake)_a=53\n",
            ">2081, disc_1(Real)=0.606, disc_2(Fake)=0.698, gen_loss=0.809, disc_1(Real)_a=78, disc_2(Fake)_a=60\n",
            ">2082, disc_1(Real)=0.661, disc_2(Fake)=0.688, gen_loss=0.823, disc_1(Real)_a=57, disc_2(Fake)_a=57\n",
            ">2083, disc_1(Real)=0.626, disc_2(Fake)=0.735, gen_loss=0.796, disc_1(Real)_a=59, disc_2(Fake)_a=57\n",
            ">2084, disc_1(Real)=0.622, disc_2(Fake)=0.731, gen_loss=0.816, disc_1(Real)_a=67, disc_2(Fake)_a=48\n",
            ">2085, disc_1(Real)=0.606, disc_2(Fake)=0.770, gen_loss=0.779, disc_1(Real)_a=68, disc_2(Fake)_a=54\n",
            ">2086, disc_1(Real)=0.659, disc_2(Fake)=0.703, gen_loss=0.762, disc_1(Real)_a=56, disc_2(Fake)_a=53\n",
            ">2087, disc_1(Real)=0.636, disc_2(Fake)=0.793, gen_loss=0.741, disc_1(Real)_a=60, disc_2(Fake)_a=34\n",
            ">2088, disc_1(Real)=0.618, disc_2(Fake)=0.756, gen_loss=0.744, disc_1(Real)_a=60, disc_2(Fake)_a=39\n",
            ">2089, disc_1(Real)=0.679, disc_2(Fake)=0.751, gen_loss=0.748, disc_1(Real)_a=53, disc_2(Fake)_a=35\n",
            ">2090, disc_1(Real)=0.609, disc_2(Fake)=0.755, gen_loss=0.747, disc_1(Real)_a=68, disc_2(Fake)_a=39\n",
            ">2091, disc_1(Real)=0.670, disc_2(Fake)=0.761, gen_loss=0.726, disc_1(Real)_a=53, disc_2(Fake)_a=32\n",
            ">2092, disc_1(Real)=0.639, disc_2(Fake)=0.761, gen_loss=0.733, disc_1(Real)_a=64, disc_2(Fake)_a=29\n",
            ">2093, disc_1(Real)=0.618, disc_2(Fake)=0.753, gen_loss=0.718, disc_1(Real)_a=68, disc_2(Fake)_a=35\n",
            ">2094, disc_1(Real)=0.651, disc_2(Fake)=0.779, gen_loss=0.710, disc_1(Real)_a=60, disc_2(Fake)_a=29\n",
            ">2095, disc_1(Real)=0.633, disc_2(Fake)=0.748, gen_loss=0.699, disc_1(Real)_a=70, disc_2(Fake)_a=39\n",
            ">2096, disc_1(Real)=0.620, disc_2(Fake)=0.793, gen_loss=0.713, disc_1(Real)_a=65, disc_2(Fake)_a=35\n",
            ">2097, disc_1(Real)=0.606, disc_2(Fake)=0.756, gen_loss=0.723, disc_1(Real)_a=68, disc_2(Fake)_a=39\n",
            ">2098, disc_1(Real)=0.627, disc_2(Fake)=0.735, gen_loss=0.737, disc_1(Real)_a=68, disc_2(Fake)_a=40\n",
            ">2099, disc_1(Real)=0.644, disc_2(Fake)=0.744, gen_loss=0.739, disc_1(Real)_a=67, disc_2(Fake)_a=37\n",
            ">2100, disc_1(Real)=0.626, disc_2(Fake)=0.752, gen_loss=0.731, disc_1(Real)_a=70, disc_2(Fake)_a=29\n",
            ">2101, disc_1(Real)=0.667, disc_2(Fake)=0.759, gen_loss=0.733, disc_1(Real)_a=64, disc_2(Fake)_a=34\n",
            ">2102, disc_1(Real)=0.635, disc_2(Fake)=0.747, gen_loss=0.748, disc_1(Real)_a=67, disc_2(Fake)_a=31\n",
            ">2103, disc_1(Real)=0.649, disc_2(Fake)=0.752, gen_loss=0.730, disc_1(Real)_a=59, disc_2(Fake)_a=39\n",
            ">2104, disc_1(Real)=0.627, disc_2(Fake)=0.772, gen_loss=0.743, disc_1(Real)_a=62, disc_2(Fake)_a=34\n",
            ">2105, disc_1(Real)=0.604, disc_2(Fake)=0.712, gen_loss=0.748, disc_1(Real)_a=71, disc_2(Fake)_a=43\n",
            ">2106, disc_1(Real)=0.630, disc_2(Fake)=0.741, gen_loss=0.723, disc_1(Real)_a=70, disc_2(Fake)_a=40\n",
            ">2107, disc_1(Real)=0.639, disc_2(Fake)=0.768, gen_loss=0.730, disc_1(Real)_a=62, disc_2(Fake)_a=32\n",
            ">2108, disc_1(Real)=0.677, disc_2(Fake)=0.751, gen_loss=0.722, disc_1(Real)_a=57, disc_2(Fake)_a=34\n",
            ">2109, disc_1(Real)=0.599, disc_2(Fake)=0.725, gen_loss=0.748, disc_1(Real)_a=73, disc_2(Fake)_a=43\n",
            ">2110, disc_1(Real)=0.627, disc_2(Fake)=0.726, gen_loss=0.749, disc_1(Real)_a=78, disc_2(Fake)_a=43\n",
            ">2111, disc_1(Real)=0.627, disc_2(Fake)=0.761, gen_loss=0.761, disc_1(Real)_a=57, disc_2(Fake)_a=40\n",
            ">2112, disc_1(Real)=0.636, disc_2(Fake)=0.687, gen_loss=0.762, disc_1(Real)_a=62, disc_2(Fake)_a=56\n",
            ">2113, disc_1(Real)=0.653, disc_2(Fake)=0.702, gen_loss=0.770, disc_1(Real)_a=57, disc_2(Fake)_a=45\n",
            ">2114, disc_1(Real)=0.624, disc_2(Fake)=0.714, gen_loss=0.793, disc_1(Real)_a=70, disc_2(Fake)_a=51\n",
            ">2115, disc_1(Real)=0.625, disc_2(Fake)=0.693, gen_loss=0.779, disc_1(Real)_a=76, disc_2(Fake)_a=59\n",
            ">2116, disc_1(Real)=0.615, disc_2(Fake)=0.703, gen_loss=0.796, disc_1(Real)_a=68, disc_2(Fake)_a=54\n",
            ">2117, disc_1(Real)=0.692, disc_2(Fake)=0.733, gen_loss=0.792, disc_1(Real)_a=51, disc_2(Fake)_a=53\n",
            ">2118, disc_1(Real)=0.667, disc_2(Fake)=0.738, gen_loss=0.776, disc_1(Real)_a=57, disc_2(Fake)_a=45\n",
            ">2119, disc_1(Real)=0.703, disc_2(Fake)=0.698, gen_loss=0.801, disc_1(Real)_a=59, disc_2(Fake)_a=56\n",
            ">2120, disc_1(Real)=0.643, disc_2(Fake)=0.690, gen_loss=0.807, disc_1(Real)_a=65, disc_2(Fake)_a=50\n",
            ">2121, disc_1(Real)=0.634, disc_2(Fake)=0.666, gen_loss=0.797, disc_1(Real)_a=67, disc_2(Fake)_a=57\n",
            ">2122, disc_1(Real)=0.653, disc_2(Fake)=0.662, gen_loss=0.818, disc_1(Real)_a=62, disc_2(Fake)_a=56\n",
            ">2123, disc_1(Real)=0.660, disc_2(Fake)=0.657, gen_loss=0.831, disc_1(Real)_a=62, disc_2(Fake)_a=60\n",
            ">2124, disc_1(Real)=0.622, disc_2(Fake)=0.627, gen_loss=0.819, disc_1(Real)_a=59, disc_2(Fake)_a=64\n",
            ">2125, disc_1(Real)=0.712, disc_2(Fake)=0.661, gen_loss=0.851, disc_1(Real)_a=51, disc_2(Fake)_a=56\n",
            ">2126, disc_1(Real)=0.741, disc_2(Fake)=0.643, gen_loss=0.837, disc_1(Real)_a=45, disc_2(Fake)_a=67\n",
            ">2127, disc_1(Real)=0.692, disc_2(Fake)=0.639, gen_loss=0.879, disc_1(Real)_a=46, disc_2(Fake)_a=68\n",
            ">2128, disc_1(Real)=0.682, disc_2(Fake)=0.627, gen_loss=0.860, disc_1(Real)_a=43, disc_2(Fake)_a=73\n",
            ">2129, disc_1(Real)=0.709, disc_2(Fake)=0.605, gen_loss=0.859, disc_1(Real)_a=48, disc_2(Fake)_a=82\n",
            ">2130, disc_1(Real)=0.664, disc_2(Fake)=0.595, gen_loss=0.868, disc_1(Real)_a=60, disc_2(Fake)_a=76\n",
            ">2131, disc_1(Real)=0.688, disc_2(Fake)=0.592, gen_loss=0.891, disc_1(Real)_a=51, disc_2(Fake)_a=85\n",
            ">2132, disc_1(Real)=0.700, disc_2(Fake)=0.579, gen_loss=0.921, disc_1(Real)_a=46, disc_2(Fake)_a=87\n",
            ">2133, disc_1(Real)=0.737, disc_2(Fake)=0.600, gen_loss=0.885, disc_1(Real)_a=48, disc_2(Fake)_a=78\n",
            ">2134, disc_1(Real)=0.702, disc_2(Fake)=0.559, gen_loss=0.932, disc_1(Real)_a=48, disc_2(Fake)_a=92\n",
            ">2135, disc_1(Real)=0.708, disc_2(Fake)=0.591, gen_loss=0.912, disc_1(Real)_a=53, disc_2(Fake)_a=84\n",
            ">2136, disc_1(Real)=0.677, disc_2(Fake)=0.595, gen_loss=0.940, disc_1(Real)_a=53, disc_2(Fake)_a=82\n",
            ">2137, disc_1(Real)=0.653, disc_2(Fake)=0.592, gen_loss=0.944, disc_1(Real)_a=65, disc_2(Fake)_a=79\n",
            ">2138, disc_1(Real)=0.718, disc_2(Fake)=0.546, gen_loss=0.959, disc_1(Real)_a=48, disc_2(Fake)_a=93\n",
            ">2139, disc_1(Real)=0.665, disc_2(Fake)=0.564, gen_loss=1.001, disc_1(Real)_a=57, disc_2(Fake)_a=78\n",
            ">2140, disc_1(Real)=0.700, disc_2(Fake)=0.536, gen_loss=0.989, disc_1(Real)_a=48, disc_2(Fake)_a=89\n",
            ">2141, disc_1(Real)=0.681, disc_2(Fake)=0.521, gen_loss=0.972, disc_1(Real)_a=50, disc_2(Fake)_a=89\n",
            ">2142, disc_1(Real)=0.665, disc_2(Fake)=0.531, gen_loss=0.966, disc_1(Real)_a=57, disc_2(Fake)_a=87\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">2143, disc_1(Real)=0.725, disc_2(Fake)=0.605, gen_loss=1.026, disc_1(Real)_a=51, disc_2(Fake)_a=75\n",
            ">2144, disc_1(Real)=0.679, disc_2(Fake)=0.527, gen_loss=1.031, disc_1(Real)_a=54, disc_2(Fake)_a=87\n",
            ">2145, disc_1(Real)=0.688, disc_2(Fake)=0.525, gen_loss=1.027, disc_1(Real)_a=51, disc_2(Fake)_a=92\n",
            ">2146, disc_1(Real)=0.712, disc_2(Fake)=0.557, gen_loss=1.020, disc_1(Real)_a=46, disc_2(Fake)_a=87\n",
            ">2147, disc_1(Real)=0.656, disc_2(Fake)=0.525, gen_loss=1.007, disc_1(Real)_a=62, disc_2(Fake)_a=98\n",
            ">2148, disc_1(Real)=0.701, disc_2(Fake)=0.501, gen_loss=0.994, disc_1(Real)_a=43, disc_2(Fake)_a=93\n",
            ">2149, disc_1(Real)=0.742, disc_2(Fake)=0.537, gen_loss=0.976, disc_1(Real)_a=43, disc_2(Fake)_a=87\n",
            ">2150, disc_1(Real)=0.692, disc_2(Fake)=0.560, gen_loss=0.984, disc_1(Real)_a=48, disc_2(Fake)_a=82\n",
            ">2151, disc_1(Real)=0.671, disc_2(Fake)=0.563, gen_loss=0.929, disc_1(Real)_a=53, disc_2(Fake)_a=84\n",
            ">2152, disc_1(Real)=0.688, disc_2(Fake)=0.562, gen_loss=0.946, disc_1(Real)_a=56, disc_2(Fake)_a=79\n",
            ">2153, disc_1(Real)=0.723, disc_2(Fake)=0.607, gen_loss=0.923, disc_1(Real)_a=46, disc_2(Fake)_a=76\n",
            ">2154, disc_1(Real)=0.690, disc_2(Fake)=0.571, gen_loss=0.896, disc_1(Real)_a=56, disc_2(Fake)_a=78\n",
            ">2155, disc_1(Real)=0.670, disc_2(Fake)=0.576, gen_loss=0.982, disc_1(Real)_a=56, disc_2(Fake)_a=76\n",
            ">2156, disc_1(Real)=0.703, disc_2(Fake)=0.562, gen_loss=0.908, disc_1(Real)_a=40, disc_2(Fake)_a=73\n",
            ">2157, disc_1(Real)=0.678, disc_2(Fake)=0.602, gen_loss=0.928, disc_1(Real)_a=53, disc_2(Fake)_a=65\n",
            ">2158, disc_1(Real)=0.723, disc_2(Fake)=0.608, gen_loss=0.920, disc_1(Real)_a=45, disc_2(Fake)_a=68\n",
            ">2159, disc_1(Real)=0.662, disc_2(Fake)=0.608, gen_loss=0.901, disc_1(Real)_a=53, disc_2(Fake)_a=65\n",
            ">2160, disc_1(Real)=0.688, disc_2(Fake)=0.628, gen_loss=0.915, disc_1(Real)_a=54, disc_2(Fake)_a=64\n",
            ">2161, disc_1(Real)=0.704, disc_2(Fake)=0.622, gen_loss=0.872, disc_1(Real)_a=46, disc_2(Fake)_a=67\n",
            ">2162, disc_1(Real)=0.702, disc_2(Fake)=0.621, gen_loss=0.879, disc_1(Real)_a=59, disc_2(Fake)_a=73\n",
            ">2163, disc_1(Real)=0.688, disc_2(Fake)=0.638, gen_loss=0.859, disc_1(Real)_a=50, disc_2(Fake)_a=62\n",
            ">2164, disc_1(Real)=0.692, disc_2(Fake)=0.584, gen_loss=0.875, disc_1(Real)_a=51, disc_2(Fake)_a=79\n",
            ">2165, disc_1(Real)=0.680, disc_2(Fake)=0.624, gen_loss=0.877, disc_1(Real)_a=54, disc_2(Fake)_a=68\n",
            ">2166, disc_1(Real)=0.670, disc_2(Fake)=0.578, gen_loss=0.879, disc_1(Real)_a=64, disc_2(Fake)_a=82\n",
            ">2167, disc_1(Real)=0.723, disc_2(Fake)=0.651, gen_loss=0.862, disc_1(Real)_a=56, disc_2(Fake)_a=65\n",
            ">2168, disc_1(Real)=0.727, disc_2(Fake)=0.602, gen_loss=0.842, disc_1(Real)_a=48, disc_2(Fake)_a=71\n",
            ">2169, disc_1(Real)=0.691, disc_2(Fake)=0.641, gen_loss=0.840, disc_1(Real)_a=64, disc_2(Fake)_a=65\n",
            ">2170, disc_1(Real)=0.687, disc_2(Fake)=0.681, gen_loss=0.840, disc_1(Real)_a=57, disc_2(Fake)_a=56\n",
            ">2171, disc_1(Real)=0.680, disc_2(Fake)=0.691, gen_loss=0.824, disc_1(Real)_a=62, disc_2(Fake)_a=57\n",
            ">2172, disc_1(Real)=0.735, disc_2(Fake)=0.678, gen_loss=0.830, disc_1(Real)_a=45, disc_2(Fake)_a=50\n",
            ">2173, disc_1(Real)=0.659, disc_2(Fake)=0.615, gen_loss=0.860, disc_1(Real)_a=57, disc_2(Fake)_a=71\n",
            ">2174, disc_1(Real)=0.701, disc_2(Fake)=0.638, gen_loss=0.844, disc_1(Real)_a=60, disc_2(Fake)_a=59\n",
            ">2175, disc_1(Real)=0.703, disc_2(Fake)=0.618, gen_loss=0.847, disc_1(Real)_a=46, disc_2(Fake)_a=68\n",
            ">2176, disc_1(Real)=0.742, disc_2(Fake)=0.653, gen_loss=0.809, disc_1(Real)_a=40, disc_2(Fake)_a=67\n",
            ">2177, disc_1(Real)=0.724, disc_2(Fake)=0.667, gen_loss=0.833, disc_1(Real)_a=50, disc_2(Fake)_a=59\n",
            ">2178, disc_1(Real)=0.711, disc_2(Fake)=0.633, gen_loss=0.818, disc_1(Real)_a=59, disc_2(Fake)_a=65\n",
            ">2179, disc_1(Real)=0.677, disc_2(Fake)=0.676, gen_loss=0.787, disc_1(Real)_a=54, disc_2(Fake)_a=56\n",
            ">2180, disc_1(Real)=0.703, disc_2(Fake)=0.670, gen_loss=0.770, disc_1(Real)_a=50, disc_2(Fake)_a=59\n",
            ">2181, disc_1(Real)=0.780, disc_2(Fake)=0.667, gen_loss=0.761, disc_1(Real)_a=45, disc_2(Fake)_a=59\n",
            ">2182, disc_1(Real)=0.701, disc_2(Fake)=0.706, gen_loss=0.785, disc_1(Real)_a=57, disc_2(Fake)_a=45\n",
            ">2183, disc_1(Real)=0.672, disc_2(Fake)=0.753, gen_loss=0.767, disc_1(Real)_a=60, disc_2(Fake)_a=37\n",
            ">2184, disc_1(Real)=0.680, disc_2(Fake)=0.687, gen_loss=0.766, disc_1(Real)_a=54, disc_2(Fake)_a=54\n",
            ">2185, disc_1(Real)=0.675, disc_2(Fake)=0.679, gen_loss=0.748, disc_1(Real)_a=54, disc_2(Fake)_a=53\n",
            ">2186, disc_1(Real)=0.666, disc_2(Fake)=0.708, gen_loss=0.773, disc_1(Real)_a=59, disc_2(Fake)_a=42\n",
            ">2187, disc_1(Real)=0.679, disc_2(Fake)=0.714, gen_loss=0.782, disc_1(Real)_a=46, disc_2(Fake)_a=43\n",
            ">2188, disc_1(Real)=0.668, disc_2(Fake)=0.695, gen_loss=0.797, disc_1(Real)_a=60, disc_2(Fake)_a=50\n",
            ">2189, disc_1(Real)=0.725, disc_2(Fake)=0.680, gen_loss=0.762, disc_1(Real)_a=51, disc_2(Fake)_a=50\n",
            ">2190, disc_1(Real)=0.735, disc_2(Fake)=0.680, gen_loss=0.772, disc_1(Real)_a=54, disc_2(Fake)_a=54\n",
            ">2191, disc_1(Real)=0.694, disc_2(Fake)=0.675, gen_loss=0.761, disc_1(Real)_a=48, disc_2(Fake)_a=56\n",
            ">2192, disc_1(Real)=0.677, disc_2(Fake)=0.705, gen_loss=0.757, disc_1(Real)_a=54, disc_2(Fake)_a=53\n",
            ">2193, disc_1(Real)=0.669, disc_2(Fake)=0.705, gen_loss=0.763, disc_1(Real)_a=64, disc_2(Fake)_a=48\n",
            ">2194, disc_1(Real)=0.686, disc_2(Fake)=0.706, gen_loss=0.801, disc_1(Real)_a=54, disc_2(Fake)_a=48\n",
            ">2195, disc_1(Real)=0.707, disc_2(Fake)=0.674, gen_loss=0.757, disc_1(Real)_a=59, disc_2(Fake)_a=51\n",
            ">2196, disc_1(Real)=0.664, disc_2(Fake)=0.672, gen_loss=0.738, disc_1(Real)_a=59, disc_2(Fake)_a=62\n",
            ">2197, disc_1(Real)=0.685, disc_2(Fake)=0.684, gen_loss=0.806, disc_1(Real)_a=59, disc_2(Fake)_a=46\n",
            ">2198, disc_1(Real)=0.687, disc_2(Fake)=0.689, gen_loss=0.789, disc_1(Real)_a=60, disc_2(Fake)_a=53\n",
            ">2199, disc_1(Real)=0.672, disc_2(Fake)=0.680, gen_loss=0.778, disc_1(Real)_a=60, disc_2(Fake)_a=53\n",
            ">2200, disc_1(Real)=0.689, disc_2(Fake)=0.658, gen_loss=0.785, disc_1(Real)_a=57, disc_2(Fake)_a=59\n",
            ">2201, disc_1(Real)=0.706, disc_2(Fake)=0.709, gen_loss=0.811, disc_1(Real)_a=45, disc_2(Fake)_a=39\n",
            ">2202, disc_1(Real)=0.679, disc_2(Fake)=0.648, gen_loss=0.804, disc_1(Real)_a=53, disc_2(Fake)_a=57\n",
            ">2203, disc_1(Real)=0.692, disc_2(Fake)=0.651, gen_loss=0.825, disc_1(Real)_a=51, disc_2(Fake)_a=62\n",
            ">2204, disc_1(Real)=0.673, disc_2(Fake)=0.651, gen_loss=0.806, disc_1(Real)_a=56, disc_2(Fake)_a=70\n",
            ">2205, disc_1(Real)=0.662, disc_2(Fake)=0.648, gen_loss=0.795, disc_1(Real)_a=57, disc_2(Fake)_a=64\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">2206, disc_1(Real)=0.662, disc_2(Fake)=0.647, gen_loss=0.819, disc_1(Real)_a=51, disc_2(Fake)_a=64\n",
            ">2207, disc_1(Real)=0.691, disc_2(Fake)=0.656, gen_loss=0.814, disc_1(Real)_a=46, disc_2(Fake)_a=70\n",
            ">2208, disc_1(Real)=0.677, disc_2(Fake)=0.662, gen_loss=0.808, disc_1(Real)_a=56, disc_2(Fake)_a=59\n",
            ">2209, disc_1(Real)=0.709, disc_2(Fake)=0.658, gen_loss=0.818, disc_1(Real)_a=46, disc_2(Fake)_a=64\n",
            ">2210, disc_1(Real)=0.712, disc_2(Fake)=0.647, gen_loss=0.819, disc_1(Real)_a=53, disc_2(Fake)_a=71\n",
            ">2211, disc_1(Real)=0.662, disc_2(Fake)=0.635, gen_loss=0.830, disc_1(Real)_a=59, disc_2(Fake)_a=73\n",
            ">2212, disc_1(Real)=0.621, disc_2(Fake)=0.652, gen_loss=0.814, disc_1(Real)_a=79, disc_2(Fake)_a=62\n",
            ">2213, disc_1(Real)=0.650, disc_2(Fake)=0.644, gen_loss=0.827, disc_1(Real)_a=68, disc_2(Fake)_a=60\n",
            ">2214, disc_1(Real)=0.655, disc_2(Fake)=0.657, gen_loss=0.832, disc_1(Real)_a=62, disc_2(Fake)_a=62\n",
            ">2215, disc_1(Real)=0.621, disc_2(Fake)=0.652, gen_loss=0.855, disc_1(Real)_a=76, disc_2(Fake)_a=59\n",
            ">2216, disc_1(Real)=0.669, disc_2(Fake)=0.639, gen_loss=0.859, disc_1(Real)_a=60, disc_2(Fake)_a=64\n",
            ">2217, disc_1(Real)=0.696, disc_2(Fake)=0.621, gen_loss=0.845, disc_1(Real)_a=53, disc_2(Fake)_a=71\n",
            ">2218, disc_1(Real)=0.650, disc_2(Fake)=0.619, gen_loss=0.831, disc_1(Real)_a=62, disc_2(Fake)_a=76\n",
            ">2219, disc_1(Real)=0.711, disc_2(Fake)=0.612, gen_loss=0.824, disc_1(Real)_a=50, disc_2(Fake)_a=79\n",
            ">2220, disc_1(Real)=0.651, disc_2(Fake)=0.657, gen_loss=0.815, disc_1(Real)_a=64, disc_2(Fake)_a=64\n",
            ">2221, disc_1(Real)=0.653, disc_2(Fake)=0.643, gen_loss=0.800, disc_1(Real)_a=60, disc_2(Fake)_a=64\n",
            ">2222, disc_1(Real)=0.650, disc_2(Fake)=0.644, gen_loss=0.826, disc_1(Real)_a=67, disc_2(Fake)_a=70\n",
            ">2223, disc_1(Real)=0.660, disc_2(Fake)=0.618, gen_loss=0.806, disc_1(Real)_a=60, disc_2(Fake)_a=78\n",
            ">2224, disc_1(Real)=0.677, disc_2(Fake)=0.670, gen_loss=0.799, disc_1(Real)_a=60, disc_2(Fake)_a=60\n",
            ">2225, disc_1(Real)=0.690, disc_2(Fake)=0.649, gen_loss=0.799, disc_1(Real)_a=53, disc_2(Fake)_a=70\n",
            ">2226, disc_1(Real)=0.691, disc_2(Fake)=0.660, gen_loss=0.819, disc_1(Real)_a=56, disc_2(Fake)_a=60\n",
            ">2227, disc_1(Real)=0.672, disc_2(Fake)=0.664, gen_loss=0.802, disc_1(Real)_a=62, disc_2(Fake)_a=60\n",
            ">2228, disc_1(Real)=0.663, disc_2(Fake)=0.641, gen_loss=0.804, disc_1(Real)_a=62, disc_2(Fake)_a=64\n",
            ">2229, disc_1(Real)=0.646, disc_2(Fake)=0.687, gen_loss=0.800, disc_1(Real)_a=64, disc_2(Fake)_a=51\n",
            ">2230, disc_1(Real)=0.645, disc_2(Fake)=0.685, gen_loss=0.787, disc_1(Real)_a=70, disc_2(Fake)_a=54\n",
            ">2231, disc_1(Real)=0.672, disc_2(Fake)=0.666, gen_loss=0.769, disc_1(Real)_a=54, disc_2(Fake)_a=59\n",
            ">2232, disc_1(Real)=0.683, disc_2(Fake)=0.698, gen_loss=0.785, disc_1(Real)_a=60, disc_2(Fake)_a=48\n",
            ">2233, disc_1(Real)=0.702, disc_2(Fake)=0.685, gen_loss=0.792, disc_1(Real)_a=54, disc_2(Fake)_a=56\n",
            ">2234, disc_1(Real)=0.672, disc_2(Fake)=0.690, gen_loss=0.795, disc_1(Real)_a=60, disc_2(Fake)_a=50\n",
            ">2235, disc_1(Real)=0.707, disc_2(Fake)=0.663, gen_loss=0.777, disc_1(Real)_a=43, disc_2(Fake)_a=62\n",
            ">2236, disc_1(Real)=0.674, disc_2(Fake)=0.702, gen_loss=0.786, disc_1(Real)_a=60, disc_2(Fake)_a=51\n",
            ">2237, disc_1(Real)=0.678, disc_2(Fake)=0.739, gen_loss=0.783, disc_1(Real)_a=57, disc_2(Fake)_a=43\n",
            ">2238, disc_1(Real)=0.710, disc_2(Fake)=0.659, gen_loss=0.802, disc_1(Real)_a=53, disc_2(Fake)_a=64\n",
            ">2239, disc_1(Real)=0.661, disc_2(Fake)=0.641, gen_loss=0.807, disc_1(Real)_a=60, disc_2(Fake)_a=73\n",
            ">2240, disc_1(Real)=0.685, disc_2(Fake)=0.660, gen_loss=0.791, disc_1(Real)_a=54, disc_2(Fake)_a=67\n",
            ">2241, disc_1(Real)=0.658, disc_2(Fake)=0.683, gen_loss=0.804, disc_1(Real)_a=56, disc_2(Fake)_a=53\n",
            ">2242, disc_1(Real)=0.641, disc_2(Fake)=0.689, gen_loss=0.795, disc_1(Real)_a=64, disc_2(Fake)_a=51\n",
            ">2243, disc_1(Real)=0.700, disc_2(Fake)=0.629, gen_loss=0.797, disc_1(Real)_a=50, disc_2(Fake)_a=65\n",
            ">2244, disc_1(Real)=0.675, disc_2(Fake)=0.659, gen_loss=0.821, disc_1(Real)_a=54, disc_2(Fake)_a=54\n",
            ">2245, disc_1(Real)=0.630, disc_2(Fake)=0.670, gen_loss=0.798, disc_1(Real)_a=73, disc_2(Fake)_a=53\n",
            ">2246, disc_1(Real)=0.711, disc_2(Fake)=0.681, gen_loss=0.786, disc_1(Real)_a=39, disc_2(Fake)_a=50\n",
            ">2247, disc_1(Real)=0.657, disc_2(Fake)=0.679, gen_loss=0.817, disc_1(Real)_a=59, disc_2(Fake)_a=56\n",
            ">2248, disc_1(Real)=0.656, disc_2(Fake)=0.639, gen_loss=0.792, disc_1(Real)_a=67, disc_2(Fake)_a=64\n",
            ">2249, disc_1(Real)=0.699, disc_2(Fake)=0.676, gen_loss=0.788, disc_1(Real)_a=53, disc_2(Fake)_a=54\n",
            ">2250, disc_1(Real)=0.657, disc_2(Fake)=0.670, gen_loss=0.789, disc_1(Real)_a=56, disc_2(Fake)_a=56\n",
            ">2251, disc_1(Real)=0.657, disc_2(Fake)=0.660, gen_loss=0.818, disc_1(Real)_a=64, disc_2(Fake)_a=65\n",
            ">2252, disc_1(Real)=0.639, disc_2(Fake)=0.666, gen_loss=0.856, disc_1(Real)_a=67, disc_2(Fake)_a=56\n",
            ">2253, disc_1(Real)=0.643, disc_2(Fake)=0.622, gen_loss=0.892, disc_1(Real)_a=62, disc_2(Fake)_a=75\n",
            ">2254, disc_1(Real)=0.687, disc_2(Fake)=0.615, gen_loss=0.882, disc_1(Real)_a=62, disc_2(Fake)_a=75\n",
            ">2255, disc_1(Real)=0.619, disc_2(Fake)=0.586, gen_loss=0.913, disc_1(Real)_a=67, disc_2(Fake)_a=82\n",
            ">2256, disc_1(Real)=0.665, disc_2(Fake)=0.607, gen_loss=0.862, disc_1(Real)_a=56, disc_2(Fake)_a=76\n",
            ">2257, disc_1(Real)=0.656, disc_2(Fake)=0.619, gen_loss=0.836, disc_1(Real)_a=62, disc_2(Fake)_a=75\n",
            ">2258, disc_1(Real)=0.684, disc_2(Fake)=0.655, gen_loss=0.807, disc_1(Real)_a=56, disc_2(Fake)_a=62\n",
            ">2259, disc_1(Real)=0.647, disc_2(Fake)=0.662, gen_loss=0.831, disc_1(Real)_a=70, disc_2(Fake)_a=65\n",
            ">2260, disc_1(Real)=0.638, disc_2(Fake)=0.690, gen_loss=0.821, disc_1(Real)_a=67, disc_2(Fake)_a=57\n",
            ">2261, disc_1(Real)=0.622, disc_2(Fake)=0.657, gen_loss=0.849, disc_1(Real)_a=65, disc_2(Fake)_a=64\n",
            ">2262, disc_1(Real)=0.631, disc_2(Fake)=0.627, gen_loss=0.835, disc_1(Real)_a=67, disc_2(Fake)_a=71\n",
            ">2263, disc_1(Real)=0.639, disc_2(Fake)=0.654, gen_loss=0.866, disc_1(Real)_a=70, disc_2(Fake)_a=62\n",
            ">2264, disc_1(Real)=0.637, disc_2(Fake)=0.601, gen_loss=0.863, disc_1(Real)_a=75, disc_2(Fake)_a=73\n",
            ">2265, disc_1(Real)=0.622, disc_2(Fake)=0.616, gen_loss=0.862, disc_1(Real)_a=70, disc_2(Fake)_a=71\n",
            ">2266, disc_1(Real)=0.604, disc_2(Fake)=0.662, gen_loss=0.829, disc_1(Real)_a=70, disc_2(Fake)_a=62\n",
            ">2267, disc_1(Real)=0.646, disc_2(Fake)=0.606, gen_loss=0.835, disc_1(Real)_a=71, disc_2(Fake)_a=78\n",
            ">2268, disc_1(Real)=0.688, disc_2(Fake)=0.645, gen_loss=0.792, disc_1(Real)_a=56, disc_2(Fake)_a=68\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">2269, disc_1(Real)=0.645, disc_2(Fake)=0.632, gen_loss=0.823, disc_1(Real)_a=67, disc_2(Fake)_a=75\n",
            ">2270, disc_1(Real)=0.642, disc_2(Fake)=0.660, gen_loss=0.814, disc_1(Real)_a=62, disc_2(Fake)_a=59\n",
            ">2271, disc_1(Real)=0.655, disc_2(Fake)=0.653, gen_loss=0.848, disc_1(Real)_a=59, disc_2(Fake)_a=67\n",
            ">2272, disc_1(Real)=0.684, disc_2(Fake)=0.657, gen_loss=0.871, disc_1(Real)_a=57, disc_2(Fake)_a=68\n",
            ">2273, disc_1(Real)=0.697, disc_2(Fake)=0.639, gen_loss=0.882, disc_1(Real)_a=57, disc_2(Fake)_a=64\n",
            ">2274, disc_1(Real)=0.661, disc_2(Fake)=0.576, gen_loss=0.911, disc_1(Real)_a=60, disc_2(Fake)_a=82\n",
            ">2275, disc_1(Real)=0.656, disc_2(Fake)=0.565, gen_loss=0.958, disc_1(Real)_a=59, disc_2(Fake)_a=87\n",
            ">2276, disc_1(Real)=0.672, disc_2(Fake)=0.591, gen_loss=0.953, disc_1(Real)_a=53, disc_2(Fake)_a=75\n",
            ">2277, disc_1(Real)=0.675, disc_2(Fake)=0.578, gen_loss=0.908, disc_1(Real)_a=59, disc_2(Fake)_a=82\n",
            ">2278, disc_1(Real)=0.681, disc_2(Fake)=0.583, gen_loss=0.912, disc_1(Real)_a=54, disc_2(Fake)_a=84\n",
            ">2279, disc_1(Real)=0.692, disc_2(Fake)=0.654, gen_loss=0.861, disc_1(Real)_a=57, disc_2(Fake)_a=68\n",
            ">2280, disc_1(Real)=0.659, disc_2(Fake)=0.630, gen_loss=0.857, disc_1(Real)_a=57, disc_2(Fake)_a=76\n",
            ">2281, disc_1(Real)=0.658, disc_2(Fake)=0.664, gen_loss=0.834, disc_1(Real)_a=60, disc_2(Fake)_a=64\n",
            ">2282, disc_1(Real)=0.645, disc_2(Fake)=0.648, gen_loss=0.830, disc_1(Real)_a=68, disc_2(Fake)_a=68\n",
            ">2283, disc_1(Real)=0.639, disc_2(Fake)=0.631, gen_loss=0.836, disc_1(Real)_a=70, disc_2(Fake)_a=76\n",
            ">2284, disc_1(Real)=0.655, disc_2(Fake)=0.608, gen_loss=0.882, disc_1(Real)_a=65, disc_2(Fake)_a=82\n",
            ">2285, disc_1(Real)=0.658, disc_2(Fake)=0.587, gen_loss=0.870, disc_1(Real)_a=64, disc_2(Fake)_a=89\n",
            ">2286, disc_1(Real)=0.615, disc_2(Fake)=0.622, gen_loss=0.871, disc_1(Real)_a=73, disc_2(Fake)_a=79\n",
            ">2287, disc_1(Real)=0.670, disc_2(Fake)=0.596, gen_loss=0.849, disc_1(Real)_a=56, disc_2(Fake)_a=79\n",
            ">2288, disc_1(Real)=0.648, disc_2(Fake)=0.628, gen_loss=0.877, disc_1(Real)_a=59, disc_2(Fake)_a=73\n",
            ">2289, disc_1(Real)=0.603, disc_2(Fake)=0.639, gen_loss=0.819, disc_1(Real)_a=70, disc_2(Fake)_a=64\n",
            ">2290, disc_1(Real)=0.671, disc_2(Fake)=0.674, gen_loss=0.821, disc_1(Real)_a=57, disc_2(Fake)_a=54\n",
            ">2291, disc_1(Real)=0.623, disc_2(Fake)=0.653, gen_loss=0.822, disc_1(Real)_a=70, disc_2(Fake)_a=65\n",
            ">2292, disc_1(Real)=0.654, disc_2(Fake)=0.668, gen_loss=0.839, disc_1(Real)_a=65, disc_2(Fake)_a=65\n",
            ">2293, disc_1(Real)=0.629, disc_2(Fake)=0.641, gen_loss=0.794, disc_1(Real)_a=67, disc_2(Fake)_a=67\n",
            ">2294, disc_1(Real)=0.663, disc_2(Fake)=0.643, gen_loss=0.837, disc_1(Real)_a=56, disc_2(Fake)_a=68\n",
            ">2295, disc_1(Real)=0.674, disc_2(Fake)=0.584, gen_loss=0.915, disc_1(Real)_a=57, disc_2(Fake)_a=89\n",
            ">2296, disc_1(Real)=0.628, disc_2(Fake)=0.600, gen_loss=0.924, disc_1(Real)_a=70, disc_2(Fake)_a=78\n",
            ">2297, disc_1(Real)=0.688, disc_2(Fake)=0.563, gen_loss=0.942, disc_1(Real)_a=56, disc_2(Fake)_a=82\n",
            ">2298, disc_1(Real)=0.680, disc_2(Fake)=0.601, gen_loss=0.930, disc_1(Real)_a=62, disc_2(Fake)_a=71\n",
            ">2299, disc_1(Real)=0.629, disc_2(Fake)=0.567, gen_loss=0.944, disc_1(Real)_a=60, disc_2(Fake)_a=76\n",
            ">2300, disc_1(Real)=0.698, disc_2(Fake)=0.583, gen_loss=0.959, disc_1(Real)_a=48, disc_2(Fake)_a=68\n",
            ">2301, disc_1(Real)=0.693, disc_2(Fake)=0.585, gen_loss=0.909, disc_1(Real)_a=51, disc_2(Fake)_a=65\n",
            ">2302, disc_1(Real)=0.701, disc_2(Fake)=0.630, gen_loss=0.896, disc_1(Real)_a=54, disc_2(Fake)_a=59\n",
            ">2303, disc_1(Real)=0.640, disc_2(Fake)=0.649, gen_loss=0.867, disc_1(Real)_a=59, disc_2(Fake)_a=57\n",
            ">2304, disc_1(Real)=0.635, disc_2(Fake)=0.635, gen_loss=0.859, disc_1(Real)_a=67, disc_2(Fake)_a=65\n",
            ">2305, disc_1(Real)=0.670, disc_2(Fake)=0.602, gen_loss=0.880, disc_1(Real)_a=62, disc_2(Fake)_a=70\n",
            ">2306, disc_1(Real)=0.641, disc_2(Fake)=0.595, gen_loss=0.911, disc_1(Real)_a=68, disc_2(Fake)_a=76\n",
            ">2307, disc_1(Real)=0.664, disc_2(Fake)=0.607, gen_loss=0.951, disc_1(Real)_a=56, disc_2(Fake)_a=79\n",
            ">2308, disc_1(Real)=0.658, disc_2(Fake)=0.557, gen_loss=0.975, disc_1(Real)_a=59, disc_2(Fake)_a=90\n",
            ">2309, disc_1(Real)=0.690, disc_2(Fake)=0.533, gen_loss=1.045, disc_1(Real)_a=54, disc_2(Fake)_a=87\n",
            ">2310, disc_1(Real)=0.720, disc_2(Fake)=0.534, gen_loss=1.015, disc_1(Real)_a=50, disc_2(Fake)_a=87\n",
            ">2311, disc_1(Real)=0.686, disc_2(Fake)=0.553, gen_loss=1.007, disc_1(Real)_a=53, disc_2(Fake)_a=81\n",
            ">2312, disc_1(Real)=0.676, disc_2(Fake)=0.522, gen_loss=0.994, disc_1(Real)_a=57, disc_2(Fake)_a=87\n",
            ">2313, disc_1(Real)=0.662, disc_2(Fake)=0.580, gen_loss=0.954, disc_1(Real)_a=60, disc_2(Fake)_a=78\n",
            ">2314, disc_1(Real)=0.696, disc_2(Fake)=0.566, gen_loss=0.935, disc_1(Real)_a=57, disc_2(Fake)_a=79\n",
            ">2315, disc_1(Real)=0.656, disc_2(Fake)=0.614, gen_loss=0.942, disc_1(Real)_a=59, disc_2(Fake)_a=68\n",
            ">2316, disc_1(Real)=0.643, disc_2(Fake)=0.567, gen_loss=0.958, disc_1(Real)_a=70, disc_2(Fake)_a=81\n",
            ">2317, disc_1(Real)=0.666, disc_2(Fake)=0.553, gen_loss=0.958, disc_1(Real)_a=53, disc_2(Fake)_a=87\n",
            ">2318, disc_1(Real)=0.670, disc_2(Fake)=0.565, gen_loss=1.018, disc_1(Real)_a=64, disc_2(Fake)_a=84\n",
            ">2319, disc_1(Real)=0.710, disc_2(Fake)=0.499, gen_loss=1.052, disc_1(Real)_a=53, disc_2(Fake)_a=98\n",
            ">2320, disc_1(Real)=0.669, disc_2(Fake)=0.529, gen_loss=1.083, disc_1(Real)_a=59, disc_2(Fake)_a=95\n",
            ">2321, disc_1(Real)=0.690, disc_2(Fake)=0.515, gen_loss=1.034, disc_1(Real)_a=48, disc_2(Fake)_a=98\n",
            ">2322, disc_1(Real)=0.630, disc_2(Fake)=0.498, gen_loss=1.046, disc_1(Real)_a=68, disc_2(Fake)_a=98\n",
            ">2323, disc_1(Real)=0.671, disc_2(Fake)=0.522, gen_loss=1.050, disc_1(Real)_a=59, disc_2(Fake)_a=96\n",
            ">2324, disc_1(Real)=0.687, disc_2(Fake)=0.535, gen_loss=0.980, disc_1(Real)_a=53, disc_2(Fake)_a=92\n",
            ">2325, disc_1(Real)=0.643, disc_2(Fake)=0.556, gen_loss=0.947, disc_1(Real)_a=62, disc_2(Fake)_a=90\n",
            ">2326, disc_1(Real)=0.604, disc_2(Fake)=0.580, gen_loss=0.947, disc_1(Real)_a=75, disc_2(Fake)_a=87\n",
            ">2327, disc_1(Real)=0.659, disc_2(Fake)=0.564, gen_loss=0.930, disc_1(Real)_a=62, disc_2(Fake)_a=93\n",
            ">2328, disc_1(Real)=0.663, disc_2(Fake)=0.572, gen_loss=0.950, disc_1(Real)_a=62, disc_2(Fake)_a=87\n",
            ">2329, disc_1(Real)=0.638, disc_2(Fake)=0.584, gen_loss=0.977, disc_1(Real)_a=75, disc_2(Fake)_a=76\n",
            ">2330, disc_1(Real)=0.633, disc_2(Fake)=0.546, gen_loss=1.041, disc_1(Real)_a=71, disc_2(Fake)_a=81\n",
            ">2331, disc_1(Real)=0.611, disc_2(Fake)=0.541, gen_loss=1.014, disc_1(Real)_a=67, disc_2(Fake)_a=82\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">2332, disc_1(Real)=0.636, disc_2(Fake)=0.522, gen_loss=0.977, disc_1(Real)_a=70, disc_2(Fake)_a=78\n",
            ">2333, disc_1(Real)=0.589, disc_2(Fake)=0.573, gen_loss=0.993, disc_1(Real)_a=79, disc_2(Fake)_a=71\n",
            ">2334, disc_1(Real)=0.652, disc_2(Fake)=0.604, gen_loss=0.957, disc_1(Real)_a=65, disc_2(Fake)_a=71\n",
            ">2335, disc_1(Real)=0.615, disc_2(Fake)=0.589, gen_loss=0.877, disc_1(Real)_a=70, disc_2(Fake)_a=78\n",
            ">2336, disc_1(Real)=0.638, disc_2(Fake)=0.632, gen_loss=0.893, disc_1(Real)_a=67, disc_2(Fake)_a=67\n",
            ">2337, disc_1(Real)=0.638, disc_2(Fake)=0.624, gen_loss=0.891, disc_1(Real)_a=64, disc_2(Fake)_a=68\n",
            ">2338, disc_1(Real)=0.663, disc_2(Fake)=0.575, gen_loss=0.910, disc_1(Real)_a=62, disc_2(Fake)_a=78\n",
            ">2339, disc_1(Real)=0.638, disc_2(Fake)=0.571, gen_loss=0.908, disc_1(Real)_a=68, disc_2(Fake)_a=81\n",
            ">2340, disc_1(Real)=0.671, disc_2(Fake)=0.611, gen_loss=0.904, disc_1(Real)_a=59, disc_2(Fake)_a=81\n",
            ">2341, disc_1(Real)=0.670, disc_2(Fake)=0.586, gen_loss=0.937, disc_1(Real)_a=56, disc_2(Fake)_a=89\n",
            ">2342, disc_1(Real)=0.630, disc_2(Fake)=0.594, gen_loss=0.907, disc_1(Real)_a=62, disc_2(Fake)_a=76\n",
            ">2343, disc_1(Real)=0.696, disc_2(Fake)=0.612, gen_loss=0.902, disc_1(Real)_a=48, disc_2(Fake)_a=81\n",
            ">2344, disc_1(Real)=0.660, disc_2(Fake)=0.649, gen_loss=0.870, disc_1(Real)_a=64, disc_2(Fake)_a=64\n",
            ">2345, disc_1(Real)=0.678, disc_2(Fake)=0.652, gen_loss=0.843, disc_1(Real)_a=54, disc_2(Fake)_a=70\n",
            ">2346, disc_1(Real)=0.649, disc_2(Fake)=0.680, gen_loss=0.784, disc_1(Real)_a=62, disc_2(Fake)_a=62\n",
            ">2347, disc_1(Real)=0.632, disc_2(Fake)=0.656, gen_loss=0.773, disc_1(Real)_a=73, disc_2(Fake)_a=65\n",
            ">2348, disc_1(Real)=0.642, disc_2(Fake)=0.717, gen_loss=0.816, disc_1(Real)_a=62, disc_2(Fake)_a=46\n",
            ">2349, disc_1(Real)=0.650, disc_2(Fake)=0.673, gen_loss=0.801, disc_1(Real)_a=67, disc_2(Fake)_a=60\n",
            ">2350, disc_1(Real)=0.642, disc_2(Fake)=0.700, gen_loss=0.788, disc_1(Real)_a=67, disc_2(Fake)_a=53\n",
            ">2351, disc_1(Real)=0.658, disc_2(Fake)=0.695, gen_loss=0.794, disc_1(Real)_a=60, disc_2(Fake)_a=53\n",
            ">2352, disc_1(Real)=0.589, disc_2(Fake)=0.680, gen_loss=0.792, disc_1(Real)_a=78, disc_2(Fake)_a=53\n",
            ">2353, disc_1(Real)=0.640, disc_2(Fake)=0.705, gen_loss=0.796, disc_1(Real)_a=65, disc_2(Fake)_a=51\n",
            ">2354, disc_1(Real)=0.658, disc_2(Fake)=0.689, gen_loss=0.794, disc_1(Real)_a=59, disc_2(Fake)_a=51\n",
            ">2355, disc_1(Real)=0.628, disc_2(Fake)=0.678, gen_loss=0.796, disc_1(Real)_a=68, disc_2(Fake)_a=51\n",
            ">2356, disc_1(Real)=0.684, disc_2(Fake)=0.692, gen_loss=0.803, disc_1(Real)_a=56, disc_2(Fake)_a=50\n",
            ">2357, disc_1(Real)=0.627, disc_2(Fake)=0.674, gen_loss=0.791, disc_1(Real)_a=70, disc_2(Fake)_a=53\n",
            ">2358, disc_1(Real)=0.648, disc_2(Fake)=0.663, gen_loss=0.814, disc_1(Real)_a=68, disc_2(Fake)_a=71\n",
            ">2359, disc_1(Real)=0.647, disc_2(Fake)=0.648, gen_loss=0.849, disc_1(Real)_a=64, disc_2(Fake)_a=68\n",
            ">2360, disc_1(Real)=0.627, disc_2(Fake)=0.637, gen_loss=0.857, disc_1(Real)_a=67, disc_2(Fake)_a=73\n",
            ">2361, disc_1(Real)=0.675, disc_2(Fake)=0.628, gen_loss=0.849, disc_1(Real)_a=64, disc_2(Fake)_a=70\n",
            ">2362, disc_1(Real)=0.641, disc_2(Fake)=0.653, gen_loss=0.843, disc_1(Real)_a=67, disc_2(Fake)_a=68\n",
            ">2363, disc_1(Real)=0.674, disc_2(Fake)=0.673, gen_loss=0.795, disc_1(Real)_a=62, disc_2(Fake)_a=56\n",
            ">2364, disc_1(Real)=0.674, disc_2(Fake)=0.672, gen_loss=0.794, disc_1(Real)_a=54, disc_2(Fake)_a=59\n",
            ">2365, disc_1(Real)=0.714, disc_2(Fake)=0.729, gen_loss=0.769, disc_1(Real)_a=54, disc_2(Fake)_a=43\n",
            ">2366, disc_1(Real)=0.660, disc_2(Fake)=0.677, gen_loss=0.812, disc_1(Real)_a=62, disc_2(Fake)_a=51\n",
            ">2367, disc_1(Real)=0.664, disc_2(Fake)=0.738, gen_loss=0.799, disc_1(Real)_a=64, disc_2(Fake)_a=37\n",
            ">2368, disc_1(Real)=0.607, disc_2(Fake)=0.696, gen_loss=0.790, disc_1(Real)_a=79, disc_2(Fake)_a=50\n",
            ">2369, disc_1(Real)=0.629, disc_2(Fake)=0.704, gen_loss=0.797, disc_1(Real)_a=70, disc_2(Fake)_a=43\n",
            ">2370, disc_1(Real)=0.683, disc_2(Fake)=0.709, gen_loss=0.784, disc_1(Real)_a=59, disc_2(Fake)_a=48\n",
            ">2371, disc_1(Real)=0.659, disc_2(Fake)=0.693, gen_loss=0.781, disc_1(Real)_a=62, disc_2(Fake)_a=54\n",
            ">2372, disc_1(Real)=0.655, disc_2(Fake)=0.709, gen_loss=0.794, disc_1(Real)_a=60, disc_2(Fake)_a=46\n",
            ">2373, disc_1(Real)=0.615, disc_2(Fake)=0.633, gen_loss=0.816, disc_1(Real)_a=71, disc_2(Fake)_a=65\n",
            ">2374, disc_1(Real)=0.637, disc_2(Fake)=0.693, gen_loss=0.841, disc_1(Real)_a=65, disc_2(Fake)_a=54\n",
            ">2375, disc_1(Real)=0.677, disc_2(Fake)=0.692, gen_loss=0.830, disc_1(Real)_a=59, disc_2(Fake)_a=53\n",
            ">2376, disc_1(Real)=0.673, disc_2(Fake)=0.649, gen_loss=0.837, disc_1(Real)_a=54, disc_2(Fake)_a=62\n",
            ">2377, disc_1(Real)=0.682, disc_2(Fake)=0.673, gen_loss=0.837, disc_1(Real)_a=60, disc_2(Fake)_a=57\n",
            ">2378, disc_1(Real)=0.670, disc_2(Fake)=0.672, gen_loss=0.819, disc_1(Real)_a=64, disc_2(Fake)_a=53\n",
            ">2379, disc_1(Real)=0.631, disc_2(Fake)=0.665, gen_loss=0.812, disc_1(Real)_a=62, disc_2(Fake)_a=57\n",
            ">2380, disc_1(Real)=0.633, disc_2(Fake)=0.655, gen_loss=0.816, disc_1(Real)_a=73, disc_2(Fake)_a=62\n",
            ">2381, disc_1(Real)=0.634, disc_2(Fake)=0.667, gen_loss=0.794, disc_1(Real)_a=64, disc_2(Fake)_a=59\n",
            ">2382, disc_1(Real)=0.652, disc_2(Fake)=0.679, gen_loss=0.808, disc_1(Real)_a=62, disc_2(Fake)_a=57\n",
            ">2383, disc_1(Real)=0.626, disc_2(Fake)=0.704, gen_loss=0.801, disc_1(Real)_a=70, disc_2(Fake)_a=46\n",
            ">2384, disc_1(Real)=0.615, disc_2(Fake)=0.695, gen_loss=0.840, disc_1(Real)_a=75, disc_2(Fake)_a=46\n",
            ">2385, disc_1(Real)=0.678, disc_2(Fake)=0.678, gen_loss=0.798, disc_1(Real)_a=56, disc_2(Fake)_a=59\n",
            ">2386, disc_1(Real)=0.633, disc_2(Fake)=0.662, gen_loss=0.782, disc_1(Real)_a=73, disc_2(Fake)_a=60\n",
            ">2387, disc_1(Real)=0.611, disc_2(Fake)=0.681, gen_loss=0.756, disc_1(Real)_a=75, disc_2(Fake)_a=64\n",
            ">2388, disc_1(Real)=0.625, disc_2(Fake)=0.741, gen_loss=0.771, disc_1(Real)_a=68, disc_2(Fake)_a=37\n",
            ">2389, disc_1(Real)=0.666, disc_2(Fake)=0.715, gen_loss=0.719, disc_1(Real)_a=56, disc_2(Fake)_a=48\n",
            ">2390, disc_1(Real)=0.594, disc_2(Fake)=0.762, gen_loss=0.758, disc_1(Real)_a=79, disc_2(Fake)_a=31\n",
            ">2391, disc_1(Real)=0.646, disc_2(Fake)=0.770, gen_loss=0.749, disc_1(Real)_a=62, disc_2(Fake)_a=32\n",
            ">2392, disc_1(Real)=0.604, disc_2(Fake)=0.757, gen_loss=0.724, disc_1(Real)_a=81, disc_2(Fake)_a=40\n",
            ">2393, disc_1(Real)=0.623, disc_2(Fake)=0.750, gen_loss=0.740, disc_1(Real)_a=71, disc_2(Fake)_a=35\n",
            ">2394, disc_1(Real)=0.698, disc_2(Fake)=0.764, gen_loss=0.728, disc_1(Real)_a=46, disc_2(Fake)_a=37\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">2395, disc_1(Real)=0.663, disc_2(Fake)=0.715, gen_loss=0.713, disc_1(Real)_a=64, disc_2(Fake)_a=45\n",
            ">2396, disc_1(Real)=0.619, disc_2(Fake)=0.733, gen_loss=0.732, disc_1(Real)_a=73, disc_2(Fake)_a=46\n",
            ">2397, disc_1(Real)=0.656, disc_2(Fake)=0.754, gen_loss=0.720, disc_1(Real)_a=67, disc_2(Fake)_a=48\n",
            ">2398, disc_1(Real)=0.611, disc_2(Fake)=0.758, gen_loss=0.719, disc_1(Real)_a=73, disc_2(Fake)_a=34\n",
            ">2399, disc_1(Real)=0.664, disc_2(Fake)=0.740, gen_loss=0.713, disc_1(Real)_a=62, disc_2(Fake)_a=42\n",
            ">2400, disc_1(Real)=0.646, disc_2(Fake)=0.789, gen_loss=0.737, disc_1(Real)_a=62, disc_2(Fake)_a=34\n",
            ">2401, disc_1(Real)=0.596, disc_2(Fake)=0.725, gen_loss=0.763, disc_1(Real)_a=78, disc_2(Fake)_a=43\n",
            ">2402, disc_1(Real)=0.604, disc_2(Fake)=0.702, gen_loss=0.768, disc_1(Real)_a=68, disc_2(Fake)_a=48\n",
            ">2403, disc_1(Real)=0.632, disc_2(Fake)=0.667, gen_loss=0.778, disc_1(Real)_a=65, disc_2(Fake)_a=62\n",
            ">2404, disc_1(Real)=0.633, disc_2(Fake)=0.669, gen_loss=0.771, disc_1(Real)_a=68, disc_2(Fake)_a=59\n",
            ">2405, disc_1(Real)=0.617, disc_2(Fake)=0.695, gen_loss=0.776, disc_1(Real)_a=70, disc_2(Fake)_a=51\n",
            ">2406, disc_1(Real)=0.612, disc_2(Fake)=0.712, gen_loss=0.753, disc_1(Real)_a=73, disc_2(Fake)_a=43\n",
            ">2407, disc_1(Real)=0.622, disc_2(Fake)=0.722, gen_loss=0.772, disc_1(Real)_a=68, disc_2(Fake)_a=40\n",
            ">2408, disc_1(Real)=0.655, disc_2(Fake)=0.729, gen_loss=0.757, disc_1(Real)_a=70, disc_2(Fake)_a=39\n",
            ">2409, disc_1(Real)=0.612, disc_2(Fake)=0.708, gen_loss=0.766, disc_1(Real)_a=68, disc_2(Fake)_a=42\n",
            ">2410, disc_1(Real)=0.630, disc_2(Fake)=0.722, gen_loss=0.788, disc_1(Real)_a=70, disc_2(Fake)_a=40\n",
            ">2411, disc_1(Real)=0.664, disc_2(Fake)=0.683, gen_loss=0.778, disc_1(Real)_a=60, disc_2(Fake)_a=60\n",
            ">2412, disc_1(Real)=0.625, disc_2(Fake)=0.686, gen_loss=0.750, disc_1(Real)_a=65, disc_2(Fake)_a=51\n",
            ">2413, disc_1(Real)=0.649, disc_2(Fake)=0.741, gen_loss=0.739, disc_1(Real)_a=65, disc_2(Fake)_a=31\n",
            ">2414, disc_1(Real)=0.603, disc_2(Fake)=0.732, gen_loss=0.771, disc_1(Real)_a=67, disc_2(Fake)_a=34\n",
            ">2415, disc_1(Real)=0.645, disc_2(Fake)=0.733, gen_loss=0.744, disc_1(Real)_a=60, disc_2(Fake)_a=42\n",
            ">2416, disc_1(Real)=0.695, disc_2(Fake)=0.740, gen_loss=0.742, disc_1(Real)_a=59, disc_2(Fake)_a=37\n",
            ">2417, disc_1(Real)=0.664, disc_2(Fake)=0.742, gen_loss=0.739, disc_1(Real)_a=65, disc_2(Fake)_a=37\n",
            ">2418, disc_1(Real)=0.609, disc_2(Fake)=0.743, gen_loss=0.699, disc_1(Real)_a=68, disc_2(Fake)_a=29\n",
            ">2419, disc_1(Real)=0.624, disc_2(Fake)=0.745, gen_loss=0.735, disc_1(Real)_a=71, disc_2(Fake)_a=40\n",
            ">2420, disc_1(Real)=0.652, disc_2(Fake)=0.758, gen_loss=0.727, disc_1(Real)_a=62, disc_2(Fake)_a=28\n",
            ">2421, disc_1(Real)=0.631, disc_2(Fake)=0.778, gen_loss=0.697, disc_1(Real)_a=70, disc_2(Fake)_a=25\n",
            ">2422, disc_1(Real)=0.651, disc_2(Fake)=0.830, gen_loss=0.676, disc_1(Real)_a=59, disc_2(Fake)_a=17\n",
            ">2423, disc_1(Real)=0.668, disc_2(Fake)=0.802, gen_loss=0.696, disc_1(Real)_a=68, disc_2(Fake)_a=21\n",
            ">2424, disc_1(Real)=0.638, disc_2(Fake)=0.790, gen_loss=0.685, disc_1(Real)_a=71, disc_2(Fake)_a=20\n",
            ">2425, disc_1(Real)=0.648, disc_2(Fake)=0.792, gen_loss=0.652, disc_1(Real)_a=65, disc_2(Fake)_a=35\n",
            ">2426, disc_1(Real)=0.649, disc_2(Fake)=0.780, gen_loss=0.704, disc_1(Real)_a=64, disc_2(Fake)_a=31\n",
            ">2427, disc_1(Real)=0.598, disc_2(Fake)=0.772, gen_loss=0.675, disc_1(Real)_a=73, disc_2(Fake)_a=35\n",
            ">2428, disc_1(Real)=0.649, disc_2(Fake)=0.800, gen_loss=0.702, disc_1(Real)_a=71, disc_2(Fake)_a=31\n",
            ">2429, disc_1(Real)=0.654, disc_2(Fake)=0.790, gen_loss=0.712, disc_1(Real)_a=62, disc_2(Fake)_a=45\n",
            ">2430, disc_1(Real)=0.727, disc_2(Fake)=0.793, gen_loss=0.700, disc_1(Real)_a=45, disc_2(Fake)_a=37\n",
            ">2431, disc_1(Real)=0.691, disc_2(Fake)=0.814, gen_loss=0.676, disc_1(Real)_a=51, disc_2(Fake)_a=35\n",
            ">2432, disc_1(Real)=0.685, disc_2(Fake)=0.738, gen_loss=0.706, disc_1(Real)_a=57, disc_2(Fake)_a=45\n",
            ">2433, disc_1(Real)=0.685, disc_2(Fake)=0.789, gen_loss=0.746, disc_1(Real)_a=59, disc_2(Fake)_a=34\n",
            ">2434, disc_1(Real)=0.677, disc_2(Fake)=0.727, gen_loss=0.728, disc_1(Real)_a=59, disc_2(Fake)_a=46\n",
            ">2435, disc_1(Real)=0.656, disc_2(Fake)=0.741, gen_loss=0.747, disc_1(Real)_a=64, disc_2(Fake)_a=39\n",
            ">2436, disc_1(Real)=0.667, disc_2(Fake)=0.696, gen_loss=0.776, disc_1(Real)_a=60, disc_2(Fake)_a=46\n",
            ">2437, disc_1(Real)=0.728, disc_2(Fake)=0.720, gen_loss=0.776, disc_1(Real)_a=51, disc_2(Fake)_a=46\n",
            ">2438, disc_1(Real)=0.695, disc_2(Fake)=0.676, gen_loss=0.780, disc_1(Real)_a=59, disc_2(Fake)_a=67\n",
            ">2439, disc_1(Real)=0.761, disc_2(Fake)=0.688, gen_loss=0.755, disc_1(Real)_a=40, disc_2(Fake)_a=60\n",
            ">2440, disc_1(Real)=0.732, disc_2(Fake)=0.688, gen_loss=0.779, disc_1(Real)_a=35, disc_2(Fake)_a=62\n",
            ">2441, disc_1(Real)=0.732, disc_2(Fake)=0.704, gen_loss=0.772, disc_1(Real)_a=43, disc_2(Fake)_a=57\n",
            ">2442, disc_1(Real)=0.706, disc_2(Fake)=0.709, gen_loss=0.771, disc_1(Real)_a=48, disc_2(Fake)_a=64\n",
            ">2443, disc_1(Real)=0.704, disc_2(Fake)=0.699, gen_loss=0.764, disc_1(Real)_a=50, disc_2(Fake)_a=64\n",
            ">2444, disc_1(Real)=0.697, disc_2(Fake)=0.737, gen_loss=0.740, disc_1(Real)_a=56, disc_2(Fake)_a=57\n",
            ">2445, disc_1(Real)=0.711, disc_2(Fake)=0.729, gen_loss=0.748, disc_1(Real)_a=50, disc_2(Fake)_a=45\n",
            ">2446, disc_1(Real)=0.699, disc_2(Fake)=0.701, gen_loss=0.755, disc_1(Real)_a=56, disc_2(Fake)_a=51\n",
            ">2447, disc_1(Real)=0.693, disc_2(Fake)=0.766, gen_loss=0.753, disc_1(Real)_a=54, disc_2(Fake)_a=34\n",
            ">2448, disc_1(Real)=0.723, disc_2(Fake)=0.758, gen_loss=0.722, disc_1(Real)_a=46, disc_2(Fake)_a=28\n",
            ">2449, disc_1(Real)=0.669, disc_2(Fake)=0.776, gen_loss=0.740, disc_1(Real)_a=59, disc_2(Fake)_a=40\n",
            ">2450, disc_1(Real)=0.654, disc_2(Fake)=0.761, gen_loss=0.741, disc_1(Real)_a=62, disc_2(Fake)_a=37\n",
            ">2451, disc_1(Real)=0.674, disc_2(Fake)=0.741, gen_loss=0.738, disc_1(Real)_a=57, disc_2(Fake)_a=35\n",
            ">2452, disc_1(Real)=0.694, disc_2(Fake)=0.740, gen_loss=0.727, disc_1(Real)_a=62, disc_2(Fake)_a=37\n",
            ">2453, disc_1(Real)=0.759, disc_2(Fake)=0.721, gen_loss=0.750, disc_1(Real)_a=42, disc_2(Fake)_a=35\n",
            ">2454, disc_1(Real)=0.706, disc_2(Fake)=0.760, gen_loss=0.724, disc_1(Real)_a=57, disc_2(Fake)_a=31\n",
            ">2455, disc_1(Real)=0.690, disc_2(Fake)=0.736, gen_loss=0.723, disc_1(Real)_a=54, disc_2(Fake)_a=39\n",
            ">2456, disc_1(Real)=0.650, disc_2(Fake)=0.703, gen_loss=0.740, disc_1(Real)_a=65, disc_2(Fake)_a=43\n",
            ">2457, disc_1(Real)=0.687, disc_2(Fake)=0.740, gen_loss=0.714, disc_1(Real)_a=51, disc_2(Fake)_a=39\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">2458, disc_1(Real)=0.667, disc_2(Fake)=0.734, gen_loss=0.736, disc_1(Real)_a=59, disc_2(Fake)_a=50\n",
            ">2459, disc_1(Real)=0.688, disc_2(Fake)=0.712, gen_loss=0.709, disc_1(Real)_a=50, disc_2(Fake)_a=62\n",
            ">2460, disc_1(Real)=0.693, disc_2(Fake)=0.732, gen_loss=0.718, disc_1(Real)_a=53, disc_2(Fake)_a=57\n",
            ">2461, disc_1(Real)=0.701, disc_2(Fake)=0.761, gen_loss=0.748, disc_1(Real)_a=53, disc_2(Fake)_a=46\n",
            ">2462, disc_1(Real)=0.663, disc_2(Fake)=0.686, gen_loss=0.773, disc_1(Real)_a=64, disc_2(Fake)_a=57\n",
            ">2463, disc_1(Real)=0.728, disc_2(Fake)=0.741, gen_loss=0.755, disc_1(Real)_a=42, disc_2(Fake)_a=57\n",
            ">2464, disc_1(Real)=0.736, disc_2(Fake)=0.728, gen_loss=0.728, disc_1(Real)_a=50, disc_2(Fake)_a=54\n",
            ">2465, disc_1(Real)=0.699, disc_2(Fake)=0.699, gen_loss=0.753, disc_1(Real)_a=57, disc_2(Fake)_a=67\n",
            ">2466, disc_1(Real)=0.666, disc_2(Fake)=0.712, gen_loss=0.742, disc_1(Real)_a=53, disc_2(Fake)_a=53\n",
            ">2467, disc_1(Real)=0.711, disc_2(Fake)=0.717, gen_loss=0.782, disc_1(Real)_a=48, disc_2(Fake)_a=53\n",
            ">2468, disc_1(Real)=0.696, disc_2(Fake)=0.702, gen_loss=0.783, disc_1(Real)_a=46, disc_2(Fake)_a=51\n",
            ">2469, disc_1(Real)=0.714, disc_2(Fake)=0.663, gen_loss=0.780, disc_1(Real)_a=46, disc_2(Fake)_a=54\n",
            ">2470, disc_1(Real)=0.713, disc_2(Fake)=0.663, gen_loss=0.791, disc_1(Real)_a=48, disc_2(Fake)_a=59\n",
            ">2471, disc_1(Real)=0.754, disc_2(Fake)=0.681, gen_loss=0.819, disc_1(Real)_a=39, disc_2(Fake)_a=48\n",
            ">2472, disc_1(Real)=0.739, disc_2(Fake)=0.661, gen_loss=0.798, disc_1(Real)_a=43, disc_2(Fake)_a=56\n",
            ">2473, disc_1(Real)=0.731, disc_2(Fake)=0.671, gen_loss=0.810, disc_1(Real)_a=40, disc_2(Fake)_a=50\n",
            ">2474, disc_1(Real)=0.696, disc_2(Fake)=0.706, gen_loss=0.804, disc_1(Real)_a=59, disc_2(Fake)_a=40\n",
            ">2475, disc_1(Real)=0.687, disc_2(Fake)=0.627, gen_loss=0.814, disc_1(Real)_a=54, disc_2(Fake)_a=65\n",
            ">2476, disc_1(Real)=0.699, disc_2(Fake)=0.603, gen_loss=0.824, disc_1(Real)_a=53, disc_2(Fake)_a=64\n",
            ">2477, disc_1(Real)=0.726, disc_2(Fake)=0.628, gen_loss=0.838, disc_1(Real)_a=50, disc_2(Fake)_a=54\n",
            ">2478, disc_1(Real)=0.727, disc_2(Fake)=0.622, gen_loss=0.844, disc_1(Real)_a=46, disc_2(Fake)_a=54\n",
            ">2479, disc_1(Real)=0.688, disc_2(Fake)=0.612, gen_loss=0.836, disc_1(Real)_a=53, disc_2(Fake)_a=57\n",
            ">2480, disc_1(Real)=0.674, disc_2(Fake)=0.608, gen_loss=0.843, disc_1(Real)_a=60, disc_2(Fake)_a=53\n",
            ">2481, disc_1(Real)=0.688, disc_2(Fake)=0.597, gen_loss=0.874, disc_1(Real)_a=56, disc_2(Fake)_a=60\n",
            ">2482, disc_1(Real)=0.662, disc_2(Fake)=0.618, gen_loss=0.897, disc_1(Real)_a=64, disc_2(Fake)_a=53\n",
            ">2483, disc_1(Real)=0.658, disc_2(Fake)=0.644, gen_loss=0.889, disc_1(Real)_a=59, disc_2(Fake)_a=43\n",
            ">2484, disc_1(Real)=0.651, disc_2(Fake)=0.633, gen_loss=0.928, disc_1(Real)_a=64, disc_2(Fake)_a=48\n",
            ">2485, disc_1(Real)=0.666, disc_2(Fake)=0.629, gen_loss=0.925, disc_1(Real)_a=60, disc_2(Fake)_a=48\n",
            ">2486, disc_1(Real)=0.693, disc_2(Fake)=0.622, gen_loss=0.935, disc_1(Real)_a=46, disc_2(Fake)_a=46\n",
            ">2487, disc_1(Real)=0.644, disc_2(Fake)=0.619, gen_loss=0.961, disc_1(Real)_a=67, disc_2(Fake)_a=50\n",
            ">2488, disc_1(Real)=0.655, disc_2(Fake)=0.597, gen_loss=0.928, disc_1(Real)_a=65, disc_2(Fake)_a=59\n",
            ">2489, disc_1(Real)=0.672, disc_2(Fake)=0.603, gen_loss=0.996, disc_1(Real)_a=64, disc_2(Fake)_a=54\n",
            ">2490, disc_1(Real)=0.668, disc_2(Fake)=0.545, gen_loss=1.064, disc_1(Real)_a=57, disc_2(Fake)_a=68\n",
            ">2491, disc_1(Real)=0.652, disc_2(Fake)=0.550, gen_loss=1.064, disc_1(Real)_a=60, disc_2(Fake)_a=68\n",
            ">2492, disc_1(Real)=0.624, disc_2(Fake)=0.563, gen_loss=1.005, disc_1(Real)_a=70, disc_2(Fake)_a=68\n",
            ">2493, disc_1(Real)=0.646, disc_2(Fake)=0.518, gen_loss=1.076, disc_1(Real)_a=64, disc_2(Fake)_a=73\n",
            ">2494, disc_1(Real)=0.632, disc_2(Fake)=0.553, gen_loss=1.045, disc_1(Real)_a=65, disc_2(Fake)_a=67\n",
            ">2495, disc_1(Real)=0.644, disc_2(Fake)=0.547, gen_loss=0.961, disc_1(Real)_a=65, disc_2(Fake)_a=67\n",
            ">2496, disc_1(Real)=0.599, disc_2(Fake)=0.570, gen_loss=1.018, disc_1(Real)_a=75, disc_2(Fake)_a=85\n",
            ">2497, disc_1(Real)=0.626, disc_2(Fake)=0.523, gen_loss=0.985, disc_1(Real)_a=67, disc_2(Fake)_a=84\n",
            ">2498, disc_1(Real)=0.642, disc_2(Fake)=0.557, gen_loss=0.991, disc_1(Real)_a=62, disc_2(Fake)_a=82\n",
            ">2499, disc_1(Real)=0.656, disc_2(Fake)=0.495, gen_loss=0.999, disc_1(Real)_a=64, disc_2(Fake)_a=98\n",
            ">2500, disc_1(Real)=0.605, disc_2(Fake)=0.483, gen_loss=0.996, disc_1(Real)_a=76, disc_2(Fake)_a=95\n",
            ">2501, disc_1(Real)=0.651, disc_2(Fake)=0.508, gen_loss=1.016, disc_1(Real)_a=59, disc_2(Fake)_a=90\n",
            ">2502, disc_1(Real)=0.610, disc_2(Fake)=0.529, gen_loss=0.979, disc_1(Real)_a=75, disc_2(Fake)_a=92\n",
            ">2503, disc_1(Real)=0.584, disc_2(Fake)=0.517, gen_loss=0.991, disc_1(Real)_a=82, disc_2(Fake)_a=96\n",
            ">2504, disc_1(Real)=0.614, disc_2(Fake)=0.510, gen_loss=1.039, disc_1(Real)_a=67, disc_2(Fake)_a=93\n",
            ">2505, disc_1(Real)=0.603, disc_2(Fake)=0.514, gen_loss=1.013, disc_1(Real)_a=71, disc_2(Fake)_a=93\n",
            ">2506, disc_1(Real)=0.598, disc_2(Fake)=0.515, gen_loss=0.998, disc_1(Real)_a=79, disc_2(Fake)_a=87\n",
            ">2507, disc_1(Real)=0.590, disc_2(Fake)=0.531, gen_loss=0.978, disc_1(Real)_a=73, disc_2(Fake)_a=92\n",
            ">2508, disc_1(Real)=0.586, disc_2(Fake)=0.507, gen_loss=0.994, disc_1(Real)_a=73, disc_2(Fake)_a=95\n",
            ">2509, disc_1(Real)=0.602, disc_2(Fake)=0.500, gen_loss=0.986, disc_1(Real)_a=70, disc_2(Fake)_a=95\n",
            ">2510, disc_1(Real)=0.592, disc_2(Fake)=0.520, gen_loss=0.985, disc_1(Real)_a=76, disc_2(Fake)_a=90\n",
            ">2511, disc_1(Real)=0.596, disc_2(Fake)=0.524, gen_loss=0.965, disc_1(Real)_a=75, disc_2(Fake)_a=93\n",
            ">2512, disc_1(Real)=0.560, disc_2(Fake)=0.550, gen_loss=0.949, disc_1(Real)_a=82, disc_2(Fake)_a=89\n",
            ">2513, disc_1(Real)=0.615, disc_2(Fake)=0.534, gen_loss=0.927, disc_1(Real)_a=68, disc_2(Fake)_a=90\n",
            ">2514, disc_1(Real)=0.586, disc_2(Fake)=0.575, gen_loss=0.948, disc_1(Real)_a=76, disc_2(Fake)_a=81\n",
            ">2515, disc_1(Real)=0.564, disc_2(Fake)=0.568, gen_loss=0.921, disc_1(Real)_a=85, disc_2(Fake)_a=75\n",
            ">2516, disc_1(Real)=0.593, disc_2(Fake)=0.564, gen_loss=0.952, disc_1(Real)_a=70, disc_2(Fake)_a=81\n",
            ">2517, disc_1(Real)=0.633, disc_2(Fake)=0.579, gen_loss=0.945, disc_1(Real)_a=67, disc_2(Fake)_a=81\n",
            ">2518, disc_1(Real)=0.574, disc_2(Fake)=0.590, gen_loss=0.919, disc_1(Real)_a=79, disc_2(Fake)_a=73\n",
            ">2519, disc_1(Real)=0.612, disc_2(Fake)=0.565, gen_loss=0.917, disc_1(Real)_a=68, disc_2(Fake)_a=85\n",
            ">2520, disc_1(Real)=0.620, disc_2(Fake)=0.585, gen_loss=0.925, disc_1(Real)_a=64, disc_2(Fake)_a=75\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">2521, disc_1(Real)=0.629, disc_2(Fake)=0.607, gen_loss=0.886, disc_1(Real)_a=62, disc_2(Fake)_a=75\n",
            ">2522, disc_1(Real)=0.575, disc_2(Fake)=0.559, gen_loss=0.882, disc_1(Real)_a=75, disc_2(Fake)_a=89\n",
            ">2523, disc_1(Real)=0.623, disc_2(Fake)=0.643, gen_loss=0.888, disc_1(Real)_a=68, disc_2(Fake)_a=67\n",
            ">2524, disc_1(Real)=0.638, disc_2(Fake)=0.584, gen_loss=0.873, disc_1(Real)_a=57, disc_2(Fake)_a=81\n",
            ">2525, disc_1(Real)=0.605, disc_2(Fake)=0.610, gen_loss=0.864, disc_1(Real)_a=75, disc_2(Fake)_a=71\n",
            ">2526, disc_1(Real)=0.631, disc_2(Fake)=0.644, gen_loss=0.885, disc_1(Real)_a=60, disc_2(Fake)_a=68\n",
            ">2527, disc_1(Real)=0.644, disc_2(Fake)=0.596, gen_loss=0.870, disc_1(Real)_a=64, disc_2(Fake)_a=75\n",
            ">2528, disc_1(Real)=0.666, disc_2(Fake)=0.609, gen_loss=0.878, disc_1(Real)_a=56, disc_2(Fake)_a=73\n",
            ">2529, disc_1(Real)=0.688, disc_2(Fake)=0.631, gen_loss=0.829, disc_1(Real)_a=48, disc_2(Fake)_a=71\n",
            ">2530, disc_1(Real)=0.642, disc_2(Fake)=0.624, gen_loss=0.847, disc_1(Real)_a=60, disc_2(Fake)_a=73\n",
            ">2531, disc_1(Real)=0.666, disc_2(Fake)=0.589, gen_loss=0.833, disc_1(Real)_a=56, disc_2(Fake)_a=76\n",
            ">2532, disc_1(Real)=0.648, disc_2(Fake)=0.626, gen_loss=0.837, disc_1(Real)_a=65, disc_2(Fake)_a=68\n",
            ">2533, disc_1(Real)=0.707, disc_2(Fake)=0.635, gen_loss=0.811, disc_1(Real)_a=51, disc_2(Fake)_a=64\n",
            ">2534, disc_1(Real)=0.654, disc_2(Fake)=0.662, gen_loss=0.793, disc_1(Real)_a=65, disc_2(Fake)_a=60\n",
            ">2535, disc_1(Real)=0.692, disc_2(Fake)=0.670, gen_loss=0.793, disc_1(Real)_a=54, disc_2(Fake)_a=51\n",
            ">2536, disc_1(Real)=0.689, disc_2(Fake)=0.671, gen_loss=0.803, disc_1(Real)_a=48, disc_2(Fake)_a=53\n",
            ">2537, disc_1(Real)=0.667, disc_2(Fake)=0.693, gen_loss=0.792, disc_1(Real)_a=56, disc_2(Fake)_a=50\n",
            ">2538, disc_1(Real)=0.765, disc_2(Fake)=0.683, gen_loss=0.783, disc_1(Real)_a=35, disc_2(Fake)_a=42\n",
            ">2539, disc_1(Real)=0.722, disc_2(Fake)=0.684, gen_loss=0.746, disc_1(Real)_a=51, disc_2(Fake)_a=50\n",
            ">2540, disc_1(Real)=0.727, disc_2(Fake)=0.724, gen_loss=0.731, disc_1(Real)_a=46, disc_2(Fake)_a=34\n",
            ">2541, disc_1(Real)=0.683, disc_2(Fake)=0.767, gen_loss=0.763, disc_1(Real)_a=50, disc_2(Fake)_a=32\n",
            ">2542, disc_1(Real)=0.706, disc_2(Fake)=0.721, gen_loss=0.750, disc_1(Real)_a=48, disc_2(Fake)_a=35\n",
            ">2543, disc_1(Real)=0.711, disc_2(Fake)=0.769, gen_loss=0.810, disc_1(Real)_a=45, disc_2(Fake)_a=28\n",
            ">2544, disc_1(Real)=0.750, disc_2(Fake)=0.716, gen_loss=0.718, disc_1(Real)_a=43, disc_2(Fake)_a=32\n",
            ">2545, disc_1(Real)=0.764, disc_2(Fake)=0.745, gen_loss=0.707, disc_1(Real)_a=42, disc_2(Fake)_a=28\n",
            ">2546, disc_1(Real)=0.711, disc_2(Fake)=0.777, gen_loss=0.754, disc_1(Real)_a=50, disc_2(Fake)_a=23\n",
            ">2547, disc_1(Real)=0.746, disc_2(Fake)=0.727, gen_loss=0.728, disc_1(Real)_a=42, disc_2(Fake)_a=39\n",
            ">2548, disc_1(Real)=0.772, disc_2(Fake)=0.739, gen_loss=0.737, disc_1(Real)_a=31, disc_2(Fake)_a=32\n",
            ">2549, disc_1(Real)=0.776, disc_2(Fake)=0.719, gen_loss=0.763, disc_1(Real)_a=42, disc_2(Fake)_a=42\n",
            ">2550, disc_1(Real)=0.770, disc_2(Fake)=0.714, gen_loss=0.727, disc_1(Real)_a=35, disc_2(Fake)_a=43\n",
            ">2551, disc_1(Real)=0.740, disc_2(Fake)=0.743, gen_loss=0.714, disc_1(Real)_a=37, disc_2(Fake)_a=34\n",
            ">2552, disc_1(Real)=0.802, disc_2(Fake)=0.733, gen_loss=0.709, disc_1(Real)_a=25, disc_2(Fake)_a=37\n",
            ">2553, disc_1(Real)=0.738, disc_2(Fake)=0.783, gen_loss=0.691, disc_1(Real)_a=43, disc_2(Fake)_a=23\n",
            ">2554, disc_1(Real)=0.693, disc_2(Fake)=0.757, gen_loss=0.698, disc_1(Real)_a=51, disc_2(Fake)_a=35\n",
            ">2555, disc_1(Real)=0.693, disc_2(Fake)=0.780, gen_loss=0.666, disc_1(Real)_a=54, disc_2(Fake)_a=26\n",
            ">2556, disc_1(Real)=0.702, disc_2(Fake)=0.777, gen_loss=0.698, disc_1(Real)_a=45, disc_2(Fake)_a=29\n",
            ">2557, disc_1(Real)=0.726, disc_2(Fake)=0.750, gen_loss=0.726, disc_1(Real)_a=37, disc_2(Fake)_a=29\n",
            ">2558, disc_1(Real)=0.686, disc_2(Fake)=0.761, gen_loss=0.710, disc_1(Real)_a=53, disc_2(Fake)_a=25\n",
            ">2559, disc_1(Real)=0.692, disc_2(Fake)=0.706, gen_loss=0.752, disc_1(Real)_a=54, disc_2(Fake)_a=37\n",
            ">2560, disc_1(Real)=0.722, disc_2(Fake)=0.677, gen_loss=0.778, disc_1(Real)_a=48, disc_2(Fake)_a=57\n",
            ">2561, disc_1(Real)=0.702, disc_2(Fake)=0.719, gen_loss=0.763, disc_1(Real)_a=51, disc_2(Fake)_a=42\n",
            ">2562, disc_1(Real)=0.688, disc_2(Fake)=0.730, gen_loss=0.760, disc_1(Real)_a=51, disc_2(Fake)_a=43\n",
            ">2563, disc_1(Real)=0.671, disc_2(Fake)=0.703, gen_loss=0.759, disc_1(Real)_a=62, disc_2(Fake)_a=50\n",
            ">2564, disc_1(Real)=0.660, disc_2(Fake)=0.707, gen_loss=0.770, disc_1(Real)_a=67, disc_2(Fake)_a=46\n",
            ">2565, disc_1(Real)=0.684, disc_2(Fake)=0.656, gen_loss=0.791, disc_1(Real)_a=59, disc_2(Fake)_a=65\n",
            ">2566, disc_1(Real)=0.715, disc_2(Fake)=0.676, gen_loss=0.794, disc_1(Real)_a=45, disc_2(Fake)_a=51\n",
            ">2567, disc_1(Real)=0.739, disc_2(Fake)=0.674, gen_loss=0.774, disc_1(Real)_a=46, disc_2(Fake)_a=53\n",
            ">2568, disc_1(Real)=0.700, disc_2(Fake)=0.678, gen_loss=0.763, disc_1(Real)_a=54, disc_2(Fake)_a=46\n",
            ">2569, disc_1(Real)=0.697, disc_2(Fake)=0.665, gen_loss=0.797, disc_1(Real)_a=51, disc_2(Fake)_a=53\n",
            ">2570, disc_1(Real)=0.702, disc_2(Fake)=0.659, gen_loss=0.783, disc_1(Real)_a=54, disc_2(Fake)_a=59\n",
            ">2571, disc_1(Real)=0.719, disc_2(Fake)=0.640, gen_loss=0.791, disc_1(Real)_a=42, disc_2(Fake)_a=64\n",
            ">2572, disc_1(Real)=0.707, disc_2(Fake)=0.651, gen_loss=0.833, disc_1(Real)_a=51, disc_2(Fake)_a=64\n",
            ">2573, disc_1(Real)=0.726, disc_2(Fake)=0.637, gen_loss=0.832, disc_1(Real)_a=51, disc_2(Fake)_a=70\n",
            ">2574, disc_1(Real)=0.644, disc_2(Fake)=0.647, gen_loss=0.823, disc_1(Real)_a=67, disc_2(Fake)_a=64\n",
            ">2575, disc_1(Real)=0.682, disc_2(Fake)=0.627, gen_loss=0.847, disc_1(Real)_a=59, disc_2(Fake)_a=73\n",
            ">2576, disc_1(Real)=0.694, disc_2(Fake)=0.637, gen_loss=0.838, disc_1(Real)_a=59, disc_2(Fake)_a=73\n",
            ">2577, disc_1(Real)=0.692, disc_2(Fake)=0.607, gen_loss=0.810, disc_1(Real)_a=51, disc_2(Fake)_a=76\n",
            ">2578, disc_1(Real)=0.661, disc_2(Fake)=0.635, gen_loss=0.824, disc_1(Real)_a=62, disc_2(Fake)_a=70\n",
            ">2579, disc_1(Real)=0.689, disc_2(Fake)=0.619, gen_loss=0.834, disc_1(Real)_a=57, disc_2(Fake)_a=76\n",
            ">2580, disc_1(Real)=0.705, disc_2(Fake)=0.597, gen_loss=0.846, disc_1(Real)_a=60, disc_2(Fake)_a=75\n",
            ">2581, disc_1(Real)=0.640, disc_2(Fake)=0.626, gen_loss=0.823, disc_1(Real)_a=68, disc_2(Fake)_a=68\n",
            ">2582, disc_1(Real)=0.708, disc_2(Fake)=0.618, gen_loss=0.834, disc_1(Real)_a=50, disc_2(Fake)_a=71\n",
            ">2583, disc_1(Real)=0.705, disc_2(Fake)=0.616, gen_loss=0.833, disc_1(Real)_a=51, disc_2(Fake)_a=68\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">2584, disc_1(Real)=0.660, disc_2(Fake)=0.607, gen_loss=0.839, disc_1(Real)_a=62, disc_2(Fake)_a=70\n",
            ">2585, disc_1(Real)=0.661, disc_2(Fake)=0.606, gen_loss=0.844, disc_1(Real)_a=62, disc_2(Fake)_a=68\n",
            ">2586, disc_1(Real)=0.632, disc_2(Fake)=0.630, gen_loss=0.802, disc_1(Real)_a=64, disc_2(Fake)_a=62\n",
            ">2587, disc_1(Real)=0.677, disc_2(Fake)=0.614, gen_loss=0.807, disc_1(Real)_a=56, disc_2(Fake)_a=65\n",
            ">2588, disc_1(Real)=0.609, disc_2(Fake)=0.625, gen_loss=0.788, disc_1(Real)_a=71, disc_2(Fake)_a=67\n",
            ">2589, disc_1(Real)=0.628, disc_2(Fake)=0.643, gen_loss=0.839, disc_1(Real)_a=68, disc_2(Fake)_a=60\n",
            ">2590, disc_1(Real)=0.670, disc_2(Fake)=0.667, gen_loss=0.800, disc_1(Real)_a=57, disc_2(Fake)_a=60\n",
            ">2591, disc_1(Real)=0.624, disc_2(Fake)=0.668, gen_loss=0.802, disc_1(Real)_a=73, disc_2(Fake)_a=56\n",
            ">2592, disc_1(Real)=0.614, disc_2(Fake)=0.644, gen_loss=0.816, disc_1(Real)_a=75, disc_2(Fake)_a=62\n",
            ">2593, disc_1(Real)=0.638, disc_2(Fake)=0.652, gen_loss=0.814, disc_1(Real)_a=67, disc_2(Fake)_a=67\n",
            ">2594, disc_1(Real)=0.651, disc_2(Fake)=0.620, gen_loss=0.812, disc_1(Real)_a=71, disc_2(Fake)_a=75\n",
            ">2595, disc_1(Real)=0.676, disc_2(Fake)=0.651, gen_loss=0.807, disc_1(Real)_a=56, disc_2(Fake)_a=70\n",
            ">2596, disc_1(Real)=0.669, disc_2(Fake)=0.647, gen_loss=0.814, disc_1(Real)_a=51, disc_2(Fake)_a=67\n",
            ">2597, disc_1(Real)=0.651, disc_2(Fake)=0.655, gen_loss=0.798, disc_1(Real)_a=60, disc_2(Fake)_a=65\n",
            ">2598, disc_1(Real)=0.659, disc_2(Fake)=0.656, gen_loss=0.778, disc_1(Real)_a=59, disc_2(Fake)_a=75\n",
            ">2599, disc_1(Real)=0.586, disc_2(Fake)=0.656, gen_loss=0.808, disc_1(Real)_a=76, disc_2(Fake)_a=65\n",
            ">2600, disc_1(Real)=0.653, disc_2(Fake)=0.664, gen_loss=0.772, disc_1(Real)_a=65, disc_2(Fake)_a=67\n",
            ">2601, disc_1(Real)=0.635, disc_2(Fake)=0.632, gen_loss=0.783, disc_1(Real)_a=67, disc_2(Fake)_a=75\n",
            ">2602, disc_1(Real)=0.634, disc_2(Fake)=0.676, gen_loss=0.787, disc_1(Real)_a=70, disc_2(Fake)_a=53\n",
            ">2603, disc_1(Real)=0.682, disc_2(Fake)=0.655, gen_loss=0.780, disc_1(Real)_a=62, disc_2(Fake)_a=64\n",
            ">2604, disc_1(Real)=0.599, disc_2(Fake)=0.658, gen_loss=0.776, disc_1(Real)_a=78, disc_2(Fake)_a=64\n",
            ">2605, disc_1(Real)=0.661, disc_2(Fake)=0.675, gen_loss=0.769, disc_1(Real)_a=68, disc_2(Fake)_a=67\n",
            ">2606, disc_1(Real)=0.613, disc_2(Fake)=0.669, gen_loss=0.761, disc_1(Real)_a=82, disc_2(Fake)_a=64\n",
            ">2607, disc_1(Real)=0.619, disc_2(Fake)=0.682, gen_loss=0.740, disc_1(Real)_a=75, disc_2(Fake)_a=60\n",
            ">2608, disc_1(Real)=0.595, disc_2(Fake)=0.656, gen_loss=0.750, disc_1(Real)_a=79, disc_2(Fake)_a=64\n",
            ">2609, disc_1(Real)=0.625, disc_2(Fake)=0.684, gen_loss=0.721, disc_1(Real)_a=73, disc_2(Fake)_a=53\n",
            ">2610, disc_1(Real)=0.622, disc_2(Fake)=0.696, gen_loss=0.753, disc_1(Real)_a=65, disc_2(Fake)_a=42\n",
            ">2611, disc_1(Real)=0.651, disc_2(Fake)=0.716, gen_loss=0.749, disc_1(Real)_a=57, disc_2(Fake)_a=45\n",
            ">2612, disc_1(Real)=0.630, disc_2(Fake)=0.712, gen_loss=0.766, disc_1(Real)_a=71, disc_2(Fake)_a=45\n",
            ">2613, disc_1(Real)=0.653, disc_2(Fake)=0.688, gen_loss=0.742, disc_1(Real)_a=68, disc_2(Fake)_a=54\n",
            ">2614, disc_1(Real)=0.655, disc_2(Fake)=0.679, gen_loss=0.733, disc_1(Real)_a=65, disc_2(Fake)_a=56\n",
            ">2615, disc_1(Real)=0.616, disc_2(Fake)=0.691, gen_loss=0.739, disc_1(Real)_a=76, disc_2(Fake)_a=51\n",
            ">2616, disc_1(Real)=0.636, disc_2(Fake)=0.710, gen_loss=0.717, disc_1(Real)_a=68, disc_2(Fake)_a=48\n",
            ">2617, disc_1(Real)=0.656, disc_2(Fake)=0.711, gen_loss=0.747, disc_1(Real)_a=60, disc_2(Fake)_a=43\n",
            ">2618, disc_1(Real)=0.641, disc_2(Fake)=0.748, gen_loss=0.727, disc_1(Real)_a=68, disc_2(Fake)_a=29\n",
            ">2619, disc_1(Real)=0.628, disc_2(Fake)=0.719, gen_loss=0.719, disc_1(Real)_a=70, disc_2(Fake)_a=42\n",
            ">2620, disc_1(Real)=0.652, disc_2(Fake)=0.720, gen_loss=0.718, disc_1(Real)_a=57, disc_2(Fake)_a=35\n",
            ">2621, disc_1(Real)=0.590, disc_2(Fake)=0.681, gen_loss=0.732, disc_1(Real)_a=78, disc_2(Fake)_a=51\n",
            ">2622, disc_1(Real)=0.647, disc_2(Fake)=0.719, gen_loss=0.727, disc_1(Real)_a=70, disc_2(Fake)_a=42\n",
            ">2623, disc_1(Real)=0.616, disc_2(Fake)=0.715, gen_loss=0.722, disc_1(Real)_a=76, disc_2(Fake)_a=42\n",
            ">2624, disc_1(Real)=0.626, disc_2(Fake)=0.707, gen_loss=0.739, disc_1(Real)_a=67, disc_2(Fake)_a=48\n",
            ">2625, disc_1(Real)=0.628, disc_2(Fake)=0.732, gen_loss=0.733, disc_1(Real)_a=67, disc_2(Fake)_a=40\n",
            ">2626, disc_1(Real)=0.645, disc_2(Fake)=0.701, gen_loss=0.719, disc_1(Real)_a=67, disc_2(Fake)_a=48\n",
            ">2627, disc_1(Real)=0.623, disc_2(Fake)=0.701, gen_loss=0.739, disc_1(Real)_a=68, disc_2(Fake)_a=46\n",
            ">2628, disc_1(Real)=0.612, disc_2(Fake)=0.707, gen_loss=0.719, disc_1(Real)_a=75, disc_2(Fake)_a=46\n",
            ">2629, disc_1(Real)=0.612, disc_2(Fake)=0.677, gen_loss=0.747, disc_1(Real)_a=71, disc_2(Fake)_a=57\n",
            ">2630, disc_1(Real)=0.617, disc_2(Fake)=0.675, gen_loss=0.735, disc_1(Real)_a=71, disc_2(Fake)_a=57\n",
            ">2631, disc_1(Real)=0.590, disc_2(Fake)=0.692, gen_loss=0.763, disc_1(Real)_a=73, disc_2(Fake)_a=56\n",
            ">2632, disc_1(Real)=0.609, disc_2(Fake)=0.670, gen_loss=0.748, disc_1(Real)_a=73, disc_2(Fake)_a=65\n",
            ">2633, disc_1(Real)=0.608, disc_2(Fake)=0.717, gen_loss=0.751, disc_1(Real)_a=62, disc_2(Fake)_a=54\n",
            ">2634, disc_1(Real)=0.609, disc_2(Fake)=0.691, gen_loss=0.746, disc_1(Real)_a=71, disc_2(Fake)_a=50\n",
            ">2635, disc_1(Real)=0.588, disc_2(Fake)=0.700, gen_loss=0.736, disc_1(Real)_a=75, disc_2(Fake)_a=56\n",
            ">2636, disc_1(Real)=0.660, disc_2(Fake)=0.688, gen_loss=0.743, disc_1(Real)_a=57, disc_2(Fake)_a=62\n",
            ">2637, disc_1(Real)=0.611, disc_2(Fake)=0.677, gen_loss=0.756, disc_1(Real)_a=75, disc_2(Fake)_a=65\n",
            ">2638, disc_1(Real)=0.630, disc_2(Fake)=0.697, gen_loss=0.733, disc_1(Real)_a=65, disc_2(Fake)_a=51\n",
            ">2639, disc_1(Real)=0.635, disc_2(Fake)=0.696, gen_loss=0.734, disc_1(Real)_a=64, disc_2(Fake)_a=60\n",
            ">2640, disc_1(Real)=0.604, disc_2(Fake)=0.692, gen_loss=0.730, disc_1(Real)_a=71, disc_2(Fake)_a=56\n",
            ">2641, disc_1(Real)=0.544, disc_2(Fake)=0.725, gen_loss=0.726, disc_1(Real)_a=87, disc_2(Fake)_a=50\n",
            ">2642, disc_1(Real)=0.563, disc_2(Fake)=0.687, gen_loss=0.744, disc_1(Real)_a=85, disc_2(Fake)_a=54\n",
            ">2643, disc_1(Real)=0.573, disc_2(Fake)=0.673, gen_loss=0.750, disc_1(Real)_a=82, disc_2(Fake)_a=71\n",
            ">2644, disc_1(Real)=0.568, disc_2(Fake)=0.669, gen_loss=0.758, disc_1(Real)_a=81, disc_2(Fake)_a=70\n",
            ">2645, disc_1(Real)=0.592, disc_2(Fake)=0.669, gen_loss=0.777, disc_1(Real)_a=78, disc_2(Fake)_a=71\n",
            ">2646, disc_1(Real)=0.624, disc_2(Fake)=0.680, gen_loss=0.764, disc_1(Real)_a=68, disc_2(Fake)_a=64\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">2647, disc_1(Real)=0.600, disc_2(Fake)=0.664, gen_loss=0.779, disc_1(Real)_a=78, disc_2(Fake)_a=67\n",
            ">2648, disc_1(Real)=0.556, disc_2(Fake)=0.676, gen_loss=0.775, disc_1(Real)_a=79, disc_2(Fake)_a=67\n",
            ">2649, disc_1(Real)=0.631, disc_2(Fake)=0.720, gen_loss=0.761, disc_1(Real)_a=64, disc_2(Fake)_a=56\n",
            ">2650, disc_1(Real)=0.599, disc_2(Fake)=0.700, gen_loss=0.752, disc_1(Real)_a=68, disc_2(Fake)_a=62\n",
            ">2651, disc_1(Real)=0.597, disc_2(Fake)=0.661, gen_loss=0.766, disc_1(Real)_a=65, disc_2(Fake)_a=70\n",
            ">2652, disc_1(Real)=0.566, disc_2(Fake)=0.659, gen_loss=0.747, disc_1(Real)_a=82, disc_2(Fake)_a=76\n",
            ">2653, disc_1(Real)=0.588, disc_2(Fake)=0.670, gen_loss=0.741, disc_1(Real)_a=75, disc_2(Fake)_a=65\n",
            ">2654, disc_1(Real)=0.599, disc_2(Fake)=0.680, gen_loss=0.741, disc_1(Real)_a=76, disc_2(Fake)_a=75\n",
            ">2655, disc_1(Real)=0.570, disc_2(Fake)=0.667, gen_loss=0.758, disc_1(Real)_a=75, disc_2(Fake)_a=71\n",
            ">2656, disc_1(Real)=0.551, disc_2(Fake)=0.715, gen_loss=0.770, disc_1(Real)_a=81, disc_2(Fake)_a=60\n",
            ">2657, disc_1(Real)=0.588, disc_2(Fake)=0.714, gen_loss=0.767, disc_1(Real)_a=75, disc_2(Fake)_a=59\n",
            ">2658, disc_1(Real)=0.577, disc_2(Fake)=0.672, gen_loss=0.731, disc_1(Real)_a=79, disc_2(Fake)_a=71\n",
            ">2659, disc_1(Real)=0.611, disc_2(Fake)=0.689, gen_loss=0.738, disc_1(Real)_a=68, disc_2(Fake)_a=60\n",
            ">2660, disc_1(Real)=0.626, disc_2(Fake)=0.706, gen_loss=0.728, disc_1(Real)_a=64, disc_2(Fake)_a=56\n",
            ">2661, disc_1(Real)=0.547, disc_2(Fake)=0.707, gen_loss=0.751, disc_1(Real)_a=85, disc_2(Fake)_a=57\n",
            ">2662, disc_1(Real)=0.603, disc_2(Fake)=0.682, gen_loss=0.736, disc_1(Real)_a=71, disc_2(Fake)_a=64\n",
            ">2663, disc_1(Real)=0.622, disc_2(Fake)=0.684, gen_loss=0.747, disc_1(Real)_a=73, disc_2(Fake)_a=62\n",
            ">2664, disc_1(Real)=0.617, disc_2(Fake)=0.690, gen_loss=0.738, disc_1(Real)_a=71, disc_2(Fake)_a=54\n",
            ">2665, disc_1(Real)=0.607, disc_2(Fake)=0.662, gen_loss=0.749, disc_1(Real)_a=78, disc_2(Fake)_a=62\n",
            ">2666, disc_1(Real)=0.598, disc_2(Fake)=0.693, gen_loss=0.735, disc_1(Real)_a=82, disc_2(Fake)_a=53\n",
            ">2667, disc_1(Real)=0.632, disc_2(Fake)=0.696, gen_loss=0.728, disc_1(Real)_a=67, disc_2(Fake)_a=51\n",
            ">2668, disc_1(Real)=0.588, disc_2(Fake)=0.695, gen_loss=0.727, disc_1(Real)_a=82, disc_2(Fake)_a=48\n",
            ">2669, disc_1(Real)=0.616, disc_2(Fake)=0.710, gen_loss=0.722, disc_1(Real)_a=68, disc_2(Fake)_a=48\n",
            ">2670, disc_1(Real)=0.592, disc_2(Fake)=0.699, gen_loss=0.743, disc_1(Real)_a=73, disc_2(Fake)_a=54\n",
            ">2671, disc_1(Real)=0.576, disc_2(Fake)=0.692, gen_loss=0.725, disc_1(Real)_a=81, disc_2(Fake)_a=48\n",
            ">2672, disc_1(Real)=0.600, disc_2(Fake)=0.706, gen_loss=0.748, disc_1(Real)_a=68, disc_2(Fake)_a=54\n",
            ">2673, disc_1(Real)=0.576, disc_2(Fake)=0.707, gen_loss=0.755, disc_1(Real)_a=78, disc_2(Fake)_a=59\n",
            ">2674, disc_1(Real)=0.571, disc_2(Fake)=0.674, gen_loss=0.766, disc_1(Real)_a=76, disc_2(Fake)_a=76\n",
            ">2675, disc_1(Real)=0.605, disc_2(Fake)=0.675, gen_loss=0.766, disc_1(Real)_a=75, disc_2(Fake)_a=65\n",
            ">2676, disc_1(Real)=0.629, disc_2(Fake)=0.712, gen_loss=0.749, disc_1(Real)_a=65, disc_2(Fake)_a=65\n",
            ">2677, disc_1(Real)=0.629, disc_2(Fake)=0.709, gen_loss=0.757, disc_1(Real)_a=65, disc_2(Fake)_a=59\n",
            ">2678, disc_1(Real)=0.674, disc_2(Fake)=0.701, gen_loss=0.759, disc_1(Real)_a=54, disc_2(Fake)_a=65\n",
            ">2679, disc_1(Real)=0.596, disc_2(Fake)=0.683, gen_loss=0.735, disc_1(Real)_a=68, disc_2(Fake)_a=59\n",
            ">2680, disc_1(Real)=0.584, disc_2(Fake)=0.750, gen_loss=0.759, disc_1(Real)_a=75, disc_2(Fake)_a=53\n",
            ">2681, disc_1(Real)=0.636, disc_2(Fake)=0.720, gen_loss=0.739, disc_1(Real)_a=64, disc_2(Fake)_a=56\n",
            ">2682, disc_1(Real)=0.647, disc_2(Fake)=0.715, gen_loss=0.716, disc_1(Real)_a=59, disc_2(Fake)_a=51\n",
            ">2683, disc_1(Real)=0.629, disc_2(Fake)=0.731, gen_loss=0.749, disc_1(Real)_a=64, disc_2(Fake)_a=54\n",
            ">2684, disc_1(Real)=0.656, disc_2(Fake)=0.683, gen_loss=0.737, disc_1(Real)_a=59, disc_2(Fake)_a=54\n",
            ">2685, disc_1(Real)=0.678, disc_2(Fake)=0.702, gen_loss=0.762, disc_1(Real)_a=51, disc_2(Fake)_a=46\n",
            ">2686, disc_1(Real)=0.664, disc_2(Fake)=0.675, gen_loss=0.777, disc_1(Real)_a=57, disc_2(Fake)_a=57\n",
            ">2687, disc_1(Real)=0.648, disc_2(Fake)=0.673, gen_loss=0.752, disc_1(Real)_a=67, disc_2(Fake)_a=59\n",
            ">2688, disc_1(Real)=0.667, disc_2(Fake)=0.670, gen_loss=0.754, disc_1(Real)_a=56, disc_2(Fake)_a=51\n",
            ">2689, disc_1(Real)=0.674, disc_2(Fake)=0.702, gen_loss=0.750, disc_1(Real)_a=59, disc_2(Fake)_a=50\n",
            ">2690, disc_1(Real)=0.662, disc_2(Fake)=0.685, gen_loss=0.726, disc_1(Real)_a=64, disc_2(Fake)_a=54\n",
            ">2691, disc_1(Real)=0.640, disc_2(Fake)=0.687, gen_loss=0.727, disc_1(Real)_a=71, disc_2(Fake)_a=51\n",
            ">2692, disc_1(Real)=0.624, disc_2(Fake)=0.703, gen_loss=0.738, disc_1(Real)_a=59, disc_2(Fake)_a=46\n",
            ">2693, disc_1(Real)=0.644, disc_2(Fake)=0.706, gen_loss=0.722, disc_1(Real)_a=56, disc_2(Fake)_a=42\n",
            ">2694, disc_1(Real)=0.652, disc_2(Fake)=0.721, gen_loss=0.718, disc_1(Real)_a=67, disc_2(Fake)_a=43\n",
            ">2695, disc_1(Real)=0.654, disc_2(Fake)=0.731, gen_loss=0.725, disc_1(Real)_a=62, disc_2(Fake)_a=53\n",
            ">2696, disc_1(Real)=0.689, disc_2(Fake)=0.757, gen_loss=0.722, disc_1(Real)_a=57, disc_2(Fake)_a=37\n",
            ">2697, disc_1(Real)=0.644, disc_2(Fake)=0.698, gen_loss=0.729, disc_1(Real)_a=60, disc_2(Fake)_a=56\n",
            ">2698, disc_1(Real)=0.653, disc_2(Fake)=0.680, gen_loss=0.736, disc_1(Real)_a=65, disc_2(Fake)_a=50\n",
            ">2699, disc_1(Real)=0.647, disc_2(Fake)=0.692, gen_loss=0.733, disc_1(Real)_a=62, disc_2(Fake)_a=50\n",
            ">2700, disc_1(Real)=0.668, disc_2(Fake)=0.703, gen_loss=0.725, disc_1(Real)_a=57, disc_2(Fake)_a=51\n",
            ">2701, disc_1(Real)=0.649, disc_2(Fake)=0.719, gen_loss=0.761, disc_1(Real)_a=64, disc_2(Fake)_a=54\n",
            ">2702, disc_1(Real)=0.680, disc_2(Fake)=0.701, gen_loss=0.730, disc_1(Real)_a=54, disc_2(Fake)_a=46\n",
            ">2703, disc_1(Real)=0.672, disc_2(Fake)=0.747, gen_loss=0.725, disc_1(Real)_a=54, disc_2(Fake)_a=29\n",
            ">2704, disc_1(Real)=0.636, disc_2(Fake)=0.745, gen_loss=0.738, disc_1(Real)_a=68, disc_2(Fake)_a=35\n",
            ">2705, disc_1(Real)=0.671, disc_2(Fake)=0.733, gen_loss=0.723, disc_1(Real)_a=62, disc_2(Fake)_a=37\n",
            ">2706, disc_1(Real)=0.667, disc_2(Fake)=0.728, gen_loss=0.767, disc_1(Real)_a=59, disc_2(Fake)_a=37\n",
            ">2707, disc_1(Real)=0.751, disc_2(Fake)=0.721, gen_loss=0.756, disc_1(Real)_a=37, disc_2(Fake)_a=43\n",
            ">2708, disc_1(Real)=0.747, disc_2(Fake)=0.699, gen_loss=0.773, disc_1(Real)_a=35, disc_2(Fake)_a=46\n",
            ">2709, disc_1(Real)=0.739, disc_2(Fake)=0.717, gen_loss=0.770, disc_1(Real)_a=29, disc_2(Fake)_a=39\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">2710, disc_1(Real)=0.716, disc_2(Fake)=0.671, gen_loss=0.780, disc_1(Real)_a=50, disc_2(Fake)_a=54\n",
            ">2711, disc_1(Real)=0.720, disc_2(Fake)=0.639, gen_loss=0.798, disc_1(Real)_a=46, disc_2(Fake)_a=67\n",
            ">2712, disc_1(Real)=0.704, disc_2(Fake)=0.696, gen_loss=0.754, disc_1(Real)_a=50, disc_2(Fake)_a=46\n",
            ">2713, disc_1(Real)=0.731, disc_2(Fake)=0.652, gen_loss=0.748, disc_1(Real)_a=51, disc_2(Fake)_a=64\n",
            ">2714, disc_1(Real)=0.734, disc_2(Fake)=0.713, gen_loss=0.708, disc_1(Real)_a=42, disc_2(Fake)_a=43\n",
            ">2715, disc_1(Real)=0.669, disc_2(Fake)=0.731, gen_loss=0.735, disc_1(Real)_a=56, disc_2(Fake)_a=45\n",
            ">2716, disc_1(Real)=0.733, disc_2(Fake)=0.723, gen_loss=0.734, disc_1(Real)_a=40, disc_2(Fake)_a=48\n",
            ">2717, disc_1(Real)=0.688, disc_2(Fake)=0.767, gen_loss=0.715, disc_1(Real)_a=59, disc_2(Fake)_a=34\n",
            ">2718, disc_1(Real)=0.720, disc_2(Fake)=0.722, gen_loss=0.730, disc_1(Real)_a=51, disc_2(Fake)_a=42\n",
            ">2719, disc_1(Real)=0.736, disc_2(Fake)=0.694, gen_loss=0.751, disc_1(Real)_a=42, disc_2(Fake)_a=59\n",
            ">2720, disc_1(Real)=0.711, disc_2(Fake)=0.664, gen_loss=0.762, disc_1(Real)_a=51, disc_2(Fake)_a=65\n",
            ">2721, disc_1(Real)=0.724, disc_2(Fake)=0.684, gen_loss=0.770, disc_1(Real)_a=46, disc_2(Fake)_a=56\n",
            ">2722, disc_1(Real)=0.718, disc_2(Fake)=0.670, gen_loss=0.776, disc_1(Real)_a=43, disc_2(Fake)_a=62\n",
            ">2723, disc_1(Real)=0.675, disc_2(Fake)=0.629, gen_loss=0.820, disc_1(Real)_a=53, disc_2(Fake)_a=81\n",
            ">2724, disc_1(Real)=0.661, disc_2(Fake)=0.637, gen_loss=0.826, disc_1(Real)_a=64, disc_2(Fake)_a=79\n",
            ">2725, disc_1(Real)=0.719, disc_2(Fake)=0.614, gen_loss=0.832, disc_1(Real)_a=43, disc_2(Fake)_a=89\n",
            ">2726, disc_1(Real)=0.705, disc_2(Fake)=0.616, gen_loss=0.840, disc_1(Real)_a=50, disc_2(Fake)_a=82\n",
            ">2727, disc_1(Real)=0.736, disc_2(Fake)=0.638, gen_loss=0.830, disc_1(Real)_a=37, disc_2(Fake)_a=65\n",
            ">2728, disc_1(Real)=0.705, disc_2(Fake)=0.662, gen_loss=0.824, disc_1(Real)_a=51, disc_2(Fake)_a=62\n",
            ">2729, disc_1(Real)=0.735, disc_2(Fake)=0.630, gen_loss=0.868, disc_1(Real)_a=40, disc_2(Fake)_a=76\n",
            ">2730, disc_1(Real)=0.687, disc_2(Fake)=0.637, gen_loss=0.849, disc_1(Real)_a=50, disc_2(Fake)_a=81\n",
            ">2731, disc_1(Real)=0.703, disc_2(Fake)=0.593, gen_loss=0.886, disc_1(Real)_a=54, disc_2(Fake)_a=85\n",
            ">2732, disc_1(Real)=0.728, disc_2(Fake)=0.581, gen_loss=0.917, disc_1(Real)_a=43, disc_2(Fake)_a=84\n",
            ">2733, disc_1(Real)=0.755, disc_2(Fake)=0.541, gen_loss=1.013, disc_1(Real)_a=34, disc_2(Fake)_a=93\n",
            ">2734, disc_1(Real)=0.737, disc_2(Fake)=0.502, gen_loss=1.026, disc_1(Real)_a=43, disc_2(Fake)_a=93\n",
            ">2735, disc_1(Real)=0.740, disc_2(Fake)=0.498, gen_loss=1.047, disc_1(Real)_a=42, disc_2(Fake)_a=93\n",
            ">2736, disc_1(Real)=0.739, disc_2(Fake)=0.467, gen_loss=1.093, disc_1(Real)_a=40, disc_2(Fake)_a=90\n",
            ">2737, disc_1(Real)=0.732, disc_2(Fake)=0.490, gen_loss=1.032, disc_1(Real)_a=42, disc_2(Fake)_a=90\n",
            ">2738, disc_1(Real)=0.768, disc_2(Fake)=0.528, gen_loss=1.025, disc_1(Real)_a=35, disc_2(Fake)_a=82\n",
            ">2739, disc_1(Real)=0.723, disc_2(Fake)=0.547, gen_loss=0.966, disc_1(Real)_a=50, disc_2(Fake)_a=82\n",
            ">2740, disc_1(Real)=0.645, disc_2(Fake)=0.583, gen_loss=0.947, disc_1(Real)_a=67, disc_2(Fake)_a=78\n",
            ">2741, disc_1(Real)=0.729, disc_2(Fake)=0.596, gen_loss=0.873, disc_1(Real)_a=48, disc_2(Fake)_a=75\n",
            ">2742, disc_1(Real)=0.712, disc_2(Fake)=0.646, gen_loss=0.826, disc_1(Real)_a=51, disc_2(Fake)_a=59\n",
            ">2743, disc_1(Real)=0.690, disc_2(Fake)=0.669, gen_loss=0.835, disc_1(Real)_a=64, disc_2(Fake)_a=64\n",
            ">2744, disc_1(Real)=0.687, disc_2(Fake)=0.614, gen_loss=0.850, disc_1(Real)_a=54, disc_2(Fake)_a=75\n",
            ">2745, disc_1(Real)=0.714, disc_2(Fake)=0.607, gen_loss=0.866, disc_1(Real)_a=51, disc_2(Fake)_a=82\n",
            ">2746, disc_1(Real)=0.676, disc_2(Fake)=0.577, gen_loss=0.901, disc_1(Real)_a=51, disc_2(Fake)_a=92\n",
            ">2747, disc_1(Real)=0.734, disc_2(Fake)=0.549, gen_loss=0.953, disc_1(Real)_a=37, disc_2(Fake)_a=92\n",
            ">2748, disc_1(Real)=0.676, disc_2(Fake)=0.508, gen_loss=1.020, disc_1(Real)_a=56, disc_2(Fake)_a=89\n",
            ">2749, disc_1(Real)=0.711, disc_2(Fake)=0.560, gen_loss=1.020, disc_1(Real)_a=46, disc_2(Fake)_a=68\n",
            ">2750, disc_1(Real)=0.728, disc_2(Fake)=0.489, gen_loss=0.992, disc_1(Real)_a=46, disc_2(Fake)_a=87\n",
            ">2751, disc_1(Real)=0.765, disc_2(Fake)=0.541, gen_loss=1.021, disc_1(Real)_a=40, disc_2(Fake)_a=68\n",
            ">2752, disc_1(Real)=0.727, disc_2(Fake)=0.556, gen_loss=0.978, disc_1(Real)_a=48, disc_2(Fake)_a=71\n",
            ">2753, disc_1(Real)=0.740, disc_2(Fake)=0.600, gen_loss=0.965, disc_1(Real)_a=51, disc_2(Fake)_a=67\n",
            ">2754, disc_1(Real)=0.717, disc_2(Fake)=0.605, gen_loss=0.930, disc_1(Real)_a=50, disc_2(Fake)_a=60\n",
            ">2755, disc_1(Real)=0.687, disc_2(Fake)=0.554, gen_loss=0.984, disc_1(Real)_a=60, disc_2(Fake)_a=85\n",
            ">2756, disc_1(Real)=0.671, disc_2(Fake)=0.512, gen_loss=1.015, disc_1(Real)_a=59, disc_2(Fake)_a=96\n",
            ">2757, disc_1(Real)=0.706, disc_2(Fake)=0.494, gen_loss=1.052, disc_1(Real)_a=50, disc_2(Fake)_a=100\n",
            ">2758, disc_1(Real)=0.715, disc_2(Fake)=0.466, gen_loss=1.099, disc_1(Real)_a=45, disc_2(Fake)_a=100\n",
            ">2759, disc_1(Real)=0.702, disc_2(Fake)=0.458, gen_loss=1.105, disc_1(Real)_a=51, disc_2(Fake)_a=100\n",
            ">2760, disc_1(Real)=0.690, disc_2(Fake)=0.473, gen_loss=1.072, disc_1(Real)_a=59, disc_2(Fake)_a=98\n",
            ">2761, disc_1(Real)=0.715, disc_2(Fake)=0.505, gen_loss=1.032, disc_1(Real)_a=51, disc_2(Fake)_a=95\n",
            ">2762, disc_1(Real)=0.657, disc_2(Fake)=0.532, gen_loss=0.969, disc_1(Real)_a=68, disc_2(Fake)_a=95\n",
            ">2763, disc_1(Real)=0.714, disc_2(Fake)=0.584, gen_loss=0.934, disc_1(Real)_a=50, disc_2(Fake)_a=84\n",
            ">2764, disc_1(Real)=0.701, disc_2(Fake)=0.589, gen_loss=0.893, disc_1(Real)_a=54, disc_2(Fake)_a=90\n",
            ">2765, disc_1(Real)=0.675, disc_2(Fake)=0.600, gen_loss=0.875, disc_1(Real)_a=64, disc_2(Fake)_a=85\n",
            ">2766, disc_1(Real)=0.690, disc_2(Fake)=0.581, gen_loss=0.902, disc_1(Real)_a=53, disc_2(Fake)_a=93\n",
            ">2767, disc_1(Real)=0.681, disc_2(Fake)=0.553, gen_loss=0.925, disc_1(Real)_a=57, disc_2(Fake)_a=89\n",
            ">2768, disc_1(Real)=0.680, disc_2(Fake)=0.569, gen_loss=0.987, disc_1(Real)_a=60, disc_2(Fake)_a=84\n",
            ">2769, disc_1(Real)=0.644, disc_2(Fake)=0.534, gen_loss=1.006, disc_1(Real)_a=62, disc_2(Fake)_a=89\n",
            ">2770, disc_1(Real)=0.685, disc_2(Fake)=0.557, gen_loss=0.928, disc_1(Real)_a=56, disc_2(Fake)_a=84\n",
            ">2771, disc_1(Real)=0.729, disc_2(Fake)=0.559, gen_loss=0.899, disc_1(Real)_a=53, disc_2(Fake)_a=73\n",
            ">2772, disc_1(Real)=0.647, disc_2(Fake)=0.626, gen_loss=0.857, disc_1(Real)_a=62, disc_2(Fake)_a=60\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">2773, disc_1(Real)=0.683, disc_2(Fake)=0.678, gen_loss=0.837, disc_1(Real)_a=59, disc_2(Fake)_a=46\n",
            ">2774, disc_1(Real)=0.680, disc_2(Fake)=0.714, gen_loss=0.812, disc_1(Real)_a=57, disc_2(Fake)_a=48\n",
            ">2775, disc_1(Real)=0.659, disc_2(Fake)=0.714, gen_loss=0.796, disc_1(Real)_a=70, disc_2(Fake)_a=40\n",
            ">2776, disc_1(Real)=0.658, disc_2(Fake)=0.725, gen_loss=0.761, disc_1(Real)_a=60, disc_2(Fake)_a=48\n",
            ">2777, disc_1(Real)=0.631, disc_2(Fake)=0.721, gen_loss=0.763, disc_1(Real)_a=70, disc_2(Fake)_a=43\n",
            ">2778, disc_1(Real)=0.695, disc_2(Fake)=0.649, gen_loss=0.748, disc_1(Real)_a=59, disc_2(Fake)_a=65\n",
            ">2779, disc_1(Real)=0.650, disc_2(Fake)=0.671, gen_loss=0.810, disc_1(Real)_a=62, disc_2(Fake)_a=59\n",
            ">2780, disc_1(Real)=0.665, disc_2(Fake)=0.655, gen_loss=0.812, disc_1(Real)_a=64, disc_2(Fake)_a=54\n",
            ">2781, disc_1(Real)=0.633, disc_2(Fake)=0.666, gen_loss=0.812, disc_1(Real)_a=65, disc_2(Fake)_a=68\n",
            ">2782, disc_1(Real)=0.687, disc_2(Fake)=0.654, gen_loss=0.817, disc_1(Real)_a=54, disc_2(Fake)_a=57\n",
            ">2783, disc_1(Real)=0.687, disc_2(Fake)=0.711, gen_loss=0.765, disc_1(Real)_a=57, disc_2(Fake)_a=48\n",
            ">2784, disc_1(Real)=0.715, disc_2(Fake)=0.704, gen_loss=0.770, disc_1(Real)_a=46, disc_2(Fake)_a=45\n",
            ">2785, disc_1(Real)=0.676, disc_2(Fake)=0.709, gen_loss=0.749, disc_1(Real)_a=64, disc_2(Fake)_a=51\n",
            ">2786, disc_1(Real)=0.690, disc_2(Fake)=0.719, gen_loss=0.747, disc_1(Real)_a=60, disc_2(Fake)_a=39\n",
            ">2787, disc_1(Real)=0.639, disc_2(Fake)=0.727, gen_loss=0.735, disc_1(Real)_a=68, disc_2(Fake)_a=43\n",
            ">2788, disc_1(Real)=0.732, disc_2(Fake)=0.704, gen_loss=0.783, disc_1(Real)_a=48, disc_2(Fake)_a=50\n",
            ">2789, disc_1(Real)=0.704, disc_2(Fake)=0.685, gen_loss=0.783, disc_1(Real)_a=56, disc_2(Fake)_a=56\n",
            ">2790, disc_1(Real)=0.716, disc_2(Fake)=0.687, gen_loss=0.824, disc_1(Real)_a=50, disc_2(Fake)_a=50\n",
            ">2791, disc_1(Real)=0.719, disc_2(Fake)=0.626, gen_loss=0.906, disc_1(Real)_a=46, disc_2(Fake)_a=65\n",
            ">2792, disc_1(Real)=0.684, disc_2(Fake)=0.567, gen_loss=0.908, disc_1(Real)_a=62, disc_2(Fake)_a=78\n",
            ">2793, disc_1(Real)=0.681, disc_2(Fake)=0.552, gen_loss=0.950, disc_1(Real)_a=51, disc_2(Fake)_a=84\n",
            ">2794, disc_1(Real)=0.675, disc_2(Fake)=0.523, gen_loss=0.968, disc_1(Real)_a=53, disc_2(Fake)_a=90\n",
            ">2795, disc_1(Real)=0.698, disc_2(Fake)=0.538, gen_loss=0.975, disc_1(Real)_a=51, disc_2(Fake)_a=90\n",
            ">2796, disc_1(Real)=0.661, disc_2(Fake)=0.581, gen_loss=0.927, disc_1(Real)_a=57, disc_2(Fake)_a=87\n",
            ">2797, disc_1(Real)=0.727, disc_2(Fake)=0.562, gen_loss=0.927, disc_1(Real)_a=51, disc_2(Fake)_a=92\n",
            ">2798, disc_1(Real)=0.724, disc_2(Fake)=0.584, gen_loss=0.899, disc_1(Real)_a=43, disc_2(Fake)_a=89\n",
            ">2799, disc_1(Real)=0.656, disc_2(Fake)=0.583, gen_loss=0.909, disc_1(Real)_a=56, disc_2(Fake)_a=89\n",
            ">2800, disc_1(Real)=0.612, disc_2(Fake)=0.570, gen_loss=0.922, disc_1(Real)_a=68, disc_2(Fake)_a=90\n",
            ">2801, disc_1(Real)=0.657, disc_2(Fake)=0.530, gen_loss=0.944, disc_1(Real)_a=70, disc_2(Fake)_a=92\n",
            ">2802, disc_1(Real)=0.626, disc_2(Fake)=0.543, gen_loss=0.972, disc_1(Real)_a=70, disc_2(Fake)_a=93\n",
            ">2803, disc_1(Real)=0.627, disc_2(Fake)=0.527, gen_loss=0.972, disc_1(Real)_a=67, disc_2(Fake)_a=92\n",
            ">2804, disc_1(Real)=0.602, disc_2(Fake)=0.534, gen_loss=0.972, disc_1(Real)_a=73, disc_2(Fake)_a=90\n",
            ">2805, disc_1(Real)=0.612, disc_2(Fake)=0.555, gen_loss=0.962, disc_1(Real)_a=75, disc_2(Fake)_a=84\n",
            ">2806, disc_1(Real)=0.615, disc_2(Fake)=0.584, gen_loss=0.902, disc_1(Real)_a=70, disc_2(Fake)_a=71\n",
            ">2807, disc_1(Real)=0.612, disc_2(Fake)=0.617, gen_loss=0.867, disc_1(Real)_a=71, disc_2(Fake)_a=70\n",
            ">2808, disc_1(Real)=0.589, disc_2(Fake)=0.649, gen_loss=0.799, disc_1(Real)_a=81, disc_2(Fake)_a=64\n",
            ">2809, disc_1(Real)=0.619, disc_2(Fake)=0.713, gen_loss=0.766, disc_1(Real)_a=78, disc_2(Fake)_a=51\n",
            ">2810, disc_1(Real)=0.627, disc_2(Fake)=0.708, gen_loss=0.749, disc_1(Real)_a=79, disc_2(Fake)_a=48\n",
            ">2811, disc_1(Real)=0.607, disc_2(Fake)=0.711, gen_loss=0.752, disc_1(Real)_a=68, disc_2(Fake)_a=50\n",
            ">2812, disc_1(Real)=0.634, disc_2(Fake)=0.697, gen_loss=0.731, disc_1(Real)_a=68, disc_2(Fake)_a=51\n",
            ">2813, disc_1(Real)=0.608, disc_2(Fake)=0.734, gen_loss=0.749, disc_1(Real)_a=71, disc_2(Fake)_a=42\n",
            ">2814, disc_1(Real)=0.609, disc_2(Fake)=0.717, gen_loss=0.772, disc_1(Real)_a=75, disc_2(Fake)_a=45\n",
            ">2815, disc_1(Real)=0.618, disc_2(Fake)=0.715, gen_loss=0.760, disc_1(Real)_a=73, disc_2(Fake)_a=42\n",
            ">2816, disc_1(Real)=0.602, disc_2(Fake)=0.661, gen_loss=0.754, disc_1(Real)_a=70, disc_2(Fake)_a=59\n",
            ">2817, disc_1(Real)=0.649, disc_2(Fake)=0.727, gen_loss=0.731, disc_1(Real)_a=62, disc_2(Fake)_a=45\n",
            ">2818, disc_1(Real)=0.645, disc_2(Fake)=0.768, gen_loss=0.731, disc_1(Real)_a=56, disc_2(Fake)_a=32\n",
            ">2819, disc_1(Real)=0.642, disc_2(Fake)=0.782, gen_loss=0.694, disc_1(Real)_a=57, disc_2(Fake)_a=32\n",
            ">2820, disc_1(Real)=0.653, disc_2(Fake)=0.797, gen_loss=0.687, disc_1(Real)_a=59, disc_2(Fake)_a=35\n",
            ">2821, disc_1(Real)=0.629, disc_2(Fake)=0.750, gen_loss=0.696, disc_1(Real)_a=68, disc_2(Fake)_a=43\n",
            ">2822, disc_1(Real)=0.676, disc_2(Fake)=0.747, gen_loss=0.660, disc_1(Real)_a=57, disc_2(Fake)_a=40\n",
            ">2823, disc_1(Real)=0.647, disc_2(Fake)=0.751, gen_loss=0.707, disc_1(Real)_a=60, disc_2(Fake)_a=37\n",
            ">2824, disc_1(Real)=0.662, disc_2(Fake)=0.788, gen_loss=0.712, disc_1(Real)_a=62, disc_2(Fake)_a=28\n",
            ">2825, disc_1(Real)=0.656, disc_2(Fake)=0.724, gen_loss=0.731, disc_1(Real)_a=60, disc_2(Fake)_a=46\n",
            ">2826, disc_1(Real)=0.701, disc_2(Fake)=0.680, gen_loss=0.767, disc_1(Real)_a=54, disc_2(Fake)_a=53\n",
            ">2827, disc_1(Real)=0.704, disc_2(Fake)=0.656, gen_loss=0.830, disc_1(Real)_a=45, disc_2(Fake)_a=59\n",
            ">2828, disc_1(Real)=0.734, disc_2(Fake)=0.654, gen_loss=0.851, disc_1(Real)_a=43, disc_2(Fake)_a=60\n",
            ">2829, disc_1(Real)=0.706, disc_2(Fake)=0.678, gen_loss=0.837, disc_1(Real)_a=48, disc_2(Fake)_a=54\n",
            ">2830, disc_1(Real)=0.666, disc_2(Fake)=0.656, gen_loss=0.849, disc_1(Real)_a=60, disc_2(Fake)_a=53\n",
            ">2831, disc_1(Real)=0.690, disc_2(Fake)=0.646, gen_loss=0.864, disc_1(Real)_a=53, disc_2(Fake)_a=50\n",
            ">2832, disc_1(Real)=0.692, disc_2(Fake)=0.667, gen_loss=0.807, disc_1(Real)_a=53, disc_2(Fake)_a=54\n",
            ">2833, disc_1(Real)=0.678, disc_2(Fake)=0.641, gen_loss=0.819, disc_1(Real)_a=57, disc_2(Fake)_a=57\n",
            ">2834, disc_1(Real)=0.694, disc_2(Fake)=0.704, gen_loss=0.810, disc_1(Real)_a=60, disc_2(Fake)_a=40\n",
            ">2835, disc_1(Real)=0.709, disc_2(Fake)=0.652, gen_loss=0.748, disc_1(Real)_a=56, disc_2(Fake)_a=54\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">2836, disc_1(Real)=0.653, disc_2(Fake)=0.701, gen_loss=0.754, disc_1(Real)_a=62, disc_2(Fake)_a=45\n",
            ">2837, disc_1(Real)=0.664, disc_2(Fake)=0.690, gen_loss=0.733, disc_1(Real)_a=64, disc_2(Fake)_a=53\n",
            ">2838, disc_1(Real)=0.702, disc_2(Fake)=0.688, gen_loss=0.787, disc_1(Real)_a=56, disc_2(Fake)_a=54\n",
            ">2839, disc_1(Real)=0.667, disc_2(Fake)=0.643, gen_loss=0.812, disc_1(Real)_a=59, disc_2(Fake)_a=67\n",
            ">2840, disc_1(Real)=0.638, disc_2(Fake)=0.621, gen_loss=0.863, disc_1(Real)_a=65, disc_2(Fake)_a=78\n",
            ">2841, disc_1(Real)=0.661, disc_2(Fake)=0.669, gen_loss=0.841, disc_1(Real)_a=56, disc_2(Fake)_a=65\n",
            ">2842, disc_1(Real)=0.581, disc_2(Fake)=0.664, gen_loss=0.846, disc_1(Real)_a=71, disc_2(Fake)_a=65\n",
            ">2843, disc_1(Real)=0.648, disc_2(Fake)=0.682, gen_loss=0.797, disc_1(Real)_a=62, disc_2(Fake)_a=62\n",
            ">2844, disc_1(Real)=0.653, disc_2(Fake)=0.733, gen_loss=0.776, disc_1(Real)_a=57, disc_2(Fake)_a=54\n",
            ">2845, disc_1(Real)=0.596, disc_2(Fake)=0.677, gen_loss=0.753, disc_1(Real)_a=70, disc_2(Fake)_a=64\n",
            ">2846, disc_1(Real)=0.637, disc_2(Fake)=0.697, gen_loss=0.765, disc_1(Real)_a=64, disc_2(Fake)_a=59\n",
            ">2847, disc_1(Real)=0.619, disc_2(Fake)=0.705, gen_loss=0.785, disc_1(Real)_a=65, disc_2(Fake)_a=53\n",
            ">2848, disc_1(Real)=0.648, disc_2(Fake)=0.704, gen_loss=0.800, disc_1(Real)_a=65, disc_2(Fake)_a=60\n",
            ">2849, disc_1(Real)=0.685, disc_2(Fake)=0.668, gen_loss=0.815, disc_1(Real)_a=53, disc_2(Fake)_a=64\n",
            ">2850, disc_1(Real)=0.628, disc_2(Fake)=0.648, gen_loss=0.816, disc_1(Real)_a=70, disc_2(Fake)_a=67\n",
            ">2851, disc_1(Real)=0.653, disc_2(Fake)=0.650, gen_loss=0.791, disc_1(Real)_a=64, disc_2(Fake)_a=68\n",
            ">2852, disc_1(Real)=0.643, disc_2(Fake)=0.692, gen_loss=0.781, disc_1(Real)_a=68, disc_2(Fake)_a=60\n",
            ">2853, disc_1(Real)=0.664, disc_2(Fake)=0.710, gen_loss=0.761, disc_1(Real)_a=64, disc_2(Fake)_a=45\n",
            ">2854, disc_1(Real)=0.699, disc_2(Fake)=0.701, gen_loss=0.750, disc_1(Real)_a=59, disc_2(Fake)_a=45\n",
            ">2855, disc_1(Real)=0.684, disc_2(Fake)=0.705, gen_loss=0.743, disc_1(Real)_a=60, disc_2(Fake)_a=50\n",
            ">2856, disc_1(Real)=0.650, disc_2(Fake)=0.723, gen_loss=0.724, disc_1(Real)_a=71, disc_2(Fake)_a=42\n",
            ">2857, disc_1(Real)=0.651, disc_2(Fake)=0.699, gen_loss=0.702, disc_1(Real)_a=60, disc_2(Fake)_a=48\n",
            ">2858, disc_1(Real)=0.640, disc_2(Fake)=0.699, gen_loss=0.712, disc_1(Real)_a=67, disc_2(Fake)_a=51\n",
            ">2859, disc_1(Real)=0.662, disc_2(Fake)=0.726, gen_loss=0.711, disc_1(Real)_a=57, disc_2(Fake)_a=35\n",
            ">2860, disc_1(Real)=0.639, disc_2(Fake)=0.728, gen_loss=0.725, disc_1(Real)_a=67, disc_2(Fake)_a=34\n",
            ">2861, disc_1(Real)=0.645, disc_2(Fake)=0.705, gen_loss=0.736, disc_1(Real)_a=62, disc_2(Fake)_a=50\n",
            ">2862, disc_1(Real)=0.655, disc_2(Fake)=0.721, gen_loss=0.712, disc_1(Real)_a=60, disc_2(Fake)_a=43\n",
            ">2863, disc_1(Real)=0.622, disc_2(Fake)=0.728, gen_loss=0.723, disc_1(Real)_a=65, disc_2(Fake)_a=42\n",
            ">2864, disc_1(Real)=0.676, disc_2(Fake)=0.733, gen_loss=0.706, disc_1(Real)_a=50, disc_2(Fake)_a=43\n",
            ">2865, disc_1(Real)=0.603, disc_2(Fake)=0.719, gen_loss=0.717, disc_1(Real)_a=67, disc_2(Fake)_a=40\n",
            ">2866, disc_1(Real)=0.651, disc_2(Fake)=0.713, gen_loss=0.700, disc_1(Real)_a=59, disc_2(Fake)_a=45\n",
            ">2867, disc_1(Real)=0.615, disc_2(Fake)=0.729, gen_loss=0.709, disc_1(Real)_a=79, disc_2(Fake)_a=39\n",
            ">2868, disc_1(Real)=0.612, disc_2(Fake)=0.720, gen_loss=0.703, disc_1(Real)_a=78, disc_2(Fake)_a=48\n",
            ">2869, disc_1(Real)=0.687, disc_2(Fake)=0.719, gen_loss=0.714, disc_1(Real)_a=59, disc_2(Fake)_a=40\n",
            ">2870, disc_1(Real)=0.668, disc_2(Fake)=0.730, gen_loss=0.739, disc_1(Real)_a=62, disc_2(Fake)_a=42\n",
            ">2871, disc_1(Real)=0.622, disc_2(Fake)=0.707, gen_loss=0.772, disc_1(Real)_a=73, disc_2(Fake)_a=42\n",
            ">2872, disc_1(Real)=0.655, disc_2(Fake)=0.669, gen_loss=0.762, disc_1(Real)_a=57, disc_2(Fake)_a=57\n",
            ">2873, disc_1(Real)=0.692, disc_2(Fake)=0.672, gen_loss=0.783, disc_1(Real)_a=57, disc_2(Fake)_a=57\n",
            ">2874, disc_1(Real)=0.676, disc_2(Fake)=0.652, gen_loss=0.781, disc_1(Real)_a=57, disc_2(Fake)_a=65\n",
            ">2875, disc_1(Real)=0.650, disc_2(Fake)=0.666, gen_loss=0.757, disc_1(Real)_a=70, disc_2(Fake)_a=67\n",
            ">2876, disc_1(Real)=0.686, disc_2(Fake)=0.707, gen_loss=0.733, disc_1(Real)_a=56, disc_2(Fake)_a=50\n",
            ">2877, disc_1(Real)=0.615, disc_2(Fake)=0.715, gen_loss=0.728, disc_1(Real)_a=76, disc_2(Fake)_a=50\n",
            ">2878, disc_1(Real)=0.592, disc_2(Fake)=0.686, gen_loss=0.729, disc_1(Real)_a=75, disc_2(Fake)_a=56\n",
            ">2879, disc_1(Real)=0.642, disc_2(Fake)=0.700, gen_loss=0.725, disc_1(Real)_a=62, disc_2(Fake)_a=51\n",
            ">2880, disc_1(Real)=0.635, disc_2(Fake)=0.715, gen_loss=0.738, disc_1(Real)_a=71, disc_2(Fake)_a=40\n",
            ">2881, disc_1(Real)=0.634, disc_2(Fake)=0.697, gen_loss=0.739, disc_1(Real)_a=68, disc_2(Fake)_a=45\n",
            ">2882, disc_1(Real)=0.618, disc_2(Fake)=0.726, gen_loss=0.726, disc_1(Real)_a=78, disc_2(Fake)_a=34\n",
            ">2883, disc_1(Real)=0.612, disc_2(Fake)=0.685, gen_loss=0.736, disc_1(Real)_a=76, disc_2(Fake)_a=59\n",
            ">2884, disc_1(Real)=0.603, disc_2(Fake)=0.706, gen_loss=0.748, disc_1(Real)_a=71, disc_2(Fake)_a=51\n",
            ">2885, disc_1(Real)=0.641, disc_2(Fake)=0.658, gen_loss=0.765, disc_1(Real)_a=67, disc_2(Fake)_a=70\n",
            ">2886, disc_1(Real)=0.599, disc_2(Fake)=0.669, gen_loss=0.772, disc_1(Real)_a=79, disc_2(Fake)_a=62\n",
            ">2887, disc_1(Real)=0.620, disc_2(Fake)=0.668, gen_loss=0.768, disc_1(Real)_a=70, disc_2(Fake)_a=59\n",
            ">2888, disc_1(Real)=0.637, disc_2(Fake)=0.664, gen_loss=0.757, disc_1(Real)_a=67, disc_2(Fake)_a=53\n",
            ">2889, disc_1(Real)=0.638, disc_2(Fake)=0.682, gen_loss=0.744, disc_1(Real)_a=68, disc_2(Fake)_a=62\n",
            ">2890, disc_1(Real)=0.649, disc_2(Fake)=0.700, gen_loss=0.751, disc_1(Real)_a=59, disc_2(Fake)_a=57\n",
            ">2891, disc_1(Real)=0.591, disc_2(Fake)=0.702, gen_loss=0.780, disc_1(Real)_a=75, disc_2(Fake)_a=57\n",
            ">2892, disc_1(Real)=0.627, disc_2(Fake)=0.697, gen_loss=0.769, disc_1(Real)_a=65, disc_2(Fake)_a=56\n",
            ">2893, disc_1(Real)=0.670, disc_2(Fake)=0.666, gen_loss=0.782, disc_1(Real)_a=60, disc_2(Fake)_a=60\n",
            ">2894, disc_1(Real)=0.644, disc_2(Fake)=0.639, gen_loss=0.821, disc_1(Real)_a=67, disc_2(Fake)_a=75\n",
            ">2895, disc_1(Real)=0.658, disc_2(Fake)=0.626, gen_loss=0.834, disc_1(Real)_a=62, disc_2(Fake)_a=78\n",
            ">2896, disc_1(Real)=0.668, disc_2(Fake)=0.619, gen_loss=0.847, disc_1(Real)_a=56, disc_2(Fake)_a=71\n",
            ">2897, disc_1(Real)=0.660, disc_2(Fake)=0.582, gen_loss=0.847, disc_1(Real)_a=67, disc_2(Fake)_a=90\n",
            ">2898, disc_1(Real)=0.715, disc_2(Fake)=0.611, gen_loss=0.850, disc_1(Real)_a=45, disc_2(Fake)_a=78\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">2899, disc_1(Real)=0.650, disc_2(Fake)=0.598, gen_loss=0.826, disc_1(Real)_a=64, disc_2(Fake)_a=84\n",
            ">2900, disc_1(Real)=0.631, disc_2(Fake)=0.631, gen_loss=0.817, disc_1(Real)_a=75, disc_2(Fake)_a=73\n",
            ">2901, disc_1(Real)=0.656, disc_2(Fake)=0.647, gen_loss=0.769, disc_1(Real)_a=60, disc_2(Fake)_a=65\n",
            ">2902, disc_1(Real)=0.668, disc_2(Fake)=0.656, gen_loss=0.753, disc_1(Real)_a=50, disc_2(Fake)_a=57\n",
            ">2903, disc_1(Real)=0.641, disc_2(Fake)=0.689, gen_loss=0.745, disc_1(Real)_a=68, disc_2(Fake)_a=53\n",
            ">2904, disc_1(Real)=0.648, disc_2(Fake)=0.688, gen_loss=0.738, disc_1(Real)_a=67, disc_2(Fake)_a=51\n",
            ">2905, disc_1(Real)=0.644, disc_2(Fake)=0.692, gen_loss=0.723, disc_1(Real)_a=62, disc_2(Fake)_a=59\n",
            ">2906, disc_1(Real)=0.650, disc_2(Fake)=0.712, gen_loss=0.732, disc_1(Real)_a=68, disc_2(Fake)_a=42\n",
            ">2907, disc_1(Real)=0.639, disc_2(Fake)=0.706, gen_loss=0.714, disc_1(Real)_a=70, disc_2(Fake)_a=45\n",
            ">2908, disc_1(Real)=0.629, disc_2(Fake)=0.677, gen_loss=0.779, disc_1(Real)_a=76, disc_2(Fake)_a=62\n",
            ">2909, disc_1(Real)=0.660, disc_2(Fake)=0.668, gen_loss=0.789, disc_1(Real)_a=59, disc_2(Fake)_a=60\n",
            ">2910, disc_1(Real)=0.672, disc_2(Fake)=0.692, gen_loss=0.807, disc_1(Real)_a=51, disc_2(Fake)_a=57\n",
            ">2911, disc_1(Real)=0.671, disc_2(Fake)=0.662, gen_loss=0.786, disc_1(Real)_a=57, disc_2(Fake)_a=60\n",
            ">2912, disc_1(Real)=0.682, disc_2(Fake)=0.682, gen_loss=0.783, disc_1(Real)_a=56, disc_2(Fake)_a=59\n",
            ">2913, disc_1(Real)=0.721, disc_2(Fake)=0.702, gen_loss=0.783, disc_1(Real)_a=42, disc_2(Fake)_a=50\n",
            ">2914, disc_1(Real)=0.720, disc_2(Fake)=0.732, gen_loss=0.745, disc_1(Real)_a=46, disc_2(Fake)_a=40\n",
            ">2915, disc_1(Real)=0.667, disc_2(Fake)=0.721, gen_loss=0.746, disc_1(Real)_a=64, disc_2(Fake)_a=46\n",
            ">2916, disc_1(Real)=0.721, disc_2(Fake)=0.703, gen_loss=0.812, disc_1(Real)_a=46, disc_2(Fake)_a=43\n",
            ">2917, disc_1(Real)=0.718, disc_2(Fake)=0.656, gen_loss=0.796, disc_1(Real)_a=48, disc_2(Fake)_a=56\n",
            ">2918, disc_1(Real)=0.714, disc_2(Fake)=0.624, gen_loss=0.814, disc_1(Real)_a=45, disc_2(Fake)_a=62\n",
            ">2919, disc_1(Real)=0.739, disc_2(Fake)=0.619, gen_loss=0.844, disc_1(Real)_a=42, disc_2(Fake)_a=75\n",
            ">2920, disc_1(Real)=0.727, disc_2(Fake)=0.619, gen_loss=0.830, disc_1(Real)_a=45, disc_2(Fake)_a=73\n",
            ">2921, disc_1(Real)=0.748, disc_2(Fake)=0.619, gen_loss=0.862, disc_1(Real)_a=46, disc_2(Fake)_a=79\n",
            ">2922, disc_1(Real)=0.739, disc_2(Fake)=0.612, gen_loss=0.846, disc_1(Real)_a=42, disc_2(Fake)_a=76\n",
            ">2923, disc_1(Real)=0.675, disc_2(Fake)=0.608, gen_loss=0.847, disc_1(Real)_a=57, disc_2(Fake)_a=75\n",
            ">2924, disc_1(Real)=0.711, disc_2(Fake)=0.619, gen_loss=0.819, disc_1(Real)_a=48, disc_2(Fake)_a=79\n",
            ">2925, disc_1(Real)=0.712, disc_2(Fake)=0.638, gen_loss=0.831, disc_1(Real)_a=53, disc_2(Fake)_a=64\n",
            ">2926, disc_1(Real)=0.701, disc_2(Fake)=0.633, gen_loss=0.826, disc_1(Real)_a=50, disc_2(Fake)_a=71\n",
            ">2927, disc_1(Real)=0.683, disc_2(Fake)=0.640, gen_loss=0.816, disc_1(Real)_a=54, disc_2(Fake)_a=73\n",
            ">2928, disc_1(Real)=0.697, disc_2(Fake)=0.606, gen_loss=0.836, disc_1(Real)_a=51, disc_2(Fake)_a=76\n",
            ">2929, disc_1(Real)=0.716, disc_2(Fake)=0.614, gen_loss=0.871, disc_1(Real)_a=45, disc_2(Fake)_a=81\n",
            ">2930, disc_1(Real)=0.643, disc_2(Fake)=0.611, gen_loss=0.884, disc_1(Real)_a=65, disc_2(Fake)_a=81\n",
            ">2931, disc_1(Real)=0.673, disc_2(Fake)=0.602, gen_loss=0.880, disc_1(Real)_a=59, disc_2(Fake)_a=78\n",
            ">2932, disc_1(Real)=0.672, disc_2(Fake)=0.573, gen_loss=0.896, disc_1(Real)_a=64, disc_2(Fake)_a=85\n",
            ">2933, disc_1(Real)=0.664, disc_2(Fake)=0.612, gen_loss=0.853, disc_1(Real)_a=51, disc_2(Fake)_a=75\n",
            ">2934, disc_1(Real)=0.656, disc_2(Fake)=0.628, gen_loss=0.856, disc_1(Real)_a=60, disc_2(Fake)_a=70\n",
            ">2935, disc_1(Real)=0.667, disc_2(Fake)=0.627, gen_loss=0.823, disc_1(Real)_a=56, disc_2(Fake)_a=71\n",
            ">2936, disc_1(Real)=0.661, disc_2(Fake)=0.616, gen_loss=0.790, disc_1(Real)_a=51, disc_2(Fake)_a=78\n",
            ">2937, disc_1(Real)=0.649, disc_2(Fake)=0.629, gen_loss=0.807, disc_1(Real)_a=53, disc_2(Fake)_a=73\n",
            ">2938, disc_1(Real)=0.619, disc_2(Fake)=0.638, gen_loss=0.818, disc_1(Real)_a=68, disc_2(Fake)_a=68\n",
            ">2939, disc_1(Real)=0.636, disc_2(Fake)=0.670, gen_loss=0.824, disc_1(Real)_a=65, disc_2(Fake)_a=59\n",
            ">2940, disc_1(Real)=0.632, disc_2(Fake)=0.634, gen_loss=0.821, disc_1(Real)_a=71, disc_2(Fake)_a=71\n",
            ">2941, disc_1(Real)=0.671, disc_2(Fake)=0.641, gen_loss=0.849, disc_1(Real)_a=57, disc_2(Fake)_a=67\n",
            ">2942, disc_1(Real)=0.629, disc_2(Fake)=0.641, gen_loss=0.846, disc_1(Real)_a=64, disc_2(Fake)_a=75\n",
            ">2943, disc_1(Real)=0.684, disc_2(Fake)=0.614, gen_loss=0.816, disc_1(Real)_a=51, disc_2(Fake)_a=84\n",
            ">2944, disc_1(Real)=0.631, disc_2(Fake)=0.620, gen_loss=0.816, disc_1(Real)_a=67, disc_2(Fake)_a=78\n",
            ">2945, disc_1(Real)=0.605, disc_2(Fake)=0.663, gen_loss=0.814, disc_1(Real)_a=78, disc_2(Fake)_a=68\n",
            ">2946, disc_1(Real)=0.626, disc_2(Fake)=0.658, gen_loss=0.779, disc_1(Real)_a=71, disc_2(Fake)_a=71\n",
            ">2947, disc_1(Real)=0.655, disc_2(Fake)=0.655, gen_loss=0.773, disc_1(Real)_a=64, disc_2(Fake)_a=64\n",
            ">2948, disc_1(Real)=0.657, disc_2(Fake)=0.663, gen_loss=0.748, disc_1(Real)_a=60, disc_2(Fake)_a=59\n",
            ">2949, disc_1(Real)=0.634, disc_2(Fake)=0.682, gen_loss=0.755, disc_1(Real)_a=68, disc_2(Fake)_a=60\n",
            ">2950, disc_1(Real)=0.599, disc_2(Fake)=0.694, gen_loss=0.746, disc_1(Real)_a=73, disc_2(Fake)_a=54\n",
            ">2951, disc_1(Real)=0.596, disc_2(Fake)=0.686, gen_loss=0.751, disc_1(Real)_a=68, disc_2(Fake)_a=53\n",
            ">2952, disc_1(Real)=0.622, disc_2(Fake)=0.661, gen_loss=0.771, disc_1(Real)_a=65, disc_2(Fake)_a=65\n",
            ">2953, disc_1(Real)=0.621, disc_2(Fake)=0.669, gen_loss=0.759, disc_1(Real)_a=68, disc_2(Fake)_a=68\n",
            ">2954, disc_1(Real)=0.653, disc_2(Fake)=0.668, gen_loss=0.758, disc_1(Real)_a=65, disc_2(Fake)_a=62\n",
            ">2955, disc_1(Real)=0.679, disc_2(Fake)=0.677, gen_loss=0.769, disc_1(Real)_a=56, disc_2(Fake)_a=60\n",
            ">2956, disc_1(Real)=0.622, disc_2(Fake)=0.681, gen_loss=0.784, disc_1(Real)_a=70, disc_2(Fake)_a=54\n",
            ">2957, disc_1(Real)=0.674, disc_2(Fake)=0.695, gen_loss=0.772, disc_1(Real)_a=53, disc_2(Fake)_a=50\n",
            ">2958, disc_1(Real)=0.672, disc_2(Fake)=0.680, gen_loss=0.771, disc_1(Real)_a=59, disc_2(Fake)_a=60\n",
            ">2959, disc_1(Real)=0.654, disc_2(Fake)=0.657, gen_loss=0.769, disc_1(Real)_a=62, disc_2(Fake)_a=65\n",
            ">2960, disc_1(Real)=0.656, disc_2(Fake)=0.673, gen_loss=0.781, disc_1(Real)_a=56, disc_2(Fake)_a=56\n",
            ">2961, disc_1(Real)=0.664, disc_2(Fake)=0.668, gen_loss=0.745, disc_1(Real)_a=59, disc_2(Fake)_a=64\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">2962, disc_1(Real)=0.675, disc_2(Fake)=0.693, gen_loss=0.739, disc_1(Real)_a=57, disc_2(Fake)_a=57\n",
            ">2963, disc_1(Real)=0.677, disc_2(Fake)=0.668, gen_loss=0.776, disc_1(Real)_a=51, disc_2(Fake)_a=62\n",
            ">2964, disc_1(Real)=0.644, disc_2(Fake)=0.664, gen_loss=0.762, disc_1(Real)_a=62, disc_2(Fake)_a=67\n",
            ">2965, disc_1(Real)=0.662, disc_2(Fake)=0.672, gen_loss=0.760, disc_1(Real)_a=60, disc_2(Fake)_a=65\n",
            ">2966, disc_1(Real)=0.621, disc_2(Fake)=0.687, gen_loss=0.768, disc_1(Real)_a=67, disc_2(Fake)_a=51\n",
            ">2967, disc_1(Real)=0.617, disc_2(Fake)=0.675, gen_loss=0.759, disc_1(Real)_a=65, disc_2(Fake)_a=62\n",
            ">2968, disc_1(Real)=0.625, disc_2(Fake)=0.658, gen_loss=0.759, disc_1(Real)_a=67, disc_2(Fake)_a=70\n",
            ">2969, disc_1(Real)=0.648, disc_2(Fake)=0.659, gen_loss=0.759, disc_1(Real)_a=62, disc_2(Fake)_a=68\n",
            ">2970, disc_1(Real)=0.644, disc_2(Fake)=0.677, gen_loss=0.781, disc_1(Real)_a=60, disc_2(Fake)_a=60\n",
            ">2971, disc_1(Real)=0.676, disc_2(Fake)=0.687, gen_loss=0.767, disc_1(Real)_a=59, disc_2(Fake)_a=59\n",
            ">2972, disc_1(Real)=0.639, disc_2(Fake)=0.691, gen_loss=0.781, disc_1(Real)_a=62, disc_2(Fake)_a=64\n",
            ">2973, disc_1(Real)=0.654, disc_2(Fake)=0.664, gen_loss=0.771, disc_1(Real)_a=64, disc_2(Fake)_a=67\n",
            ">2974, disc_1(Real)=0.636, disc_2(Fake)=0.658, gen_loss=0.795, disc_1(Real)_a=70, disc_2(Fake)_a=62\n",
            ">2975, disc_1(Real)=0.632, disc_2(Fake)=0.642, gen_loss=0.806, disc_1(Real)_a=65, disc_2(Fake)_a=70\n",
            ">2976, disc_1(Real)=0.623, disc_2(Fake)=0.652, gen_loss=0.785, disc_1(Real)_a=68, disc_2(Fake)_a=67\n",
            ">2977, disc_1(Real)=0.633, disc_2(Fake)=0.658, gen_loss=0.796, disc_1(Real)_a=67, disc_2(Fake)_a=67\n",
            ">2978, disc_1(Real)=0.646, disc_2(Fake)=0.642, gen_loss=0.808, disc_1(Real)_a=59, disc_2(Fake)_a=71\n",
            ">2979, disc_1(Real)=0.673, disc_2(Fake)=0.651, gen_loss=0.801, disc_1(Real)_a=57, disc_2(Fake)_a=67\n",
            ">2980, disc_1(Real)=0.685, disc_2(Fake)=0.617, gen_loss=0.804, disc_1(Real)_a=48, disc_2(Fake)_a=76\n",
            ">2981, disc_1(Real)=0.678, disc_2(Fake)=0.610, gen_loss=0.840, disc_1(Real)_a=56, disc_2(Fake)_a=76\n",
            ">2982, disc_1(Real)=0.670, disc_2(Fake)=0.657, gen_loss=0.809, disc_1(Real)_a=60, disc_2(Fake)_a=68\n",
            ">2983, disc_1(Real)=0.618, disc_2(Fake)=0.672, gen_loss=0.819, disc_1(Real)_a=65, disc_2(Fake)_a=65\n",
            ">2984, disc_1(Real)=0.676, disc_2(Fake)=0.642, gen_loss=0.798, disc_1(Real)_a=59, disc_2(Fake)_a=68\n",
            ">2985, disc_1(Real)=0.644, disc_2(Fake)=0.653, gen_loss=0.805, disc_1(Real)_a=68, disc_2(Fake)_a=65\n",
            ">2986, disc_1(Real)=0.648, disc_2(Fake)=0.642, gen_loss=0.781, disc_1(Real)_a=64, disc_2(Fake)_a=65\n",
            ">2987, disc_1(Real)=0.669, disc_2(Fake)=0.655, gen_loss=0.784, disc_1(Real)_a=56, disc_2(Fake)_a=62\n",
            ">2988, disc_1(Real)=0.670, disc_2(Fake)=0.660, gen_loss=0.797, disc_1(Real)_a=56, disc_2(Fake)_a=64\n",
            ">2989, disc_1(Real)=0.619, disc_2(Fake)=0.630, gen_loss=0.823, disc_1(Real)_a=70, disc_2(Fake)_a=68\n",
            ">2990, disc_1(Real)=0.647, disc_2(Fake)=0.648, gen_loss=0.813, disc_1(Real)_a=67, disc_2(Fake)_a=65\n",
            ">2991, disc_1(Real)=0.639, disc_2(Fake)=0.654, gen_loss=0.818, disc_1(Real)_a=62, disc_2(Fake)_a=56\n",
            ">2992, disc_1(Real)=0.605, disc_2(Fake)=0.668, gen_loss=0.798, disc_1(Real)_a=76, disc_2(Fake)_a=54\n",
            ">2993, disc_1(Real)=0.632, disc_2(Fake)=0.655, gen_loss=0.808, disc_1(Real)_a=76, disc_2(Fake)_a=62\n",
            ">2994, disc_1(Real)=0.649, disc_2(Fake)=0.657, gen_loss=0.790, disc_1(Real)_a=62, disc_2(Fake)_a=59\n",
            ">2995, disc_1(Real)=0.626, disc_2(Fake)=0.656, gen_loss=0.748, disc_1(Real)_a=67, disc_2(Fake)_a=64\n",
            ">2996, disc_1(Real)=0.644, disc_2(Fake)=0.690, gen_loss=0.769, disc_1(Real)_a=60, disc_2(Fake)_a=53\n",
            ">2997, disc_1(Real)=0.652, disc_2(Fake)=0.677, gen_loss=0.801, disc_1(Real)_a=62, disc_2(Fake)_a=53\n",
            ">2998, disc_1(Real)=0.659, disc_2(Fake)=0.699, gen_loss=0.811, disc_1(Real)_a=60, disc_2(Fake)_a=45\n",
            ">2999, disc_1(Real)=0.660, disc_2(Fake)=0.674, gen_loss=0.805, disc_1(Real)_a=59, disc_2(Fake)_a=53\n",
            ">3000, disc_1(Real)=0.644, disc_2(Fake)=0.645, gen_loss=0.799, disc_1(Real)_a=60, disc_2(Fake)_a=64\n",
            ">3001, disc_1(Real)=0.651, disc_2(Fake)=0.649, gen_loss=0.820, disc_1(Real)_a=60, disc_2(Fake)_a=62\n",
            ">3002, disc_1(Real)=0.673, disc_2(Fake)=0.630, gen_loss=0.801, disc_1(Real)_a=64, disc_2(Fake)_a=64\n",
            ">3003, disc_1(Real)=0.649, disc_2(Fake)=0.680, gen_loss=0.814, disc_1(Real)_a=67, disc_2(Fake)_a=56\n",
            ">3004, disc_1(Real)=0.669, disc_2(Fake)=0.684, gen_loss=0.797, disc_1(Real)_a=54, disc_2(Fake)_a=50\n",
            ">3005, disc_1(Real)=0.641, disc_2(Fake)=0.661, gen_loss=0.791, disc_1(Real)_a=65, disc_2(Fake)_a=60\n",
            ">3006, disc_1(Real)=0.641, disc_2(Fake)=0.646, gen_loss=0.801, disc_1(Real)_a=71, disc_2(Fake)_a=62\n",
            ">3007, disc_1(Real)=0.647, disc_2(Fake)=0.661, gen_loss=0.788, disc_1(Real)_a=65, disc_2(Fake)_a=53\n",
            ">3008, disc_1(Real)=0.621, disc_2(Fake)=0.664, gen_loss=0.820, disc_1(Real)_a=68, disc_2(Fake)_a=57\n",
            ">3009, disc_1(Real)=0.623, disc_2(Fake)=0.674, gen_loss=0.846, disc_1(Real)_a=78, disc_2(Fake)_a=60\n",
            ">3010, disc_1(Real)=0.672, disc_2(Fake)=0.653, gen_loss=0.783, disc_1(Real)_a=62, disc_2(Fake)_a=59\n",
            ">3011, disc_1(Real)=0.638, disc_2(Fake)=0.646, gen_loss=0.835, disc_1(Real)_a=67, disc_2(Fake)_a=65\n",
            ">3012, disc_1(Real)=0.638, disc_2(Fake)=0.657, gen_loss=0.807, disc_1(Real)_a=67, disc_2(Fake)_a=62\n",
            ">3013, disc_1(Real)=0.635, disc_2(Fake)=0.651, gen_loss=0.849, disc_1(Real)_a=65, disc_2(Fake)_a=59\n",
            ">3014, disc_1(Real)=0.648, disc_2(Fake)=0.633, gen_loss=0.815, disc_1(Real)_a=71, disc_2(Fake)_a=67\n",
            ">3015, disc_1(Real)=0.657, disc_2(Fake)=0.645, gen_loss=0.821, disc_1(Real)_a=59, disc_2(Fake)_a=62\n",
            ">3016, disc_1(Real)=0.628, disc_2(Fake)=0.634, gen_loss=0.841, disc_1(Real)_a=75, disc_2(Fake)_a=60\n",
            ">3017, disc_1(Real)=0.652, disc_2(Fake)=0.692, gen_loss=0.847, disc_1(Real)_a=62, disc_2(Fake)_a=48\n",
            ">3018, disc_1(Real)=0.682, disc_2(Fake)=0.651, gen_loss=0.818, disc_1(Real)_a=64, disc_2(Fake)_a=62\n",
            ">3019, disc_1(Real)=0.629, disc_2(Fake)=0.625, gen_loss=0.835, disc_1(Real)_a=73, disc_2(Fake)_a=70\n",
            ">3020, disc_1(Real)=0.657, disc_2(Fake)=0.625, gen_loss=0.862, disc_1(Real)_a=59, disc_2(Fake)_a=70\n",
            ">3021, disc_1(Real)=0.611, disc_2(Fake)=0.618, gen_loss=0.858, disc_1(Real)_a=76, disc_2(Fake)_a=78\n",
            ">3022, disc_1(Real)=0.626, disc_2(Fake)=0.625, gen_loss=0.847, disc_1(Real)_a=71, disc_2(Fake)_a=73\n",
            ">3023, disc_1(Real)=0.623, disc_2(Fake)=0.623, gen_loss=0.851, disc_1(Real)_a=71, disc_2(Fake)_a=70\n",
            ">3024, disc_1(Real)=0.642, disc_2(Fake)=0.589, gen_loss=0.876, disc_1(Real)_a=68, disc_2(Fake)_a=79\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">3025, disc_1(Real)=0.676, disc_2(Fake)=0.586, gen_loss=0.861, disc_1(Real)_a=56, disc_2(Fake)_a=82\n",
            ">3026, disc_1(Real)=0.665, disc_2(Fake)=0.620, gen_loss=0.830, disc_1(Real)_a=57, disc_2(Fake)_a=65\n",
            ">3027, disc_1(Real)=0.670, disc_2(Fake)=0.579, gen_loss=0.873, disc_1(Real)_a=62, disc_2(Fake)_a=82\n",
            ">3028, disc_1(Real)=0.624, disc_2(Fake)=0.590, gen_loss=0.861, disc_1(Real)_a=71, disc_2(Fake)_a=78\n",
            ">3029, disc_1(Real)=0.622, disc_2(Fake)=0.594, gen_loss=0.852, disc_1(Real)_a=67, disc_2(Fake)_a=85\n",
            ">3030, disc_1(Real)=0.626, disc_2(Fake)=0.595, gen_loss=0.906, disc_1(Real)_a=73, disc_2(Fake)_a=84\n",
            ">3031, disc_1(Real)=0.678, disc_2(Fake)=0.596, gen_loss=0.884, disc_1(Real)_a=57, disc_2(Fake)_a=78\n",
            ">3032, disc_1(Real)=0.622, disc_2(Fake)=0.582, gen_loss=0.915, disc_1(Real)_a=73, disc_2(Fake)_a=81\n",
            ">3033, disc_1(Real)=0.630, disc_2(Fake)=0.575, gen_loss=0.887, disc_1(Real)_a=65, disc_2(Fake)_a=79\n",
            ">3034, disc_1(Real)=0.620, disc_2(Fake)=0.601, gen_loss=0.879, disc_1(Real)_a=70, disc_2(Fake)_a=71\n",
            ">3035, disc_1(Real)=0.619, disc_2(Fake)=0.588, gen_loss=0.871, disc_1(Real)_a=71, disc_2(Fake)_a=82\n",
            ">3036, disc_1(Real)=0.640, disc_2(Fake)=0.598, gen_loss=0.845, disc_1(Real)_a=65, disc_2(Fake)_a=73\n",
            ">3037, disc_1(Real)=0.657, disc_2(Fake)=0.631, gen_loss=0.828, disc_1(Real)_a=56, disc_2(Fake)_a=70\n",
            ">3038, disc_1(Real)=0.653, disc_2(Fake)=0.600, gen_loss=0.853, disc_1(Real)_a=56, disc_2(Fake)_a=76\n",
            ">3039, disc_1(Real)=0.647, disc_2(Fake)=0.630, gen_loss=0.840, disc_1(Real)_a=67, disc_2(Fake)_a=64\n",
            ">3040, disc_1(Real)=0.656, disc_2(Fake)=0.616, gen_loss=0.836, disc_1(Real)_a=62, disc_2(Fake)_a=70\n",
            ">3041, disc_1(Real)=0.690, disc_2(Fake)=0.611, gen_loss=0.893, disc_1(Real)_a=51, disc_2(Fake)_a=73\n",
            ">3042, disc_1(Real)=0.697, disc_2(Fake)=0.615, gen_loss=0.924, disc_1(Real)_a=50, disc_2(Fake)_a=60\n",
            ">3043, disc_1(Real)=0.666, disc_2(Fake)=0.604, gen_loss=0.930, disc_1(Real)_a=54, disc_2(Fake)_a=70\n",
            ">3044, disc_1(Real)=0.646, disc_2(Fake)=0.612, gen_loss=0.898, disc_1(Real)_a=62, disc_2(Fake)_a=67\n",
            ">3045, disc_1(Real)=0.643, disc_2(Fake)=0.578, gen_loss=0.907, disc_1(Real)_a=67, disc_2(Fake)_a=73\n",
            ">3046, disc_1(Real)=0.621, disc_2(Fake)=0.616, gen_loss=0.883, disc_1(Real)_a=70, disc_2(Fake)_a=60\n",
            ">3047, disc_1(Real)=0.677, disc_2(Fake)=0.619, gen_loss=0.878, disc_1(Real)_a=56, disc_2(Fake)_a=59\n",
            ">3048, disc_1(Real)=0.669, disc_2(Fake)=0.672, gen_loss=0.858, disc_1(Real)_a=60, disc_2(Fake)_a=50\n",
            ">3049, disc_1(Real)=0.654, disc_2(Fake)=0.638, gen_loss=0.847, disc_1(Real)_a=64, disc_2(Fake)_a=62\n",
            ">3050, disc_1(Real)=0.697, disc_2(Fake)=0.628, gen_loss=0.856, disc_1(Real)_a=54, disc_2(Fake)_a=68\n",
            ">3051, disc_1(Real)=0.677, disc_2(Fake)=0.612, gen_loss=0.889, disc_1(Real)_a=56, disc_2(Fake)_a=81\n",
            ">3052, disc_1(Real)=0.677, disc_2(Fake)=0.593, gen_loss=0.882, disc_1(Real)_a=62, disc_2(Fake)_a=79\n",
            ">3053, disc_1(Real)=0.690, disc_2(Fake)=0.614, gen_loss=0.904, disc_1(Real)_a=45, disc_2(Fake)_a=78\n",
            ">3054, disc_1(Real)=0.662, disc_2(Fake)=0.600, gen_loss=0.918, disc_1(Real)_a=65, disc_2(Fake)_a=76\n",
            ">3055, disc_1(Real)=0.709, disc_2(Fake)=0.601, gen_loss=0.897, disc_1(Real)_a=56, disc_2(Fake)_a=71\n",
            ">3056, disc_1(Real)=0.693, disc_2(Fake)=0.592, gen_loss=0.933, disc_1(Real)_a=62, disc_2(Fake)_a=81\n",
            ">3057, disc_1(Real)=0.742, disc_2(Fake)=0.558, gen_loss=0.916, disc_1(Real)_a=40, disc_2(Fake)_a=92\n",
            ">3058, disc_1(Real)=0.670, disc_2(Fake)=0.561, gen_loss=0.929, disc_1(Real)_a=59, disc_2(Fake)_a=95\n",
            ">3059, disc_1(Real)=0.710, disc_2(Fake)=0.585, gen_loss=0.915, disc_1(Real)_a=59, disc_2(Fake)_a=81\n",
            ">3060, disc_1(Real)=0.691, disc_2(Fake)=0.555, gen_loss=0.942, disc_1(Real)_a=57, disc_2(Fake)_a=90\n",
            ">3061, disc_1(Real)=0.671, disc_2(Fake)=0.559, gen_loss=0.934, disc_1(Real)_a=62, disc_2(Fake)_a=92\n",
            ">3062, disc_1(Real)=0.711, disc_2(Fake)=0.568, gen_loss=0.928, disc_1(Real)_a=50, disc_2(Fake)_a=93\n",
            ">3063, disc_1(Real)=0.631, disc_2(Fake)=0.559, gen_loss=0.964, disc_1(Real)_a=70, disc_2(Fake)_a=84\n",
            ">3064, disc_1(Real)=0.714, disc_2(Fake)=0.563, gen_loss=0.987, disc_1(Real)_a=50, disc_2(Fake)_a=84\n",
            ">3065, disc_1(Real)=0.749, disc_2(Fake)=0.535, gen_loss=0.934, disc_1(Real)_a=35, disc_2(Fake)_a=96\n",
            ">3066, disc_1(Real)=0.647, disc_2(Fake)=0.578, gen_loss=0.925, disc_1(Real)_a=64, disc_2(Fake)_a=90\n",
            ">3067, disc_1(Real)=0.668, disc_2(Fake)=0.573, gen_loss=0.937, disc_1(Real)_a=59, disc_2(Fake)_a=82\n",
            ">3068, disc_1(Real)=0.638, disc_2(Fake)=0.606, gen_loss=0.916, disc_1(Real)_a=73, disc_2(Fake)_a=70\n",
            ">3069, disc_1(Real)=0.660, disc_2(Fake)=0.563, gen_loss=0.940, disc_1(Real)_a=64, disc_2(Fake)_a=82\n",
            ">3070, disc_1(Real)=0.642, disc_2(Fake)=0.596, gen_loss=0.921, disc_1(Real)_a=65, disc_2(Fake)_a=79\n",
            ">3071, disc_1(Real)=0.680, disc_2(Fake)=0.597, gen_loss=0.883, disc_1(Real)_a=60, disc_2(Fake)_a=70\n",
            ">3072, disc_1(Real)=0.670, disc_2(Fake)=0.631, gen_loss=0.866, disc_1(Real)_a=57, disc_2(Fake)_a=73\n",
            ">3073, disc_1(Real)=0.664, disc_2(Fake)=0.628, gen_loss=0.842, disc_1(Real)_a=57, disc_2(Fake)_a=70\n",
            ">3074, disc_1(Real)=0.674, disc_2(Fake)=0.624, gen_loss=0.853, disc_1(Real)_a=65, disc_2(Fake)_a=73\n",
            ">3075, disc_1(Real)=0.658, disc_2(Fake)=0.641, gen_loss=0.830, disc_1(Real)_a=64, disc_2(Fake)_a=68\n",
            ">3076, disc_1(Real)=0.702, disc_2(Fake)=0.663, gen_loss=0.796, disc_1(Real)_a=56, disc_2(Fake)_a=60\n",
            ">3077, disc_1(Real)=0.665, disc_2(Fake)=0.673, gen_loss=0.772, disc_1(Real)_a=60, disc_2(Fake)_a=56\n",
            ">3078, disc_1(Real)=0.665, disc_2(Fake)=0.689, gen_loss=0.751, disc_1(Real)_a=64, disc_2(Fake)_a=54\n",
            ">3079, disc_1(Real)=0.647, disc_2(Fake)=0.726, gen_loss=0.747, disc_1(Real)_a=64, disc_2(Fake)_a=39\n",
            ">3080, disc_1(Real)=0.629, disc_2(Fake)=0.760, gen_loss=0.735, disc_1(Real)_a=70, disc_2(Fake)_a=37\n",
            ">3081, disc_1(Real)=0.615, disc_2(Fake)=0.759, gen_loss=0.736, disc_1(Real)_a=73, disc_2(Fake)_a=32\n",
            ">3082, disc_1(Real)=0.674, disc_2(Fake)=0.706, gen_loss=0.736, disc_1(Real)_a=64, disc_2(Fake)_a=51\n",
            ">3083, disc_1(Real)=0.672, disc_2(Fake)=0.744, gen_loss=0.740, disc_1(Real)_a=59, disc_2(Fake)_a=43\n",
            ">3084, disc_1(Real)=0.693, disc_2(Fake)=0.717, gen_loss=0.756, disc_1(Real)_a=59, disc_2(Fake)_a=45\n",
            ">3085, disc_1(Real)=0.697, disc_2(Fake)=0.717, gen_loss=0.748, disc_1(Real)_a=54, disc_2(Fake)_a=51\n",
            ">3086, disc_1(Real)=0.669, disc_2(Fake)=0.673, gen_loss=0.822, disc_1(Real)_a=60, disc_2(Fake)_a=45\n",
            ">3087, disc_1(Real)=0.683, disc_2(Fake)=0.698, gen_loss=0.781, disc_1(Real)_a=54, disc_2(Fake)_a=53\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">3088, disc_1(Real)=0.690, disc_2(Fake)=0.692, gen_loss=0.794, disc_1(Real)_a=53, disc_2(Fake)_a=50\n",
            ">3089, disc_1(Real)=0.691, disc_2(Fake)=0.703, gen_loss=0.759, disc_1(Real)_a=56, disc_2(Fake)_a=42\n",
            ">3090, disc_1(Real)=0.661, disc_2(Fake)=0.688, gen_loss=0.761, disc_1(Real)_a=62, disc_2(Fake)_a=51\n",
            ">3091, disc_1(Real)=0.683, disc_2(Fake)=0.675, gen_loss=0.774, disc_1(Real)_a=57, disc_2(Fake)_a=60\n",
            ">3092, disc_1(Real)=0.674, disc_2(Fake)=0.668, gen_loss=0.767, disc_1(Real)_a=59, disc_2(Fake)_a=57\n",
            ">3093, disc_1(Real)=0.606, disc_2(Fake)=0.673, gen_loss=0.761, disc_1(Real)_a=78, disc_2(Fake)_a=60\n",
            ">3094, disc_1(Real)=0.644, disc_2(Fake)=0.682, gen_loss=0.762, disc_1(Real)_a=65, disc_2(Fake)_a=62\n",
            ">3095, disc_1(Real)=0.615, disc_2(Fake)=0.692, gen_loss=0.787, disc_1(Real)_a=79, disc_2(Fake)_a=51\n",
            ">3096, disc_1(Real)=0.622, disc_2(Fake)=0.671, gen_loss=0.778, disc_1(Real)_a=73, disc_2(Fake)_a=67\n",
            ">3097, disc_1(Real)=0.624, disc_2(Fake)=0.667, gen_loss=0.781, disc_1(Real)_a=76, disc_2(Fake)_a=57\n",
            ">3098, disc_1(Real)=0.617, disc_2(Fake)=0.693, gen_loss=0.779, disc_1(Real)_a=70, disc_2(Fake)_a=57\n",
            ">3099, disc_1(Real)=0.599, disc_2(Fake)=0.667, gen_loss=0.781, disc_1(Real)_a=81, disc_2(Fake)_a=68\n",
            ">3100, disc_1(Real)=0.585, disc_2(Fake)=0.661, gen_loss=0.796, disc_1(Real)_a=84, disc_2(Fake)_a=65\n",
            ">3101, disc_1(Real)=0.584, disc_2(Fake)=0.659, gen_loss=0.797, disc_1(Real)_a=82, disc_2(Fake)_a=71\n",
            ">3102, disc_1(Real)=0.613, disc_2(Fake)=0.650, gen_loss=0.832, disc_1(Real)_a=78, disc_2(Fake)_a=70\n",
            ">3103, disc_1(Real)=0.608, disc_2(Fake)=0.613, gen_loss=0.841, disc_1(Real)_a=75, disc_2(Fake)_a=75\n",
            ">3104, disc_1(Real)=0.605, disc_2(Fake)=0.598, gen_loss=0.882, disc_1(Real)_a=76, disc_2(Fake)_a=82\n",
            ">3105, disc_1(Real)=0.626, disc_2(Fake)=0.633, gen_loss=0.827, disc_1(Real)_a=75, disc_2(Fake)_a=60\n",
            ">3106, disc_1(Real)=0.638, disc_2(Fake)=0.608, gen_loss=0.846, disc_1(Real)_a=67, disc_2(Fake)_a=75\n",
            ">3107, disc_1(Real)=0.618, disc_2(Fake)=0.647, gen_loss=0.842, disc_1(Real)_a=75, disc_2(Fake)_a=62\n",
            ">3108, disc_1(Real)=0.604, disc_2(Fake)=0.645, gen_loss=0.827, disc_1(Real)_a=73, disc_2(Fake)_a=67\n",
            ">3109, disc_1(Real)=0.597, disc_2(Fake)=0.619, gen_loss=0.857, disc_1(Real)_a=75, disc_2(Fake)_a=71\n",
            ">3110, disc_1(Real)=0.585, disc_2(Fake)=0.621, gen_loss=0.860, disc_1(Real)_a=76, disc_2(Fake)_a=75\n",
            ">3111, disc_1(Real)=0.589, disc_2(Fake)=0.602, gen_loss=0.852, disc_1(Real)_a=87, disc_2(Fake)_a=78\n",
            ">3112, disc_1(Real)=0.603, disc_2(Fake)=0.624, gen_loss=0.837, disc_1(Real)_a=79, disc_2(Fake)_a=75\n",
            ">3113, disc_1(Real)=0.586, disc_2(Fake)=0.613, gen_loss=0.801, disc_1(Real)_a=81, disc_2(Fake)_a=73\n",
            ">3114, disc_1(Real)=0.598, disc_2(Fake)=0.615, gen_loss=0.830, disc_1(Real)_a=82, disc_2(Fake)_a=79\n",
            ">3115, disc_1(Real)=0.565, disc_2(Fake)=0.619, gen_loss=0.810, disc_1(Real)_a=84, disc_2(Fake)_a=78\n",
            ">3116, disc_1(Real)=0.593, disc_2(Fake)=0.617, gen_loss=0.834, disc_1(Real)_a=84, disc_2(Fake)_a=75\n",
            ">3117, disc_1(Real)=0.547, disc_2(Fake)=0.591, gen_loss=0.849, disc_1(Real)_a=92, disc_2(Fake)_a=84\n",
            ">3118, disc_1(Real)=0.550, disc_2(Fake)=0.631, gen_loss=0.848, disc_1(Real)_a=89, disc_2(Fake)_a=70\n",
            ">3119, disc_1(Real)=0.588, disc_2(Fake)=0.617, gen_loss=0.842, disc_1(Real)_a=81, disc_2(Fake)_a=82\n",
            ">3120, disc_1(Real)=0.587, disc_2(Fake)=0.619, gen_loss=0.858, disc_1(Real)_a=82, disc_2(Fake)_a=73\n",
            ">3121, disc_1(Real)=0.588, disc_2(Fake)=0.614, gen_loss=0.848, disc_1(Real)_a=84, disc_2(Fake)_a=73\n",
            ">3122, disc_1(Real)=0.599, disc_2(Fake)=0.584, gen_loss=0.852, disc_1(Real)_a=81, disc_2(Fake)_a=82\n",
            ">3123, disc_1(Real)=0.567, disc_2(Fake)=0.598, gen_loss=0.874, disc_1(Real)_a=84, disc_2(Fake)_a=76\n",
            ">3124, disc_1(Real)=0.602, disc_2(Fake)=0.598, gen_loss=0.888, disc_1(Real)_a=73, disc_2(Fake)_a=89\n",
            ">3125, disc_1(Real)=0.624, disc_2(Fake)=0.601, gen_loss=0.889, disc_1(Real)_a=68, disc_2(Fake)_a=82\n",
            ">3126, disc_1(Real)=0.622, disc_2(Fake)=0.615, gen_loss=0.877, disc_1(Real)_a=78, disc_2(Fake)_a=81\n",
            ">3127, disc_1(Real)=0.628, disc_2(Fake)=0.606, gen_loss=0.864, disc_1(Real)_a=73, disc_2(Fake)_a=81\n",
            ">3128, disc_1(Real)=0.609, disc_2(Fake)=0.612, gen_loss=0.873, disc_1(Real)_a=78, disc_2(Fake)_a=81\n",
            ">3129, disc_1(Real)=0.617, disc_2(Fake)=0.610, gen_loss=0.837, disc_1(Real)_a=73, disc_2(Fake)_a=70\n",
            ">3130, disc_1(Real)=0.614, disc_2(Fake)=0.645, gen_loss=0.836, disc_1(Real)_a=71, disc_2(Fake)_a=68\n",
            ">3131, disc_1(Real)=0.636, disc_2(Fake)=0.609, gen_loss=0.830, disc_1(Real)_a=68, disc_2(Fake)_a=79\n",
            ">3132, disc_1(Real)=0.599, disc_2(Fake)=0.653, gen_loss=0.826, disc_1(Real)_a=76, disc_2(Fake)_a=68\n",
            ">3133, disc_1(Real)=0.599, disc_2(Fake)=0.618, gen_loss=0.825, disc_1(Real)_a=82, disc_2(Fake)_a=79\n",
            ">3134, disc_1(Real)=0.594, disc_2(Fake)=0.618, gen_loss=0.818, disc_1(Real)_a=79, disc_2(Fake)_a=79\n",
            ">3135, disc_1(Real)=0.594, disc_2(Fake)=0.633, gen_loss=0.809, disc_1(Real)_a=71, disc_2(Fake)_a=73\n",
            ">3136, disc_1(Real)=0.590, disc_2(Fake)=0.666, gen_loss=0.816, disc_1(Real)_a=81, disc_2(Fake)_a=57\n",
            ">3137, disc_1(Real)=0.651, disc_2(Fake)=0.649, gen_loss=0.803, disc_1(Real)_a=68, disc_2(Fake)_a=68\n",
            ">3138, disc_1(Real)=0.631, disc_2(Fake)=0.653, gen_loss=0.815, disc_1(Real)_a=71, disc_2(Fake)_a=65\n",
            ">3139, disc_1(Real)=0.634, disc_2(Fake)=0.643, gen_loss=0.821, disc_1(Real)_a=70, disc_2(Fake)_a=75\n",
            ">3140, disc_1(Real)=0.607, disc_2(Fake)=0.684, gen_loss=0.797, disc_1(Real)_a=73, disc_2(Fake)_a=51\n",
            ">3141, disc_1(Real)=0.640, disc_2(Fake)=0.671, gen_loss=0.801, disc_1(Real)_a=73, disc_2(Fake)_a=62\n",
            ">3142, disc_1(Real)=0.621, disc_2(Fake)=0.715, gen_loss=0.782, disc_1(Real)_a=73, disc_2(Fake)_a=51\n",
            ">3143, disc_1(Real)=0.666, disc_2(Fake)=0.658, gen_loss=0.782, disc_1(Real)_a=57, disc_2(Fake)_a=65\n",
            ">3144, disc_1(Real)=0.645, disc_2(Fake)=0.676, gen_loss=0.795, disc_1(Real)_a=67, disc_2(Fake)_a=54\n",
            ">3145, disc_1(Real)=0.645, disc_2(Fake)=0.683, gen_loss=0.801, disc_1(Real)_a=73, disc_2(Fake)_a=64\n",
            ">3146, disc_1(Real)=0.699, disc_2(Fake)=0.680, gen_loss=0.792, disc_1(Real)_a=46, disc_2(Fake)_a=57\n",
            ">3147, disc_1(Real)=0.677, disc_2(Fake)=0.698, gen_loss=0.803, disc_1(Real)_a=59, disc_2(Fake)_a=57\n",
            ">3148, disc_1(Real)=0.675, disc_2(Fake)=0.715, gen_loss=0.806, disc_1(Real)_a=54, disc_2(Fake)_a=56\n",
            ">3149, disc_1(Real)=0.678, disc_2(Fake)=0.708, gen_loss=0.766, disc_1(Real)_a=57, disc_2(Fake)_a=57\n",
            ">3150, disc_1(Real)=0.684, disc_2(Fake)=0.671, gen_loss=0.762, disc_1(Real)_a=46, disc_2(Fake)_a=62\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvGkU_QqV9ca"
      },
      "source": [
        "#Question 1 - Part 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "iF2ZkK35WId0",
        "outputId": "8186c125-41d9-4668-d7f9-d24d5b7ea5fa"
      },
      "source": [
        "pyplot.plot(d1_hist2, label='disc_real_loss')\n",
        "pyplot.plot(d2_hist2, label='disc_fake_loss')\n",
        "pyplot.plot(g_hist2, label='gen_loss')\n",
        "pyplot.legend()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fa88f04b250>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yz6qHEETcGC2"
      },
      "source": [
        "From the results we can see that after first 500 steps, the generator is not letting the discriminator win and viceversa. Both of their accuracies are increasing above 50 and then decreasing in the next steps such that both of them have the same losses.\n",
        "\n",
        "As we can see from the above figure, all three losses are converging smoothly and the model is thus stable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4dx6vEtayd2"
      },
      "source": [
        "#Question 1 - Part 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryr0wHwla6TL"
      },
      "source": [
        "def generate_samples(n):\n",
        "  x_input = generate_latent_points(latent_dim, n)\n",
        "\t# predict outputs\n",
        "  X = generator.predict(x_input)\n",
        "  # scale from [-1,1] to [0,1]\n",
        "  X = (X + 1) / 2.0\n",
        "  # plot images\n",
        "  for i in range(n):\n",
        "    # define subplot\n",
        "    pyplot.subplot(1,n,i+1)\n",
        "    # turn off axis\n",
        "    pyplot.axis('off')\n",
        "    # plot raw pixel data\n",
        "    backtorgb = cv2.cvtColor(X[i, :, :, :],cv2.COLOR_GRAY2RGB)\n",
        "    pyplot.imshow((backtorgb+1)/2)"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "onMJzgJzeFOD",
        "outputId": "688c5160-491c-4df4-da10-359ff14f080b"
      },
      "source": [
        "generate_samples(20)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 20 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "KywCbdPafm7s",
        "outputId": "c3690f69-8949-4795-e115-771f56153797"
      },
      "source": [
        "generate_samples(4)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "SeCsihL3eIUx",
        "outputId": "d866ea46-54df-4c9f-c965-3b4e36fd2a67"
      },
      "source": [
        "generate_samples(4)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "zX3W1frbeJ2p",
        "outputId": "f23e4b9e-c0b9-42e5-deda-3ebdbcc9f947"
      },
      "source": [
        "generate_samples(4)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "s51C_YYYeLjn",
        "outputId": "2cf25176-0a65-4945-e7cc-ce67d32ada79"
      },
      "source": [
        "generate_samples(4)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "PPYpifiIeNRX",
        "outputId": "1dc16d47-eb67-4b73-9d83-c6461fa1cd00"
      },
      "source": [
        "generate_samples(4)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmpQXIw8f-hp"
      },
      "source": [
        "The produced images show that the generator was not trained properly. \n",
        "\n",
        "You can also see this during the first 500 steps of the loss plot where generator loss increases significantly and then converges.\n",
        "\n",
        "If the GAN is run for more epochs, then the results may improve."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHGmiVSCeRkj"
      },
      "source": [
        "#Question 1 - Part 7 - Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agbpokQGiVwB"
      },
      "source": [
        "#Part a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ue0rdEfEidCC"
      },
      "source": [
        "Yes, we can use a pre-trained VGG-16 network for the above defined GAN.\n",
        "\n",
        "Yes, the resulting network would be a DCGAN and VGG-16 is DCNN.\n",
        "\n",
        "VGG-16 is used in classification and not upsampling or deconvolution, hence it cannot be used in generator, but it can be used in a discriminator which can classofy real or fake.\n",
        "\n",
        "The network architecture of the discriminator will have to be modified. \n",
        "\n",
        "VGG-16 model will be imported that has been pre-trained on ImageNet. All the layers will be imported except the last layer, instead a few fully connected dense layers will be connected on the output side, and only these layers will trained again on the Stanford Cars dataset. \n",
        "\n",
        "Earlier layers of the network usually extract minor features like edges and contrast differences which are present in all the images, and outer layers extract more prominent features like wheels, mirrors, headlights etc. Therefore only the newly added layers will need to be trained. \n",
        "\n",
        "This way the discriminator will be more efficient. The generator remains same.\n",
        "\n",
        "The number of networks in the overall architecture remain two."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zE6chabekBN3"
      },
      "source": [
        "#Part b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUi-ikEXkCGd"
      },
      "source": [
        "As elaborated in the above part VGG-16 is only suitable for the discriminator as it does not upsample/tranpose convolution/deconvolution but has convolutional layers and uses them to extract feautures and classify - which is the job of the discriminator.\n",
        "\n",
        "VGG-16 cannot be used as a generator because of its architecture. It inputs images and outputs numbers, while a generator should input numbers and output images. \n",
        "\n",
        "Reiterating, convolutional layers are used in VGG-16 which downsamples an image by extracting feature maps from them which is the opposite of a generator which takes a random number list from a gaussian distribution and upsamples it into an image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-aLZJdEl2Ab"
      },
      "source": [
        "#Part c - Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZcs8JxSq6li"
      },
      "source": [
        "Since VGG16 takes 3 channel inputs, we are proceeding with a 32x32x3 image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NiQb8DseZEG"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from keras.applications import vgg16 as vgg\n",
        "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D,BatchNormalization\n",
        "from keras import optimizers\n",
        "from keras.layers import LeakyReLU\n",
        "from keras import Model\n",
        "from os import makedirs\n",
        "from numpy import expand_dims\n",
        "from numpy import zeros\n",
        "from numpy import ones\n",
        "from numpy.random import randn\n",
        "from numpy.random import randint\n",
        "from keras.datasets.mnist import load_data\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.initializers import RandomNormal\n",
        "from matplotlib import pyplot\n",
        "from os import listdir\n",
        "from numpy import asarray\n",
        "from numpy import vstack\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import load_img\n",
        "from numpy import savez_compressed"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqTIwGxQr8aT"
      },
      "source": [
        "# load images\n",
        "def load_real_samples():\n",
        "  data = list()\n",
        "  # load dataset\n",
        "  for filename in os.listdir('/content/images_cars/cars_train/cars_train/'):\n",
        "    pixels = load_img('/content/images_cars/cars_train/cars_train/'+str(filename), target_size = (32,32))\n",
        "    pixels = img_to_array(pixels)\n",
        "    data.append(pixels)\n",
        "\n",
        "  X = asarray(data)\n",
        "  # convert from ints to floats\n",
        "  X = X.astype('float32')\n",
        "  # scale from [0,255] to [-1,1] to match the generator images\n",
        "  X = (X - 127.5) / 127.5\n",
        "  return X"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBDFfMSAtTFB",
        "outputId": "1fec5019-9fc2-49e4-eae8-4c5f78981c65"
      },
      "source": [
        "X = load_real_samples()\n",
        "print(X.shape)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8144, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "BjoOKTKesNpp",
        "outputId": "4d5dbe3e-3122-4f8f-8f78-42e1cca5bc47"
      },
      "source": [
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "\n",
        "print(X[0].shape) \n",
        "\n",
        "pyplot.imshow((X[0]+1)/2) "
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 32, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa88b96a210>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qT1xS8uvuSup"
      },
      "source": [
        "EPOCHS = 50 #same hyperparameters as before so we can compare results and the effect of VGG-16\n",
        "BATCH_SIZE = 128\n",
        "lr = 0.00012\n",
        "latent_dim = 100"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNojw9KbrLM4"
      },
      "source": [
        "#Defining the CNN based discriminator model\n",
        "def define_discriminator(in_shape=(32,32,3)):\n",
        "  # weight initialization\n",
        "  init = RandomNormal(stddev=0.02)\n",
        " \n",
        "\t#Importing VGG Network without Classifier Layer\n",
        "  base_model = vgg.VGG16(weights='imagenet', include_top=False, input_shape=in_shape)\n",
        "\n",
        "  # Extract the last layer from third block of vgg16 model\n",
        "  last = base_model.get_layer('block3_pool').output\n",
        "\n",
        "  # Add classification layers on top of it\n",
        "  x = BatchNormalization()(last)\n",
        "  x = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(x)\n",
        "  x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "  x = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(x)\n",
        "  x = LeakyReLU(alpha=0.2)(x)\n",
        "  x = Dropout(0.7)(x)\n",
        "  x = Flatten()(x)\n",
        "\n",
        "  pred = Dense(1, activation='sigmoid')(x)\n",
        "  model = Model(base_model.input, pred)\n",
        "\n",
        "  #Freezing the layers of VGG network to make them untrainable\n",
        "  for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "  model.compile(loss='binary_crossentropy', optimizer=optimizers.Adam(lr=0.00012, beta_1=0.5), metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "#Implementing the Generator network to accept 100x1 noise vector and output 64x64x3 image\n",
        "latent_dim = 100\n",
        "\n",
        "def define_generator(latent_dim):\n",
        "  # weight initialization\n",
        "  init = RandomNormal(stddev=0.02)\n",
        "  # define model\n",
        "  model = Sequential()\n",
        "  # foundation for 8x8 image\n",
        "  n_nodes = 128 * 8 * 8\n",
        "  model.add(Dense(n_nodes, kernel_initializer=init, input_dim=latent_dim))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "  model.add(Reshape((8, 8, 128)))\n",
        " \n",
        "  model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        " \n",
        "  model.add(Conv2DTranspose(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        " \n",
        "  # output 32x32x3\n",
        "  model.add(Conv2D(3, (5,5), activation='tanh', padding='same', kernel_initializer=init))\n",
        "  return model\n",
        "\n",
        "  # define the combined generator and discriminator model, for updating the generator\n",
        "def define_gan(generator, discriminator):\n",
        "\t# make weights in the discriminator not trainable\n",
        "\tdiscriminator.trainable = False\n",
        "\t# connect them\n",
        "\tmodel = Sequential()\n",
        "\t# add generator\n",
        "\tmodel.add(generator)\n",
        "\t# add the discriminator\n",
        "\tmodel.add(discriminator)\n",
        "\t# compile model\n",
        "\topt = Adam(lr=0.00012, beta_1=0.5)\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer=opt)\n",
        "\treturn model\n",
        "\n",
        "  # select real samples\n",
        "def generate_real_samples(dataset, n_samples):\n",
        "\t# choose random instances\n",
        "\tix = randint(0, dataset.shape[0], n_samples)\n",
        "\t# select images\n",
        "\tX = dataset[ix]\n",
        "\t# generate class labels\n",
        "\ty = ones((n_samples, 1))\n",
        "\treturn X, y\n",
        " \n",
        "# generate points in latent space as input for the generator\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "\t# generate points in the latent space\n",
        "\tx_input = randn(latent_dim * n_samples)\n",
        "\t# reshape into a batch of inputs for the network\n",
        "\tx_input = x_input.reshape(n_samples, latent_dim)\n",
        "\treturn x_input\n",
        " \n",
        "# use the generator to generate n fake examples, with class labels\n",
        "def generate_fake_samples(generator, latent_dim, n_samples):\n",
        "\t# generate points in latent space\n",
        "\tx_input = generate_latent_points(latent_dim, n_samples)\n",
        "\t# predict outputs\n",
        "\tX = generator.predict(x_input)\n",
        "\t# create class labels\n",
        "\ty = zeros((n_samples, 1))\n",
        "\treturn X, y\n",
        " \n",
        "# generate samples and save as a plot and save the model\n",
        "def summarize_performance(step, g_model, latent_dim, n_samples=16):\n",
        "\t# prepare fake examples\n",
        "\tX, _ = generate_fake_samples(g_model, latent_dim, n_samples)\n",
        "\t# scale from [-1,1] to [0,1]\n",
        "\tX = (X + 1) / 2.0\n",
        "\t# plot images\n",
        "\tfor i in range(4 * 4):\n",
        "\t\t# define subplot\n",
        "\t\tpyplot.subplot(4, 4, 1 + i)\n",
        "\t\t# turn off axis\n",
        "\t\tpyplot.axis('off')\n",
        "\t\t# plot raw pixel data\n",
        "\t\tpyplot.imshow(X[i, :, :, :])\n",
        "\t# save plot to file\n",
        "\tpyplot.savefig('results_baseline/generated_plot_%03d.png' % (step+1))\n",
        "\tpyplot.close()\n",
        "\t# save the generator model\n",
        "\tg_model.save('/content/drive/MyDrive/CV_Assignment_02/model_%03d.h5' % (step+1))\n",
        " \n",
        "# create a line plot of loss for the gan and save to file\n",
        "def plot_history(d1_hist, d2_hist, g_hist, a1_hist, a2_hist):\n",
        "\t# plot loss\n",
        "\tpyplot.subplot(2, 1, 1)\n",
        "\tpyplot.plot(d1_hist, label='d-real')\n",
        "\tpyplot.plot(d2_hist, label='d-fake')\n",
        "\tpyplot.plot(g_hist, label='gen')\n",
        "\tpyplot.legend()\n",
        "\t# plot discriminator accuracy\n",
        "\tpyplot.subplot(2, 1, 2)\n",
        "\tpyplot.plot(a1_hist, label='acc-real')\n",
        "\tpyplot.plot(a2_hist, label='acc-fake')\n",
        "\tpyplot.legend()\n",
        "\t# save plot to file\n",
        "\tpyplot.savefig('results_baseline/plot_line_plot_loss.png')\n",
        "\tpyplot.close()\n",
        " \n",
        "# train the generator and discriminator\n",
        "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=EPOCHS, n_batch=256):\n",
        "  # calculate the number of batches per epoch\n",
        "  bat_per_epo = int(dataset.shape[0] / n_batch)\n",
        "  # calculate the total iterations based on batch and epoch\n",
        "  n_steps = bat_per_epo * n_epochs\n",
        "  # calculate the number of samples in half a batch\n",
        "  half_batch = int(n_batch / 2)\n",
        "  # prepare lists for storing stats each iteration\n",
        "  d1_hist, d2_hist, g_hist, a1_hist, a2_hist = list(), list(), list(), list(), list()\n",
        "  # manually enumerate epochs\n",
        "  for i in range(n_steps):\n",
        "    # get randomly selected 'real' samples\n",
        "    X_real, y_real = generate_real_samples(dataset, half_batch)\n",
        "    # update discriminator model weights\n",
        "    d_loss1, d_acc1 = d_model.train_on_batch(X_real, y_real)\n",
        "    # generate 'fake' examples\n",
        "    X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
        "    # update discriminator model weights\n",
        "    d_loss2, d_acc2 = d_model.train_on_batch(X_fake, y_fake)\n",
        "    # prepare points in latent space as input for the generator\n",
        "    X_gan = generate_latent_points(latent_dim, n_batch)\n",
        "    # create inverted labels for the fake samples\n",
        "    y_gan = ones((n_batch, 1))\n",
        "    # update the generator via the discriminator's error\n",
        "    g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
        "    # summarize loss on this batch\n",
        "    print('>%d, d1=%.3f, d2=%.3f g=%.3f, a1=%d, a2=%d' %\n",
        "      (i+1, d_loss1, d_loss2, g_loss, int(100*d_acc1), int(100*d_acc2)))\n",
        "    # record history\n",
        "    d1_hist.append(d_loss1)\n",
        "    d2_hist.append(d_loss2)\n",
        "    g_hist.append(g_loss)\n",
        "    a1_hist.append(d_acc1)\n",
        "    a2_hist.append(d_acc2)\n",
        "    # evaluate the model performance every 'epoch'\n",
        "    if (i+1) % bat_per_epo == 0:\n",
        "      summarize_performance(i, g_model, latent_dim)\n",
        "  plot_history(d1_hist, d2_hist, g_hist, a1_hist, a2_hist)\n",
        "  return d1_hist, d2_hist, g_hist, a1_hist, a2_hist"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1n8L5Rcu2jg",
        "outputId": "559cb665-3a10-48c4-8651-9b90d4b1e281"
      },
      "source": [
        "# make folder for results\n",
        "makedirs('results_baseline', exist_ok=True)\n",
        "# size of the latent space\n",
        "latent_dim = 100\n",
        "# create the discriminator\n",
        "discriminator = define_discriminator()\n",
        "# create the generator\n",
        "generator = define_generator(latent_dim)\n",
        "# create the gan\n",
        "gan_model = define_gan(generator, discriminator)\n",
        "# load image data\n",
        "dataset = load_real_samples()\n",
        "print(dataset.shape)"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(8144, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5xUCktIwXZe",
        "outputId": "05106ec2-bdf0-4c4a-addf-dd9d7383315c"
      },
      "source": [
        "d1_hist3, d2_hist3, g_hist3, a1_hist3, a2_hist3 = train(generator, discriminator, gan_model, dataset, latent_dim)"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">1, d1=0.630, d2=0.726 g=0.517, a1=63, a2=43\n",
            ">2, d1=0.538, d2=0.528 g=0.589, a1=87, a2=86\n",
            ">3, d1=0.513, d2=0.426 g=0.633, a1=86, a2=96\n",
            ">4, d1=0.452, d2=0.339 g=0.667, a1=95, a2=100\n",
            ">5, d1=0.427, d2=0.286 g=0.699, a1=91, a2=98\n",
            ">6, d1=0.385, d2=0.230 g=0.789, a1=96, a2=99\n",
            ">7, d1=0.345, d2=0.215 g=0.777, a1=98, a2=100\n",
            ">8, d1=0.319, d2=0.220 g=0.803, a1=99, a2=98\n",
            ">9, d1=0.278, d2=0.206 g=0.819, a1=98, a2=100\n",
            ">10, d1=0.251, d2=0.178 g=0.822, a1=98, a2=99\n",
            ">11, d1=0.256, d2=0.158 g=0.886, a1=98, a2=99\n",
            ">12, d1=0.224, d2=0.120 g=0.888, a1=99, a2=100\n",
            ">13, d1=0.197, d2=0.170 g=0.897, a1=98, a2=99\n",
            ">14, d1=0.172, d2=0.165 g=0.945, a1=100, a2=100\n",
            ">15, d1=0.189, d2=0.159 g=0.886, a1=98, a2=100\n",
            ">16, d1=0.141, d2=0.170 g=0.980, a1=100, a2=99\n",
            ">17, d1=0.147, d2=0.139 g=1.235, a1=99, a2=100\n",
            ">18, d1=0.150, d2=0.106 g=1.311, a1=99, a2=100\n",
            ">19, d1=0.151, d2=0.087 g=1.364, a1=99, a2=99\n",
            ">20, d1=0.114, d2=0.096 g=1.412, a1=99, a2=100\n",
            ">21, d1=0.108, d2=0.084 g=1.470, a1=99, a2=100\n",
            ">22, d1=0.088, d2=0.077 g=1.452, a1=100, a2=100\n",
            ">23, d1=0.130, d2=0.101 g=1.345, a1=98, a2=100\n",
            ">24, d1=0.093, d2=0.113 g=1.336, a1=99, a2=100\n",
            ">25, d1=0.089, d2=0.092 g=1.367, a1=100, a2=100\n",
            ">26, d1=0.098, d2=0.087 g=1.328, a1=100, a2=100\n",
            ">27, d1=0.096, d2=0.074 g=1.344, a1=99, a2=100\n",
            ">28, d1=0.069, d2=0.070 g=1.418, a1=100, a2=100\n",
            ">29, d1=0.108, d2=0.064 g=1.288, a1=98, a2=100\n",
            ">30, d1=0.100, d2=0.070 g=1.296, a1=97, a2=100\n",
            ">31, d1=0.062, d2=0.057 g=1.473, a1=99, a2=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">32, d1=0.075, d2=0.049 g=1.507, a1=100, a2=100\n",
            ">33, d1=0.073, d2=0.054 g=1.414, a1=98, a2=100\n",
            ">34, d1=0.057, d2=0.059 g=1.677, a1=99, a2=100\n",
            ">35, d1=0.082, d2=0.055 g=1.581, a1=98, a2=100\n",
            ">36, d1=0.072, d2=0.066 g=1.497, a1=99, a2=100\n",
            ">37, d1=0.075, d2=0.063 g=1.590, a1=98, a2=100\n",
            ">38, d1=0.052, d2=0.107 g=1.630, a1=100, a2=100\n",
            ">39, d1=0.058, d2=0.157 g=1.811, a1=99, a2=96\n",
            ">40, d1=0.095, d2=0.165 g=1.835, a1=98, a2=95\n",
            ">41, d1=0.063, d2=0.212 g=1.728, a1=98, a2=92\n",
            ">42, d1=0.134, d2=0.205 g=1.665, a1=96, a2=94\n",
            ">43, d1=0.152, d2=0.252 g=1.832, a1=95, a2=89\n",
            ">44, d1=0.216, d2=0.267 g=1.745, a1=91, a2=90\n",
            ">45, d1=0.206, d2=0.311 g=1.880, a1=92, a2=88\n",
            ">46, d1=0.191, d2=0.217 g=1.761, a1=94, a2=92\n",
            ">47, d1=0.220, d2=0.161 g=1.602, a1=89, a2=96\n",
            ">48, d1=0.226, d2=0.264 g=1.471, a1=92, a2=92\n",
            ">49, d1=0.189, d2=0.264 g=1.510, a1=95, a2=92\n",
            ">50, d1=0.182, d2=0.217 g=1.652, a1=94, a2=95\n",
            ">51, d1=0.194, d2=0.190 g=1.683, a1=92, a2=96\n",
            ">52, d1=0.164, d2=0.157 g=1.793, a1=95, a2=96\n",
            ">53, d1=0.156, d2=0.196 g=1.812, a1=95, a2=96\n",
            ">54, d1=0.156, d2=0.245 g=2.196, a1=94, a2=92\n",
            ">55, d1=0.156, d2=0.206 g=2.234, a1=96, a2=94\n",
            ">56, d1=0.183, d2=0.223 g=2.456, a1=94, a2=94\n",
            ">57, d1=0.236, d2=0.186 g=2.527, a1=91, a2=96\n",
            ">58, d1=0.256, d2=0.164 g=2.429, a1=89, a2=96\n",
            ">59, d1=0.272, d2=0.194 g=2.516, a1=89, a2=95\n",
            ">60, d1=0.160, d2=0.168 g=2.397, a1=96, a2=96\n",
            ">61, d1=0.160, d2=0.103 g=1.895, a1=93, a2=98\n",
            ">62, d1=0.159, d2=0.098 g=1.632, a1=96, a2=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">63, d1=0.128, d2=0.076 g=1.388, a1=98, a2=99\n",
            ">64, d1=0.118, d2=0.077 g=1.377, a1=96, a2=100\n",
            ">65, d1=0.118, d2=0.124 g=1.487, a1=98, a2=98\n",
            ">66, d1=0.108, d2=0.151 g=1.677, a1=97, a2=99\n",
            ">67, d1=0.162, d2=0.132 g=1.978, a1=96, a2=96\n",
            ">68, d1=0.145, d2=0.115 g=2.209, a1=95, a2=98\n",
            ">69, d1=0.155, d2=0.202 g=2.506, a1=93, a2=94\n",
            ">70, d1=0.168, d2=0.141 g=2.770, a1=95, a2=99\n",
            ">71, d1=0.161, d2=0.218 g=2.813, a1=92, a2=90\n",
            ">72, d1=0.228, d2=0.205 g=2.760, a1=90, a2=95\n",
            ">73, d1=0.186, d2=0.109 g=2.516, a1=94, a2=98\n",
            ">74, d1=0.290, d2=0.184 g=2.513, a1=88, a2=93\n",
            ">75, d1=0.168, d2=0.166 g=2.375, a1=95, a2=96\n",
            ">76, d1=0.211, d2=0.151 g=2.366, a1=93, a2=94\n",
            ">77, d1=0.256, d2=0.149 g=2.049, a1=89, a2=96\n",
            ">78, d1=0.156, d2=0.153 g=1.782, a1=94, a2=96\n",
            ">79, d1=0.175, d2=0.152 g=1.657, a1=93, a2=95\n",
            ">80, d1=0.160, d2=0.128 g=1.792, a1=96, a2=96\n",
            ">81, d1=0.133, d2=0.101 g=1.646, a1=96, a2=98\n",
            ">82, d1=0.254, d2=0.173 g=1.650, a1=89, a2=93\n",
            ">83, d1=0.145, d2=0.117 g=1.479, a1=95, a2=97\n",
            ">84, d1=0.194, d2=0.160 g=1.567, a1=92, a2=96\n",
            ">85, d1=0.141, d2=0.114 g=1.354, a1=94, a2=99\n",
            ">86, d1=0.187, d2=0.082 g=1.243, a1=94, a2=99\n",
            ">87, d1=0.104, d2=0.083 g=1.005, a1=97, a2=98\n",
            ">88, d1=0.127, d2=0.061 g=0.772, a1=96, a2=100\n",
            ">89, d1=0.127, d2=0.071 g=0.663, a1=96, a2=99\n",
            ">90, d1=0.059, d2=0.092 g=0.700, a1=99, a2=99\n",
            ">91, d1=0.116, d2=0.090 g=0.743, a1=96, a2=100\n",
            ">92, d1=0.081, d2=0.095 g=0.774, a1=97, a2=98\n",
            ">93, d1=0.129, d2=0.087 g=0.762, a1=96, a2=99\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">94, d1=0.106, d2=0.084 g=0.803, a1=94, a2=98\n",
            ">95, d1=0.064, d2=0.092 g=0.913, a1=100, a2=99\n",
            ">96, d1=0.066, d2=0.129 g=0.995, a1=97, a2=96\n",
            ">97, d1=0.142, d2=0.094 g=1.172, a1=96, a2=100\n",
            ">98, d1=0.127, d2=0.102 g=1.228, a1=95, a2=99\n",
            ">99, d1=0.103, d2=0.100 g=1.294, a1=96, a2=100\n",
            ">100, d1=0.114, d2=0.125 g=1.161, a1=96, a2=96\n",
            ">101, d1=0.131, d2=0.088 g=1.178, a1=97, a2=99\n",
            ">102, d1=0.098, d2=0.101 g=1.198, a1=96, a2=97\n",
            ">103, d1=0.152, d2=0.095 g=0.968, a1=95, a2=99\n",
            ">104, d1=0.097, d2=0.194 g=1.294, a1=97, a2=92\n",
            ">105, d1=0.221, d2=0.103 g=1.152, a1=92, a2=99\n",
            ">106, d1=0.078, d2=0.076 g=1.291, a1=96, a2=100\n",
            ">107, d1=0.167, d2=0.089 g=0.919, a1=92, a2=98\n",
            ">108, d1=0.092, d2=0.085 g=0.987, a1=98, a2=99\n",
            ">109, d1=0.105, d2=0.144 g=1.009, a1=96, a2=96\n",
            ">110, d1=0.098, d2=0.097 g=0.980, a1=96, a2=98\n",
            ">111, d1=0.138, d2=0.103 g=0.979, a1=94, a2=98\n",
            ">112, d1=0.101, d2=0.090 g=0.986, a1=96, a2=99\n",
            ">113, d1=0.141, d2=0.124 g=1.006, a1=96, a2=96\n",
            ">114, d1=0.085, d2=0.104 g=1.129, a1=97, a2=98\n",
            ">115, d1=0.180, d2=0.100 g=1.181, a1=93, a2=97\n",
            ">116, d1=0.076, d2=0.082 g=1.214, a1=98, a2=99\n",
            ">117, d1=0.143, d2=0.114 g=1.245, a1=94, a2=96\n",
            ">118, d1=0.166, d2=0.078 g=1.316, a1=94, a2=100\n",
            ">119, d1=0.185, d2=0.092 g=1.068, a1=92, a2=97\n",
            ">120, d1=0.091, d2=0.078 g=0.969, a1=96, a2=99\n",
            ">121, d1=0.102, d2=0.070 g=0.931, a1=96, a2=100\n",
            ">122, d1=0.104, d2=0.096 g=0.923, a1=94, a2=97\n",
            ">123, d1=0.058, d2=0.070 g=1.001, a1=99, a2=100\n",
            ">124, d1=0.098, d2=0.069 g=1.085, a1=96, a2=99\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">125, d1=0.076, d2=0.054 g=0.909, a1=98, a2=100\n",
            ">126, d1=0.051, d2=0.062 g=1.076, a1=100, a2=100\n",
            ">127, d1=0.119, d2=0.055 g=0.839, a1=93, a2=100\n",
            ">128, d1=0.067, d2=0.061 g=0.747, a1=97, a2=99\n",
            ">129, d1=0.099, d2=0.068 g=0.809, a1=97, a2=99\n",
            ">130, d1=0.097, d2=0.056 g=0.798, a1=96, a2=98\n",
            ">131, d1=0.081, d2=0.034 g=0.690, a1=97, a2=100\n",
            ">132, d1=0.121, d2=0.063 g=0.576, a1=94, a2=98\n",
            ">133, d1=0.046, d2=0.040 g=0.586, a1=99, a2=100\n",
            ">134, d1=0.097, d2=0.066 g=0.665, a1=98, a2=99\n",
            ">135, d1=0.100, d2=0.047 g=0.567, a1=96, a2=100\n",
            ">136, d1=0.077, d2=0.036 g=0.539, a1=97, a2=100\n",
            ">137, d1=0.052, d2=0.056 g=0.563, a1=98, a2=100\n",
            ">138, d1=0.054, d2=0.038 g=0.466, a1=99, a2=100\n",
            ">139, d1=0.128, d2=0.034 g=0.353, a1=96, a2=100\n",
            ">140, d1=0.036, d2=0.039 g=0.427, a1=99, a2=99\n",
            ">141, d1=0.039, d2=0.032 g=0.361, a1=98, a2=100\n",
            ">142, d1=0.034, d2=0.024 g=0.327, a1=99, a2=100\n",
            ">143, d1=0.033, d2=0.031 g=0.352, a1=100, a2=100\n",
            ">144, d1=0.053, d2=0.052 g=0.353, a1=98, a2=98\n",
            ">145, d1=0.057, d2=0.048 g=0.339, a1=98, a2=99\n",
            ">146, d1=0.041, d2=0.031 g=0.378, a1=100, a2=99\n",
            ">147, d1=0.055, d2=0.034 g=0.359, a1=97, a2=100\n",
            ">148, d1=0.065, d2=0.028 g=0.308, a1=96, a2=100\n",
            ">149, d1=0.046, d2=0.031 g=0.236, a1=99, a2=100\n",
            ">150, d1=0.034, d2=0.034 g=0.293, a1=100, a2=100\n",
            ">151, d1=0.039, d2=0.033 g=0.318, a1=100, a2=100\n",
            ">152, d1=0.026, d2=0.027 g=0.273, a1=100, a2=100\n",
            ">153, d1=0.036, d2=0.039 g=0.364, a1=100, a2=100\n",
            ">154, d1=0.037, d2=0.034 g=0.311, a1=99, a2=100\n",
            ">155, d1=0.036, d2=0.022 g=0.346, a1=98, a2=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">156, d1=0.046, d2=0.022 g=0.284, a1=100, a2=100\n",
            ">157, d1=0.028, d2=0.020 g=0.265, a1=100, a2=100\n",
            ">158, d1=0.051, d2=0.024 g=0.288, a1=99, a2=100\n",
            ">159, d1=0.042, d2=0.025 g=0.223, a1=100, a2=100\n",
            ">160, d1=0.029, d2=0.021 g=0.178, a1=99, a2=100\n",
            ">161, d1=0.044, d2=0.019 g=0.207, a1=98, a2=100\n",
            ">162, d1=0.021, d2=0.018 g=0.225, a1=100, a2=100\n",
            ">163, d1=0.019, d2=0.017 g=0.211, a1=100, a2=100\n",
            ">164, d1=0.031, d2=0.015 g=0.193, a1=100, a2=100\n",
            ">165, d1=0.017, d2=0.013 g=0.230, a1=100, a2=100\n",
            ">166, d1=0.057, d2=0.014 g=0.145, a1=97, a2=100\n",
            ">167, d1=0.016, d2=0.026 g=0.145, a1=100, a2=100\n",
            ">168, d1=0.035, d2=0.012 g=0.128, a1=99, a2=100\n",
            ">169, d1=0.018, d2=0.011 g=0.130, a1=100, a2=100\n",
            ">170, d1=0.018, d2=0.015 g=0.161, a1=100, a2=100\n",
            ">171, d1=0.011, d2=0.012 g=0.142, a1=100, a2=100\n",
            ">172, d1=0.018, d2=0.010 g=0.161, a1=100, a2=100\n",
            ">173, d1=0.011, d2=0.008 g=0.161, a1=100, a2=100\n",
            ">174, d1=0.023, d2=0.012 g=0.149, a1=99, a2=100\n",
            ">175, d1=0.016, d2=0.012 g=0.137, a1=100, a2=100\n",
            ">176, d1=0.017, d2=0.010 g=0.123, a1=100, a2=100\n",
            ">177, d1=0.052, d2=0.010 g=0.122, a1=98, a2=100\n",
            ">178, d1=0.010, d2=0.010 g=0.076, a1=100, a2=100\n",
            ">179, d1=0.010, d2=0.009 g=0.117, a1=100, a2=100\n",
            ">180, d1=0.017, d2=0.011 g=0.116, a1=100, a2=100\n",
            ">181, d1=0.010, d2=0.013 g=0.125, a1=100, a2=100\n",
            ">182, d1=0.022, d2=0.010 g=0.129, a1=100, a2=100\n",
            ">183, d1=0.013, d2=0.008 g=0.097, a1=99, a2=100\n",
            ">184, d1=0.015, d2=0.006 g=0.096, a1=100, a2=100\n",
            ">185, d1=0.010, d2=0.007 g=0.116, a1=100, a2=100\n",
            ">186, d1=0.012, d2=0.008 g=0.095, a1=100, a2=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">187, d1=0.011, d2=0.009 g=0.115, a1=100, a2=100\n",
            ">188, d1=0.019, d2=0.008 g=0.085, a1=99, a2=100\n",
            ">189, d1=0.013, d2=0.010 g=0.090, a1=100, a2=100\n",
            ">190, d1=0.008, d2=0.008 g=0.105, a1=100, a2=100\n",
            ">191, d1=0.014, d2=0.004 g=0.084, a1=100, a2=100\n",
            ">192, d1=0.008, d2=0.007 g=0.090, a1=100, a2=100\n",
            ">193, d1=0.013, d2=0.005 g=0.094, a1=100, a2=100\n",
            ">194, d1=0.007, d2=0.006 g=0.092, a1=100, a2=100\n",
            ">195, d1=0.024, d2=0.011 g=0.086, a1=99, a2=100\n",
            ">196, d1=0.013, d2=0.005 g=0.098, a1=100, a2=100\n",
            ">197, d1=0.005, d2=0.006 g=0.107, a1=100, a2=100\n",
            ">198, d1=0.004, d2=0.005 g=0.075, a1=100, a2=100\n",
            ">199, d1=0.012, d2=0.004 g=0.081, a1=100, a2=100\n",
            ">200, d1=0.010, d2=0.006 g=0.082, a1=100, a2=100\n",
            ">201, d1=0.010, d2=0.005 g=0.094, a1=100, a2=100\n",
            ">202, d1=0.006, d2=0.009 g=0.115, a1=100, a2=100\n",
            ">203, d1=0.013, d2=0.003 g=0.098, a1=100, a2=100\n",
            ">204, d1=0.004, d2=0.007 g=0.090, a1=100, a2=100\n",
            ">205, d1=0.012, d2=0.003 g=0.108, a1=100, a2=100\n",
            ">206, d1=0.010, d2=0.004 g=0.086, a1=100, a2=100\n",
            ">207, d1=0.010, d2=0.005 g=0.081, a1=100, a2=100\n",
            ">208, d1=0.006, d2=0.003 g=0.094, a1=100, a2=100\n",
            ">209, d1=0.004, d2=0.004 g=0.088, a1=100, a2=100\n",
            ">210, d1=0.009, d2=0.003 g=0.089, a1=100, a2=100\n",
            ">211, d1=0.007, d2=0.003 g=0.072, a1=100, a2=100\n",
            ">212, d1=0.009, d2=0.004 g=0.065, a1=100, a2=100\n",
            ">213, d1=0.005, d2=0.004 g=0.103, a1=100, a2=100\n",
            ">214, d1=0.007, d2=0.004 g=0.099, a1=100, a2=100\n",
            ">215, d1=0.008, d2=0.003 g=0.084, a1=100, a2=100\n",
            ">216, d1=0.006, d2=0.003 g=0.088, a1=100, a2=100\n",
            ">217, d1=0.003, d2=0.004 g=0.074, a1=100, a2=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">218, d1=0.006, d2=0.004 g=0.080, a1=100, a2=100\n",
            ">219, d1=0.003, d2=0.003 g=0.097, a1=100, a2=100\n",
            ">220, d1=0.005, d2=0.003 g=0.082, a1=100, a2=100\n",
            ">221, d1=0.009, d2=0.004 g=0.088, a1=100, a2=100\n",
            ">222, d1=0.015, d2=0.010 g=0.079, a1=99, a2=100\n",
            ">223, d1=0.008, d2=0.005 g=0.092, a1=100, a2=100\n",
            ">224, d1=0.006, d2=0.005 g=0.071, a1=100, a2=100\n",
            ">225, d1=0.006, d2=0.005 g=0.071, a1=100, a2=100\n",
            ">226, d1=0.005, d2=0.003 g=0.075, a1=100, a2=100\n",
            ">227, d1=0.004, d2=0.003 g=0.076, a1=100, a2=100\n",
            ">228, d1=0.003, d2=0.004 g=0.073, a1=100, a2=100\n",
            ">229, d1=0.006, d2=0.003 g=0.100, a1=100, a2=100\n",
            ">230, d1=0.005, d2=0.005 g=0.080, a1=100, a2=100\n",
            ">231, d1=0.004, d2=0.005 g=0.096, a1=100, a2=100\n",
            ">232, d1=0.006, d2=0.004 g=0.095, a1=100, a2=100\n",
            ">233, d1=0.005, d2=0.003 g=0.107, a1=100, a2=100\n",
            ">234, d1=0.004, d2=0.002 g=0.082, a1=100, a2=100\n",
            ">235, d1=0.005, d2=0.004 g=0.067, a1=100, a2=100\n",
            ">236, d1=0.009, d2=0.002 g=0.077, a1=100, a2=100\n",
            ">237, d1=0.007, d2=0.005 g=0.091, a1=100, a2=100\n",
            ">238, d1=0.005, d2=0.005 g=0.073, a1=100, a2=100\n",
            ">239, d1=0.008, d2=0.003 g=0.057, a1=100, a2=100\n",
            ">240, d1=0.005, d2=0.005 g=0.069, a1=100, a2=100\n",
            ">241, d1=0.006, d2=0.004 g=0.084, a1=100, a2=100\n",
            ">242, d1=0.013, d2=0.003 g=0.067, a1=99, a2=100\n",
            ">243, d1=0.007, d2=0.004 g=0.078, a1=100, a2=100\n",
            ">244, d1=0.005, d2=0.003 g=0.063, a1=100, a2=100\n",
            ">245, d1=0.004, d2=0.005 g=0.069, a1=100, a2=100\n",
            ">246, d1=0.002, d2=0.003 g=0.069, a1=100, a2=100\n",
            ">247, d1=0.005, d2=0.004 g=0.063, a1=100, a2=100\n",
            ">248, d1=0.010, d2=0.004 g=0.061, a1=100, a2=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">249, d1=0.006, d2=0.003 g=0.058, a1=100, a2=100\n",
            ">250, d1=0.002, d2=0.003 g=0.054, a1=100, a2=100\n",
            ">251, d1=0.004, d2=0.005 g=0.056, a1=100, a2=100\n",
            ">252, d1=0.005, d2=0.004 g=0.056, a1=100, a2=100\n",
            ">253, d1=0.007, d2=0.002 g=0.057, a1=100, a2=100\n",
            ">254, d1=0.002, d2=0.003 g=0.075, a1=100, a2=100\n",
            ">255, d1=0.002, d2=0.004 g=0.056, a1=100, a2=100\n",
            ">256, d1=0.002, d2=0.003 g=0.052, a1=100, a2=100\n",
            ">257, d1=0.003, d2=0.004 g=0.064, a1=100, a2=100\n",
            ">258, d1=0.002, d2=0.005 g=0.074, a1=100, a2=100\n",
            ">259, d1=0.003, d2=0.006 g=0.084, a1=100, a2=100\n",
            ">260, d1=0.009, d2=0.005 g=0.069, a1=100, a2=100\n",
            ">261, d1=0.004, d2=0.002 g=0.073, a1=100, a2=100\n",
            ">262, d1=0.002, d2=0.002 g=0.066, a1=100, a2=100\n",
            ">263, d1=0.004, d2=0.002 g=0.050, a1=100, a2=100\n",
            ">264, d1=0.002, d2=0.004 g=0.065, a1=100, a2=100\n",
            ">265, d1=0.006, d2=0.002 g=0.073, a1=100, a2=100\n",
            ">266, d1=0.003, d2=0.004 g=0.078, a1=100, a2=100\n",
            ">267, d1=0.005, d2=0.006 g=0.064, a1=100, a2=100\n",
            ">268, d1=0.003, d2=0.004 g=0.062, a1=100, a2=100\n",
            ">269, d1=0.003, d2=0.003 g=0.079, a1=100, a2=100\n",
            ">270, d1=0.003, d2=0.002 g=0.072, a1=100, a2=100\n",
            ">271, d1=0.005, d2=0.003 g=0.059, a1=100, a2=100\n",
            ">272, d1=0.012, d2=0.004 g=0.068, a1=99, a2=100\n",
            ">273, d1=0.004, d2=0.002 g=0.046, a1=100, a2=100\n",
            ">274, d1=0.003, d2=0.002 g=0.063, a1=100, a2=100\n",
            ">275, d1=0.003, d2=0.002 g=0.051, a1=100, a2=100\n",
            ">276, d1=0.008, d2=0.004 g=0.062, a1=100, a2=100\n",
            ">277, d1=0.003, d2=0.005 g=0.064, a1=100, a2=100\n",
            ">278, d1=0.003, d2=0.004 g=0.062, a1=100, a2=100\n",
            ">279, d1=0.003, d2=0.002 g=0.063, a1=100, a2=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">280, d1=0.002, d2=0.003 g=0.071, a1=100, a2=100\n",
            ">281, d1=0.006, d2=0.005 g=0.049, a1=100, a2=100\n",
            ">282, d1=0.003, d2=0.003 g=0.052, a1=100, a2=100\n",
            ">283, d1=0.002, d2=0.004 g=0.056, a1=100, a2=100\n",
            ">284, d1=0.002, d2=0.002 g=0.056, a1=100, a2=100\n",
            ">285, d1=0.004, d2=0.005 g=0.076, a1=100, a2=100\n",
            ">286, d1=0.003, d2=0.002 g=0.061, a1=100, a2=100\n",
            ">287, d1=0.002, d2=0.002 g=0.047, a1=100, a2=100\n",
            ">288, d1=0.010, d2=0.002 g=0.055, a1=100, a2=100\n",
            ">289, d1=0.002, d2=0.003 g=0.048, a1=100, a2=100\n",
            ">290, d1=0.005, d2=0.006 g=0.042, a1=100, a2=100\n",
            ">291, d1=0.003, d2=0.003 g=0.054, a1=100, a2=100\n",
            ">292, d1=0.002, d2=0.002 g=0.071, a1=100, a2=100\n",
            ">293, d1=0.005, d2=0.002 g=0.047, a1=100, a2=100\n",
            ">294, d1=0.002, d2=0.002 g=0.051, a1=100, a2=100\n",
            ">295, d1=0.003, d2=0.006 g=0.048, a1=100, a2=100\n",
            ">296, d1=0.003, d2=0.002 g=0.050, a1=100, a2=100\n",
            ">297, d1=0.003, d2=0.002 g=0.048, a1=100, a2=100\n",
            ">298, d1=0.003, d2=0.002 g=0.065, a1=100, a2=100\n",
            ">299, d1=0.003, d2=0.003 g=0.048, a1=100, a2=100\n",
            ">300, d1=0.003, d2=0.002 g=0.058, a1=100, a2=100\n",
            ">301, d1=0.003, d2=0.003 g=0.047, a1=100, a2=100\n",
            ">302, d1=0.009, d2=0.002 g=0.056, a1=99, a2=100\n",
            ">303, d1=0.004, d2=0.005 g=0.061, a1=100, a2=100\n",
            ">304, d1=0.010, d2=0.003 g=0.036, a1=100, a2=100\n",
            ">305, d1=0.001, d2=0.003 g=0.034, a1=100, a2=100\n",
            ">306, d1=0.003, d2=0.002 g=0.044, a1=100, a2=100\n",
            ">307, d1=0.002, d2=0.003 g=0.041, a1=100, a2=100\n",
            ">308, d1=0.001, d2=0.003 g=0.036, a1=100, a2=100\n",
            ">309, d1=0.002, d2=0.003 g=0.055, a1=100, a2=100\n",
            ">310, d1=0.003, d2=0.001 g=0.045, a1=100, a2=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">311, d1=0.002, d2=0.001 g=0.056, a1=100, a2=100\n",
            ">312, d1=0.002, d2=0.001 g=0.053, a1=100, a2=100\n",
            ">313, d1=0.003, d2=0.002 g=0.050, a1=100, a2=100\n",
            ">314, d1=0.002, d2=0.001 g=0.039, a1=100, a2=100\n",
            ">315, d1=0.002, d2=0.002 g=0.048, a1=100, a2=100\n",
            ">316, d1=0.008, d2=0.002 g=0.044, a1=100, a2=100\n",
            ">317, d1=0.002, d2=0.003 g=0.048, a1=100, a2=100\n",
            ">318, d1=0.002, d2=0.002 g=0.048, a1=100, a2=100\n",
            ">319, d1=0.004, d2=0.003 g=0.038, a1=100, a2=100\n",
            ">320, d1=0.001, d2=0.004 g=0.047, a1=100, a2=100\n",
            ">321, d1=0.002, d2=0.002 g=0.043, a1=100, a2=100\n",
            ">322, d1=0.002, d2=0.004 g=0.048, a1=100, a2=100\n",
            ">323, d1=0.005, d2=0.002 g=0.043, a1=100, a2=100\n",
            ">324, d1=0.002, d2=0.002 g=0.070, a1=100, a2=100\n",
            ">325, d1=0.001, d2=0.002 g=0.048, a1=100, a2=100\n",
            ">326, d1=0.004, d2=0.002 g=0.046, a1=100, a2=100\n",
            ">327, d1=0.001, d2=0.002 g=0.041, a1=100, a2=100\n",
            ">328, d1=0.003, d2=0.002 g=0.055, a1=100, a2=100\n",
            ">329, d1=0.003, d2=0.002 g=0.043, a1=100, a2=100\n",
            ">330, d1=0.002, d2=0.002 g=0.054, a1=100, a2=100\n",
            ">331, d1=0.002, d2=0.002 g=0.038, a1=100, a2=100\n",
            ">332, d1=0.003, d2=0.002 g=0.039, a1=100, a2=100\n",
            ">333, d1=0.001, d2=0.002 g=0.044, a1=100, a2=100\n",
            ">334, d1=0.002, d2=0.004 g=0.052, a1=100, a2=100\n",
            ">335, d1=0.006, d2=0.001 g=0.050, a1=100, a2=100\n",
            ">336, d1=0.002, d2=0.002 g=0.055, a1=100, a2=100\n",
            ">337, d1=0.003, d2=0.002 g=0.042, a1=100, a2=100\n",
            ">338, d1=0.002, d2=0.001 g=0.043, a1=100, a2=100\n",
            ">339, d1=0.002, d2=0.001 g=0.045, a1=100, a2=100\n",
            ">340, d1=0.004, d2=0.001 g=0.056, a1=100, a2=100\n",
            ">341, d1=0.002, d2=0.003 g=0.038, a1=100, a2=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">342, d1=0.002, d2=0.004 g=0.046, a1=100, a2=100\n",
            ">343, d1=0.002, d2=0.002 g=0.051, a1=100, a2=100\n",
            ">344, d1=0.001, d2=0.001 g=0.047, a1=100, a2=100\n",
            ">345, d1=0.003, d2=0.001 g=0.041, a1=100, a2=100\n",
            ">346, d1=0.001, d2=0.002 g=0.042, a1=100, a2=100\n",
            ">347, d1=0.001, d2=0.002 g=0.036, a1=100, a2=100\n",
            ">348, d1=0.005, d2=0.002 g=0.036, a1=100, a2=100\n",
            ">349, d1=0.002, d2=0.001 g=0.036, a1=100, a2=100\n",
            ">350, d1=0.002, d2=0.002 g=0.046, a1=100, a2=100\n",
            ">351, d1=0.003, d2=0.002 g=0.040, a1=100, a2=100\n",
            ">352, d1=0.002, d2=0.002 g=0.034, a1=100, a2=100\n",
            ">353, d1=0.002, d2=0.002 g=0.038, a1=100, a2=100\n",
            ">354, d1=0.001, d2=0.002 g=0.051, a1=100, a2=100\n",
            ">355, d1=0.003, d2=0.001 g=0.049, a1=100, a2=100\n",
            ">356, d1=0.002, d2=0.001 g=0.040, a1=100, a2=100\n",
            ">357, d1=0.001, d2=0.002 g=0.036, a1=100, a2=100\n",
            ">358, d1=0.002, d2=0.002 g=0.052, a1=100, a2=100\n",
            ">359, d1=0.001, d2=0.002 g=0.035, a1=100, a2=100\n",
            ">360, d1=0.002, d2=0.003 g=0.043, a1=100, a2=100\n",
            ">361, d1=0.002, d2=0.002 g=0.043, a1=100, a2=100\n",
            ">362, d1=0.002, d2=0.002 g=0.049, a1=100, a2=100\n",
            ">363, d1=0.003, d2=0.002 g=0.036, a1=100, a2=100\n",
            ">364, d1=0.002, d2=0.002 g=0.041, a1=100, a2=100\n",
            ">365, d1=0.001, d2=0.001 g=0.041, a1=100, a2=100\n",
            ">366, d1=0.002, d2=0.004 g=0.047, a1=100, a2=100\n",
            ">367, d1=0.002, d2=0.002 g=0.034, a1=100, a2=100\n",
            ">368, d1=0.004, d2=0.002 g=0.050, a1=100, a2=100\n",
            ">369, d1=0.003, d2=0.001 g=0.053, a1=100, a2=100\n",
            ">370, d1=0.003, d2=0.001 g=0.040, a1=100, a2=100\n",
            ">371, d1=0.001, d2=0.002 g=0.043, a1=100, a2=100\n",
            ">372, d1=0.001, d2=0.002 g=0.051, a1=100, a2=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">373, d1=0.002, d2=0.002 g=0.040, a1=100, a2=100\n",
            ">374, d1=0.002, d2=0.001 g=0.030, a1=100, a2=100\n",
            ">375, d1=0.001, d2=0.002 g=0.045, a1=100, a2=100\n",
            ">376, d1=0.001, d2=0.002 g=0.037, a1=100, a2=100\n",
            ">377, d1=0.001, d2=0.003 g=0.038, a1=100, a2=100\n",
            ">378, d1=0.003, d2=0.001 g=0.053, a1=100, a2=100\n",
            ">379, d1=0.002, d2=0.002 g=0.034, a1=100, a2=100\n",
            ">380, d1=0.001, d2=0.002 g=0.044, a1=100, a2=100\n",
            ">381, d1=0.001, d2=0.003 g=0.044, a1=100, a2=100\n",
            ">382, d1=0.001, d2=0.001 g=0.061, a1=100, a2=100\n",
            ">383, d1=0.001, d2=0.002 g=0.037, a1=100, a2=100\n",
            ">384, d1=0.006, d2=0.003 g=0.040, a1=100, a2=100\n",
            ">385, d1=0.002, d2=0.001 g=0.039, a1=100, a2=100\n",
            ">386, d1=0.001, d2=0.001 g=0.037, a1=100, a2=100\n",
            ">387, d1=0.002, d2=0.001 g=0.055, a1=100, a2=100\n",
            ">388, d1=0.002, d2=0.001 g=0.055, a1=100, a2=100\n",
            ">389, d1=0.001, d2=0.001 g=0.047, a1=100, a2=100\n",
            ">390, d1=0.001, d2=0.001 g=0.036, a1=100, a2=100\n",
            ">391, d1=0.004, d2=0.002 g=0.046, a1=100, a2=100\n",
            ">392, d1=0.002, d2=0.002 g=0.049, a1=100, a2=100\n",
            ">393, d1=0.003, d2=0.001 g=0.030, a1=100, a2=100\n",
            ">394, d1=0.005, d2=0.002 g=0.053, a1=100, a2=100\n",
            ">395, d1=0.002, d2=0.005 g=0.043, a1=100, a2=100\n",
            ">396, d1=0.001, d2=0.002 g=0.042, a1=100, a2=100\n",
            ">397, d1=0.005, d2=0.002 g=0.034, a1=100, a2=100\n",
            ">398, d1=0.002, d2=0.001 g=0.062, a1=100, a2=100\n",
            ">399, d1=0.001, d2=0.001 g=0.045, a1=100, a2=100\n",
            ">400, d1=0.001, d2=0.001 g=0.038, a1=100, a2=100\n",
            ">401, d1=0.002, d2=0.002 g=0.037, a1=100, a2=100\n",
            ">402, d1=0.001, d2=0.001 g=0.031, a1=100, a2=100\n",
            ">403, d1=0.001, d2=0.001 g=0.041, a1=100, a2=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">404, d1=0.003, d2=0.001 g=0.032, a1=100, a2=100\n",
            ">405, d1=0.000, d2=0.001 g=0.038, a1=100, a2=100\n",
            ">406, d1=0.001, d2=0.001 g=0.045, a1=100, a2=100\n",
            ">407, d1=0.003, d2=0.002 g=0.044, a1=100, a2=100\n",
            ">408, d1=0.002, d2=0.001 g=0.047, a1=100, a2=100\n",
            ">409, d1=0.001, d2=0.001 g=0.030, a1=100, a2=100\n",
            ">410, d1=0.003, d2=0.001 g=0.030, a1=100, a2=100\n",
            ">411, d1=0.001, d2=0.001 g=0.046, a1=100, a2=100\n",
            ">412, d1=0.001, d2=0.001 g=0.031, a1=100, a2=100\n",
            ">413, d1=0.002, d2=0.002 g=0.035, a1=100, a2=100\n",
            ">414, d1=0.002, d2=0.002 g=0.032, a1=100, a2=100\n",
            ">415, d1=0.002, d2=0.001 g=0.037, a1=100, a2=100\n",
            ">416, d1=0.001, d2=0.001 g=0.038, a1=100, a2=100\n",
            ">417, d1=0.001, d2=0.002 g=0.037, a1=100, a2=100\n",
            ">418, d1=0.003, d2=0.002 g=0.032, a1=100, a2=100\n",
            ">419, d1=0.001, d2=0.003 g=0.037, a1=100, a2=100\n",
            ">420, d1=0.004, d2=0.001 g=0.045, a1=100, a2=100\n",
            ">421, d1=0.004, d2=0.001 g=0.027, a1=100, a2=100\n",
            ">422, d1=0.001, d2=0.001 g=0.037, a1=100, a2=100\n",
            ">423, d1=0.002, d2=0.002 g=0.029, a1=100, a2=100\n",
            ">424, d1=0.001, d2=0.001 g=0.031, a1=100, a2=100\n",
            ">425, d1=0.001, d2=0.002 g=0.036, a1=100, a2=100\n",
            ">426, d1=0.001, d2=0.001 g=0.030, a1=100, a2=100\n",
            ">427, d1=0.001, d2=0.001 g=0.039, a1=100, a2=100\n",
            ">428, d1=0.001, d2=0.002 g=0.038, a1=100, a2=100\n",
            ">429, d1=0.002, d2=0.001 g=0.033, a1=100, a2=100\n",
            ">430, d1=0.001, d2=0.002 g=0.028, a1=100, a2=100\n",
            ">431, d1=0.001, d2=0.001 g=0.027, a1=100, a2=100\n",
            ">432, d1=0.001, d2=0.001 g=0.023, a1=100, a2=100\n",
            ">433, d1=0.001, d2=0.002 g=0.035, a1=100, a2=100\n",
            ">434, d1=0.000, d2=0.001 g=0.032, a1=100, a2=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">435, d1=0.002, d2=0.002 g=0.040, a1=100, a2=100\n",
            ">436, d1=0.002, d2=0.003 g=0.043, a1=100, a2=100\n",
            ">437, d1=0.001, d2=0.001 g=0.032, a1=100, a2=100\n",
            ">438, d1=0.001, d2=0.002 g=0.031, a1=100, a2=100\n",
            ">439, d1=0.002, d2=0.002 g=0.039, a1=100, a2=100\n",
            ">440, d1=0.001, d2=0.001 g=0.033, a1=100, a2=100\n",
            ">441, d1=0.003, d2=0.001 g=0.052, a1=100, a2=100\n",
            ">442, d1=0.001, d2=0.001 g=0.037, a1=100, a2=100\n",
            ">443, d1=0.001, d2=0.002 g=0.041, a1=100, a2=100\n",
            ">444, d1=0.003, d2=0.001 g=0.040, a1=100, a2=100\n",
            ">445, d1=0.001, d2=0.001 g=0.034, a1=100, a2=100\n",
            ">446, d1=0.002, d2=0.002 g=0.043, a1=100, a2=100\n",
            ">447, d1=0.000, d2=0.002 g=0.040, a1=100, a2=100\n",
            ">448, d1=0.005, d2=0.003 g=0.032, a1=100, a2=100\n",
            ">449, d1=0.001, d2=0.001 g=0.030, a1=100, a2=100\n",
            ">450, d1=0.001, d2=0.001 g=0.029, a1=100, a2=100\n",
            ">451, d1=0.002, d2=0.001 g=0.031, a1=100, a2=100\n",
            ">452, d1=0.001, d2=0.001 g=0.038, a1=100, a2=100\n",
            ">453, d1=0.001, d2=0.001 g=0.028, a1=100, a2=100\n",
            ">454, d1=0.002, d2=0.001 g=0.027, a1=100, a2=100\n",
            ">455, d1=0.001, d2=0.001 g=0.025, a1=100, a2=100\n",
            ">456, d1=0.000, d2=0.002 g=0.033, a1=100, a2=100\n",
            ">457, d1=0.004, d2=0.001 g=0.032, a1=100, a2=100\n",
            ">458, d1=0.001, d2=0.001 g=0.027, a1=100, a2=100\n",
            ">459, d1=0.001, d2=0.001 g=0.018, a1=100, a2=100\n",
            ">460, d1=0.002, d2=0.002 g=0.026, a1=100, a2=100\n",
            ">461, d1=0.001, d2=0.003 g=0.028, a1=100, a2=100\n",
            ">462, d1=0.001, d2=0.002 g=0.033, a1=100, a2=100\n",
            ">463, d1=0.001, d2=0.001 g=0.024, a1=100, a2=100\n",
            ">464, d1=0.001, d2=0.002 g=0.033, a1=100, a2=100\n",
            ">465, d1=0.001, d2=0.001 g=0.029, a1=100, a2=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">466, d1=0.001, d2=0.002 g=0.050, a1=100, a2=100\n",
            ">467, d1=0.001, d2=0.001 g=0.031, a1=100, a2=100\n",
            ">468, d1=0.001, d2=0.001 g=0.029, a1=100, a2=100\n",
            ">469, d1=0.000, d2=0.001 g=0.019, a1=100, a2=100\n",
            ">470, d1=0.001, d2=0.001 g=0.029, a1=100, a2=100\n",
            ">471, d1=0.002, d2=0.001 g=0.030, a1=100, a2=100\n",
            ">472, d1=0.002, d2=0.001 g=0.033, a1=100, a2=100\n",
            ">473, d1=0.001, d2=0.002 g=0.025, a1=100, a2=100\n",
            ">474, d1=0.001, d2=0.002 g=0.035, a1=100, a2=100\n",
            ">475, d1=0.001, d2=0.001 g=0.034, a1=100, a2=100\n",
            ">476, d1=0.001, d2=0.001 g=0.027, a1=100, a2=100\n",
            ">477, d1=0.001, d2=0.001 g=0.042, a1=100, a2=100\n",
            ">478, d1=0.001, d2=0.002 g=0.019, a1=100, a2=100\n",
            ">479, d1=0.002, d2=0.002 g=0.034, a1=100, a2=100\n",
            ">480, d1=0.002, d2=0.003 g=0.024, a1=100, a2=100\n",
            ">481, d1=0.001, d2=0.001 g=0.037, a1=100, a2=100\n",
            ">482, d1=0.001, d2=0.001 g=0.038, a1=100, a2=100\n",
            ">483, d1=0.001, d2=0.002 g=0.039, a1=100, a2=100\n",
            ">484, d1=0.001, d2=0.001 g=0.025, a1=100, a2=100\n",
            ">485, d1=0.002, d2=0.001 g=0.037, a1=100, a2=100\n",
            ">486, d1=0.003, d2=0.001 g=0.028, a1=100, a2=100\n",
            ">487, d1=0.002, d2=0.001 g=0.030, a1=100, a2=100\n",
            ">488, d1=0.001, d2=0.002 g=0.036, a1=100, a2=100\n",
            ">489, d1=0.001, d2=0.001 g=0.045, a1=100, a2=100\n",
            ">490, d1=0.001, d2=0.001 g=0.032, a1=100, a2=100\n",
            ">491, d1=0.002, d2=0.001 g=0.034, a1=100, a2=100\n",
            ">492, d1=0.001, d2=0.001 g=0.034, a1=100, a2=100\n",
            ">493, d1=0.001, d2=0.000 g=0.037, a1=100, a2=100\n",
            ">494, d1=0.006, d2=0.001 g=0.034, a1=100, a2=100\n",
            ">495, d1=0.001, d2=0.001 g=0.043, a1=100, a2=100\n",
            ">496, d1=0.001, d2=0.001 g=0.049, a1=100, a2=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">497, d1=0.002, d2=0.002 g=0.032, a1=100, a2=100\n",
            ">498, d1=0.002, d2=0.002 g=0.029, a1=100, a2=100\n",
            ">499, d1=0.001, d2=0.002 g=0.030, a1=100, a2=100\n",
            ">500, d1=0.001, d2=0.001 g=0.035, a1=100, a2=100\n",
            ">501, d1=0.001, d2=0.001 g=0.025, a1=100, a2=100\n",
            ">502, d1=0.002, d2=0.001 g=0.028, a1=100, a2=100\n",
            ">503, d1=0.001, d2=0.001 g=0.034, a1=100, a2=100\n",
            ">504, d1=0.001, d2=0.003 g=0.030, a1=100, a2=100\n",
            ">505, d1=0.002, d2=0.001 g=0.033, a1=100, a2=100\n",
            ">506, d1=0.001, d2=0.001 g=0.037, a1=100, a2=100\n",
            ">507, d1=0.001, d2=0.001 g=0.033, a1=100, a2=100\n",
            ">508, d1=0.003, d2=0.001 g=0.034, a1=100, a2=100\n",
            ">509, d1=0.001, d2=0.001 g=0.041, a1=100, a2=100\n",
            ">510, d1=0.001, d2=0.001 g=0.051, a1=100, a2=100\n",
            ">511, d1=0.001, d2=0.002 g=0.043, a1=100, a2=100\n",
            ">512, d1=0.001, d2=0.001 g=0.038, a1=100, a2=100\n",
            ">513, d1=0.002, d2=0.001 g=0.038, a1=100, a2=100\n",
            ">514, d1=0.001, d2=0.001 g=0.034, a1=100, a2=100\n",
            ">515, d1=0.000, d2=0.001 g=0.032, a1=100, a2=100\n",
            ">516, d1=0.001, d2=0.001 g=0.033, a1=100, a2=100\n",
            ">517, d1=0.001, d2=0.001 g=0.032, a1=100, a2=100\n",
            ">518, d1=0.000, d2=0.002 g=0.039, a1=100, a2=100\n",
            ">519, d1=0.002, d2=0.001 g=0.020, a1=100, a2=100\n",
            ">520, d1=0.001, d2=0.001 g=0.019, a1=100, a2=100\n",
            ">521, d1=0.001, d2=0.002 g=0.030, a1=100, a2=100\n",
            ">522, d1=0.003, d2=0.001 g=0.024, a1=100, a2=100\n",
            ">523, d1=0.001, d2=0.001 g=0.025, a1=100, a2=100\n",
            ">524, d1=0.002, d2=0.001 g=0.018, a1=100, a2=100\n",
            ">525, d1=0.001, d2=0.001 g=0.021, a1=100, a2=100\n",
            ">526, d1=0.001, d2=0.002 g=0.044, a1=100, a2=100\n",
            ">527, d1=0.001, d2=0.001 g=0.024, a1=100, a2=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">528, d1=0.001, d2=0.001 g=0.038, a1=100, a2=100\n",
            ">529, d1=0.003, d2=0.000 g=0.035, a1=100, a2=100\n",
            ">530, d1=0.000, d2=0.001 g=0.025, a1=100, a2=100\n",
            ">531, d1=0.001, d2=0.002 g=0.028, a1=100, a2=100\n",
            ">532, d1=0.001, d2=0.002 g=0.028, a1=100, a2=100\n",
            ">533, d1=0.001, d2=0.001 g=0.028, a1=100, a2=100\n",
            ">534, d1=0.002, d2=0.004 g=0.031, a1=100, a2=100\n",
            ">535, d1=0.001, d2=0.002 g=0.034, a1=100, a2=100\n",
            ">536, d1=0.003, d2=0.001 g=0.034, a1=100, a2=100\n",
            ">537, d1=0.000, d2=0.002 g=0.038, a1=100, a2=100\n",
            ">538, d1=0.001, d2=0.001 g=0.042, a1=100, a2=100\n",
            ">539, d1=0.001, d2=0.001 g=0.024, a1=100, a2=100\n",
            ">540, d1=0.001, d2=0.001 g=0.030, a1=100, a2=100\n",
            ">541, d1=0.001, d2=0.001 g=0.031, a1=100, a2=100\n",
            ">542, d1=0.002, d2=0.001 g=0.029, a1=100, a2=100\n",
            ">543, d1=0.003, d2=0.002 g=0.024, a1=100, a2=100\n",
            ">544, d1=0.001, d2=0.001 g=0.031, a1=100, a2=100\n",
            ">545, d1=0.001, d2=0.001 g=0.027, a1=100, a2=100\n",
            ">546, d1=0.001, d2=0.001 g=0.040, a1=100, a2=100\n",
            ">547, d1=0.001, d2=0.001 g=0.023, a1=100, a2=100\n",
            ">548, d1=0.001, d2=0.001 g=0.036, a1=100, a2=100\n",
            ">549, d1=0.001, d2=0.001 g=0.029, a1=100, a2=100\n",
            ">550, d1=0.001, d2=0.001 g=0.032, a1=100, a2=100\n",
            ">551, d1=0.001, d2=0.001 g=0.026, a1=100, a2=100\n",
            ">552, d1=0.002, d2=0.001 g=0.031, a1=100, a2=100\n",
            ">553, d1=0.002, d2=0.002 g=0.031, a1=100, a2=100\n",
            ">554, d1=0.001, d2=0.001 g=0.024, a1=100, a2=100\n",
            ">555, d1=0.002, d2=0.001 g=0.022, a1=100, a2=100\n",
            ">556, d1=0.001, d2=0.001 g=0.030, a1=100, a2=100\n",
            ">557, d1=0.002, d2=0.001 g=0.039, a1=100, a2=100\n",
            ">558, d1=0.000, d2=0.001 g=0.022, a1=100, a2=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">559, d1=0.002, d2=0.001 g=0.023, a1=100, a2=100\n",
            ">560, d1=0.001, d2=0.001 g=0.026, a1=100, a2=100\n",
            ">561, d1=0.001, d2=0.002 g=0.029, a1=100, a2=100\n",
            ">562, d1=0.002, d2=0.001 g=0.033, a1=100, a2=100\n",
            ">563, d1=0.002, d2=0.001 g=0.025, a1=100, a2=100\n",
            ">564, d1=0.000, d2=0.001 g=0.029, a1=100, a2=100\n",
            ">565, d1=0.003, d2=0.001 g=0.025, a1=100, a2=100\n",
            ">566, d1=0.001, d2=0.001 g=0.025, a1=100, a2=100\n",
            ">567, d1=0.001, d2=0.001 g=0.026, a1=100, a2=100\n",
            ">568, d1=0.000, d2=0.001 g=0.038, a1=100, a2=100\n",
            ">569, d1=0.000, d2=0.001 g=0.024, a1=100, a2=100\n",
            ">570, d1=0.001, d2=0.001 g=0.022, a1=100, a2=100\n",
            ">571, d1=0.001, d2=0.000 g=0.027, a1=100, a2=100\n",
            ">572, d1=0.000, d2=0.002 g=0.042, a1=100, a2=100\n",
            ">573, d1=0.001, d2=0.000 g=0.035, a1=100, a2=100\n",
            ">574, d1=0.001, d2=0.000 g=0.033, a1=100, a2=100\n",
            ">575, d1=0.000, d2=0.001 g=0.033, a1=100, a2=100\n",
            ">576, d1=0.000, d2=0.002 g=0.023, a1=100, a2=100\n",
            ">577, d1=0.001, d2=0.001 g=0.033, a1=100, a2=100\n",
            ">578, d1=0.001, d2=0.001 g=0.027, a1=100, a2=100\n",
            ">579, d1=0.002, d2=0.001 g=0.039, a1=100, a2=100\n",
            ">580, d1=0.001, d2=0.001 g=0.025, a1=100, a2=100\n",
            ">581, d1=0.001, d2=0.001 g=0.031, a1=100, a2=100\n",
            ">582, d1=0.001, d2=0.001 g=0.033, a1=100, a2=100\n",
            ">583, d1=0.001, d2=0.002 g=0.029, a1=100, a2=100\n",
            ">584, d1=0.001, d2=0.002 g=0.022, a1=100, a2=100\n",
            ">585, d1=0.000, d2=0.002 g=0.025, a1=100, a2=100\n",
            ">586, d1=0.001, d2=0.002 g=0.031, a1=100, a2=100\n",
            ">587, d1=0.000, d2=0.001 g=0.031, a1=100, a2=100\n",
            ">588, d1=0.001, d2=0.001 g=0.034, a1=100, a2=100\n",
            ">589, d1=0.001, d2=0.001 g=0.028, a1=100, a2=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">590, d1=0.001, d2=0.001 g=0.035, a1=100, a2=100\n",
            ">591, d1=0.001, d2=0.001 g=0.028, a1=100, a2=100\n",
            ">592, d1=0.001, d2=0.001 g=0.023, a1=100, a2=100\n",
            ">593, d1=0.001, d2=0.001 g=0.021, a1=100, a2=100\n",
            ">594, d1=0.000, d2=0.001 g=0.036, a1=100, a2=100\n",
            ">595, d1=0.001, d2=0.001 g=0.039, a1=100, a2=100\n",
            ">596, d1=0.002, d2=0.001 g=0.033, a1=100, a2=100\n",
            ">597, d1=0.001, d2=0.002 g=0.033, a1=100, a2=100\n",
            ">598, d1=0.001, d2=0.002 g=0.033, a1=100, a2=100\n",
            ">599, d1=0.001, d2=0.002 g=0.025, a1=100, a2=100\n",
            ">600, d1=0.001, d2=0.001 g=0.038, a1=100, a2=100\n",
            ">601, d1=0.001, d2=0.001 g=0.031, a1=100, a2=100\n",
            ">602, d1=0.001, d2=0.000 g=0.041, a1=100, a2=100\n",
            ">603, d1=0.002, d2=0.001 g=0.027, a1=100, a2=100\n",
            ">604, d1=0.001, d2=0.001 g=0.032, a1=100, a2=100\n",
            ">605, d1=0.000, d2=0.003 g=0.026, a1=100, a2=100\n",
            ">606, d1=0.001, d2=0.002 g=0.032, a1=100, a2=100\n",
            ">607, d1=0.001, d2=0.001 g=0.035, a1=100, a2=100\n",
            ">608, d1=0.000, d2=0.001 g=0.031, a1=100, a2=100\n",
            ">609, d1=0.000, d2=0.002 g=0.041, a1=100, a2=100\n",
            ">610, d1=0.000, d2=0.001 g=0.038, a1=100, a2=100\n",
            ">611, d1=0.001, d2=0.001 g=0.036, a1=100, a2=100\n",
            ">612, d1=0.001, d2=0.000 g=0.033, a1=100, a2=100\n",
            ">613, d1=0.002, d2=0.001 g=0.025, a1=100, a2=100\n",
            ">614, d1=0.001, d2=0.002 g=0.048, a1=100, a2=100\n",
            ">615, d1=0.001, d2=0.001 g=0.045, a1=100, a2=100\n",
            ">616, d1=0.001, d2=0.000 g=0.034, a1=100, a2=100\n",
            ">617, d1=0.001, d2=0.001 g=0.037, a1=100, a2=100\n",
            ">618, d1=0.001, d2=0.000 g=0.031, a1=100, a2=100\n",
            ">619, d1=0.000, d2=0.001 g=0.036, a1=100, a2=100\n",
            ">620, d1=0.002, d2=0.002 g=0.051, a1=100, a2=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">621, d1=0.000, d2=0.001 g=0.035, a1=100, a2=100\n",
            ">622, d1=0.001, d2=0.001 g=0.036, a1=100, a2=100\n",
            ">623, d1=0.001, d2=0.001 g=0.023, a1=100, a2=100\n",
            ">624, d1=0.000, d2=0.001 g=0.050, a1=100, a2=100\n",
            ">625, d1=0.001, d2=0.001 g=0.027, a1=100, a2=100\n",
            ">626, d1=0.000, d2=0.001 g=0.035, a1=100, a2=100\n",
            ">627, d1=0.001, d2=0.001 g=0.047, a1=100, a2=100\n",
            ">628, d1=0.001, d2=0.001 g=0.023, a1=100, a2=100\n",
            ">629, d1=0.000, d2=0.000 g=0.047, a1=100, a2=100\n",
            ">630, d1=0.001, d2=0.001 g=0.039, a1=100, a2=100\n",
            ">631, d1=0.000, d2=0.001 g=0.038, a1=100, a2=100\n",
            ">632, d1=0.002, d2=0.001 g=0.038, a1=100, a2=100\n",
            ">633, d1=0.001, d2=0.002 g=0.042, a1=100, a2=100\n",
            ">634, d1=0.000, d2=0.001 g=0.021, a1=100, a2=100\n",
            ">635, d1=0.000, d2=0.001 g=0.028, a1=100, a2=100\n",
            ">636, d1=0.001, d2=0.001 g=0.032, a1=100, a2=100\n",
            ">637, d1=0.001, d2=0.001 g=0.027, a1=100, a2=100\n",
            ">638, d1=0.001, d2=0.001 g=0.027, a1=100, a2=100\n",
            ">639, d1=0.001, d2=0.001 g=0.037, a1=100, a2=100\n",
            ">640, d1=0.000, d2=0.002 g=0.044, a1=100, a2=100\n",
            ">641, d1=0.001, d2=0.000 g=0.035, a1=100, a2=100\n",
            ">642, d1=0.001, d2=0.001 g=0.034, a1=100, a2=100\n",
            ">643, d1=0.002, d2=0.002 g=0.027, a1=100, a2=100\n",
            ">644, d1=0.001, d2=0.001 g=0.031, a1=100, a2=100\n",
            ">645, d1=0.001, d2=0.002 g=0.031, a1=100, a2=100\n",
            ">646, d1=0.001, d2=0.000 g=0.030, a1=100, a2=100\n",
            ">647, d1=0.001, d2=0.001 g=0.044, a1=100, a2=100\n",
            ">648, d1=0.000, d2=0.001 g=0.035, a1=100, a2=100\n",
            ">649, d1=0.001, d2=0.001 g=0.038, a1=100, a2=100\n",
            ">650, d1=0.001, d2=0.000 g=0.028, a1=100, a2=100\n",
            ">651, d1=0.000, d2=0.000 g=0.036, a1=100, a2=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">652, d1=0.002, d2=0.001 g=0.023, a1=100, a2=100\n",
            ">653, d1=0.001, d2=0.001 g=0.029, a1=100, a2=100\n",
            ">654, d1=0.001, d2=0.000 g=0.042, a1=100, a2=100\n",
            ">655, d1=0.000, d2=0.001 g=0.030, a1=100, a2=100\n",
            ">656, d1=0.001, d2=0.001 g=0.024, a1=100, a2=100\n",
            ">657, d1=0.001, d2=0.001 g=0.044, a1=100, a2=100\n",
            ">658, d1=0.001, d2=0.001 g=0.051, a1=100, a2=100\n",
            ">659, d1=0.001, d2=0.000 g=0.032, a1=100, a2=100\n",
            ">660, d1=0.000, d2=0.001 g=0.033, a1=100, a2=100\n",
            ">661, d1=0.002, d2=0.001 g=0.027, a1=100, a2=100\n",
            ">662, d1=0.000, d2=0.001 g=0.039, a1=100, a2=100\n",
            ">663, d1=0.001, d2=0.001 g=0.036, a1=100, a2=100\n",
            ">664, d1=0.000, d2=0.001 g=0.034, a1=100, a2=100\n",
            ">665, d1=0.001, d2=0.001 g=0.035, a1=100, a2=100\n",
            ">666, d1=0.001, d2=0.001 g=0.034, a1=100, a2=100\n",
            ">667, d1=0.001, d2=0.001 g=0.036, a1=100, a2=100\n",
            ">668, d1=0.001, d2=0.001 g=0.040, a1=100, a2=100\n",
            ">669, d1=0.001, d2=0.002 g=0.024, a1=100, a2=100\n",
            ">670, d1=0.001, d2=0.002 g=0.025, a1=100, a2=100\n",
            ">671, d1=0.000, d2=0.001 g=0.023, a1=100, a2=100\n",
            ">672, d1=0.001, d2=0.001 g=0.031, a1=100, a2=100\n",
            ">673, d1=0.001, d2=0.001 g=0.033, a1=100, a2=100\n",
            ">674, d1=0.000, d2=0.000 g=0.037, a1=100, a2=100\n",
            ">675, d1=0.000, d2=0.001 g=0.029, a1=100, a2=100\n",
            ">676, d1=0.000, d2=0.001 g=0.020, a1=100, a2=100\n",
            ">677, d1=0.001, d2=0.001 g=0.029, a1=100, a2=100\n",
            ">678, d1=0.000, d2=0.001 g=0.035, a1=100, a2=100\n",
            ">679, d1=0.001, d2=0.001 g=0.024, a1=100, a2=100\n",
            ">680, d1=0.001, d2=0.000 g=0.034, a1=100, a2=100\n",
            ">681, d1=0.000, d2=0.000 g=0.028, a1=100, a2=100\n",
            ">682, d1=0.002, d2=0.002 g=0.024, a1=100, a2=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">683, d1=0.001, d2=0.001 g=0.045, a1=100, a2=100\n",
            ">684, d1=0.001, d2=0.001 g=0.027, a1=100, a2=100\n",
            ">685, d1=0.000, d2=0.001 g=0.034, a1=100, a2=100\n",
            ">686, d1=0.000, d2=0.002 g=0.037, a1=100, a2=100\n",
            ">687, d1=0.001, d2=0.001 g=0.027, a1=100, a2=100\n",
            ">688, d1=0.001, d2=0.001 g=0.030, a1=100, a2=100\n",
            ">689, d1=0.001, d2=0.000 g=0.038, a1=100, a2=100\n",
            ">690, d1=0.001, d2=0.001 g=0.038, a1=100, a2=100\n",
            ">691, d1=0.000, d2=0.001 g=0.031, a1=100, a2=100\n",
            ">692, d1=0.000, d2=0.000 g=0.028, a1=100, a2=100\n",
            ">693, d1=0.001, d2=0.000 g=0.041, a1=100, a2=100\n",
            ">694, d1=0.001, d2=0.002 g=0.031, a1=100, a2=100\n",
            ">695, d1=0.000, d2=0.000 g=0.037, a1=100, a2=100\n",
            ">696, d1=0.001, d2=0.001 g=0.024, a1=100, a2=100\n",
            ">697, d1=0.001, d2=0.002 g=0.039, a1=100, a2=100\n",
            ">698, d1=0.001, d2=0.001 g=0.038, a1=100, a2=100\n",
            ">699, d1=0.000, d2=0.000 g=0.035, a1=100, a2=100\n",
            ">700, d1=0.001, d2=0.001 g=0.028, a1=100, a2=100\n",
            ">701, d1=0.000, d2=0.001 g=0.033, a1=100, a2=100\n",
            ">702, d1=0.001, d2=0.000 g=0.026, a1=100, a2=100\n",
            ">703, d1=0.001, d2=0.001 g=0.034, a1=100, a2=100\n",
            ">704, d1=0.001, d2=0.001 g=0.029, a1=100, a2=100\n",
            ">705, d1=0.002, d2=0.001 g=0.057, a1=100, a2=100\n",
            ">706, d1=0.001, d2=0.001 g=0.033, a1=100, a2=100\n",
            ">707, d1=0.001, d2=0.001 g=0.027, a1=100, a2=100\n",
            ">708, d1=0.001, d2=0.000 g=0.029, a1=100, a2=100\n",
            ">709, d1=0.000, d2=0.001 g=0.030, a1=100, a2=100\n",
            ">710, d1=0.000, d2=0.002 g=0.028, a1=100, a2=100\n",
            ">711, d1=0.001, d2=0.000 g=0.034, a1=100, a2=100\n",
            ">712, d1=0.000, d2=0.001 g=0.025, a1=100, a2=100\n",
            ">713, d1=0.000, d2=0.001 g=0.039, a1=100, a2=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">714, d1=0.004, d2=0.001 g=0.025, a1=100, a2=100\n",
            ">715, d1=0.000, d2=0.001 g=0.037, a1=100, a2=100\n",
            ">716, d1=0.000, d2=0.001 g=0.025, a1=100, a2=100\n",
            ">717, d1=0.001, d2=0.000 g=0.024, a1=100, a2=100\n",
            ">718, d1=0.001, d2=0.000 g=0.028, a1=100, a2=100\n",
            ">719, d1=0.002, d2=0.001 g=0.025, a1=100, a2=100\n",
            ">720, d1=0.001, d2=0.001 g=0.026, a1=100, a2=100\n",
            ">721, d1=0.000, d2=0.000 g=0.029, a1=100, a2=100\n",
            ">722, d1=0.000, d2=0.001 g=0.019, a1=100, a2=100\n",
            ">723, d1=0.000, d2=0.001 g=0.023, a1=100, a2=100\n",
            ">724, d1=0.001, d2=0.000 g=0.021, a1=100, a2=100\n",
            ">725, d1=0.000, d2=0.001 g=0.024, a1=100, a2=100\n",
            ">726, d1=0.000, d2=0.001 g=0.023, a1=100, a2=100\n",
            ">727, d1=0.002, d2=0.002 g=0.023, a1=100, a2=100\n",
            ">728, d1=0.000, d2=0.001 g=0.028, a1=100, a2=100\n",
            ">729, d1=0.000, d2=0.001 g=0.025, a1=100, a2=100\n",
            ">730, d1=0.000, d2=0.000 g=0.021, a1=100, a2=100\n",
            ">731, d1=0.002, d2=0.001 g=0.022, a1=100, a2=100\n",
            ">732, d1=0.000, d2=0.001 g=0.035, a1=100, a2=100\n",
            ">733, d1=0.001, d2=0.000 g=0.025, a1=100, a2=100\n",
            ">734, d1=0.000, d2=0.001 g=0.034, a1=100, a2=100\n",
            ">735, d1=0.000, d2=0.000 g=0.039, a1=100, a2=100\n",
            ">736, d1=0.001, d2=0.001 g=0.026, a1=100, a2=100\n",
            ">737, d1=0.000, d2=0.000 g=0.029, a1=100, a2=100\n",
            ">738, d1=0.000, d2=0.000 g=0.021, a1=100, a2=100\n",
            ">739, d1=0.000, d2=0.000 g=0.026, a1=100, a2=100\n",
            ">740, d1=0.000, d2=0.000 g=0.023, a1=100, a2=100\n",
            ">741, d1=0.001, d2=0.000 g=0.025, a1=100, a2=100\n",
            ">742, d1=0.001, d2=0.000 g=0.027, a1=100, a2=100\n",
            ">743, d1=0.001, d2=0.001 g=0.027, a1=100, a2=100\n",
            ">744, d1=0.000, d2=0.001 g=0.024, a1=100, a2=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">745, d1=0.000, d2=0.001 g=0.030, a1=100, a2=100\n",
            ">746, d1=0.000, d2=0.000 g=0.022, a1=100, a2=100\n",
            ">747, d1=0.001, d2=0.000 g=0.038, a1=100, a2=100\n",
            ">748, d1=0.002, d2=0.001 g=0.026, a1=100, a2=100\n",
            ">749, d1=0.001, d2=0.000 g=0.019, a1=100, a2=100\n",
            ">750, d1=0.000, d2=0.001 g=0.019, a1=100, a2=100\n",
            ">751, d1=0.000, d2=0.001 g=0.020, a1=100, a2=100\n",
            ">752, d1=0.001, d2=0.001 g=0.029, a1=100, a2=100\n",
            ">753, d1=0.002, d2=0.001 g=0.025, a1=100, a2=100\n",
            ">754, d1=0.001, d2=0.001 g=0.017, a1=100, a2=100\n",
            ">755, d1=0.001, d2=0.002 g=0.028, a1=100, a2=100\n",
            ">756, d1=0.001, d2=0.001 g=0.029, a1=100, a2=100\n",
            ">757, d1=0.000, d2=0.000 g=0.027, a1=100, a2=100\n",
            ">758, d1=0.000, d2=0.000 g=0.032, a1=100, a2=100\n",
            ">759, d1=0.001, d2=0.001 g=0.023, a1=100, a2=100\n",
            ">760, d1=0.001, d2=0.000 g=0.018, a1=100, a2=100\n",
            ">761, d1=0.000, d2=0.000 g=0.034, a1=100, a2=100\n",
            ">762, d1=0.000, d2=0.001 g=0.027, a1=100, a2=100\n",
            ">763, d1=0.000, d2=0.001 g=0.034, a1=100, a2=100\n",
            ">764, d1=0.000, d2=0.000 g=0.026, a1=100, a2=100\n",
            ">765, d1=0.001, d2=0.001 g=0.033, a1=100, a2=100\n",
            ">766, d1=0.000, d2=0.001 g=0.020, a1=100, a2=100\n",
            ">767, d1=0.000, d2=0.001 g=0.018, a1=100, a2=100\n",
            ">768, d1=0.001, d2=0.001 g=0.022, a1=100, a2=100\n",
            ">769, d1=0.000, d2=0.001 g=0.024, a1=100, a2=100\n",
            ">770, d1=0.000, d2=0.000 g=0.034, a1=100, a2=100\n",
            ">771, d1=0.001, d2=0.000 g=0.024, a1=100, a2=100\n",
            ">772, d1=0.001, d2=0.001 g=0.031, a1=100, a2=100\n",
            ">773, d1=0.000, d2=0.000 g=0.036, a1=100, a2=100\n",
            ">774, d1=0.001, d2=0.001 g=0.030, a1=100, a2=100\n",
            ">775, d1=0.002, d2=0.000 g=0.032, a1=100, a2=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">776, d1=0.001, d2=0.001 g=0.020, a1=100, a2=100\n",
            ">777, d1=0.001, d2=0.001 g=0.019, a1=100, a2=100\n",
            ">778, d1=0.001, d2=0.000 g=0.029, a1=100, a2=100\n",
            ">779, d1=0.001, d2=0.000 g=0.023, a1=100, a2=100\n",
            ">780, d1=0.002, d2=0.000 g=0.025, a1=100, a2=100\n",
            ">781, d1=0.000, d2=0.001 g=0.027, a1=100, a2=100\n",
            ">782, d1=0.001, d2=0.000 g=0.018, a1=100, a2=100\n",
            ">783, d1=0.001, d2=0.000 g=0.018, a1=100, a2=100\n",
            ">784, d1=0.000, d2=0.001 g=0.015, a1=100, a2=100\n",
            ">785, d1=0.000, d2=0.001 g=0.031, a1=100, a2=100\n",
            ">786, d1=0.000, d2=0.001 g=0.021, a1=100, a2=100\n",
            ">787, d1=0.000, d2=0.002 g=0.027, a1=100, a2=100\n",
            ">788, d1=0.001, d2=0.000 g=0.025, a1=100, a2=100\n",
            ">789, d1=0.001, d2=0.001 g=0.028, a1=100, a2=100\n",
            ">790, d1=0.001, d2=0.001 g=0.025, a1=100, a2=100\n",
            ">791, d1=0.001, d2=0.000 g=0.017, a1=100, a2=100\n",
            ">792, d1=0.000, d2=0.001 g=0.034, a1=100, a2=100\n",
            ">793, d1=0.000, d2=0.000 g=0.028, a1=100, a2=100\n",
            ">794, d1=0.001, d2=0.000 g=0.024, a1=100, a2=100\n",
            ">795, d1=0.001, d2=0.001 g=0.022, a1=100, a2=100\n",
            ">796, d1=0.000, d2=0.001 g=0.015, a1=100, a2=100\n",
            ">797, d1=0.000, d2=0.001 g=0.025, a1=100, a2=100\n",
            ">798, d1=0.001, d2=0.001 g=0.023, a1=100, a2=100\n",
            ">799, d1=0.000, d2=0.003 g=0.023, a1=100, a2=100\n",
            ">800, d1=0.000, d2=0.000 g=0.033, a1=100, a2=100\n",
            ">801, d1=0.000, d2=0.001 g=0.032, a1=100, a2=100\n",
            ">802, d1=0.001, d2=0.001 g=0.019, a1=100, a2=100\n",
            ">803, d1=0.000, d2=0.000 g=0.039, a1=100, a2=100\n",
            ">804, d1=0.000, d2=0.001 g=0.029, a1=100, a2=100\n",
            ">805, d1=0.000, d2=0.001 g=0.027, a1=100, a2=100\n",
            ">806, d1=0.000, d2=0.000 g=0.023, a1=100, a2=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">807, d1=0.000, d2=0.002 g=0.036, a1=100, a2=100\n",
            ">808, d1=0.002, d2=0.000 g=0.023, a1=100, a2=100\n",
            ">809, d1=0.001, d2=0.001 g=0.030, a1=100, a2=100\n",
            ">810, d1=0.000, d2=0.001 g=0.020, a1=100, a2=100\n",
            ">811, d1=0.000, d2=0.001 g=0.047, a1=100, a2=100\n",
            ">812, d1=0.000, d2=0.001 g=0.021, a1=100, a2=100\n",
            ">813, d1=0.001, d2=0.000 g=0.021, a1=100, a2=100\n",
            ">814, d1=0.000, d2=0.001 g=0.036, a1=100, a2=100\n",
            ">815, d1=0.000, d2=0.000 g=0.030, a1=100, a2=100\n",
            ">816, d1=0.001, d2=0.000 g=0.032, a1=100, a2=100\n",
            ">817, d1=0.000, d2=0.001 g=0.024, a1=100, a2=100\n",
            ">818, d1=0.000, d2=0.001 g=0.032, a1=100, a2=100\n",
            ">819, d1=0.000, d2=0.000 g=0.037, a1=100, a2=100\n",
            ">820, d1=0.000, d2=0.001 g=0.032, a1=100, a2=100\n",
            ">821, d1=0.000, d2=0.001 g=0.042, a1=100, a2=100\n",
            ">822, d1=0.000, d2=0.000 g=0.049, a1=100, a2=100\n",
            ">823, d1=0.001, d2=0.001 g=0.023, a1=100, a2=100\n",
            ">824, d1=0.001, d2=0.000 g=0.023, a1=100, a2=100\n",
            ">825, d1=0.000, d2=0.001 g=0.029, a1=100, a2=100\n",
            ">826, d1=0.001, d2=0.000 g=0.033, a1=100, a2=100\n",
            ">827, d1=0.000, d2=0.000 g=0.024, a1=100, a2=100\n",
            ">828, d1=0.000, d2=0.000 g=0.019, a1=100, a2=100\n",
            ">829, d1=0.002, d2=0.000 g=0.027, a1=100, a2=100\n",
            ">830, d1=0.000, d2=0.000 g=0.020, a1=100, a2=100\n",
            ">831, d1=0.001, d2=0.000 g=0.038, a1=100, a2=100\n",
            ">832, d1=0.001, d2=0.000 g=0.016, a1=100, a2=100\n",
            ">833, d1=0.002, d2=0.000 g=0.024, a1=100, a2=100\n",
            ">834, d1=0.001, d2=0.001 g=0.025, a1=100, a2=100\n",
            ">835, d1=0.002, d2=0.000 g=0.043, a1=100, a2=100\n",
            ">836, d1=0.001, d2=0.000 g=0.028, a1=100, a2=100\n",
            ">837, d1=0.000, d2=0.000 g=0.027, a1=100, a2=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">838, d1=0.000, d2=0.000 g=0.015, a1=100, a2=100\n",
            ">839, d1=0.001, d2=0.000 g=0.035, a1=100, a2=100\n",
            ">840, d1=0.000, d2=0.001 g=0.028, a1=100, a2=100\n",
            ">841, d1=0.001, d2=0.000 g=0.023, a1=100, a2=100\n",
            ">842, d1=0.000, d2=0.000 g=0.022, a1=100, a2=100\n",
            ">843, d1=0.000, d2=0.001 g=0.032, a1=100, a2=100\n",
            ">844, d1=0.000, d2=0.000 g=0.023, a1=100, a2=100\n",
            ">845, d1=0.000, d2=0.000 g=0.018, a1=100, a2=100\n",
            ">846, d1=0.001, d2=0.000 g=0.020, a1=100, a2=100\n",
            ">847, d1=0.001, d2=0.001 g=0.022, a1=100, a2=100\n",
            ">848, d1=0.000, d2=0.001 g=0.018, a1=100, a2=100\n",
            ">849, d1=0.000, d2=0.001 g=0.019, a1=100, a2=100\n",
            ">850, d1=0.001, d2=0.001 g=0.020, a1=100, a2=100\n",
            ">851, d1=0.001, d2=0.000 g=0.024, a1=100, a2=100\n",
            ">852, d1=0.000, d2=0.000 g=0.037, a1=100, a2=100\n",
            ">853, d1=0.001, d2=0.001 g=0.026, a1=100, a2=100\n",
            ">854, d1=0.000, d2=0.000 g=0.025, a1=100, a2=100\n",
            ">855, d1=0.001, d2=0.001 g=0.031, a1=100, a2=100\n",
            ">856, d1=0.002, d2=0.000 g=0.025, a1=100, a2=100\n",
            ">857, d1=0.000, d2=0.000 g=0.024, a1=100, a2=100\n",
            ">858, d1=0.000, d2=0.000 g=0.017, a1=100, a2=100\n",
            ">859, d1=0.001, d2=0.000 g=0.017, a1=100, a2=100\n",
            ">860, d1=0.000, d2=0.001 g=0.027, a1=100, a2=100\n",
            ">861, d1=0.000, d2=0.000 g=0.016, a1=100, a2=100\n",
            ">862, d1=0.000, d2=0.000 g=0.023, a1=100, a2=100\n",
            ">863, d1=0.001, d2=0.000 g=0.014, a1=100, a2=100\n",
            ">864, d1=0.001, d2=0.000 g=0.020, a1=100, a2=100\n",
            ">865, d1=0.001, d2=0.000 g=0.018, a1=100, a2=100\n",
            ">866, d1=0.000, d2=0.001 g=0.025, a1=100, a2=100\n",
            ">867, d1=0.001, d2=0.000 g=0.017, a1=100, a2=100\n",
            ">868, d1=0.001, d2=0.000 g=0.022, a1=100, a2=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">869, d1=0.000, d2=0.000 g=0.021, a1=100, a2=100\n",
            ">870, d1=0.001, d2=0.000 g=0.017, a1=100, a2=100\n",
            ">871, d1=0.001, d2=0.000 g=0.020, a1=100, a2=100\n",
            ">872, d1=0.001, d2=0.001 g=0.021, a1=100, a2=100\n",
            ">873, d1=0.001, d2=0.000 g=0.013, a1=100, a2=100\n",
            ">874, d1=0.001, d2=0.000 g=0.018, a1=100, a2=100\n",
            ">875, d1=0.000, d2=0.000 g=0.025, a1=100, a2=100\n",
            ">876, d1=0.000, d2=0.000 g=0.018, a1=100, a2=100\n",
            ">877, d1=0.003, d2=0.000 g=0.018, a1=100, a2=100\n",
            ">878, d1=0.000, d2=0.000 g=0.018, a1=100, a2=100\n",
            ">879, d1=0.001, d2=0.000 g=0.018, a1=100, a2=100\n",
            ">880, d1=0.000, d2=0.001 g=0.021, a1=100, a2=100\n",
            ">881, d1=0.000, d2=0.000 g=0.024, a1=100, a2=100\n",
            ">882, d1=0.000, d2=0.001 g=0.019, a1=100, a2=100\n",
            ">883, d1=0.001, d2=0.000 g=0.017, a1=100, a2=100\n",
            ">884, d1=0.001, d2=0.000 g=0.022, a1=100, a2=100\n",
            ">885, d1=0.000, d2=0.001 g=0.015, a1=100, a2=100\n",
            ">886, d1=0.000, d2=0.000 g=0.015, a1=100, a2=100\n",
            ">887, d1=0.001, d2=0.001 g=0.012, a1=100, a2=100\n",
            ">888, d1=0.000, d2=0.002 g=0.022, a1=100, a2=100\n",
            ">889, d1=0.000, d2=0.000 g=0.023, a1=100, a2=100\n",
            ">890, d1=0.000, d2=0.000 g=0.019, a1=100, a2=100\n",
            ">891, d1=0.000, d2=0.001 g=0.026, a1=100, a2=100\n",
            ">892, d1=0.000, d2=0.000 g=0.015, a1=100, a2=100\n",
            ">893, d1=0.001, d2=0.000 g=0.018, a1=100, a2=100\n",
            ">894, d1=0.000, d2=0.000 g=0.024, a1=100, a2=100\n",
            ">895, d1=0.000, d2=0.001 g=0.023, a1=100, a2=100\n",
            ">896, d1=0.002, d2=0.000 g=0.019, a1=100, a2=100\n",
            ">897, d1=0.000, d2=0.001 g=0.031, a1=100, a2=100\n",
            ">898, d1=0.000, d2=0.002 g=0.015, a1=100, a2=100\n",
            ">899, d1=0.000, d2=0.001 g=0.019, a1=100, a2=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">900, d1=0.000, d2=0.000 g=0.022, a1=100, a2=100\n",
            ">901, d1=0.000, d2=0.000 g=0.025, a1=100, a2=100\n",
            ">902, d1=0.000, d2=0.001 g=0.017, a1=100, a2=100\n",
            ">903, d1=0.000, d2=0.000 g=0.036, a1=100, a2=100\n",
            ">904, d1=0.000, d2=0.000 g=0.026, a1=100, a2=100\n",
            ">905, d1=0.000, d2=0.001 g=0.033, a1=100, a2=100\n",
            ">906, d1=0.000, d2=0.001 g=0.023, a1=100, a2=100\n",
            ">907, d1=0.000, d2=0.000 g=0.022, a1=100, a2=100\n",
            ">908, d1=0.000, d2=0.001 g=0.020, a1=100, a2=100\n",
            ">909, d1=0.001, d2=0.003 g=0.016, a1=100, a2=100\n",
            ">910, d1=0.001, d2=0.001 g=0.032, a1=100, a2=100\n",
            ">911, d1=0.001, d2=0.001 g=0.034, a1=100, a2=100\n",
            ">912, d1=0.001, d2=0.000 g=0.025, a1=100, a2=100\n",
            ">913, d1=0.000, d2=0.000 g=0.030, a1=100, a2=100\n",
            ">914, d1=0.001, d2=0.000 g=0.023, a1=100, a2=100\n",
            ">915, d1=0.001, d2=0.001 g=0.025, a1=100, a2=100\n",
            ">916, d1=0.001, d2=0.001 g=0.033, a1=100, a2=100\n",
            ">917, d1=0.001, d2=0.000 g=0.024, a1=100, a2=100\n",
            ">918, d1=0.000, d2=0.001 g=0.027, a1=100, a2=100\n",
            ">919, d1=0.001, d2=0.001 g=0.031, a1=100, a2=100\n",
            ">920, d1=0.000, d2=0.001 g=0.022, a1=100, a2=100\n",
            ">921, d1=0.000, d2=0.000 g=0.034, a1=100, a2=100\n",
            ">922, d1=0.000, d2=0.001 g=0.029, a1=100, a2=100\n",
            ">923, d1=0.000, d2=0.001 g=0.026, a1=100, a2=100\n",
            ">924, d1=0.001, d2=0.002 g=0.032, a1=100, a2=100\n",
            ">925, d1=0.000, d2=0.000 g=0.027, a1=100, a2=100\n",
            ">926, d1=0.000, d2=0.000 g=0.023, a1=100, a2=100\n",
            ">927, d1=0.001, d2=0.000 g=0.033, a1=100, a2=100\n",
            ">928, d1=0.000, d2=0.000 g=0.033, a1=100, a2=100\n",
            ">929, d1=0.000, d2=0.000 g=0.018, a1=100, a2=100\n",
            ">930, d1=0.002, d2=0.000 g=0.022, a1=100, a2=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">931, d1=0.000, d2=0.001 g=0.033, a1=100, a2=100\n",
            ">932, d1=0.002, d2=0.000 g=0.032, a1=100, a2=100\n",
            ">933, d1=0.000, d2=0.000 g=0.022, a1=100, a2=100\n",
            ">934, d1=0.001, d2=0.000 g=0.027, a1=100, a2=100\n",
            ">935, d1=0.000, d2=0.000 g=0.021, a1=100, a2=100\n",
            ">936, d1=0.001, d2=0.001 g=0.019, a1=100, a2=100\n",
            ">937, d1=0.000, d2=0.000 g=0.024, a1=100, a2=100\n",
            ">938, d1=0.000, d2=0.000 g=0.027, a1=100, a2=100\n",
            ">939, d1=0.000, d2=0.001 g=0.019, a1=100, a2=100\n",
            ">940, d1=0.000, d2=0.000 g=0.022, a1=100, a2=100\n",
            ">941, d1=0.000, d2=0.000 g=0.031, a1=100, a2=100\n",
            ">942, d1=0.000, d2=0.000 g=0.029, a1=100, a2=100\n",
            ">943, d1=0.001, d2=0.000 g=0.019, a1=100, a2=100\n",
            ">944, d1=0.000, d2=0.000 g=0.022, a1=100, a2=100\n",
            ">945, d1=0.000, d2=0.001 g=0.021, a1=100, a2=100\n",
            ">946, d1=0.000, d2=0.001 g=0.019, a1=100, a2=100\n",
            ">947, d1=0.000, d2=0.001 g=0.023, a1=100, a2=100\n",
            ">948, d1=0.000, d2=0.000 g=0.025, a1=100, a2=100\n",
            ">949, d1=0.000, d2=0.000 g=0.031, a1=100, a2=100\n",
            ">950, d1=0.001, d2=0.000 g=0.025, a1=100, a2=100\n",
            ">951, d1=0.000, d2=0.001 g=0.023, a1=100, a2=100\n",
            ">952, d1=0.001, d2=0.001 g=0.026, a1=100, a2=100\n",
            ">953, d1=0.000, d2=0.001 g=0.022, a1=100, a2=100\n",
            ">954, d1=0.000, d2=0.000 g=0.021, a1=100, a2=100\n",
            ">955, d1=0.000, d2=0.000 g=0.029, a1=100, a2=100\n",
            ">956, d1=0.001, d2=0.000 g=0.041, a1=100, a2=100\n",
            ">957, d1=0.001, d2=0.000 g=0.026, a1=100, a2=100\n",
            ">958, d1=0.000, d2=0.000 g=0.025, a1=100, a2=100\n",
            ">959, d1=0.000, d2=0.000 g=0.013, a1=100, a2=100\n",
            ">960, d1=0.001, d2=0.001 g=0.026, a1=100, a2=100\n",
            ">961, d1=0.001, d2=0.000 g=0.018, a1=100, a2=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">962, d1=0.000, d2=0.000 g=0.015, a1=100, a2=100\n",
            ">963, d1=0.000, d2=0.001 g=0.011, a1=100, a2=100\n",
            ">964, d1=0.000, d2=0.000 g=0.013, a1=100, a2=100\n",
            ">965, d1=0.001, d2=0.001 g=0.019, a1=100, a2=100\n",
            ">966, d1=0.000, d2=0.000 g=0.018, a1=100, a2=100\n",
            ">967, d1=0.000, d2=0.000 g=0.012, a1=100, a2=100\n",
            ">968, d1=0.000, d2=0.000 g=0.019, a1=100, a2=100\n",
            ">969, d1=0.000, d2=0.000 g=0.020, a1=100, a2=100\n",
            ">970, d1=0.000, d2=0.000 g=0.021, a1=100, a2=100\n",
            ">971, d1=0.000, d2=0.000 g=0.018, a1=100, a2=100\n",
            ">972, d1=0.001, d2=0.001 g=0.015, a1=100, a2=100\n",
            ">973, d1=0.000, d2=0.001 g=0.015, a1=100, a2=100\n",
            ">974, d1=0.000, d2=0.000 g=0.025, a1=100, a2=100\n",
            ">975, d1=0.000, d2=0.000 g=0.017, a1=100, a2=100\n",
            ">976, d1=0.001, d2=0.001 g=0.018, a1=100, a2=100\n",
            ">977, d1=0.000, d2=0.000 g=0.019, a1=100, a2=100\n",
            ">978, d1=0.001, d2=0.000 g=0.019, a1=100, a2=100\n",
            ">979, d1=0.000, d2=0.000 g=0.021, a1=100, a2=100\n",
            ">980, d1=0.000, d2=0.000 g=0.021, a1=100, a2=100\n",
            ">981, d1=0.000, d2=0.000 g=0.017, a1=100, a2=100\n",
            ">982, d1=0.000, d2=0.000 g=0.019, a1=100, a2=100\n",
            ">983, d1=0.000, d2=0.001 g=0.023, a1=100, a2=100\n",
            ">984, d1=0.000, d2=0.001 g=0.016, a1=100, a2=100\n",
            ">985, d1=0.000, d2=0.000 g=0.032, a1=100, a2=100\n",
            ">986, d1=0.000, d2=0.000 g=0.027, a1=100, a2=100\n",
            ">987, d1=0.001, d2=0.001 g=0.035, a1=100, a2=100\n",
            ">988, d1=0.002, d2=0.000 g=0.020, a1=100, a2=100\n",
            ">989, d1=0.007, d2=0.002 g=0.015, a1=99, a2=100\n",
            ">990, d1=0.000, d2=0.000 g=0.016, a1=100, a2=100\n",
            ">991, d1=0.000, d2=0.000 g=0.021, a1=100, a2=100\n",
            ">992, d1=0.001, d2=0.000 g=0.025, a1=100, a2=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">993, d1=0.000, d2=0.000 g=0.016, a1=100, a2=100\n",
            ">994, d1=0.000, d2=0.000 g=0.022, a1=100, a2=100\n",
            ">995, d1=0.000, d2=0.001 g=0.012, a1=100, a2=100\n",
            ">996, d1=0.000, d2=0.002 g=0.013, a1=100, a2=100\n",
            ">997, d1=0.000, d2=0.001 g=0.022, a1=100, a2=100\n",
            ">998, d1=0.001, d2=0.000 g=0.018, a1=100, a2=100\n",
            ">999, d1=0.001, d2=0.000 g=0.014, a1=100, a2=100\n",
            ">1000, d1=0.003, d2=0.000 g=0.021, a1=100, a2=100\n",
            ">1001, d1=0.001, d2=0.001 g=0.018, a1=100, a2=100\n",
            ">1002, d1=0.001, d2=0.000 g=0.015, a1=100, a2=100\n",
            ">1003, d1=0.000, d2=0.000 g=0.015, a1=100, a2=100\n",
            ">1004, d1=0.000, d2=0.000 g=0.021, a1=100, a2=100\n",
            ">1005, d1=0.000, d2=0.001 g=0.015, a1=100, a2=100\n",
            ">1006, d1=0.000, d2=0.000 g=0.017, a1=100, a2=100\n",
            ">1007, d1=0.001, d2=0.000 g=0.011, a1=100, a2=100\n",
            ">1008, d1=0.001, d2=0.000 g=0.014, a1=100, a2=100\n",
            ">1009, d1=0.002, d2=0.000 g=0.013, a1=100, a2=100\n",
            ">1010, d1=0.000, d2=0.001 g=0.019, a1=100, a2=100\n",
            ">1011, d1=0.000, d2=0.001 g=0.014, a1=100, a2=100\n",
            ">1012, d1=0.000, d2=0.000 g=0.011, a1=100, a2=100\n",
            ">1013, d1=0.000, d2=0.000 g=0.018, a1=100, a2=100\n",
            ">1014, d1=0.000, d2=0.001 g=0.009, a1=100, a2=100\n",
            ">1015, d1=0.000, d2=0.000 g=0.015, a1=100, a2=100\n",
            ">1016, d1=0.000, d2=0.001 g=0.018, a1=100, a2=100\n",
            ">1017, d1=0.000, d2=0.000 g=0.017, a1=100, a2=100\n",
            ">1018, d1=0.000, d2=0.000 g=0.026, a1=100, a2=100\n",
            ">1019, d1=0.000, d2=0.001 g=0.016, a1=100, a2=100\n",
            ">1020, d1=0.001, d2=0.000 g=0.012, a1=100, a2=100\n",
            ">1021, d1=0.000, d2=0.000 g=0.019, a1=100, a2=100\n",
            ">1022, d1=0.000, d2=0.000 g=0.013, a1=100, a2=100\n",
            ">1023, d1=0.001, d2=0.000 g=0.014, a1=100, a2=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">1024, d1=0.000, d2=0.003 g=0.012, a1=100, a2=100\n",
            ">1025, d1=0.000, d2=0.000 g=0.016, a1=100, a2=100\n",
            ">1026, d1=0.000, d2=0.001 g=0.015, a1=100, a2=100\n",
            ">1027, d1=0.000, d2=0.000 g=0.017, a1=100, a2=100\n",
            ">1028, d1=0.001, d2=0.000 g=0.015, a1=100, a2=100\n",
            ">1029, d1=0.000, d2=0.000 g=0.026, a1=100, a2=100\n",
            ">1030, d1=0.000, d2=0.001 g=0.027, a1=100, a2=100\n",
            ">1031, d1=0.000, d2=0.001 g=0.021, a1=100, a2=100\n",
            ">1032, d1=0.001, d2=0.000 g=0.025, a1=100, a2=100\n",
            ">1033, d1=0.000, d2=0.000 g=0.022, a1=100, a2=100\n",
            ">1034, d1=0.001, d2=0.000 g=0.026, a1=100, a2=100\n",
            ">1035, d1=0.000, d2=0.000 g=0.017, a1=100, a2=100\n",
            ">1036, d1=0.000, d2=0.000 g=0.022, a1=100, a2=100\n",
            ">1037, d1=0.000, d2=0.000 g=0.018, a1=100, a2=100\n",
            ">1038, d1=0.000, d2=0.000 g=0.021, a1=100, a2=100\n",
            ">1039, d1=0.000, d2=0.001 g=0.017, a1=100, a2=100\n",
            ">1040, d1=0.000, d2=0.001 g=0.023, a1=100, a2=100\n",
            ">1041, d1=0.000, d2=0.002 g=0.023, a1=100, a2=100\n",
            ">1042, d1=0.000, d2=0.000 g=0.014, a1=100, a2=100\n",
            ">1043, d1=0.000, d2=0.000 g=0.020, a1=100, a2=100\n",
            ">1044, d1=0.000, d2=0.000 g=0.021, a1=100, a2=100\n",
            ">1045, d1=0.000, d2=0.001 g=0.014, a1=100, a2=100\n",
            ">1046, d1=0.001, d2=0.000 g=0.022, a1=100, a2=100\n",
            ">1047, d1=0.000, d2=0.000 g=0.019, a1=100, a2=100\n",
            ">1048, d1=0.000, d2=0.000 g=0.023, a1=100, a2=100\n",
            ">1049, d1=0.000, d2=0.001 g=0.016, a1=100, a2=100\n",
            ">1050, d1=0.000, d2=0.000 g=0.025, a1=100, a2=100\n",
            ">1051, d1=0.000, d2=0.001 g=0.022, a1=100, a2=100\n",
            ">1052, d1=0.000, d2=0.000 g=0.016, a1=100, a2=100\n",
            ">1053, d1=0.000, d2=0.000 g=0.016, a1=100, a2=100\n",
            ">1054, d1=0.001, d2=0.000 g=0.034, a1=100, a2=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">1055, d1=0.000, d2=0.001 g=0.018, a1=100, a2=100\n",
            ">1056, d1=0.000, d2=0.001 g=0.018, a1=100, a2=100\n",
            ">1057, d1=0.000, d2=0.000 g=0.027, a1=100, a2=100\n",
            ">1058, d1=0.000, d2=0.000 g=0.023, a1=100, a2=100\n",
            ">1059, d1=0.000, d2=0.000 g=0.019, a1=100, a2=100\n",
            ">1060, d1=0.001, d2=0.000 g=0.018, a1=100, a2=100\n",
            ">1061, d1=0.000, d2=0.000 g=0.018, a1=100, a2=100\n",
            ">1062, d1=0.000, d2=0.000 g=0.019, a1=100, a2=100\n",
            ">1063, d1=0.000, d2=0.000 g=0.019, a1=100, a2=100\n",
            ">1064, d1=0.000, d2=0.000 g=0.028, a1=100, a2=100\n",
            ">1065, d1=0.000, d2=0.000 g=0.014, a1=100, a2=100\n",
            ">1066, d1=0.001, d2=0.000 g=0.021, a1=100, a2=100\n",
            ">1067, d1=0.000, d2=0.001 g=0.016, a1=100, a2=100\n",
            ">1068, d1=0.000, d2=0.001 g=0.013, a1=100, a2=100\n",
            ">1069, d1=0.000, d2=0.000 g=0.023, a1=100, a2=100\n",
            ">1070, d1=0.001, d2=0.001 g=0.016, a1=100, a2=100\n",
            ">1071, d1=0.000, d2=0.000 g=0.028, a1=100, a2=100\n",
            ">1072, d1=0.000, d2=0.002 g=0.019, a1=100, a2=100\n",
            ">1073, d1=0.001, d2=0.000 g=0.015, a1=100, a2=100\n",
            ">1074, d1=0.000, d2=0.000 g=0.018, a1=100, a2=100\n",
            ">1075, d1=0.000, d2=0.000 g=0.020, a1=100, a2=100\n",
            ">1076, d1=0.001, d2=0.000 g=0.022, a1=100, a2=100\n",
            ">1077, d1=0.001, d2=0.001 g=0.014, a1=100, a2=100\n",
            ">1078, d1=0.002, d2=0.000 g=0.019, a1=100, a2=100\n",
            ">1079, d1=0.000, d2=0.000 g=0.015, a1=100, a2=100\n",
            ">1080, d1=0.000, d2=0.000 g=0.013, a1=100, a2=100\n",
            ">1081, d1=0.000, d2=0.000 g=0.019, a1=100, a2=100\n",
            ">1082, d1=0.000, d2=0.000 g=0.011, a1=100, a2=100\n",
            ">1083, d1=0.000, d2=0.000 g=0.020, a1=100, a2=100\n",
            ">1084, d1=0.001, d2=0.000 g=0.013, a1=100, a2=100\n",
            ">1085, d1=0.000, d2=0.002 g=0.020, a1=100, a2=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">1086, d1=0.000, d2=0.000 g=0.022, a1=100, a2=100\n",
            ">1087, d1=0.000, d2=0.001 g=0.023, a1=100, a2=100\n",
            ">1088, d1=0.001, d2=0.000 g=0.022, a1=100, a2=100\n",
            ">1089, d1=0.001, d2=0.000 g=0.009, a1=100, a2=100\n",
            ">1090, d1=0.000, d2=0.000 g=0.015, a1=100, a2=100\n",
            ">1091, d1=0.000, d2=0.003 g=0.012, a1=100, a2=100\n",
            ">1092, d1=0.000, d2=0.000 g=0.020, a1=100, a2=100\n",
            ">1093, d1=0.001, d2=0.000 g=0.026, a1=100, a2=100\n",
            ">1094, d1=0.000, d2=0.000 g=0.035, a1=100, a2=100\n",
            ">1095, d1=0.000, d2=0.000 g=0.023, a1=100, a2=100\n",
            ">1096, d1=0.001, d2=0.000 g=0.025, a1=100, a2=100\n",
            ">1097, d1=0.001, d2=0.000 g=0.029, a1=100, a2=100\n",
            ">1098, d1=0.001, d2=0.000 g=0.026, a1=100, a2=100\n",
            ">1099, d1=0.000, d2=0.000 g=0.016, a1=100, a2=100\n",
            ">1100, d1=0.000, d2=0.000 g=0.019, a1=100, a2=100\n",
            ">1101, d1=0.000, d2=0.001 g=0.025, a1=100, a2=100\n",
            ">1102, d1=0.000, d2=0.000 g=0.018, a1=100, a2=100\n",
            ">1103, d1=0.000, d2=0.000 g=0.019, a1=100, a2=100\n",
            ">1104, d1=0.000, d2=0.000 g=0.029, a1=100, a2=100\n",
            ">1105, d1=0.000, d2=0.000 g=0.015, a1=100, a2=100\n",
            ">1106, d1=0.000, d2=0.000 g=0.032, a1=100, a2=100\n",
            ">1107, d1=0.000, d2=0.000 g=0.027, a1=100, a2=100\n",
            ">1108, d1=0.000, d2=0.000 g=0.022, a1=100, a2=100\n",
            ">1109, d1=0.000, d2=0.000 g=0.011, a1=100, a2=100\n",
            ">1110, d1=0.000, d2=0.000 g=0.014, a1=100, a2=100\n",
            ">1111, d1=0.000, d2=0.000 g=0.012, a1=100, a2=100\n",
            ">1112, d1=0.000, d2=0.000 g=0.015, a1=100, a2=100\n",
            ">1113, d1=0.001, d2=0.000 g=0.015, a1=100, a2=100\n",
            ">1114, d1=0.000, d2=0.000 g=0.018, a1=100, a2=100\n",
            ">1115, d1=0.000, d2=0.001 g=0.018, a1=100, a2=100\n",
            ">1116, d1=0.000, d2=0.000 g=0.021, a1=100, a2=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">1117, d1=0.000, d2=0.001 g=0.017, a1=100, a2=100\n",
            ">1118, d1=0.002, d2=0.001 g=0.014, a1=100, a2=100\n",
            ">1119, d1=0.000, d2=0.000 g=0.018, a1=100, a2=100\n",
            ">1120, d1=0.000, d2=0.001 g=0.020, a1=100, a2=100\n",
            ">1121, d1=0.000, d2=0.000 g=0.013, a1=100, a2=100\n",
            ">1122, d1=0.000, d2=0.001 g=0.015, a1=100, a2=100\n",
            ">1123, d1=0.001, d2=0.000 g=0.019, a1=100, a2=100\n",
            ">1124, d1=0.000, d2=0.000 g=0.025, a1=100, a2=100\n",
            ">1125, d1=0.001, d2=0.001 g=0.015, a1=100, a2=100\n",
            ">1126, d1=0.000, d2=0.001 g=0.018, a1=100, a2=100\n",
            ">1127, d1=0.001, d2=0.000 g=0.015, a1=100, a2=100\n",
            ">1128, d1=0.000, d2=0.000 g=0.016, a1=100, a2=100\n",
            ">1129, d1=0.000, d2=0.000 g=0.017, a1=100, a2=100\n",
            ">1130, d1=0.001, d2=0.000 g=0.019, a1=100, a2=100\n",
            ">1131, d1=0.000, d2=0.000 g=0.020, a1=100, a2=100\n",
            ">1132, d1=0.000, d2=0.000 g=0.019, a1=100, a2=100\n",
            ">1133, d1=0.001, d2=0.000 g=0.032, a1=100, a2=100\n",
            ">1134, d1=0.000, d2=0.000 g=0.025, a1=100, a2=100\n",
            ">1135, d1=0.000, d2=0.000 g=0.013, a1=100, a2=100\n",
            ">1136, d1=0.000, d2=0.000 g=0.016, a1=100, a2=100\n",
            ">1137, d1=0.000, d2=0.000 g=0.017, a1=100, a2=100\n",
            ">1138, d1=0.001, d2=0.000 g=0.015, a1=100, a2=100\n",
            ">1139, d1=0.001, d2=0.000 g=0.013, a1=100, a2=100\n",
            ">1140, d1=0.000, d2=0.000 g=0.015, a1=100, a2=100\n",
            ">1141, d1=0.001, d2=0.000 g=0.011, a1=100, a2=100\n",
            ">1142, d1=0.000, d2=0.000 g=0.015, a1=100, a2=100\n",
            ">1143, d1=0.000, d2=0.000 g=0.012, a1=100, a2=100\n",
            ">1144, d1=0.000, d2=0.000 g=0.020, a1=100, a2=100\n",
            ">1145, d1=0.000, d2=0.000 g=0.012, a1=100, a2=100\n",
            ">1146, d1=0.000, d2=0.000 g=0.014, a1=100, a2=100\n",
            ">1147, d1=0.000, d2=0.002 g=0.017, a1=100, a2=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">1148, d1=0.000, d2=0.000 g=0.012, a1=100, a2=100\n",
            ">1149, d1=0.000, d2=0.000 g=0.010, a1=100, a2=100\n",
            ">1150, d1=0.000, d2=0.000 g=0.011, a1=100, a2=100\n",
            ">1151, d1=0.000, d2=0.001 g=0.010, a1=100, a2=100\n",
            ">1152, d1=0.000, d2=0.000 g=0.017, a1=100, a2=100\n",
            ">1153, d1=0.000, d2=0.001 g=0.013, a1=100, a2=100\n",
            ">1154, d1=0.000, d2=0.000 g=0.020, a1=100, a2=100\n",
            ">1155, d1=0.000, d2=0.000 g=0.012, a1=100, a2=100\n",
            ">1156, d1=0.000, d2=0.000 g=0.016, a1=100, a2=100\n",
            ">1157, d1=0.000, d2=0.000 g=0.011, a1=100, a2=100\n",
            ">1158, d1=0.000, d2=0.000 g=0.010, a1=100, a2=100\n",
            ">1159, d1=0.000, d2=0.000 g=0.018, a1=100, a2=100\n",
            ">1160, d1=0.000, d2=0.000 g=0.013, a1=100, a2=100\n",
            ">1161, d1=0.000, d2=0.000 g=0.011, a1=100, a2=100\n",
            ">1162, d1=0.000, d2=0.000 g=0.010, a1=100, a2=100\n",
            ">1163, d1=0.000, d2=0.000 g=0.014, a1=100, a2=100\n",
            ">1164, d1=0.000, d2=0.000 g=0.009, a1=100, a2=100\n",
            ">1165, d1=0.000, d2=0.000 g=0.010, a1=100, a2=100\n",
            ">1166, d1=0.000, d2=0.000 g=0.009, a1=100, a2=100\n",
            ">1167, d1=0.000, d2=0.000 g=0.010, a1=100, a2=100\n",
            ">1168, d1=0.000, d2=0.000 g=0.010, a1=100, a2=100\n",
            ">1169, d1=0.000, d2=0.001 g=0.023, a1=100, a2=100\n",
            ">1170, d1=0.000, d2=0.000 g=0.019, a1=100, a2=100\n",
            ">1171, d1=0.000, d2=0.000 g=0.013, a1=100, a2=100\n",
            ">1172, d1=0.000, d2=0.000 g=0.021, a1=100, a2=100\n",
            ">1173, d1=0.000, d2=0.000 g=0.014, a1=100, a2=100\n",
            ">1174, d1=0.001, d2=0.001 g=0.010, a1=100, a2=100\n",
            ">1175, d1=0.000, d2=0.000 g=0.012, a1=100, a2=100\n",
            ">1176, d1=0.000, d2=0.000 g=0.015, a1=100, a2=100\n",
            ">1177, d1=0.000, d2=0.001 g=0.021, a1=100, a2=100\n",
            ">1178, d1=0.000, d2=0.000 g=0.014, a1=100, a2=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">1179, d1=0.000, d2=0.000 g=0.013, a1=100, a2=100\n",
            ">1180, d1=0.000, d2=0.000 g=0.017, a1=100, a2=100\n",
            ">1181, d1=0.000, d2=0.000 g=0.015, a1=100, a2=100\n",
            ">1182, d1=0.001, d2=0.000 g=0.012, a1=100, a2=100\n",
            ">1183, d1=0.000, d2=0.000 g=0.012, a1=100, a2=100\n",
            ">1184, d1=0.000, d2=0.000 g=0.015, a1=100, a2=100\n",
            ">1185, d1=0.000, d2=0.001 g=0.011, a1=100, a2=100\n",
            ">1186, d1=0.000, d2=0.000 g=0.016, a1=100, a2=100\n",
            ">1187, d1=0.000, d2=0.001 g=0.016, a1=100, a2=100\n",
            ">1188, d1=0.000, d2=0.000 g=0.014, a1=100, a2=100\n",
            ">1189, d1=0.000, d2=0.001 g=0.014, a1=100, a2=100\n",
            ">1190, d1=0.000, d2=0.000 g=0.017, a1=100, a2=100\n",
            ">1191, d1=0.001, d2=0.000 g=0.013, a1=100, a2=100\n",
            ">1192, d1=0.000, d2=0.000 g=0.013, a1=100, a2=100\n",
            ">1193, d1=0.001, d2=0.000 g=0.019, a1=100, a2=100\n",
            ">1194, d1=0.000, d2=0.000 g=0.010, a1=100, a2=100\n",
            ">1195, d1=0.000, d2=0.000 g=0.012, a1=100, a2=100\n",
            ">1196, d1=0.001, d2=0.000 g=0.013, a1=100, a2=100\n",
            ">1197, d1=0.000, d2=0.000 g=0.007, a1=100, a2=100\n",
            ">1198, d1=0.000, d2=0.000 g=0.014, a1=100, a2=100\n",
            ">1199, d1=0.000, d2=0.000 g=0.011, a1=100, a2=100\n",
            ">1200, d1=0.001, d2=0.000 g=0.010, a1=100, a2=100\n",
            ">1201, d1=0.000, d2=0.000 g=0.009, a1=100, a2=100\n",
            ">1202, d1=0.001, d2=0.000 g=0.015, a1=100, a2=100\n",
            ">1203, d1=0.001, d2=0.001 g=0.015, a1=100, a2=100\n",
            ">1204, d1=0.000, d2=0.001 g=0.008, a1=100, a2=100\n",
            ">1205, d1=0.000, d2=0.001 g=0.007, a1=100, a2=100\n",
            ">1206, d1=0.000, d2=0.000 g=0.015, a1=100, a2=100\n",
            ">1207, d1=0.000, d2=0.000 g=0.014, a1=100, a2=100\n",
            ">1208, d1=0.000, d2=0.000 g=0.011, a1=100, a2=100\n",
            ">1209, d1=0.000, d2=0.000 g=0.020, a1=100, a2=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">1210, d1=0.000, d2=0.000 g=0.013, a1=100, a2=100\n",
            ">1211, d1=0.000, d2=0.000 g=0.013, a1=100, a2=100\n",
            ">1212, d1=0.000, d2=0.001 g=0.015, a1=100, a2=100\n",
            ">1213, d1=0.000, d2=0.000 g=0.012, a1=100, a2=100\n",
            ">1214, d1=0.001, d2=0.000 g=0.033, a1=100, a2=100\n",
            ">1215, d1=0.000, d2=0.000 g=0.008, a1=100, a2=100\n",
            ">1216, d1=0.001, d2=0.000 g=0.011, a1=100, a2=100\n",
            ">1217, d1=0.000, d2=0.000 g=0.009, a1=100, a2=100\n",
            ">1218, d1=0.000, d2=0.000 g=0.013, a1=100, a2=100\n",
            ">1219, d1=0.000, d2=0.000 g=0.015, a1=100, a2=100\n",
            ">1220, d1=0.000, d2=0.001 g=0.021, a1=100, a2=100\n",
            ">1221, d1=0.001, d2=0.000 g=0.016, a1=100, a2=100\n",
            ">1222, d1=0.000, d2=0.001 g=0.015, a1=100, a2=100\n",
            ">1223, d1=0.000, d2=0.001 g=0.016, a1=100, a2=100\n",
            ">1224, d1=0.000, d2=0.000 g=0.018, a1=100, a2=100\n",
            ">1225, d1=0.000, d2=0.000 g=0.016, a1=100, a2=100\n",
            ">1226, d1=0.000, d2=0.000 g=0.029, a1=100, a2=100\n",
            ">1227, d1=0.000, d2=0.000 g=0.009, a1=100, a2=100\n",
            ">1228, d1=0.000, d2=0.000 g=0.022, a1=100, a2=100\n",
            ">1229, d1=0.001, d2=0.000 g=0.018, a1=100, a2=100\n",
            ">1230, d1=0.000, d2=0.001 g=0.014, a1=100, a2=100\n",
            ">1231, d1=0.001, d2=0.000 g=0.015, a1=100, a2=100\n",
            ">1232, d1=0.000, d2=0.000 g=0.014, a1=100, a2=100\n",
            ">1233, d1=0.000, d2=0.001 g=0.008, a1=100, a2=100\n",
            ">1234, d1=0.000, d2=0.000 g=0.019, a1=100, a2=100\n",
            ">1235, d1=0.000, d2=0.000 g=0.014, a1=100, a2=100\n",
            ">1236, d1=0.000, d2=0.001 g=0.013, a1=100, a2=100\n",
            ">1237, d1=0.000, d2=0.001 g=0.018, a1=100, a2=100\n",
            ">1238, d1=0.000, d2=0.000 g=0.022, a1=100, a2=100\n",
            ">1239, d1=0.000, d2=0.000 g=0.019, a1=100, a2=100\n",
            ">1240, d1=0.000, d2=0.000 g=0.020, a1=100, a2=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">1241, d1=0.000, d2=0.000 g=0.014, a1=100, a2=100\n",
            ">1242, d1=0.000, d2=0.000 g=0.011, a1=100, a2=100\n",
            ">1243, d1=0.001, d2=0.000 g=0.014, a1=100, a2=100\n",
            ">1244, d1=0.000, d2=0.000 g=0.032, a1=100, a2=100\n",
            ">1245, d1=0.000, d2=0.000 g=0.025, a1=100, a2=100\n",
            ">1246, d1=0.000, d2=0.000 g=0.020, a1=100, a2=100\n",
            ">1247, d1=0.000, d2=0.000 g=0.016, a1=100, a2=100\n",
            ">1248, d1=0.001, d2=0.000 g=0.021, a1=100, a2=100\n",
            ">1249, d1=0.000, d2=0.001 g=0.015, a1=100, a2=100\n",
            ">1250, d1=0.000, d2=0.001 g=0.013, a1=100, a2=100\n",
            ">1251, d1=0.000, d2=0.000 g=0.026, a1=100, a2=100\n",
            ">1252, d1=0.000, d2=0.000 g=0.013, a1=100, a2=100\n",
            ">1253, d1=0.000, d2=0.000 g=0.011, a1=100, a2=100\n",
            ">1254, d1=0.000, d2=0.000 g=0.011, a1=100, a2=100\n",
            ">1255, d1=0.000, d2=0.000 g=0.017, a1=100, a2=100\n",
            ">1256, d1=0.000, d2=0.001 g=0.025, a1=100, a2=100\n",
            ">1257, d1=0.000, d2=0.001 g=0.021, a1=100, a2=100\n",
            ">1258, d1=0.000, d2=0.000 g=0.009, a1=100, a2=100\n",
            ">1259, d1=0.002, d2=0.001 g=0.013, a1=100, a2=100\n",
            ">1260, d1=0.001, d2=0.000 g=0.015, a1=100, a2=100\n",
            ">1261, d1=0.001, d2=0.001 g=0.015, a1=100, a2=100\n",
            ">1262, d1=0.001, d2=0.000 g=0.011, a1=100, a2=100\n",
            ">1263, d1=0.000, d2=0.000 g=0.010, a1=100, a2=100\n",
            ">1264, d1=0.001, d2=0.000 g=0.012, a1=100, a2=100\n",
            ">1265, d1=0.000, d2=0.001 g=0.011, a1=100, a2=100\n",
            ">1266, d1=0.000, d2=0.000 g=0.009, a1=100, a2=100\n",
            ">1267, d1=0.000, d2=0.001 g=0.011, a1=100, a2=100\n",
            ">1268, d1=0.000, d2=0.000 g=0.014, a1=100, a2=100\n",
            ">1269, d1=0.000, d2=0.000 g=0.019, a1=100, a2=100\n",
            ">1270, d1=0.000, d2=0.000 g=0.013, a1=100, a2=100\n",
            ">1271, d1=0.000, d2=0.000 g=0.020, a1=100, a2=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">1272, d1=0.000, d2=0.001 g=0.013, a1=100, a2=100\n",
            ">1273, d1=0.000, d2=0.000 g=0.009, a1=100, a2=100\n",
            ">1274, d1=0.000, d2=0.000 g=0.016, a1=100, a2=100\n",
            ">1275, d1=0.000, d2=0.000 g=0.007, a1=100, a2=100\n",
            ">1276, d1=0.000, d2=0.000 g=0.016, a1=100, a2=100\n",
            ">1277, d1=0.000, d2=0.000 g=0.017, a1=100, a2=100\n",
            ">1278, d1=0.000, d2=0.000 g=0.030, a1=100, a2=100\n",
            ">1279, d1=0.000, d2=0.002 g=0.025, a1=100, a2=100\n",
            ">1280, d1=0.000, d2=0.000 g=0.025, a1=100, a2=100\n",
            ">1281, d1=0.000, d2=0.001 g=0.024, a1=100, a2=100\n",
            ">1282, d1=0.000, d2=0.000 g=0.021, a1=100, a2=100\n",
            ">1283, d1=0.000, d2=0.000 g=0.026, a1=100, a2=100\n",
            ">1284, d1=0.000, d2=0.000 g=0.023, a1=100, a2=100\n",
            ">1285, d1=0.000, d2=0.000 g=0.022, a1=100, a2=100\n",
            ">1286, d1=0.000, d2=0.000 g=0.027, a1=100, a2=100\n",
            ">1287, d1=0.001, d2=0.000 g=0.016, a1=100, a2=100\n",
            ">1288, d1=0.000, d2=0.000 g=0.026, a1=100, a2=100\n",
            ">1289, d1=0.000, d2=0.000 g=0.034, a1=100, a2=100\n",
            ">1290, d1=0.000, d2=0.000 g=0.016, a1=100, a2=100\n",
            ">1291, d1=0.001, d2=0.001 g=0.021, a1=100, a2=100\n",
            ">1292, d1=0.000, d2=0.000 g=0.025, a1=100, a2=100\n",
            ">1293, d1=0.001, d2=0.000 g=0.017, a1=100, a2=100\n",
            ">1294, d1=0.000, d2=0.000 g=0.015, a1=100, a2=100\n",
            ">1295, d1=0.000, d2=0.001 g=0.012, a1=100, a2=100\n",
            ">1296, d1=0.000, d2=0.000 g=0.011, a1=100, a2=100\n",
            ">1297, d1=0.000, d2=0.000 g=0.017, a1=100, a2=100\n",
            ">1298, d1=0.000, d2=0.000 g=0.023, a1=100, a2=100\n",
            ">1299, d1=0.000, d2=0.000 g=0.013, a1=100, a2=100\n",
            ">1300, d1=0.000, d2=0.000 g=0.014, a1=100, a2=100\n",
            ">1301, d1=0.000, d2=0.001 g=0.016, a1=100, a2=100\n",
            ">1302, d1=0.000, d2=0.001 g=0.015, a1=100, a2=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">1303, d1=0.000, d2=0.000 g=0.020, a1=100, a2=100\n",
            ">1304, d1=0.000, d2=0.000 g=0.018, a1=100, a2=100\n",
            ">1305, d1=0.000, d2=0.001 g=0.031, a1=100, a2=100\n",
            ">1306, d1=0.001, d2=0.001 g=0.021, a1=100, a2=100\n",
            ">1307, d1=0.000, d2=0.001 g=0.015, a1=100, a2=100\n",
            ">1308, d1=0.000, d2=0.002 g=0.026, a1=100, a2=100\n",
            ">1309, d1=0.000, d2=0.000 g=0.053, a1=100, a2=100\n",
            ">1310, d1=0.001, d2=0.001 g=0.052, a1=100, a2=100\n",
            ">1311, d1=0.000, d2=0.000 g=0.026, a1=100, a2=100\n",
            ">1312, d1=0.000, d2=0.001 g=0.047, a1=100, a2=100\n",
            ">1313, d1=0.000, d2=0.000 g=0.032, a1=100, a2=100\n",
            ">1314, d1=0.000, d2=0.000 g=0.021, a1=100, a2=100\n",
            ">1315, d1=0.000, d2=0.000 g=0.021, a1=100, a2=100\n",
            ">1316, d1=0.000, d2=0.000 g=0.027, a1=100, a2=100\n",
            ">1317, d1=0.001, d2=0.000 g=0.025, a1=100, a2=100\n",
            ">1318, d1=0.000, d2=0.001 g=0.031, a1=100, a2=100\n",
            ">1319, d1=0.000, d2=0.000 g=0.016, a1=100, a2=100\n",
            ">1320, d1=0.000, d2=0.001 g=0.025, a1=100, a2=100\n",
            ">1321, d1=0.000, d2=0.000 g=0.016, a1=100, a2=100\n",
            ">1322, d1=0.000, d2=0.001 g=0.018, a1=100, a2=100\n",
            ">1323, d1=0.001, d2=0.000 g=0.023, a1=100, a2=100\n",
            ">1324, d1=0.000, d2=0.001 g=0.030, a1=100, a2=100\n",
            ">1325, d1=0.000, d2=0.001 g=0.036, a1=100, a2=100\n",
            ">1326, d1=0.001, d2=0.001 g=0.015, a1=100, a2=100\n",
            ">1327, d1=0.001, d2=0.000 g=0.035, a1=100, a2=100\n",
            ">1328, d1=0.000, d2=0.000 g=0.037, a1=100, a2=100\n",
            ">1329, d1=0.000, d2=0.000 g=0.023, a1=100, a2=100\n",
            ">1330, d1=0.001, d2=0.001 g=0.033, a1=100, a2=100\n",
            ">1331, d1=0.000, d2=0.001 g=0.020, a1=100, a2=100\n",
            ">1332, d1=0.000, d2=0.001 g=0.014, a1=100, a2=100\n",
            ">1333, d1=0.000, d2=0.001 g=0.013, a1=100, a2=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">1334, d1=0.002, d2=0.000 g=0.010, a1=100, a2=100\n",
            ">1335, d1=0.000, d2=0.001 g=0.027, a1=100, a2=100\n",
            ">1336, d1=0.000, d2=0.001 g=0.020, a1=100, a2=100\n",
            ">1337, d1=0.000, d2=0.001 g=0.010, a1=100, a2=100\n",
            ">1338, d1=0.001, d2=0.000 g=0.020, a1=100, a2=100\n",
            ">1339, d1=0.000, d2=0.001 g=0.007, a1=100, a2=100\n",
            ">1340, d1=0.001, d2=0.001 g=0.012, a1=100, a2=100\n",
            ">1341, d1=0.000, d2=0.001 g=0.015, a1=100, a2=100\n",
            ">1342, d1=0.000, d2=0.000 g=0.012, a1=100, a2=100\n",
            ">1343, d1=0.001, d2=0.000 g=0.018, a1=100, a2=100\n",
            ">1344, d1=0.000, d2=0.000 g=0.010, a1=100, a2=100\n",
            ">1345, d1=0.000, d2=0.000 g=0.013, a1=100, a2=100\n",
            ">1346, d1=0.001, d2=0.002 g=0.015, a1=100, a2=100\n",
            ">1347, d1=0.001, d2=0.001 g=0.015, a1=100, a2=100\n",
            ">1348, d1=0.003, d2=0.000 g=0.009, a1=100, a2=100\n",
            ">1349, d1=0.000, d2=0.000 g=0.009, a1=100, a2=100\n",
            ">1350, d1=0.000, d2=0.001 g=0.009, a1=100, a2=100\n",
            ">1351, d1=0.007, d2=0.001 g=0.008, a1=99, a2=100\n",
            ">1352, d1=0.002, d2=0.001 g=0.006, a1=100, a2=100\n",
            ">1353, d1=0.000, d2=0.001 g=0.003, a1=100, a2=100\n",
            ">1354, d1=0.000, d2=0.002 g=0.008, a1=100, a2=100\n",
            ">1355, d1=0.000, d2=0.000 g=0.017, a1=100, a2=100\n",
            ">1356, d1=0.000, d2=0.000 g=0.009, a1=100, a2=100\n",
            ">1357, d1=0.000, d2=0.003 g=0.024, a1=100, a2=100\n",
            ">1358, d1=0.000, d2=0.000 g=0.018, a1=100, a2=100\n",
            ">1359, d1=0.000, d2=0.000 g=0.013, a1=100, a2=100\n",
            ">1360, d1=0.001, d2=0.000 g=0.016, a1=100, a2=100\n",
            ">1361, d1=0.000, d2=0.000 g=0.009, a1=100, a2=100\n",
            ">1362, d1=0.000, d2=0.001 g=0.026, a1=100, a2=100\n",
            ">1363, d1=0.000, d2=0.000 g=0.013, a1=100, a2=100\n",
            ">1364, d1=0.000, d2=0.000 g=0.021, a1=100, a2=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">1365, d1=0.000, d2=0.000 g=0.010, a1=100, a2=100\n",
            ">1366, d1=0.001, d2=0.000 g=0.010, a1=100, a2=100\n",
            ">1367, d1=0.000, d2=0.000 g=0.007, a1=100, a2=100\n",
            ">1368, d1=0.001, d2=0.001 g=0.013, a1=100, a2=100\n",
            ">1369, d1=0.000, d2=0.000 g=0.019, a1=100, a2=100\n",
            ">1370, d1=0.007, d2=0.000 g=0.005, a1=100, a2=100\n",
            ">1371, d1=0.000, d2=0.000 g=0.004, a1=100, a2=100\n",
            ">1372, d1=0.000, d2=0.002 g=0.003, a1=100, a2=100\n",
            ">1373, d1=0.000, d2=0.000 g=0.005, a1=100, a2=100\n",
            ">1374, d1=0.000, d2=0.000 g=0.003, a1=100, a2=100\n",
            ">1375, d1=0.000, d2=0.000 g=0.003, a1=100, a2=100\n",
            ">1376, d1=0.000, d2=0.000 g=0.002, a1=100, a2=100\n",
            ">1377, d1=0.000, d2=0.000 g=0.003, a1=100, a2=100\n",
            ">1378, d1=0.000, d2=0.000 g=0.008, a1=100, a2=100\n",
            ">1379, d1=0.000, d2=0.001 g=0.003, a1=100, a2=100\n",
            ">1380, d1=0.001, d2=0.000 g=0.003, a1=100, a2=100\n",
            ">1381, d1=0.000, d2=0.000 g=0.003, a1=100, a2=100\n",
            ">1382, d1=0.000, d2=0.000 g=0.006, a1=100, a2=100\n",
            ">1383, d1=0.000, d2=0.000 g=0.003, a1=100, a2=100\n",
            ">1384, d1=0.001, d2=0.000 g=0.004, a1=100, a2=100\n",
            ">1385, d1=0.001, d2=0.000 g=0.004, a1=100, a2=100\n",
            ">1386, d1=0.000, d2=0.001 g=0.010, a1=100, a2=100\n",
            ">1387, d1=0.000, d2=0.000 g=0.005, a1=100, a2=100\n",
            ">1388, d1=0.000, d2=0.000 g=0.011, a1=100, a2=100\n",
            ">1389, d1=0.000, d2=0.000 g=0.011, a1=100, a2=100\n",
            ">1390, d1=0.000, d2=0.000 g=0.005, a1=100, a2=100\n",
            ">1391, d1=0.000, d2=0.000 g=0.007, a1=100, a2=100\n",
            ">1392, d1=0.000, d2=0.001 g=0.007, a1=100, a2=100\n",
            ">1393, d1=0.000, d2=0.001 g=0.006, a1=100, a2=100\n",
            ">1394, d1=0.001, d2=0.000 g=0.006, a1=100, a2=100\n",
            ">1395, d1=0.000, d2=0.000 g=0.006, a1=100, a2=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">1396, d1=0.000, d2=0.000 g=0.006, a1=100, a2=100\n",
            ">1397, d1=0.000, d2=0.000 g=0.004, a1=100, a2=100\n",
            ">1398, d1=0.000, d2=0.000 g=0.006, a1=100, a2=100\n",
            ">1399, d1=0.000, d2=0.000 g=0.006, a1=100, a2=100\n",
            ">1400, d1=0.001, d2=0.000 g=0.016, a1=100, a2=100\n",
            ">1401, d1=0.000, d2=0.000 g=0.004, a1=100, a2=100\n",
            ">1402, d1=0.000, d2=0.000 g=0.004, a1=100, a2=100\n",
            ">1403, d1=0.000, d2=0.000 g=0.007, a1=100, a2=100\n",
            ">1404, d1=0.000, d2=0.000 g=0.009, a1=100, a2=100\n",
            ">1405, d1=0.000, d2=0.000 g=0.014, a1=100, a2=100\n",
            ">1406, d1=0.000, d2=0.000 g=0.004, a1=100, a2=100\n",
            ">1407, d1=0.000, d2=0.000 g=0.005, a1=100, a2=100\n",
            ">1408, d1=0.000, d2=0.000 g=0.005, a1=100, a2=100\n",
            ">1409, d1=0.001, d2=0.000 g=0.005, a1=100, a2=100\n",
            ">1410, d1=0.000, d2=0.000 g=0.004, a1=100, a2=100\n",
            ">1411, d1=0.000, d2=0.000 g=0.006, a1=100, a2=100\n",
            ">1412, d1=0.000, d2=0.000 g=0.005, a1=100, a2=100\n",
            ">1413, d1=0.000, d2=0.000 g=0.004, a1=100, a2=100\n",
            ">1414, d1=0.000, d2=0.000 g=0.006, a1=100, a2=100\n",
            ">1415, d1=0.000, d2=0.001 g=0.007, a1=100, a2=100\n",
            ">1416, d1=0.000, d2=0.000 g=0.008, a1=100, a2=100\n",
            ">1417, d1=0.000, d2=0.000 g=0.007, a1=100, a2=100\n",
            ">1418, d1=0.000, d2=0.000 g=0.011, a1=100, a2=100\n",
            ">1419, d1=0.000, d2=0.000 g=0.006, a1=100, a2=100\n",
            ">1420, d1=0.000, d2=0.000 g=0.022, a1=100, a2=100\n",
            ">1421, d1=0.000, d2=0.000 g=0.015, a1=100, a2=100\n",
            ">1422, d1=0.000, d2=0.000 g=0.007, a1=100, a2=100\n",
            ">1423, d1=0.000, d2=0.000 g=0.007, a1=100, a2=100\n",
            ">1424, d1=0.000, d2=0.001 g=0.006, a1=100, a2=100\n",
            ">1425, d1=0.000, d2=0.000 g=0.007, a1=100, a2=100\n",
            ">1426, d1=0.000, d2=0.000 g=0.008, a1=100, a2=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">1427, d1=0.000, d2=0.000 g=0.007, a1=100, a2=100\n",
            ">1428, d1=0.000, d2=0.000 g=0.010, a1=100, a2=100\n",
            ">1429, d1=0.001, d2=0.001 g=0.014, a1=100, a2=100\n",
            ">1430, d1=0.000, d2=0.000 g=0.009, a1=100, a2=100\n",
            ">1431, d1=0.003, d2=0.000 g=0.006, a1=100, a2=100\n",
            ">1432, d1=0.000, d2=0.000 g=0.007, a1=100, a2=100\n",
            ">1433, d1=0.000, d2=0.000 g=0.004, a1=100, a2=100\n",
            ">1434, d1=0.000, d2=0.000 g=0.006, a1=100, a2=100\n",
            ">1435, d1=0.000, d2=0.001 g=0.010, a1=100, a2=100\n",
            ">1436, d1=0.000, d2=0.000 g=0.006, a1=100, a2=100\n",
            ">1437, d1=0.000, d2=0.001 g=0.010, a1=100, a2=100\n",
            ">1438, d1=0.000, d2=0.000 g=0.004, a1=100, a2=100\n",
            ">1439, d1=0.000, d2=0.000 g=0.005, a1=100, a2=100\n",
            ">1440, d1=0.000, d2=0.000 g=0.006, a1=100, a2=100\n",
            ">1441, d1=0.000, d2=0.000 g=0.007, a1=100, a2=100\n",
            ">1442, d1=0.000, d2=0.000 g=0.010, a1=100, a2=100\n",
            ">1443, d1=0.000, d2=0.000 g=0.007, a1=100, a2=100\n",
            ">1444, d1=0.000, d2=0.000 g=0.010, a1=100, a2=100\n",
            ">1445, d1=0.000, d2=0.001 g=0.015, a1=100, a2=100\n",
            ">1446, d1=0.000, d2=0.000 g=0.013, a1=100, a2=100\n",
            ">1447, d1=0.000, d2=0.000 g=0.014, a1=100, a2=100\n",
            ">1448, d1=0.000, d2=0.000 g=0.019, a1=100, a2=100\n",
            ">1449, d1=0.000, d2=0.000 g=0.014, a1=100, a2=100\n",
            ">1450, d1=0.001, d2=0.001 g=0.007, a1=100, a2=100\n",
            ">1451, d1=0.000, d2=0.000 g=0.012, a1=100, a2=100\n",
            ">1452, d1=0.000, d2=0.001 g=0.013, a1=100, a2=100\n",
            ">1453, d1=0.000, d2=0.000 g=0.011, a1=100, a2=100\n",
            ">1454, d1=0.000, d2=0.000 g=0.009, a1=100, a2=100\n",
            ">1455, d1=0.000, d2=0.000 g=0.010, a1=100, a2=100\n",
            ">1456, d1=0.000, d2=0.000 g=0.015, a1=100, a2=100\n",
            ">1457, d1=0.000, d2=0.001 g=0.016, a1=100, a2=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">1458, d1=0.000, d2=0.000 g=0.012, a1=100, a2=100\n",
            ">1459, d1=0.000, d2=0.000 g=0.018, a1=100, a2=100\n",
            ">1460, d1=0.001, d2=0.000 g=0.012, a1=100, a2=100\n",
            ">1461, d1=0.000, d2=0.000 g=0.012, a1=100, a2=100\n",
            ">1462, d1=0.000, d2=0.000 g=0.026, a1=100, a2=100\n",
            ">1463, d1=0.001, d2=0.000 g=0.015, a1=100, a2=100\n",
            ">1464, d1=0.000, d2=0.000 g=0.015, a1=100, a2=100\n",
            ">1465, d1=0.002, d2=0.000 g=0.011, a1=100, a2=100\n",
            ">1466, d1=0.002, d2=0.002 g=0.012, a1=100, a2=100\n",
            ">1467, d1=0.000, d2=0.000 g=0.011, a1=100, a2=100\n",
            ">1468, d1=0.000, d2=0.000 g=0.011, a1=100, a2=100\n",
            ">1469, d1=0.001, d2=0.000 g=0.007, a1=100, a2=100\n",
            ">1470, d1=0.000, d2=0.000 g=0.014, a1=100, a2=100\n",
            ">1471, d1=0.000, d2=0.000 g=0.012, a1=100, a2=100\n",
            ">1472, d1=0.000, d2=0.001 g=0.009, a1=100, a2=100\n",
            ">1473, d1=0.000, d2=0.000 g=0.010, a1=100, a2=100\n",
            ">1474, d1=0.000, d2=0.001 g=0.008, a1=100, a2=100\n",
            ">1475, d1=0.000, d2=0.000 g=0.006, a1=100, a2=100\n",
            ">1476, d1=0.000, d2=0.000 g=0.013, a1=100, a2=100\n",
            ">1477, d1=0.000, d2=0.000 g=0.016, a1=100, a2=100\n",
            ">1478, d1=0.000, d2=0.000 g=0.021, a1=100, a2=100\n",
            ">1479, d1=0.002, d2=0.000 g=0.012, a1=100, a2=100\n",
            ">1480, d1=0.001, d2=0.001 g=0.020, a1=100, a2=100\n",
            ">1481, d1=0.000, d2=0.000 g=0.012, a1=100, a2=100\n",
            ">1482, d1=0.001, d2=0.000 g=0.010, a1=100, a2=100\n",
            ">1483, d1=0.000, d2=0.001 g=0.007, a1=100, a2=100\n",
            ">1484, d1=0.000, d2=0.002 g=0.025, a1=100, a2=100\n",
            ">1485, d1=0.000, d2=0.001 g=0.014, a1=100, a2=100\n",
            ">1486, d1=0.000, d2=0.000 g=0.017, a1=100, a2=100\n",
            ">1487, d1=0.002, d2=0.002 g=0.034, a1=100, a2=100\n",
            ">1488, d1=0.000, d2=0.000 g=0.045, a1=100, a2=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">1489, d1=0.000, d2=0.000 g=0.031, a1=100, a2=100\n",
            ">1490, d1=0.000, d2=0.000 g=0.034, a1=100, a2=100\n",
            ">1491, d1=0.000, d2=0.000 g=0.022, a1=100, a2=100\n",
            ">1492, d1=0.000, d2=0.000 g=0.031, a1=100, a2=100\n",
            ">1493, d1=0.000, d2=0.000 g=0.028, a1=100, a2=100\n",
            ">1494, d1=0.001, d2=0.000 g=0.009, a1=100, a2=100\n",
            ">1495, d1=0.000, d2=0.000 g=0.014, a1=100, a2=100\n",
            ">1496, d1=0.000, d2=0.000 g=0.012, a1=100, a2=100\n",
            ">1497, d1=0.000, d2=0.003 g=0.020, a1=100, a2=100\n",
            ">1498, d1=0.001, d2=0.000 g=0.011, a1=100, a2=100\n",
            ">1499, d1=0.002, d2=0.001 g=0.011, a1=100, a2=100\n",
            ">1500, d1=0.000, d2=0.000 g=0.011, a1=100, a2=100\n",
            ">1501, d1=0.001, d2=0.000 g=0.017, a1=100, a2=100\n",
            ">1502, d1=0.000, d2=0.000 g=0.016, a1=100, a2=100\n",
            ">1503, d1=0.002, d2=0.000 g=0.006, a1=100, a2=100\n",
            ">1504, d1=0.001, d2=0.000 g=0.005, a1=100, a2=100\n",
            ">1505, d1=0.000, d2=0.000 g=0.006, a1=100, a2=100\n",
            ">1506, d1=0.002, d2=0.000 g=0.014, a1=100, a2=100\n",
            ">1507, d1=0.000, d2=0.001 g=0.007, a1=100, a2=100\n",
            ">1508, d1=0.000, d2=0.001 g=0.016, a1=100, a2=100\n",
            ">1509, d1=0.001, d2=0.000 g=0.008, a1=100, a2=100\n",
            ">1510, d1=0.000, d2=0.001 g=0.017, a1=100, a2=100\n",
            ">1511, d1=0.001, d2=0.000 g=0.016, a1=100, a2=100\n",
            ">1512, d1=0.001, d2=0.000 g=0.014, a1=100, a2=100\n",
            ">1513, d1=0.000, d2=0.000 g=0.006, a1=100, a2=100\n",
            ">1514, d1=0.000, d2=0.000 g=0.011, a1=100, a2=100\n",
            ">1515, d1=0.001, d2=0.000 g=0.019, a1=100, a2=100\n",
            ">1516, d1=0.000, d2=0.000 g=0.012, a1=100, a2=100\n",
            ">1517, d1=0.000, d2=0.001 g=0.010, a1=100, a2=100\n",
            ">1518, d1=0.000, d2=0.001 g=0.022, a1=100, a2=100\n",
            ">1519, d1=0.000, d2=0.000 g=0.016, a1=100, a2=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">1520, d1=0.003, d2=0.001 g=0.010, a1=100, a2=100\n",
            ">1521, d1=0.000, d2=0.001 g=0.010, a1=100, a2=100\n",
            ">1522, d1=0.000, d2=0.003 g=0.023, a1=100, a2=100\n",
            ">1523, d1=0.000, d2=0.001 g=0.042, a1=100, a2=100\n",
            ">1524, d1=0.000, d2=0.001 g=0.050, a1=100, a2=100\n",
            ">1525, d1=0.001, d2=0.000 g=0.052, a1=100, a2=100\n",
            ">1526, d1=0.000, d2=0.000 g=0.050, a1=100, a2=100\n",
            ">1527, d1=0.001, d2=0.000 g=0.080, a1=100, a2=100\n",
            ">1528, d1=0.000, d2=0.000 g=0.386, a1=100, a2=100\n",
            ">1529, d1=0.002, d2=0.000 g=7.424, a1=100, a2=100\n",
            ">1530, d1=0.001, d2=0.000 g=7.434, a1=100, a2=100\n",
            ">1531, d1=0.000, d2=0.000 g=9.906, a1=100, a2=100\n",
            ">1532, d1=0.000, d2=0.000 g=10.639, a1=100, a2=100\n",
            ">1533, d1=0.000, d2=0.000 g=5.577, a1=100, a2=100\n",
            ">1534, d1=0.001, d2=0.000 g=3.651, a1=100, a2=100\n",
            ">1535, d1=0.000, d2=0.000 g=4.856, a1=100, a2=100\n",
            ">1536, d1=0.001, d2=0.000 g=1.563, a1=100, a2=100\n",
            ">1537, d1=0.000, d2=0.000 g=1.102, a1=100, a2=100\n",
            ">1538, d1=0.000, d2=0.000 g=0.501, a1=100, a2=100\n",
            ">1539, d1=0.000, d2=0.000 g=0.266, a1=100, a2=100\n",
            ">1540, d1=0.000, d2=0.000 g=0.210, a1=100, a2=100\n",
            ">1541, d1=0.000, d2=0.000 g=0.150, a1=100, a2=100\n",
            ">1542, d1=0.001, d2=0.000 g=0.132, a1=100, a2=100\n",
            ">1543, d1=0.000, d2=0.000 g=0.068, a1=100, a2=100\n",
            ">1544, d1=0.001, d2=0.000 g=0.088, a1=100, a2=100\n",
            ">1545, d1=0.000, d2=0.000 g=0.075, a1=100, a2=100\n",
            ">1546, d1=0.000, d2=0.000 g=0.044, a1=100, a2=100\n",
            ">1547, d1=0.000, d2=0.000 g=0.076, a1=100, a2=100\n",
            ">1548, d1=0.000, d2=0.000 g=0.064, a1=100, a2=100\n",
            ">1549, d1=0.000, d2=0.000 g=0.030, a1=100, a2=100\n",
            ">1550, d1=0.000, d2=0.000 g=0.050, a1=100, a2=100\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "eX2Dcp9_wcq7",
        "outputId": "5820d5ea-092b-4f00-f692-628fa9155f65"
      },
      "source": [
        "pyplot.figure(1)\n",
        "pyplot.plot(d1_hist3, label='d-real loss')\n",
        "pyplot.plot(d2_hist3, label='d-fake loss')\n",
        "pyplot.plot(g_hist3, label='gen loss')\n",
        "pyplot.legend()"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fa892e80890>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "I9kPmR1_wi7E",
        "outputId": "6eea0060-b06b-468b-97a0-ae5d544e8caa"
      },
      "source": [
        "def generate_samples(n):\n",
        "  x_input = generate_latent_points(latent_dim, n)\n",
        "\t# predict outputs\n",
        "  X = generator.predict(x_input)\n",
        "  # scale from [-1,1] to [0,1]\n",
        "  X = (X + 1) / 2.0\n",
        "  # plot images\n",
        "  for i in range(n):\n",
        "    # define subplot\n",
        "    pyplot.subplot(1, n, 1 + i)\n",
        "    # turn off axis\n",
        "    pyplot.axis('off')\n",
        "    # plot raw pixel data\n",
        "    pyplot.imshow(X[i, :, :, :])\n",
        "generate_samples(4)"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Qbbux4_wl38"
      },
      "source": [
        "Using VGG-16 in the discriminator - the results are comparitively worse as compared to my GAN model before.\n",
        "\n",
        "We see an overly trained discriminator on real and fake images based on the loss plots - so the GAN is unstable - worse as compared to my previous model.\n",
        "\n",
        "The reason being of overtrained and exceptionally efficient VGG-16 which makes the discriminator over-efficient and so it affects the generator adversely. We end up with high generator loss.\n",
        "\n",
        "The discriminator becomes too good at identifying the fake images from true images.\n",
        "\n",
        "If the discriminator becomes too good, then generator training can fail due to vanishing gradients. In effect, an optimal discriminator doesn't provide enough information for the generator to make progress. Therefore, the generator is not able to produce clear images as visible from the generate_sample function in the above cell.\n",
        "\n",
        "In a stable GAN, discriminator loss is around 0.5 while generator loss can be between 0.7 to even 2. This is not the case here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DA_sqT60ebNJ"
      },
      "source": [
        "#Question 1 - Part 8 - Bonus - LsGAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bTlwT_GE1HA"
      },
      "source": [
        "Earlier we implemented a type of Vanilla GAN called a DCGAN.\n",
        "\n",
        "Vanilla GANs has two networks called generator network and a discriminator network. Both the networks are trained at the same time and compete or battle against each other in a minimax play.\n",
        "\n",
        "In regular GAN, the discriminator uses cross-entropy loss function which sometimes leads to vanishing gradient problems. Instead of that LsGAN proposes to use the least-squares loss function for the discriminator. This formulation provides a higher quality of images generated by GAN.\n",
        "\n",
        "In this part, we will try to implement LsGAN on the Car dataset. \n",
        "\n",
        "Code Inspired from: https://machinelearningmastery.com/least-squares-generative-adversarial-network/\n",
        "\n",
        "Inspired from: https://neptune.ai/blog/6-gan-architectures\n",
        "\n",
        "Github: https://github.com/xudonmao/LSGAN\n",
        "\n",
        "Research Paper: https://arxiv.org/pdf/1611.04076.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OGRC_ufUqM1"
      },
      "source": [
        "The Least Squares Generative Adversarial Network, or LSGAN for short, is an extension to the GAN architecture that addresses the problem of vanishing gradients and loss saturation.\n",
        "\n",
        "It is motivated by the desire to provide a signal to the generator about fake samples that are far from the discriminator model’s decision boundary for classifying them as real or fake. The further the generated images are from the decision boundary, the larger the error signal provided to the generator, encouraging the generation of more realistic images.\n",
        "\n",
        "The LSGAN can be implemented with a minor change to the output layer of the discriminator layer and the adoption of the least squares, or L2, loss function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jl6qK0EmYJMX"
      },
      "source": [
        "from numpy import expand_dims\n",
        "from numpy import zeros\n",
        "from numpy import ones\n",
        "from numpy.random import randn\n",
        "from numpy.random import randint\n",
        "from keras.datasets.mnist import load_data\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import Activation\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.initializers import RandomNormal\n",
        "from matplotlib import pyplot"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-25YaRPSWeMG"
      },
      "source": [
        "# load images\n",
        "def load_real_samples():\n",
        "  data = list()\n",
        "  # load dataset\n",
        "  for filename in os.listdir('/content/images_cars/cars_train/cars_train/'):\n",
        "    pixels = load_img('/content/images_cars/cars_train/cars_train/'+str(filename), target_size = (64,64))\n",
        "    pixels = img_to_array(pixels)\n",
        "    data.append(pixels)\n",
        "\n",
        "  X = asarray(data)\n",
        "  # convert from ints to floats\n",
        "  X = X.astype('float32')\n",
        "  # scale from [0,255] to [-1,1] to match the generator images\n",
        "  X = (X - 127.5) / 127.5\n",
        "  return X"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQh3cW-F0a2A"
      },
      "source": [
        "# define the standalone discriminator model\n",
        "def define_discriminator(in_shape=(64,64,3)):\n",
        "\t# weight initialization\n",
        "\tinit = RandomNormal(stddev=0.02)\n",
        "\t# define model\n",
        "\tmodel = Sequential()\n",
        "\t# downsample to 14x14\n",
        "\tmodel.add(Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init, input_shape=in_shape))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\t# downsample to 7x7\n",
        "\tmodel.add(Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\t# classifier\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(1, activation='linear', kernel_initializer=init))\n",
        "\t# compile model with L2 loss\n",
        "\tmodel.compile(loss='mse', optimizer=Adam(lr=0.0002, beta_1=0.5))\n",
        "\treturn model\n",
        "\n",
        "  # define the standalone generator model\n",
        "def define_generator(latent_dim):\n",
        "\t# weight initialization\n",
        "\tinit = RandomNormal(stddev=0.02)\n",
        "\t# define model\n",
        "\tmodel = Sequential()\n",
        "\t# foundation for 16x16 image\n",
        "\tn_nodes = 256 * 16 * 16\n",
        "\tmodel.add(Dense(n_nodes, kernel_initializer=init, input_dim=latent_dim))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Activation('relu'))\n",
        "\tmodel.add(Reshape((16, 16, 256)))\n",
        "\t# upsample to 32x32\n",
        "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Activation('relu'))\n",
        "\t# upsample to 64x64\n",
        "\tmodel.add(Conv2DTranspose(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Activation('relu'))\n",
        "\t# output 64x64x3\n",
        "\tmodel.add(Conv2D(3, (7,7), padding='same', kernel_initializer=init))\n",
        "\tmodel.add(Activation('tanh'))\n",
        "\treturn model\n",
        "\n",
        "  # define the combined generator and discriminator model, for updating the generator\n",
        "def define_gan(generator, discriminator):\n",
        "\t# make weights in the discriminator not trainable\n",
        "\tfor layer in discriminator.layers:\n",
        "\t\tif not isinstance(layer, BatchNormalization):\n",
        "\t\t\tlayer.trainable = False\n",
        "\t# connect them\n",
        "\tmodel = Sequential()\n",
        "\t# add generator\n",
        "\tmodel.add(generator)\n",
        "\t# add the discriminator\n",
        "\tmodel.add(discriminator)\n",
        "\t# compile model with L2 loss\n",
        "\tmodel.compile(loss='mse', optimizer=Adam(lr=0.0002, beta_1=0.5))\n",
        "\treturn model\n",
        "\n",
        "  # select real samples\n",
        "def generate_real_samples(dataset, n_samples):\n",
        "\t# choose random instances\n",
        "\tix = randint(0, dataset.shape[0], n_samples)\n",
        "\t# select images\n",
        "\tX = dataset[ix]\n",
        "\t# generate class labels\n",
        "\ty = ones((n_samples, 1))\n",
        "\treturn X, y\n",
        "\n",
        "  # generate points in latent space as input for the generator\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "\t# generate points in the latent space\n",
        "\tx_input = randn(latent_dim * n_samples)\n",
        "\t# reshape into a batch of inputs for the network\n",
        "\tx_input = x_input.reshape(n_samples, latent_dim)\n",
        "\treturn x_input\n",
        "\n",
        "  # use the generator to generate n fake examples, with class labels\n",
        "def generate_fake_samples(generator, latent_dim, n_samples):\n",
        "\t# generate points in latent space\n",
        "\tx_input = generate_latent_points(latent_dim, n_samples)\n",
        "\t# predict outputs\n",
        "\tX = generator.predict(x_input)\n",
        "\t# create class labels\n",
        "\ty = zeros((n_samples, 1))\n",
        "\treturn X, y\n",
        "\n",
        "  # generate samples and save as a plot and save the model\n",
        "def summarize_performance(step, g_model, latent_dim, n_samples=100):\n",
        "\t# prepare fake examples\n",
        "\tX, _ = generate_fake_samples(g_model, latent_dim, n_samples)\n",
        "\t# scale from [-1,1] to [0,1]\n",
        "\tX = (X + 1) / 2.0\n",
        "\t# plot images\n",
        "\tfor i in range(10 * 10):\n",
        "\t\t# define subplot\n",
        "\t\tpyplot.subplot(10, 10, 1 + i)\n",
        "\t\t# turn off axis\n",
        "\t\tpyplot.axis('off')\n",
        "\t\t# plot raw pixel data\n",
        "\t\tpyplot.imshow(X[i, :, :, 0], cmap='gray_r')\n",
        "\t# save plot to file\n",
        "\tfilename1 = 'generated_plot_%06d.png' % (step+1)\n",
        "\tpyplot.savefig(filename1)\n",
        "\tpyplot.close()\n",
        "\t# save the generator model\n",
        "\tfilename2 = 'model_%06d.h5' % (step+1)\n",
        "\tg_model.save(filename2)\n",
        "\tprint('Saved %s and %s' % (filename1, filename2))\n",
        " \n",
        "\n",
        " \n",
        "def plot_history(d1_hist, d2_hist, g_hist):\n",
        "  # plot loss\n",
        "  pyplot.subplot(2, 1, 1)\n",
        "  pyplot.plot(d1_hist, label='d-real')\n",
        "  pyplot.plot(d2_hist, label='d-fake')\n",
        "  pyplot.plot(g_hist, label='gen')\n",
        "  pyplot.legend()\n",
        "  pyplot.close()\n",
        " \n",
        " # train the generator and discriminator\n",
        "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=20, n_batch=64):\n",
        "  # calculate the number of batches per training epoch\n",
        "  bat_per_epo = int(dataset.shape[0] / n_batch)\n",
        "  # calculate the number of training iterations\n",
        "  n_steps = bat_per_epo * n_epochs\n",
        "  # calculate the size of half a batch of samples\n",
        "  half_batch = int(n_batch / 2)\n",
        "  # lists for storing loss, for plotting later\n",
        "  d1_hist, d2_hist, g_hist = list(), list(), list()\n",
        "  # manually enumerate epochs\n",
        "  for i in range(n_steps):\n",
        "    # prepare real and fake samples\n",
        "    X_real, y_real = generate_real_samples(dataset, half_batch)\n",
        "    X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
        "    # update discriminator model\n",
        "    d_loss1 = d_model.train_on_batch(X_real, y_real)\n",
        "    d_loss2 = d_model.train_on_batch(X_fake, y_fake)\n",
        "    # update the generator via the discriminator's error\n",
        "    z_input = generate_latent_points(latent_dim, n_batch)\n",
        "    y_real2 = ones((n_batch, 1))\n",
        "    g_loss = gan_model.train_on_batch(z_input, y_real2)\n",
        "    # summarize loss on this batch\n",
        "    print('>%d, d1=%.3f, d2=%.3f g=%.3f' % (i+1, d_loss1, d_loss2, g_loss))\n",
        "    # record history\n",
        "    d1_hist.append(d_loss1)\n",
        "    d2_hist.append(d_loss2)\n",
        "    g_hist.append(g_loss)\n",
        "    # evaluate the model performance every 'epoch'\n",
        "    if (i+1) % (bat_per_epo * 1) == 0:\n",
        "      summarize_performance(i, g_model, latent_dim)\n",
        "  # create line plot of training history\n",
        "  plot_history(d1_hist, d2_hist, g_hist)\n",
        "  return d1_hist, d2_hist, g_hist"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZvHpGdEXFp6"
      },
      "source": [
        "Final Training on LsGAN with Stanford Cars Dataset of size 64x64x3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mjmj2hHwXEuD",
        "outputId": "3ab08dc4-8a71-4822-8bd8-6e4777495e9d"
      },
      "source": [
        "# size of the latent space\n",
        "latent_dim = 100\n",
        "# create the discriminator\n",
        "discriminator = define_discriminator()\n",
        "# create the generator\n",
        "generator = define_generator(latent_dim)\n",
        "# create the gan\n",
        "gan_model = define_gan(generator, discriminator)\n",
        "# load image data\n",
        "dataset = load_real_samples()\n",
        "print(dataset.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(8144, 64, 64, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3eV0aF0Z2Jc"
      },
      "source": [
        "Running the code below will report the loss of the discriminator on real (d1) and fake (d2) examples and the loss of the generator via the discriminator on generated examples presented as real (g).\n",
        "\n",
        "These scores are printed at the end of each training run and are expected to remain small values throughout the training process. Values of zero for an extended period may indicate a failure mode and the training process should be restarted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tm3pxvjTXTbx",
        "outputId": "ac5b28b0-4bd3-4ace-c938-13523543a456"
      },
      "source": [
        "d1_hist, d2_hist, g_hist = train(generator, discriminator, gan_model, dataset, latent_dim)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">1, d1=0.069, d2=0.050 g=0.421\n",
            ">2, d1=0.059, d2=0.032 g=0.456\n",
            ">3, d1=0.053, d2=0.042 g=0.600\n",
            ">4, d1=0.100, d2=0.020 g=0.373\n",
            ">5, d1=0.086, d2=0.028 g=0.484\n",
            ">6, d1=0.040, d2=0.035 g=0.484\n",
            ">7, d1=0.078, d2=0.043 g=0.400\n",
            ">8, d1=0.064, d2=0.034 g=0.348\n",
            ">9, d1=0.079, d2=0.029 g=0.494\n",
            ">10, d1=0.035, d2=0.050 g=0.355\n",
            ">11, d1=0.051, d2=0.052 g=0.257\n",
            ">12, d1=0.039, d2=0.050 g=0.484\n",
            ">13, d1=0.091, d2=0.027 g=0.239\n",
            ">14, d1=0.109, d2=0.015 g=0.444\n",
            ">15, d1=0.072, d2=0.030 g=0.261\n",
            ">16, d1=0.020, d2=0.034 g=0.196\n",
            ">17, d1=0.046, d2=0.019 g=0.220\n",
            ">18, d1=0.027, d2=0.027 g=0.252\n",
            ">19, d1=0.028, d2=0.028 g=0.309\n",
            ">20, d1=0.055, d2=0.028 g=0.206\n",
            ">21, d1=0.058, d2=0.051 g=0.311\n",
            ">22, d1=0.039, d2=0.043 g=0.365\n",
            ">23, d1=0.050, d2=0.045 g=0.213\n",
            ">24, d1=0.055, d2=0.037 g=0.283\n",
            ">25, d1=0.038, d2=0.028 g=0.323\n",
            ">26, d1=0.071, d2=0.034 g=0.246\n",
            ">27, d1=0.029, d2=0.021 g=0.262\n",
            ">28, d1=0.024, d2=0.037 g=0.238\n",
            ">29, d1=0.052, d2=0.037 g=0.186\n",
            ">30, d1=0.028, d2=0.040 g=0.278\n",
            ">31, d1=0.036, d2=0.050 g=0.258\n",
            ">32, d1=0.035, d2=0.015 g=0.180\n",
            ">33, d1=0.042, d2=0.032 g=0.270\n",
            ">34, d1=0.075, d2=0.024 g=0.149\n",
            ">35, d1=0.036, d2=0.040 g=0.246\n",
            ">36, d1=0.053, d2=0.026 g=0.134\n",
            ">37, d1=0.054, d2=0.051 g=0.169\n",
            ">38, d1=0.138, d2=0.165 g=0.065\n",
            ">39, d1=0.133, d2=0.243 g=0.237\n",
            ">40, d1=0.245, d2=0.221 g=0.213\n",
            ">41, d1=0.211, d2=0.351 g=0.249\n",
            ">42, d1=0.246, d2=0.326 g=0.461\n",
            ">43, d1=0.349, d2=0.299 g=0.452\n",
            ">44, d1=0.227, d2=0.237 g=0.571\n",
            ">45, d1=0.418, d2=0.406 g=0.492\n",
            ">46, d1=0.257, d2=0.312 g=0.708\n",
            ">47, d1=0.368, d2=0.224 g=0.603\n",
            ">48, d1=0.269, d2=0.453 g=0.630\n",
            ">49, d1=0.186, d2=0.070 g=0.565\n",
            ">50, d1=0.151, d2=0.228 g=0.564\n",
            ">51, d1=0.155, d2=0.154 g=0.406\n",
            ">52, d1=0.126, d2=0.200 g=0.517\n",
            ">53, d1=0.283, d2=0.255 g=0.507\n",
            ">54, d1=0.246, d2=0.270 g=0.377\n",
            ">55, d1=0.227, d2=0.093 g=0.619\n",
            ">56, d1=0.469, d2=0.392 g=0.203\n",
            ">57, d1=0.151, d2=0.096 g=0.737\n",
            ">58, d1=0.301, d2=0.219 g=0.337\n",
            ">59, d1=0.192, d2=0.167 g=0.437\n",
            ">60, d1=0.152, d2=0.108 g=0.236\n",
            ">61, d1=0.111, d2=0.227 g=0.319\n",
            ">62, d1=0.171, d2=0.077 g=0.378\n",
            ">63, d1=0.208, d2=0.269 g=0.419\n",
            ">64, d1=0.191, d2=0.100 g=0.376\n",
            ">65, d1=0.248, d2=0.115 g=0.283\n",
            ">66, d1=0.159, d2=0.123 g=0.247\n",
            ">67, d1=0.151, d2=0.211 g=0.365\n",
            ">68, d1=0.205, d2=0.098 g=0.240\n",
            ">69, d1=0.172, d2=0.236 g=0.278\n",
            ">70, d1=0.150, d2=0.051 g=0.207\n",
            ">71, d1=0.162, d2=0.096 g=0.189\n",
            ">72, d1=0.162, d2=0.115 g=0.156\n",
            ">73, d1=0.091, d2=0.170 g=0.356\n",
            ">74, d1=0.329, d2=0.120 g=0.160\n",
            ">75, d1=0.162, d2=0.066 g=0.247\n",
            ">76, d1=0.131, d2=0.157 g=0.230\n",
            ">77, d1=0.158, d2=0.112 g=0.317\n",
            ">78, d1=0.132, d2=0.084 g=0.268\n",
            ">79, d1=0.126, d2=0.058 g=0.181\n",
            ">80, d1=0.181, d2=0.090 g=0.200\n",
            ">81, d1=0.104, d2=0.099 g=0.258\n",
            ">82, d1=0.092, d2=0.079 g=0.213\n",
            ">83, d1=0.161, d2=0.125 g=0.227\n",
            ">84, d1=0.093, d2=0.087 g=0.169\n",
            ">85, d1=0.137, d2=0.229 g=0.259\n",
            ">86, d1=0.165, d2=0.118 g=0.463\n",
            ">87, d1=0.279, d2=0.190 g=0.259\n",
            ">88, d1=0.174, d2=0.071 g=0.201\n",
            ">89, d1=0.094, d2=0.108 g=0.298\n",
            ">90, d1=0.238, d2=0.094 g=0.428\n",
            ">91, d1=0.108, d2=0.124 g=0.268\n",
            ">92, d1=0.124, d2=0.348 g=0.771\n",
            ">93, d1=0.210, d2=0.138 g=0.214\n",
            ">94, d1=0.195, d2=0.409 g=0.865\n",
            ">95, d1=0.174, d2=0.210 g=0.310\n",
            ">96, d1=0.218, d2=0.743 g=0.966\n",
            ">97, d1=0.304, d2=0.109 g=0.972\n",
            ">98, d1=0.234, d2=0.202 g=0.586\n",
            ">99, d1=0.134, d2=0.136 g=0.626\n",
            ">100, d1=0.198, d2=0.156 g=0.752\n",
            ">101, d1=0.146, d2=0.105 g=0.585\n",
            ">102, d1=0.163, d2=0.229 g=0.707\n",
            ">103, d1=0.175, d2=0.103 g=0.687\n",
            ">104, d1=0.169, d2=0.064 g=0.880\n",
            ">105, d1=0.290, d2=0.150 g=0.511\n",
            ">106, d1=0.216, d2=0.094 g=0.862\n",
            ">107, d1=0.302, d2=0.292 g=0.563\n",
            ">108, d1=0.113, d2=0.113 g=0.973\n",
            ">109, d1=0.203, d2=0.108 g=0.571\n",
            ">110, d1=0.216, d2=0.075 g=0.961\n",
            ">111, d1=0.163, d2=0.125 g=0.594\n",
            ">112, d1=0.181, d2=0.276 g=0.919\n",
            ">113, d1=0.099, d2=0.072 g=0.808\n",
            ">114, d1=0.119, d2=0.177 g=0.626\n",
            ">115, d1=0.157, d2=0.104 g=0.964\n",
            ">116, d1=0.157, d2=0.092 g=0.706\n",
            ">117, d1=0.100, d2=0.147 g=0.917\n",
            ">118, d1=0.233, d2=0.078 g=0.604\n",
            ">119, d1=0.114, d2=0.098 g=0.732\n",
            ">120, d1=0.077, d2=0.064 g=0.723\n",
            ">121, d1=0.097, d2=0.094 g=0.643\n",
            ">122, d1=0.086, d2=0.063 g=0.727\n",
            ">123, d1=0.192, d2=0.070 g=0.539\n",
            ">124, d1=0.096, d2=0.064 g=0.805\n",
            ">125, d1=0.205, d2=0.115 g=0.602\n",
            ">126, d1=0.140, d2=0.105 g=0.679\n",
            ">127, d1=0.067, d2=0.033 g=0.651\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Saved generated_plot_000127.png and model_000127.h5\n",
            ">128, d1=0.105, d2=0.068 g=0.577\n",
            ">129, d1=0.066, d2=0.071 g=0.794\n",
            ">130, d1=0.238, d2=0.102 g=0.562\n",
            ">131, d1=0.098, d2=0.045 g=0.528\n",
            ">132, d1=0.095, d2=0.032 g=0.688\n",
            ">133, d1=0.115, d2=0.072 g=0.618\n",
            ">134, d1=0.122, d2=0.081 g=0.413\n",
            ">135, d1=0.100, d2=0.092 g=0.622\n",
            ">136, d1=0.214, d2=0.170 g=0.290\n",
            ">137, d1=0.082, d2=0.063 g=0.559\n",
            ">138, d1=0.118, d2=0.068 g=0.466\n",
            ">139, d1=0.127, d2=0.070 g=0.449\n",
            ">140, d1=0.098, d2=0.063 g=0.527\n",
            ">141, d1=0.074, d2=0.039 g=0.366\n",
            ">142, d1=0.189, d2=0.207 g=0.404\n",
            ">143, d1=0.094, d2=0.070 g=0.440\n",
            ">144, d1=0.134, d2=0.213 g=0.488\n",
            ">145, d1=0.117, d2=0.052 g=0.601\n",
            ">146, d1=0.046, d2=0.044 g=0.380\n",
            ">147, d1=0.069, d2=0.055 g=0.490\n",
            ">148, d1=0.181, d2=0.108 g=0.431\n",
            ">149, d1=0.125, d2=0.070 g=0.602\n",
            ">150, d1=0.194, d2=0.152 g=0.475\n",
            ">151, d1=0.113, d2=0.081 g=0.466\n",
            ">152, d1=0.109, d2=0.180 g=0.697\n",
            ">153, d1=0.360, d2=0.245 g=0.447\n",
            ">154, d1=0.151, d2=0.115 g=0.717\n",
            ">155, d1=0.469, d2=0.216 g=0.637\n",
            ">156, d1=0.208, d2=0.080 g=0.529\n",
            ">157, d1=0.209, d2=0.114 g=0.554\n",
            ">158, d1=0.207, d2=0.101 g=0.498\n",
            ">159, d1=0.218, d2=0.190 g=0.445\n",
            ">160, d1=0.248, d2=0.081 g=0.488\n",
            ">161, d1=0.165, d2=0.166 g=0.564\n",
            ">162, d1=0.345, d2=0.298 g=0.562\n",
            ">163, d1=0.249, d2=0.087 g=0.431\n",
            ">164, d1=0.197, d2=0.399 g=0.456\n",
            ">165, d1=0.121, d2=0.145 g=0.459\n",
            ">166, d1=0.474, d2=0.757 g=0.538\n",
            ">167, d1=0.207, d2=0.144 g=0.611\n",
            ">168, d1=0.263, d2=0.309 g=0.469\n",
            ">169, d1=0.204, d2=0.183 g=0.297\n",
            ">170, d1=0.100, d2=0.092 g=0.290\n",
            ">171, d1=0.314, d2=0.229 g=0.231\n",
            ">172, d1=0.165, d2=0.191 g=0.445\n",
            ">173, d1=0.287, d2=0.142 g=0.378\n",
            ">174, d1=0.120, d2=0.149 g=0.281\n",
            ">175, d1=0.254, d2=0.625 g=1.096\n",
            ">176, d1=0.366, d2=0.130 g=0.323\n",
            ">177, d1=0.248, d2=0.167 g=0.697\n",
            ">178, d1=0.166, d2=0.126 g=0.492\n",
            ">179, d1=0.205, d2=0.180 g=0.294\n",
            ">180, d1=0.160, d2=0.157 g=0.326\n",
            ">181, d1=0.168, d2=0.134 g=0.175\n",
            ">182, d1=0.080, d2=0.123 g=0.152\n",
            ">183, d1=0.271, d2=0.123 g=0.149\n",
            ">184, d1=0.091, d2=0.283 g=0.641\n",
            ">185, d1=0.160, d2=0.133 g=0.230\n",
            ">186, d1=0.218, d2=0.241 g=0.548\n",
            ">187, d1=0.542, d2=0.263 g=0.271\n",
            ">188, d1=0.284, d2=0.217 g=0.217\n",
            ">189, d1=0.158, d2=0.387 g=0.502\n",
            ">190, d1=0.182, d2=0.219 g=0.337\n",
            ">191, d1=0.205, d2=0.290 g=0.438\n",
            ">192, d1=0.258, d2=0.333 g=0.801\n",
            ">193, d1=0.333, d2=0.303 g=0.647\n",
            ">194, d1=0.211, d2=0.583 g=2.155\n",
            ">195, d1=0.533, d2=0.412 g=1.521\n",
            ">196, d1=0.788, d2=10.373 g=29.769\n",
            ">197, d1=5.402, d2=37.034 g=49.148\n",
            ">198, d1=21.766, d2=49.897 g=11.323\n",
            ">199, d1=19.589, d2=24.382 g=66.440\n",
            ">200, d1=13.081, d2=97.949 g=71.072\n",
            ">201, d1=30.862, d2=83.370 g=2.789\n",
            ">202, d1=2.389, d2=79.708 g=4.644\n",
            ">203, d1=1.993, d2=17.302 g=7.339\n",
            ">204, d1=3.221, d2=0.423 g=0.250\n",
            ">205, d1=1.102, d2=0.840 g=0.846\n",
            ">206, d1=1.359, d2=0.086 g=1.256\n",
            ">207, d1=0.987, d2=0.112 g=0.780\n",
            ">208, d1=0.784, d2=0.115 g=0.585\n",
            ">209, d1=0.544, d2=0.044 g=0.958\n",
            ">210, d1=0.400, d2=0.055 g=0.666\n",
            ">211, d1=0.568, d2=0.028 g=0.553\n",
            ">212, d1=0.412, d2=0.055 g=0.844\n",
            ">213, d1=0.261, d2=0.054 g=0.681\n",
            ">214, d1=0.500, d2=0.069 g=0.646\n",
            ">215, d1=0.214, d2=0.036 g=0.746\n",
            ">216, d1=0.379, d2=0.026 g=0.711\n",
            ">217, d1=0.251, d2=0.041 g=0.822\n",
            ">218, d1=0.272, d2=0.031 g=0.872\n",
            ">219, d1=0.145, d2=0.022 g=0.940\n",
            ">220, d1=0.339, d2=0.019 g=0.885\n",
            ">221, d1=0.285, d2=0.032 g=1.044\n",
            ">222, d1=0.234, d2=0.014 g=1.038\n",
            ">223, d1=0.154, d2=0.015 g=1.062\n",
            ">224, d1=0.122, d2=0.012 g=0.948\n",
            ">225, d1=0.166, d2=0.022 g=0.990\n",
            ">226, d1=0.199, d2=0.018 g=0.930\n",
            ">227, d1=0.254, d2=0.013 g=0.970\n",
            ">228, d1=0.133, d2=0.013 g=0.913\n",
            ">229, d1=0.087, d2=0.017 g=0.853\n",
            ">230, d1=0.153, d2=0.018 g=0.852\n",
            ">231, d1=0.096, d2=0.010 g=0.868\n",
            ">232, d1=0.185, d2=0.015 g=0.750\n",
            ">233, d1=0.158, d2=0.026 g=0.878\n",
            ">234, d1=0.130, d2=0.015 g=0.918\n",
            ">235, d1=0.078, d2=0.015 g=0.869\n",
            ">236, d1=0.101, d2=0.014 g=0.826\n",
            ">237, d1=0.116, d2=0.015 g=0.817\n",
            ">238, d1=0.070, d2=0.013 g=0.894\n",
            ">239, d1=0.098, d2=0.016 g=0.812\n",
            ">240, d1=0.147, d2=0.013 g=0.768\n",
            ">241, d1=0.155, d2=0.011 g=0.713\n",
            ">242, d1=0.155, d2=0.012 g=0.906\n",
            ">243, d1=0.125, d2=0.018 g=0.794\n",
            ">244, d1=0.150, d2=0.009 g=0.786\n",
            ">245, d1=0.153, d2=0.020 g=0.765\n",
            ">246, d1=0.131, d2=0.024 g=0.906\n",
            ">247, d1=0.166, d2=0.020 g=0.987\n",
            ">248, d1=0.087, d2=0.009 g=0.811\n",
            ">249, d1=0.101, d2=0.016 g=0.818\n",
            ">250, d1=0.062, d2=0.010 g=0.917\n",
            ">251, d1=0.082, d2=0.014 g=0.847\n",
            ">252, d1=0.126, d2=0.012 g=0.844\n",
            ">253, d1=0.081, d2=0.015 g=0.810\n",
            ">254, d1=0.145, d2=0.012 g=0.909\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Saved generated_plot_000254.png and model_000254.h5\n",
            ">255, d1=0.157, d2=0.010 g=0.823\n",
            ">256, d1=0.187, d2=0.017 g=0.860\n",
            ">257, d1=0.088, d2=0.012 g=0.891\n",
            ">258, d1=0.081, d2=0.010 g=0.836\n",
            ">259, d1=0.140, d2=0.014 g=0.802\n",
            ">260, d1=0.143, d2=0.009 g=0.807\n",
            ">261, d1=0.054, d2=0.012 g=0.815\n",
            ">262, d1=0.051, d2=0.010 g=0.714\n",
            ">263, d1=0.105, d2=0.036 g=0.875\n",
            ">264, d1=0.070, d2=0.034 g=0.735\n",
            ">265, d1=0.057, d2=0.034 g=0.760\n",
            ">266, d1=0.078, d2=0.014 g=0.802\n",
            ">267, d1=0.065, d2=0.022 g=0.845\n",
            ">268, d1=0.100, d2=0.006 g=0.765\n",
            ">269, d1=0.062, d2=0.009 g=0.760\n",
            ">270, d1=0.070, d2=0.008 g=0.757\n",
            ">271, d1=0.057, d2=0.020 g=0.727\n",
            ">272, d1=0.061, d2=0.018 g=0.763\n",
            ">273, d1=0.162, d2=0.035 g=0.826\n",
            ">274, d1=0.064, d2=0.018 g=0.781\n",
            ">275, d1=0.042, d2=0.021 g=0.732\n",
            ">276, d1=0.059, d2=0.014 g=0.721\n",
            ">277, d1=0.083, d2=0.010 g=0.723\n",
            ">278, d1=0.100, d2=0.015 g=0.733\n",
            ">279, d1=0.096, d2=0.009 g=0.789\n",
            ">280, d1=0.055, d2=0.014 g=0.670\n",
            ">281, d1=0.032, d2=0.013 g=0.768\n",
            ">282, d1=0.049, d2=0.012 g=0.699\n",
            ">283, d1=0.053, d2=0.015 g=0.717\n",
            ">284, d1=0.039, d2=0.015 g=0.707\n",
            ">285, d1=0.100, d2=0.017 g=0.739\n",
            ">286, d1=0.057, d2=0.019 g=0.697\n",
            ">287, d1=0.042, d2=0.017 g=0.656\n",
            ">288, d1=0.054, d2=0.021 g=0.798\n",
            ">289, d1=0.071, d2=0.023 g=0.718\n",
            ">290, d1=0.099, d2=0.017 g=0.701\n",
            ">291, d1=0.075, d2=0.011 g=0.691\n",
            ">292, d1=0.048, d2=0.015 g=0.756\n",
            ">293, d1=0.061, d2=0.014 g=0.672\n",
            ">294, d1=0.089, d2=0.015 g=0.751\n",
            ">295, d1=0.063, d2=0.020 g=0.572\n",
            ">296, d1=0.076, d2=0.031 g=0.798\n",
            ">297, d1=0.069, d2=0.030 g=0.595\n",
            ">298, d1=0.066, d2=0.033 g=0.749\n",
            ">299, d1=0.047, d2=0.025 g=0.542\n",
            ">300, d1=0.072, d2=0.028 g=0.690\n",
            ">301, d1=0.079, d2=0.045 g=0.468\n",
            ">302, d1=0.046, d2=0.061 g=0.753\n",
            ">303, d1=0.068, d2=0.068 g=0.456\n",
            ">304, d1=0.067, d2=0.083 g=0.727\n",
            ">305, d1=0.100, d2=0.055 g=0.449\n",
            ">306, d1=0.093, d2=0.046 g=0.658\n",
            ">307, d1=0.053, d2=0.040 g=0.460\n",
            ">308, d1=0.069, d2=0.043 g=0.637\n",
            ">309, d1=0.091, d2=0.021 g=0.450\n",
            ">310, d1=0.073, d2=0.031 g=0.618\n",
            ">311, d1=0.089, d2=0.050 g=0.406\n",
            ">312, d1=0.057, d2=0.068 g=0.666\n",
            ">313, d1=0.036, d2=0.052 g=0.444\n",
            ">314, d1=0.044, d2=0.066 g=0.736\n",
            ">315, d1=0.058, d2=0.055 g=0.419\n",
            ">316, d1=0.056, d2=0.054 g=0.690\n",
            ">317, d1=0.072, d2=0.070 g=0.354\n",
            ">318, d1=0.045, d2=0.175 g=1.000\n",
            ">319, d1=0.056, d2=0.310 g=0.172\n",
            ">320, d1=0.098, d2=0.470 g=1.203\n",
            ">321, d1=0.106, d2=0.648 g=0.093\n",
            ">322, d1=0.090, d2=0.939 g=1.478\n",
            ">323, d1=0.041, d2=1.411 g=0.020\n",
            ">324, d1=0.076, d2=2.183 g=2.324\n",
            ">325, d1=0.126, d2=3.120 g=0.014\n",
            ">326, d1=0.134, d2=3.702 g=2.186\n",
            ">327, d1=0.167, d2=3.849 g=0.033\n",
            ">328, d1=0.175, d2=3.313 g=1.788\n",
            ">329, d1=0.236, d2=2.535 g=0.161\n",
            ">330, d1=0.091, d2=1.774 g=1.168\n",
            ">331, d1=0.090, d2=1.223 g=0.252\n",
            ">332, d1=0.066, d2=0.767 g=0.884\n",
            ">333, d1=0.092, d2=0.354 g=0.426\n",
            ">334, d1=0.038, d2=0.214 g=0.657\n",
            ">335, d1=0.068, d2=0.094 g=0.496\n",
            ">336, d1=0.032, d2=0.069 g=0.685\n",
            ">337, d1=0.070, d2=0.048 g=0.425\n",
            ">338, d1=0.067, d2=0.055 g=0.661\n",
            ">339, d1=0.051, d2=0.068 g=0.427\n",
            ">340, d1=0.036, d2=0.085 g=0.682\n",
            ">341, d1=0.055, d2=0.072 g=0.394\n",
            ">342, d1=0.051, d2=0.107 g=0.783\n",
            ">343, d1=0.065, d2=0.071 g=0.471\n",
            ">344, d1=0.064, d2=0.045 g=0.676\n",
            ">345, d1=0.081, d2=0.024 g=0.617\n",
            ">346, d1=0.063, d2=0.032 g=0.761\n",
            ">347, d1=0.040, d2=0.070 g=0.376\n",
            ">348, d1=0.074, d2=0.137 g=0.948\n",
            ">349, d1=0.024, d2=0.203 g=0.353\n",
            ">350, d1=0.031, d2=0.256 g=0.910\n",
            ">351, d1=0.037, d2=0.206 g=0.445\n",
            ">352, d1=0.075, d2=0.205 g=0.877\n",
            ">353, d1=0.070, d2=0.179 g=0.352\n",
            ">354, d1=0.062, d2=0.198 g=0.931\n",
            ">355, d1=0.035, d2=0.161 g=0.466\n",
            ">356, d1=0.055, d2=0.158 g=0.907\n",
            ">357, d1=0.070, d2=0.162 g=0.439\n",
            ">358, d1=0.046, d2=0.168 g=0.948\n",
            ">359, d1=0.077, d2=0.138 g=0.404\n",
            ">360, d1=0.112, d2=0.157 g=1.141\n",
            ">361, d1=0.092, d2=0.214 g=0.340\n",
            ">362, d1=0.077, d2=0.328 g=1.279\n",
            ">363, d1=0.051, d2=0.420 g=0.264\n",
            ">364, d1=0.039, d2=0.534 g=1.319\n",
            ">365, d1=0.042, d2=0.679 g=0.196\n",
            ">366, d1=0.066, d2=0.842 g=1.521\n",
            ">367, d1=0.060, d2=0.985 g=0.162\n",
            ">368, d1=0.045, d2=1.343 g=1.827\n",
            ">369, d1=0.035, d2=1.799 g=0.068\n",
            ">370, d1=0.096, d2=2.029 g=1.865\n",
            ">371, d1=0.088, d2=2.016 g=0.103\n",
            ">372, d1=0.073, d2=1.903 g=1.686\n",
            ">373, d1=0.045, d2=1.779 g=0.188\n",
            ">374, d1=0.063, d2=1.570 g=1.532\n",
            ">375, d1=0.066, d2=1.287 g=0.265\n",
            ">376, d1=0.082, d2=1.038 g=1.412\n",
            ">377, d1=0.119, d2=0.772 g=0.325\n",
            ">378, d1=0.102, d2=0.737 g=1.415\n",
            ">379, d1=0.036, d2=0.783 g=0.290\n",
            ">380, d1=0.064, d2=0.797 g=1.409\n",
            ">381, d1=0.031, d2=0.785 g=0.338\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Saved generated_plot_000381.png and model_000381.h5\n",
            ">382, d1=0.048, d2=0.749 g=1.351\n",
            ">383, d1=0.053, d2=0.690 g=0.371\n",
            ">384, d1=0.052, d2=0.603 g=1.193\n",
            ">385, d1=0.071, d2=0.451 g=0.456\n",
            ">386, d1=0.044, d2=0.451 g=1.157\n",
            ">387, d1=0.040, d2=0.399 g=0.462\n",
            ">388, d1=0.092, d2=0.364 g=1.084\n",
            ">389, d1=0.051, d2=0.374 g=0.421\n",
            ">390, d1=0.052, d2=0.324 g=1.054\n",
            ">391, d1=0.062, d2=0.181 g=0.653\n",
            ">392, d1=0.047, d2=0.126 g=0.988\n",
            ">393, d1=0.086, d2=0.067 g=0.629\n",
            ">394, d1=0.072, d2=0.070 g=1.004\n",
            ">395, d1=0.068, d2=0.098 g=0.559\n",
            ">396, d1=0.057, d2=0.126 g=0.939\n",
            ">397, d1=0.031, d2=0.081 g=0.681\n",
            ">398, d1=0.039, d2=0.056 g=0.819\n",
            ">399, d1=0.065, d2=0.025 g=0.684\n",
            ">400, d1=0.048, d2=0.023 g=0.824\n",
            ">401, d1=0.021, d2=0.023 g=0.679\n",
            ">402, d1=0.048, d2=0.045 g=0.924\n",
            ">403, d1=0.088, d2=0.095 g=0.464\n",
            ">404, d1=0.029, d2=0.187 g=1.145\n",
            ">405, d1=0.057, d2=0.195 g=0.513\n",
            ">406, d1=0.095, d2=0.187 g=1.132\n",
            ">407, d1=0.046, d2=0.190 g=0.469\n",
            ">408, d1=0.058, d2=0.217 g=0.976\n",
            ">409, d1=0.083, d2=0.203 g=0.488\n",
            ">410, d1=0.034, d2=0.242 g=1.195\n",
            ">411, d1=0.119, d2=0.232 g=0.398\n",
            ">412, d1=0.160, d2=0.272 g=1.282\n",
            ">413, d1=0.163, d2=0.283 g=0.461\n",
            ">414, d1=0.108, d2=0.313 g=1.217\n",
            ">415, d1=0.084, d2=0.390 g=0.244\n",
            ">416, d1=0.040, d2=0.672 g=1.547\n",
            ">417, d1=0.039, d2=1.022 g=0.144\n",
            ">418, d1=0.100, d2=1.354 g=1.807\n",
            ">419, d1=0.115, d2=1.477 g=0.158\n",
            ">420, d1=0.150, d2=1.511 g=1.789\n",
            ">421, d1=0.255, d2=1.487 g=0.144\n",
            ">422, d1=0.198, d2=1.485 g=1.581\n",
            ">423, d1=0.175, d2=1.259 g=0.223\n",
            ">424, d1=0.147, d2=1.094 g=1.434\n",
            ">425, d1=0.035, d2=0.993 g=0.289\n",
            ">426, d1=0.067, d2=0.976 g=1.514\n",
            ">427, d1=0.071, d2=0.893 g=0.300\n",
            ">428, d1=0.065, d2=0.833 g=1.249\n",
            ">429, d1=0.078, d2=0.547 g=0.429\n",
            ">430, d1=0.048, d2=0.391 g=1.017\n",
            ">431, d1=0.079, d2=0.243 g=0.407\n",
            ">432, d1=0.114, d2=0.215 g=0.997\n",
            ">433, d1=0.067, d2=0.200 g=0.359\n",
            ">434, d1=0.022, d2=0.307 g=1.137\n",
            ">435, d1=0.034, d2=0.319 g=0.385\n",
            ">436, d1=0.032, d2=0.371 g=1.186\n",
            ">437, d1=0.077, d2=0.431 g=0.187\n",
            ">438, d1=0.047, d2=0.618 g=1.385\n",
            ">439, d1=0.038, d2=0.845 g=0.126\n",
            ">440, d1=0.044, d2=1.117 g=1.496\n",
            ">441, d1=0.048, d2=1.413 g=0.062\n",
            ">442, d1=0.082, d2=1.725 g=1.646\n",
            ">443, d1=0.126, d2=1.755 g=0.051\n",
            ">444, d1=0.255, d2=1.807 g=1.797\n",
            ">445, d1=0.253, d2=1.856 g=0.062\n",
            ">446, d1=0.225, d2=1.902 g=1.502\n",
            ">447, d1=0.132, d2=1.622 g=0.150\n",
            ">448, d1=0.086, d2=1.412 g=1.374\n",
            ">449, d1=0.129, d2=1.341 g=0.109\n",
            ">450, d1=0.119, d2=1.234 g=1.260\n",
            ">451, d1=0.156, d2=1.081 g=0.122\n",
            ">452, d1=0.120, d2=1.074 g=1.086\n",
            ">453, d1=0.048, d2=0.925 g=0.167\n",
            ">454, d1=0.038, d2=0.726 g=0.808\n",
            ">455, d1=0.049, d2=0.447 g=0.251\n",
            ">456, d1=0.073, d2=0.375 g=0.764\n",
            ">457, d1=0.103, d2=0.264 g=0.260\n",
            ">458, d1=0.073, d2=0.202 g=0.647\n",
            ">459, d1=0.031, d2=0.198 g=0.299\n",
            ">460, d1=0.033, d2=0.166 g=0.470\n",
            ">461, d1=0.036, d2=0.100 g=0.243\n",
            ">462, d1=0.042, d2=0.127 g=0.523\n",
            ">463, d1=0.067, d2=0.097 g=0.311\n",
            ">464, d1=0.044, d2=0.069 g=0.364\n",
            ">465, d1=0.025, d2=0.036 g=0.267\n",
            ">466, d1=0.011, d2=0.065 g=0.546\n",
            ">467, d1=0.034, d2=0.079 g=0.272\n",
            ">468, d1=0.046, d2=0.063 g=0.415\n",
            ">469, d1=0.046, d2=0.047 g=0.228\n",
            ">470, d1=0.035, d2=0.085 g=0.548\n",
            ">471, d1=0.053, d2=0.056 g=0.245\n",
            ">472, d1=0.024, d2=0.098 g=0.488\n",
            ">473, d1=0.037, d2=0.113 g=0.149\n",
            ">474, d1=0.024, d2=0.148 g=0.465\n",
            ">475, d1=0.031, d2=0.181 g=0.095\n",
            ">476, d1=0.049, d2=0.218 g=0.471\n",
            ">477, d1=0.101, d2=0.174 g=0.093\n",
            ">478, d1=0.096, d2=0.228 g=0.620\n",
            ">479, d1=0.166, d2=0.250 g=0.079\n",
            ">480, d1=0.199, d2=0.251 g=0.536\n",
            ">481, d1=0.126, d2=0.241 g=0.057\n",
            ">482, d1=0.131, d2=0.363 g=0.802\n",
            ">483, d1=0.201, d2=0.567 g=0.028\n",
            ">484, d1=0.192, d2=0.759 g=0.864\n",
            ">485, d1=0.168, d2=0.853 g=0.039\n",
            ">486, d1=0.177, d2=1.224 g=1.414\n",
            ">487, d1=0.145, d2=1.775 g=0.040\n",
            ">488, d1=0.145, d2=1.710 g=1.024\n",
            ">489, d1=0.082, d2=1.230 g=0.027\n",
            ">490, d1=0.202, d2=1.091 g=1.180\n",
            ">491, d1=0.294, d2=1.020 g=0.031\n",
            ">492, d1=0.106, d2=0.976 g=0.830\n",
            ">493, d1=0.050, d2=0.868 g=0.049\n",
            ">494, d1=0.087, d2=0.871 g=0.886\n",
            ">495, d1=0.214, d2=0.760 g=0.065\n",
            ">496, d1=0.160, d2=0.488 g=0.391\n",
            ">497, d1=0.117, d2=0.243 g=0.127\n",
            ">498, d1=0.069, d2=0.250 g=0.465\n",
            ">499, d1=0.036, d2=0.317 g=0.084\n",
            ">500, d1=0.050, d2=0.234 g=0.263\n",
            ">501, d1=0.059, d2=0.121 g=0.137\n",
            ">502, d1=0.073, d2=0.068 g=0.242\n",
            ">503, d1=0.046, d2=0.037 g=0.136\n",
            ">504, d1=0.031, d2=0.055 g=0.260\n",
            ">505, d1=0.049, d2=0.060 g=0.084\n",
            ">506, d1=0.065, d2=0.114 g=0.354\n",
            ">507, d1=0.065, d2=0.123 g=0.086\n",
            ">508, d1=0.040, d2=0.121 g=0.233\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Saved generated_plot_000508.png and model_000508.h5\n",
            ">509, d1=0.046, d2=0.091 g=0.163\n",
            ">510, d1=0.053, d2=0.050 g=0.161\n",
            ">511, d1=0.044, d2=0.031 g=0.139\n",
            ">512, d1=0.023, d2=0.033 g=0.097\n",
            ">513, d1=0.053, d2=0.031 g=0.204\n",
            ">514, d1=0.061, d2=0.016 g=0.227\n",
            ">515, d1=0.050, d2=0.051 g=0.097\n",
            ">516, d1=0.043, d2=0.111 g=0.376\n",
            ">517, d1=0.032, d2=0.181 g=0.054\n",
            ">518, d1=0.030, d2=0.253 g=0.372\n",
            ">519, d1=0.086, d2=0.252 g=0.044\n",
            ">520, d1=0.073, d2=0.283 g=0.377\n",
            ">521, d1=0.064, d2=0.288 g=0.061\n",
            ">522, d1=0.040, d2=0.297 g=0.357\n",
            ">523, d1=0.069, d2=0.238 g=0.059\n",
            ">524, d1=0.057, d2=0.274 g=0.438\n",
            ">525, d1=0.061, d2=0.325 g=0.031\n",
            ">526, d1=0.060, d2=0.366 g=0.392\n",
            ">527, d1=0.069, d2=0.411 g=0.038\n",
            ">528, d1=0.041, d2=0.542 g=0.610\n",
            ">529, d1=0.077, d2=0.630 g=0.047\n",
            ">530, d1=0.082, d2=0.792 g=0.852\n",
            ">531, d1=0.108, d2=1.184 g=0.082\n",
            ">532, d1=0.163, d2=1.358 g=0.875\n",
            ">533, d1=0.151, d2=1.330 g=0.081\n",
            ">534, d1=0.175, d2=1.641 g=1.457\n",
            ">535, d1=0.210, d2=2.131 g=0.119\n",
            ">536, d1=0.207, d2=1.379 g=0.612\n",
            ">537, d1=0.169, d2=0.267 g=0.172\n",
            ">538, d1=0.112, d2=0.081 g=0.460\n",
            ">539, d1=0.045, d2=0.057 g=0.181\n",
            ">540, d1=0.026, d2=0.050 g=0.220\n",
            ">541, d1=0.037, d2=0.091 g=0.051\n",
            ">542, d1=0.034, d2=0.095 g=0.176\n",
            ">543, d1=0.033, d2=0.042 g=0.122\n",
            ">544, d1=0.043, d2=0.036 g=0.152\n",
            ">545, d1=0.062, d2=0.021 g=0.188\n",
            ">546, d1=0.058, d2=0.021 g=0.153\n",
            ">547, d1=0.055, d2=0.037 g=0.183\n",
            ">548, d1=0.038, d2=0.029 g=0.084\n",
            ">549, d1=0.034, d2=0.051 g=0.203\n",
            ">550, d1=0.030, d2=0.061 g=0.077\n",
            ">551, d1=0.058, d2=0.061 g=0.250\n",
            ">552, d1=0.121, d2=0.077 g=0.042\n",
            ">553, d1=0.174, d2=0.098 g=0.358\n",
            ">554, d1=0.122, d2=0.138 g=0.054\n",
            ">555, d1=0.070, d2=0.155 g=0.279\n",
            ">556, d1=0.036, d2=0.179 g=0.053\n",
            ">557, d1=0.027, d2=0.234 g=0.277\n",
            ">558, d1=0.037, d2=0.254 g=0.037\n",
            ">559, d1=0.038, d2=0.402 g=0.677\n",
            ">560, d1=0.072, d2=0.731 g=0.066\n",
            ">561, d1=0.082, d2=0.817 g=0.617\n",
            ">562, d1=0.078, d2=0.601 g=0.040\n",
            ">563, d1=0.123, d2=0.579 g=1.191\n",
            ">564, d1=0.102, d2=0.887 g=0.059\n",
            ">565, d1=0.115, d2=0.474 g=0.499\n",
            ">566, d1=0.057, d2=0.026 g=0.411\n",
            ">567, d1=0.051, d2=0.030 g=0.180\n",
            ">568, d1=0.047, d2=0.035 g=0.255\n",
            ">569, d1=0.024, d2=0.033 g=0.112\n",
            ">570, d1=0.033, d2=0.030 g=0.088\n",
            ">571, d1=0.048, d2=0.039 g=0.068\n",
            ">572, d1=0.041, d2=0.062 g=0.080\n",
            ">573, d1=0.039, d2=0.014 g=0.150\n",
            ">574, d1=0.034, d2=0.023 g=0.136\n",
            ">575, d1=0.041, d2=0.020 g=0.186\n",
            ">576, d1=0.031, d2=0.042 g=0.065\n",
            ">577, d1=0.026, d2=0.053 g=0.165\n",
            ">578, d1=0.052, d2=0.032 g=0.084\n",
            ">579, d1=0.061, d2=0.038 g=0.164\n",
            ">580, d1=0.028, d2=0.037 g=0.100\n",
            ">581, d1=0.019, d2=0.048 g=0.092\n",
            ">582, d1=0.033, d2=0.034 g=0.101\n",
            ">583, d1=0.047, d2=0.027 g=0.097\n",
            ">584, d1=0.040, d2=0.043 g=0.057\n",
            ">585, d1=0.038, d2=0.036 g=0.118\n",
            ">586, d1=0.068, d2=0.030 g=0.092\n",
            ">587, d1=0.055, d2=0.017 g=0.083\n",
            ">588, d1=0.062, d2=0.034 g=0.182\n",
            ">589, d1=0.044, d2=0.082 g=0.060\n",
            ">590, d1=0.011, d2=0.185 g=0.311\n",
            ">591, d1=0.035, d2=0.215 g=0.052\n",
            ">592, d1=0.077, d2=0.250 g=0.398\n",
            ">593, d1=0.122, d2=0.324 g=0.048\n",
            ">594, d1=0.176, d2=0.484 g=0.607\n",
            ">595, d1=0.265, d2=0.690 g=0.142\n",
            ">596, d1=0.451, d2=1.202 g=1.537\n",
            ">597, d1=0.769, d2=1.991 g=0.359\n",
            ">598, d1=1.028, d2=2.717 g=1.944\n",
            ">599, d1=1.232, d2=2.803 g=0.308\n",
            ">600, d1=1.772, d2=2.305 g=1.656\n",
            ">601, d1=1.328, d2=2.863 g=0.471\n",
            ">602, d1=1.277, d2=0.934 g=0.955\n",
            ">603, d1=0.623, d2=0.056 g=0.611\n",
            ">604, d1=0.326, d2=0.053 g=0.213\n",
            ">605, d1=0.118, d2=0.144 g=0.431\n",
            ">606, d1=0.037, d2=0.180 g=0.072\n",
            ">607, d1=0.065, d2=0.144 g=0.218\n",
            ">608, d1=0.034, d2=0.073 g=0.099\n",
            ">609, d1=0.044, d2=0.171 g=0.365\n",
            ">610, d1=0.028, d2=0.366 g=0.058\n",
            ">611, d1=0.044, d2=0.486 g=0.402\n",
            ">612, d1=0.108, d2=0.542 g=0.074\n",
            ">613, d1=0.192, d2=0.419 g=0.313\n",
            ">614, d1=0.239, d2=0.154 g=0.073\n",
            ">615, d1=0.205, d2=0.144 g=0.411\n",
            ">616, d1=0.177, d2=0.198 g=0.051\n",
            ">617, d1=0.077, d2=0.402 g=0.486\n",
            ">618, d1=0.047, d2=0.499 g=0.047\n",
            ">619, d1=0.024, d2=0.696 g=0.668\n",
            ">620, d1=0.040, d2=0.981 g=0.065\n",
            ">621, d1=0.067, d2=0.691 g=0.511\n",
            ">622, d1=0.041, d2=0.188 g=0.189\n",
            ">623, d1=0.025, d2=0.099 g=0.314\n",
            ">624, d1=0.035, d2=0.128 g=0.061\n",
            ">625, d1=0.025, d2=0.080 g=0.111\n",
            ">626, d1=0.038, d2=0.055 g=0.045\n",
            ">627, d1=0.031, d2=0.106 g=0.226\n",
            ">628, d1=0.031, d2=0.137 g=0.047\n",
            ">629, d1=0.035, d2=0.205 g=0.315\n",
            ">630, d1=0.074, d2=0.335 g=0.079\n",
            ">631, d1=0.148, d2=0.485 g=0.480\n",
            ">632, d1=0.249, d2=0.411 g=0.049\n",
            ">633, d1=0.170, d2=0.622 g=1.035\n",
            ">634, d1=0.124, d2=1.839 g=0.422\n",
            ">635, d1=0.324, d2=0.426 g=0.667\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Saved generated_plot_000635.png and model_000635.h5\n",
            ">636, d1=0.360, d2=0.435 g=0.856\n",
            ">637, d1=0.204, d2=1.021 g=0.065\n",
            ">638, d1=0.172, d2=1.085 g=2.408\n",
            ">639, d1=0.416, d2=0.725 g=0.167\n",
            ">640, d1=0.376, d2=0.497 g=0.843\n",
            ">641, d1=0.202, d2=0.118 g=0.080\n",
            ">642, d1=0.081, d2=0.051 g=0.102\n",
            ">643, d1=0.072, d2=0.050 g=0.161\n",
            ">644, d1=0.022, d2=0.040 g=0.116\n",
            ">645, d1=0.030, d2=0.036 g=0.159\n",
            ">646, d1=0.043, d2=0.053 g=0.113\n",
            ">647, d1=0.049, d2=0.044 g=0.128\n",
            ">648, d1=0.043, d2=0.047 g=0.065\n",
            ">649, d1=0.036, d2=0.092 g=0.233\n",
            ">650, d1=0.068, d2=0.098 g=0.061\n",
            ">651, d1=0.063, d2=0.101 g=0.211\n",
            ">652, d1=0.043, d2=0.171 g=0.054\n",
            ">653, d1=0.041, d2=0.281 g=0.326\n",
            ">654, d1=0.059, d2=0.428 g=0.122\n",
            ">655, d1=0.077, d2=0.769 g=0.803\n",
            ">656, d1=0.106, d2=1.371 g=0.456\n",
            ">657, d1=0.133, d2=2.075 g=1.155\n",
            ">658, d1=0.275, d2=2.600 g=0.588\n",
            ">659, d1=0.479, d2=3.153 g=2.711\n",
            ">660, d1=0.827, d2=5.263 g=1.527\n",
            ">661, d1=1.841, d2=1.186 g=0.781\n",
            ">662, d1=1.147, d2=0.052 g=0.377\n",
            ">663, d1=0.251, d2=0.084 g=0.586\n",
            ">664, d1=0.055, d2=0.074 g=0.338\n",
            ">665, d1=0.096, d2=0.170 g=0.533\n",
            ">666, d1=0.080, d2=0.050 g=0.209\n",
            ">667, d1=0.087, d2=0.041 g=0.086\n",
            ">668, d1=0.072, d2=0.132 g=0.230\n",
            ">669, d1=0.049, d2=0.144 g=0.076\n",
            ">670, d1=0.071, d2=0.213 g=0.257\n",
            ">671, d1=0.142, d2=0.171 g=0.055\n",
            ">672, d1=0.133, d2=0.173 g=0.216\n",
            ">673, d1=0.133, d2=0.090 g=0.094\n",
            ">674, d1=0.114, d2=0.049 g=0.122\n",
            ">675, d1=0.063, d2=0.046 g=0.078\n",
            ">676, d1=0.033, d2=0.109 g=0.366\n",
            ">677, d1=0.099, d2=0.205 g=0.092\n",
            ">678, d1=0.104, d2=0.424 g=0.516\n",
            ">679, d1=0.211, d2=0.698 g=0.298\n",
            ">680, d1=0.335, d2=1.010 g=0.944\n",
            ">681, d1=0.763, d2=0.980 g=0.291\n",
            ">682, d1=0.633, d2=0.941 g=2.162\n",
            ">683, d1=0.542, d2=1.605 g=0.623\n",
            ">684, d1=0.661, d2=0.232 g=0.796\n",
            ">685, d1=0.431, d2=0.094 g=1.033\n",
            ">686, d1=0.101, d2=0.231 g=0.879\n",
            ">687, d1=0.360, d2=0.059 g=0.101\n",
            ">688, d1=0.110, d2=0.057 g=0.152\n",
            ">689, d1=0.099, d2=0.163 g=0.567\n",
            ">690, d1=0.042, d2=0.161 g=0.085\n",
            ">691, d1=0.084, d2=0.220 g=0.583\n",
            ">692, d1=0.182, d2=0.160 g=0.118\n",
            ">693, d1=0.183, d2=0.128 g=0.211\n",
            ">694, d1=0.065, d2=0.128 g=0.103\n",
            ">695, d1=0.041, d2=0.157 g=0.234\n",
            ">696, d1=0.067, d2=0.254 g=0.196\n",
            ">697, d1=0.153, d2=0.356 g=0.337\n",
            ">698, d1=0.243, d2=0.289 g=0.160\n",
            ">699, d1=0.227, d2=0.458 g=0.490\n",
            ">700, d1=0.244, d2=0.549 g=0.268\n",
            ">701, d1=0.278, d2=0.712 g=1.079\n",
            ">702, d1=0.424, d2=0.708 g=0.177\n",
            ">703, d1=0.511, d2=0.484 g=1.208\n",
            ">704, d1=0.368, d2=0.496 g=0.428\n",
            ">705, d1=0.239, d2=0.046 g=0.061\n",
            ">706, d1=0.095, d2=0.045 g=0.123\n",
            ">707, d1=0.067, d2=0.177 g=0.527\n",
            ">708, d1=0.048, d2=0.066 g=0.180\n",
            ">709, d1=0.144, d2=0.160 g=0.248\n",
            ">710, d1=0.183, d2=0.267 g=0.109\n",
            ">711, d1=0.158, d2=1.011 g=2.465\n",
            ">712, d1=0.125, d2=4.767 g=2.855\n",
            ">713, d1=1.072, d2=0.597 g=0.268\n",
            ">714, d1=1.335, d2=0.291 g=0.357\n",
            ">715, d1=0.900, d2=0.288 g=0.742\n",
            ">716, d1=0.976, d2=0.244 g=0.416\n",
            ">717, d1=0.916, d2=0.105 g=0.300\n",
            ">718, d1=0.118, d2=0.154 g=0.391\n",
            ">719, d1=0.085, d2=0.071 g=0.299\n",
            ">720, d1=0.044, d2=0.047 g=0.254\n",
            ">721, d1=0.070, d2=0.060 g=0.159\n",
            ">722, d1=0.053, d2=0.099 g=0.092\n",
            ">723, d1=0.035, d2=0.270 g=0.524\n",
            ">724, d1=0.050, d2=0.569 g=0.342\n",
            ">725, d1=0.141, d2=1.551 g=1.908\n",
            ">726, d1=0.623, d2=2.258 g=0.440\n",
            ">727, d1=2.084, d2=2.934 g=6.027\n",
            ">728, d1=3.685, d2=9.854 g=6.708\n",
            ">729, d1=6.287, d2=3.294 g=3.692\n",
            ">730, d1=1.866, d2=2.607 g=0.118\n",
            ">731, d1=1.348, d2=4.323 g=5.946\n",
            ">732, d1=0.400, d2=5.704 g=0.209\n",
            ">733, d1=0.389, d2=11.892 g=11.830\n",
            ">734, d1=3.223, d2=13.267 g=1.671\n",
            ">735, d1=3.388, d2=13.918 g=6.472\n",
            ">736, d1=2.120, d2=7.446 g=0.221\n",
            ">737, d1=1.030, d2=9.733 g=9.702\n",
            ">738, d1=1.864, d2=8.908 g=0.472\n",
            ">739, d1=0.744, d2=10.037 g=4.435\n",
            ">740, d1=0.980, d2=5.923 g=0.308\n",
            ">741, d1=0.576, d2=5.507 g=3.483\n",
            ">742, d1=0.546, d2=3.924 g=0.341\n",
            ">743, d1=0.630, d2=6.011 g=4.406\n",
            ">744, d1=1.957, d2=3.802 g=0.356\n",
            ">745, d1=1.071, d2=5.361 g=5.135\n",
            ">746, d1=1.029, d2=5.880 g=0.514\n",
            ">747, d1=1.235, d2=6.335 g=4.444\n",
            ">748, d1=1.430, d2=2.505 g=0.185\n",
            ">749, d1=0.313, d2=5.931 g=7.526\n",
            ">750, d1=1.380, d2=9.263 g=2.756\n",
            ">751, d1=3.740, d2=4.034 g=5.227\n",
            ">752, d1=0.717, d2=1.582 g=1.774\n",
            ">753, d1=0.377, d2=5.916 g=8.617\n",
            ">754, d1=1.076, d2=3.315 g=0.702\n",
            ">755, d1=0.633, d2=6.656 g=10.433\n",
            ">756, d1=2.328, d2=3.755 g=4.229\n",
            ">757, d1=1.164, d2=2.592 g=3.834\n",
            ">758, d1=0.429, d2=0.416 g=1.015\n",
            ">759, d1=0.255, d2=5.191 g=23.872\n",
            ">760, d1=2.223, d2=1.026 g=0.673\n",
            ">761, d1=0.631, d2=16.595 g=79.848\n",
            ">762, d1=2.836, d2=37.602 g=30.050\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Saved generated_plot_000762.png and model_000762.h5\n",
            ">763, d1=4.725, d2=2.570 g=10.789\n",
            ">764, d1=2.413, d2=4.630 g=48.285\n",
            ">765, d1=6.410, d2=3.068 g=8.532\n",
            ">766, d1=5.160, d2=38.330 g=120.720\n",
            ">767, d1=6.798, d2=138.330 g=75.366\n",
            ">768, d1=20.396, d2=66.727 g=4.170\n",
            ">769, d1=14.820, d2=14.631 g=0.995\n",
            ">770, d1=3.018, d2=8.749 g=3.216\n",
            ">771, d1=2.053, d2=1.065 g=0.878\n",
            ">772, d1=2.075, d2=9.628 g=24.704\n",
            ">773, d1=1.631, d2=14.381 g=2.841\n",
            ">774, d1=1.918, d2=31.604 g=15.971\n",
            ">775, d1=3.236, d2=4.723 g=6.067\n",
            ">776, d1=2.529, d2=18.746 g=15.100\n",
            ">777, d1=5.977, d2=9.039 g=0.779\n",
            ">778, d1=2.040, d2=22.902 g=9.119\n",
            ">779, d1=1.471, d2=11.042 g=1.030\n",
            ">780, d1=2.682, d2=18.041 g=5.148\n",
            ">781, d1=1.317, d2=3.936 g=3.892\n",
            ">782, d1=1.651, d2=5.343 g=3.506\n",
            ">783, d1=1.577, d2=0.886 g=1.046\n",
            ">784, d1=0.787, d2=2.106 g=1.281\n",
            ">785, d1=1.087, d2=0.273 g=0.781\n",
            ">786, d1=0.979, d2=0.545 g=0.736\n",
            ">787, d1=0.745, d2=0.139 g=0.394\n",
            ">788, d1=0.374, d2=0.329 g=0.609\n",
            ">789, d1=0.469, d2=0.153 g=0.199\n",
            ">790, d1=0.448, d2=0.389 g=0.369\n",
            ">791, d1=0.517, d2=0.371 g=0.793\n",
            ">792, d1=0.512, d2=0.256 g=0.979\n",
            ">793, d1=0.682, d2=0.328 g=0.369\n",
            ">794, d1=0.301, d2=1.564 g=2.266\n",
            ">795, d1=0.303, d2=6.185 g=6.426\n",
            ">796, d1=0.342, d2=17.763 g=20.855\n",
            ">797, d1=1.400, d2=12.216 g=0.680\n",
            ">798, d1=1.272, d2=18.749 g=7.175\n",
            ">799, d1=1.268, d2=16.595 g=0.169\n",
            ">800, d1=0.938, d2=8.152 g=0.584\n",
            ">801, d1=0.690, d2=1.718 g=0.487\n",
            ">802, d1=0.714, d2=1.154 g=0.795\n",
            ">803, d1=0.283, d2=0.413 g=0.315\n",
            ">804, d1=0.379, d2=0.480 g=0.732\n",
            ">805, d1=0.294, d2=0.303 g=0.267\n",
            ">806, d1=0.366, d2=0.513 g=0.726\n",
            ">807, d1=0.264, d2=0.375 g=0.118\n",
            ">808, d1=0.490, d2=0.798 g=0.778\n",
            ">809, d1=0.305, d2=0.698 g=0.124\n",
            ">810, d1=0.236, d2=0.986 g=1.190\n",
            ">811, d1=0.418, d2=0.839 g=0.124\n",
            ">812, d1=0.239, d2=1.528 g=1.902\n",
            ">813, d1=0.267, d2=1.633 g=0.073\n",
            ">814, d1=0.301, d2=3.129 g=3.141\n",
            ">815, d1=0.503, d2=3.272 g=0.092\n",
            ">816, d1=0.249, d2=5.697 g=4.615\n",
            ">817, d1=0.495, d2=6.021 g=0.188\n",
            ">818, d1=0.212, d2=9.677 g=5.797\n",
            ">819, d1=0.884, d2=9.176 g=0.183\n",
            ">820, d1=0.477, d2=11.731 g=5.455\n",
            ">821, d1=0.810, d2=9.197 g=0.088\n",
            ">822, d1=0.499, d2=10.295 g=4.331\n",
            ">823, d1=0.397, d2=6.790 g=0.343\n",
            ">824, d1=0.295, d2=5.999 g=2.964\n",
            ">825, d1=0.319, d2=3.761 g=0.267\n",
            ">826, d1=0.129, d2=3.476 g=1.928\n",
            ">827, d1=0.254, d2=1.383 g=0.606\n",
            ">828, d1=0.175, d2=1.897 g=2.530\n",
            ">829, d1=0.253, d2=1.839 g=0.392\n",
            ">830, d1=0.166, d2=1.878 g=1.869\n",
            ">831, d1=0.159, d2=0.942 g=0.545\n",
            ">832, d1=0.146, d2=1.117 g=1.611\n",
            ">833, d1=0.257, d2=0.806 g=0.255\n",
            ">834, d1=0.169, d2=0.879 g=0.896\n",
            ">835, d1=0.199, d2=0.143 g=0.920\n",
            ">836, d1=0.262, d2=0.133 g=0.326\n",
            ">837, d1=0.155, d2=0.101 g=0.214\n",
            ">838, d1=0.263, d2=0.131 g=0.105\n",
            ">839, d1=0.113, d2=0.153 g=0.305\n",
            ">840, d1=0.163, d2=0.126 g=0.087\n",
            ">841, d1=0.088, d2=0.276 g=0.536\n",
            ">842, d1=0.271, d2=0.259 g=0.052\n",
            ">843, d1=0.159, d2=0.871 g=1.332\n",
            ">844, d1=0.251, d2=0.797 g=0.069\n",
            ">845, d1=0.166, d2=1.484 g=1.969\n",
            ">846, d1=0.220, d2=2.205 g=0.076\n",
            ">847, d1=0.152, d2=4.129 g=3.060\n",
            ">848, d1=0.354, d2=5.486 g=0.249\n",
            ">849, d1=0.296, d2=6.199 g=1.647\n",
            ">850, d1=0.271, d2=3.741 g=0.113\n",
            ">851, d1=0.155, d2=2.398 g=0.669\n",
            ">852, d1=0.216, d2=0.850 g=0.317\n",
            ">853, d1=0.158, d2=0.838 g=0.632\n",
            ">854, d1=0.114, d2=0.257 g=0.306\n",
            ">855, d1=0.109, d2=0.225 g=0.388\n",
            ">856, d1=0.181, d2=0.096 g=0.385\n",
            ">857, d1=0.092, d2=0.125 g=0.635\n",
            ">858, d1=0.107, d2=0.104 g=0.286\n",
            ">859, d1=0.154, d2=0.136 g=0.446\n",
            ">860, d1=0.153, d2=0.100 g=0.249\n",
            ">861, d1=0.195, d2=0.207 g=0.460\n",
            ">862, d1=0.144, d2=0.145 g=0.240\n",
            ">863, d1=0.135, d2=0.356 g=0.703\n",
            ">864, d1=0.139, d2=0.316 g=0.143\n",
            ">865, d1=0.096, d2=0.225 g=0.294\n",
            ">866, d1=0.101, d2=0.163 g=0.166\n",
            ">867, d1=0.079, d2=0.173 g=0.436\n",
            ">868, d1=0.085, d2=0.139 g=0.151\n",
            ">869, d1=0.082, d2=0.280 g=0.449\n",
            ">870, d1=0.104, d2=0.213 g=0.149\n",
            ">871, d1=0.080, d2=0.200 g=0.311\n",
            ">872, d1=0.084, d2=0.169 g=0.099\n",
            ">873, d1=0.082, d2=0.421 g=0.576\n",
            ">874, d1=0.074, d2=0.649 g=0.048\n",
            ">875, d1=0.158, d2=0.768 g=0.593\n",
            ">876, d1=0.212, d2=0.766 g=0.060\n",
            ">877, d1=0.134, d2=1.004 g=0.539\n",
            ">878, d1=0.146, d2=0.850 g=0.061\n",
            ">879, d1=0.082, d2=0.752 g=0.508\n",
            ">880, d1=0.057, d2=0.690 g=0.090\n",
            ">881, d1=0.098, d2=0.512 g=0.256\n",
            ">882, d1=0.147, d2=0.185 g=0.161\n",
            ">883, d1=0.123, d2=0.115 g=0.214\n",
            ">884, d1=0.092, d2=0.112 g=0.119\n",
            ">885, d1=0.068, d2=0.072 g=0.158\n",
            ">886, d1=0.129, d2=0.085 g=0.084\n",
            ">887, d1=0.068, d2=0.102 g=0.207\n",
            ">888, d1=0.121, d2=0.058 g=0.134\n",
            ">889, d1=0.090, d2=0.054 g=0.151\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Saved generated_plot_000889.png and model_000889.h5\n",
            ">890, d1=0.118, d2=0.068 g=0.092\n",
            ">891, d1=0.048, d2=0.106 g=0.261\n",
            ">892, d1=0.058, d2=0.093 g=0.121\n",
            ">893, d1=0.070, d2=0.135 g=0.187\n",
            ">894, d1=0.108, d2=0.120 g=0.120\n",
            ">895, d1=0.068, d2=0.074 g=0.137\n",
            ">896, d1=0.056, d2=0.061 g=0.169\n",
            ">897, d1=0.044, d2=0.051 g=0.107\n",
            ">898, d1=0.077, d2=0.058 g=0.188\n",
            ">899, d1=0.068, d2=0.056 g=0.122\n",
            ">900, d1=0.082, d2=0.069 g=0.150\n",
            ">901, d1=0.060, d2=0.113 g=0.085\n",
            ">902, d1=0.065, d2=0.227 g=0.328\n",
            ">903, d1=0.089, d2=0.274 g=0.064\n",
            ">904, d1=0.085, d2=0.317 g=0.187\n",
            ">905, d1=0.071, d2=0.260 g=0.066\n",
            ">906, d1=0.083, d2=0.309 g=0.273\n",
            ">907, d1=0.078, d2=0.243 g=0.078\n",
            ">908, d1=0.086, d2=0.196 g=0.163\n",
            ">909, d1=0.069, d2=0.138 g=0.084\n",
            ">910, d1=0.069, d2=0.147 g=0.183\n",
            ">911, d1=0.059, d2=0.122 g=0.089\n",
            ">912, d1=0.046, d2=0.170 g=0.252\n",
            ">913, d1=0.097, d2=0.108 g=0.070\n",
            ">914, d1=0.098, d2=0.205 g=0.174\n",
            ">915, d1=0.038, d2=0.086 g=0.118\n",
            ">916, d1=0.070, d2=0.126 g=0.188\n",
            ">917, d1=0.071, d2=0.065 g=0.095\n",
            ">918, d1=0.049, d2=0.040 g=0.098\n",
            ">919, d1=0.067, d2=0.051 g=0.180\n",
            ">920, d1=0.046, d2=0.048 g=0.101\n",
            ">921, d1=0.063, d2=0.092 g=0.150\n",
            ">922, d1=0.061, d2=0.048 g=0.139\n",
            ">923, d1=0.037, d2=0.056 g=0.102\n",
            ">924, d1=0.050, d2=0.071 g=0.178\n",
            ">925, d1=0.048, d2=0.110 g=0.058\n",
            ">926, d1=0.105, d2=0.279 g=0.332\n",
            ">927, d1=0.069, d2=0.273 g=0.088\n",
            ">928, d1=0.047, d2=0.281 g=0.200\n",
            ">929, d1=0.082, d2=0.074 g=0.150\n",
            ">930, d1=0.060, d2=0.052 g=0.074\n",
            ">931, d1=0.052, d2=0.127 g=0.330\n",
            ">932, d1=0.068, d2=0.212 g=0.068\n",
            ">933, d1=0.065, d2=0.291 g=0.222\n",
            ">934, d1=0.115, d2=0.151 g=0.139\n",
            ">935, d1=0.067, d2=0.134 g=0.203\n",
            ">936, d1=0.041, d2=0.085 g=0.112\n",
            ">937, d1=0.039, d2=0.086 g=0.110\n",
            ">938, d1=0.065, d2=0.070 g=0.249\n",
            ">939, d1=0.045, d2=0.036 g=0.251\n",
            ">940, d1=0.076, d2=0.057 g=0.261\n",
            ">941, d1=0.078, d2=0.089 g=0.095\n",
            ">942, d1=0.053, d2=0.219 g=0.348\n",
            ">943, d1=0.060, d2=0.223 g=0.086\n",
            ">944, d1=0.056, d2=0.294 g=0.329\n",
            ">945, d1=0.075, d2=0.239 g=0.061\n",
            ">946, d1=0.052, d2=0.209 g=0.224\n",
            ">947, d1=0.070, d2=0.092 g=0.164\n",
            ">948, d1=0.043, d2=0.058 g=0.163\n",
            ">949, d1=0.033, d2=0.056 g=0.153\n",
            ">950, d1=0.038, d2=0.064 g=0.285\n",
            ">951, d1=0.042, d2=0.080 g=0.138\n",
            ">952, d1=0.045, d2=0.099 g=0.282\n",
            ">953, d1=0.047, d2=0.103 g=0.154\n",
            ">954, d1=0.054, d2=0.077 g=0.170\n",
            ">955, d1=0.067, d2=0.057 g=0.198\n",
            ">956, d1=0.041, d2=0.046 g=0.146\n",
            ">957, d1=0.053, d2=0.037 g=0.149\n",
            ">958, d1=0.061, d2=0.052 g=0.087\n",
            ">959, d1=0.044, d2=0.073 g=0.140\n",
            ">960, d1=0.052, d2=0.035 g=0.205\n",
            ">961, d1=0.043, d2=0.046 g=0.117\n",
            ">962, d1=0.049, d2=0.059 g=0.125\n",
            ">963, d1=0.080, d2=0.037 g=0.172\n",
            ">964, d1=0.052, d2=0.059 g=0.137\n",
            ">965, d1=0.051, d2=0.036 g=0.265\n",
            ">966, d1=0.050, d2=0.067 g=0.199\n",
            ">967, d1=0.067, d2=0.050 g=0.219\n",
            ">968, d1=0.060, d2=0.058 g=0.233\n",
            ">969, d1=0.057, d2=0.043 g=0.179\n",
            ">970, d1=0.066, d2=0.045 g=0.141\n",
            ">971, d1=0.089, d2=0.053 g=0.164\n",
            ">972, d1=0.041, d2=0.063 g=0.163\n",
            ">973, d1=0.081, d2=0.055 g=0.207\n",
            ">974, d1=0.027, d2=0.088 g=0.130\n",
            ">975, d1=0.056, d2=0.161 g=0.319\n",
            ">976, d1=0.087, d2=0.128 g=0.107\n",
            ">977, d1=0.051, d2=0.143 g=0.269\n",
            ">978, d1=0.082, d2=0.142 g=0.103\n",
            ">979, d1=0.053, d2=0.205 g=0.297\n",
            ">980, d1=0.074, d2=0.118 g=0.169\n",
            ">981, d1=0.033, d2=0.104 g=0.159\n",
            ">982, d1=0.028, d2=0.054 g=0.232\n",
            ">983, d1=0.094, d2=0.051 g=0.233\n",
            ">984, d1=0.064, d2=0.060 g=0.210\n",
            ">985, d1=0.040, d2=0.064 g=0.267\n",
            ">986, d1=0.064, d2=0.049 g=0.203\n",
            ">987, d1=0.041, d2=0.070 g=0.252\n",
            ">988, d1=0.045, d2=0.094 g=0.097\n",
            ">989, d1=0.051, d2=0.182 g=0.494\n",
            ">990, d1=0.046, d2=0.247 g=0.087\n",
            ">991, d1=0.050, d2=0.422 g=0.624\n",
            ">992, d1=0.062, d2=0.656 g=0.062\n",
            ">993, d1=0.066, d2=0.965 g=0.943\n",
            ">994, d1=0.092, d2=1.157 g=0.054\n",
            ">995, d1=0.070, d2=1.076 g=0.495\n",
            ">996, d1=0.089, d2=0.623 g=0.180\n",
            ">997, d1=0.060, d2=0.302 g=0.257\n",
            ">998, d1=0.062, d2=0.149 g=0.181\n",
            ">999, d1=0.038, d2=0.102 g=0.281\n",
            ">1000, d1=0.094, d2=0.079 g=0.261\n",
            ">1001, d1=0.035, d2=0.088 g=0.219\n",
            ">1002, d1=0.049, d2=0.075 g=0.325\n",
            ">1003, d1=0.044, d2=0.061 g=0.217\n",
            ">1004, d1=0.063, d2=0.100 g=0.460\n",
            ">1005, d1=0.054, d2=0.101 g=0.269\n",
            ">1006, d1=0.054, d2=0.126 g=0.497\n",
            ">1007, d1=0.057, d2=0.102 g=0.259\n",
            ">1008, d1=0.031, d2=0.109 g=0.335\n",
            ">1009, d1=0.028, d2=0.041 g=0.289\n",
            ">1010, d1=0.084, d2=0.120 g=0.479\n",
            ">1011, d1=0.056, d2=0.132 g=0.231\n",
            ">1012, d1=0.059, d2=0.177 g=0.408\n",
            ">1013, d1=0.041, d2=0.147 g=0.185\n",
            ">1014, d1=0.083, d2=0.190 g=0.401\n",
            ">1015, d1=0.040, d2=0.109 g=0.365\n",
            ">1016, d1=0.061, d2=0.069 g=0.323\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Saved generated_plot_001016.png and model_001016.h5\n",
            ">1017, d1=0.061, d2=0.088 g=0.435\n",
            ">1018, d1=0.071, d2=0.082 g=0.253\n",
            ">1019, d1=0.044, d2=0.095 g=0.308\n",
            ">1020, d1=0.050, d2=0.072 g=0.344\n",
            ">1021, d1=0.047, d2=0.079 g=0.304\n",
            ">1022, d1=0.053, d2=0.119 g=0.323\n",
            ">1023, d1=0.026, d2=0.055 g=0.481\n",
            ">1024, d1=0.058, d2=0.088 g=0.285\n",
            ">1025, d1=0.035, d2=0.117 g=0.440\n",
            ">1026, d1=0.026, d2=0.097 g=0.219\n",
            ">1027, d1=0.066, d2=0.179 g=0.478\n",
            ">1028, d1=0.067, d2=0.158 g=0.273\n",
            ">1029, d1=0.044, d2=0.172 g=0.262\n",
            ">1030, d1=0.055, d2=0.106 g=0.275\n",
            ">1031, d1=0.028, d2=0.085 g=0.301\n",
            ">1032, d1=0.036, d2=0.073 g=0.386\n",
            ">1033, d1=0.047, d2=0.070 g=0.303\n",
            ">1034, d1=0.048, d2=0.101 g=0.228\n",
            ">1035, d1=0.044, d2=0.080 g=0.342\n",
            ">1036, d1=0.069, d2=0.071 g=0.341\n",
            ">1037, d1=0.048, d2=0.054 g=0.299\n",
            ">1038, d1=0.071, d2=0.131 g=0.279\n",
            ">1039, d1=0.041, d2=0.097 g=0.349\n",
            ">1040, d1=0.038, d2=0.064 g=0.303\n",
            ">1041, d1=0.038, d2=0.113 g=0.440\n",
            ">1042, d1=0.045, d2=0.095 g=0.298\n",
            ">1043, d1=0.037, d2=0.100 g=0.321\n",
            ">1044, d1=0.046, d2=0.061 g=0.246\n",
            ">1045, d1=0.062, d2=0.107 g=0.177\n",
            ">1046, d1=0.039, d2=0.155 g=0.216\n",
            ">1047, d1=0.039, d2=0.132 g=0.368\n",
            ">1048, d1=0.082, d2=0.081 g=0.222\n",
            ">1049, d1=0.047, d2=0.119 g=0.304\n",
            ">1050, d1=0.063, d2=0.105 g=0.169\n",
            ">1051, d1=0.057, d2=0.144 g=0.317\n",
            ">1052, d1=0.058, d2=0.099 g=0.356\n",
            ">1053, d1=0.045, d2=0.096 g=0.175\n",
            ">1054, d1=0.053, d2=0.120 g=0.279\n",
            ">1055, d1=0.049, d2=0.147 g=0.269\n",
            ">1056, d1=0.050, d2=0.113 g=0.245\n",
            ">1057, d1=0.065, d2=0.159 g=0.257\n",
            ">1058, d1=0.064, d2=0.091 g=0.249\n",
            ">1059, d1=0.077, d2=0.172 g=0.285\n",
            ">1060, d1=0.045, d2=0.106 g=0.194\n",
            ">1061, d1=0.072, d2=0.079 g=0.181\n",
            ">1062, d1=0.034, d2=0.111 g=0.107\n",
            ">1063, d1=0.052, d2=0.109 g=0.175\n",
            ">1064, d1=0.062, d2=0.089 g=0.349\n",
            ">1065, d1=0.049, d2=0.067 g=0.207\n",
            ">1066, d1=0.041, d2=0.107 g=0.094\n",
            ">1067, d1=0.053, d2=0.115 g=0.116\n",
            ">1068, d1=0.034, d2=0.083 g=0.149\n",
            ">1069, d1=0.049, d2=0.121 g=0.159\n",
            ">1070, d1=0.055, d2=0.094 g=0.161\n",
            ">1071, d1=0.046, d2=0.107 g=0.332\n",
            ">1072, d1=0.037, d2=0.110 g=0.239\n",
            ">1073, d1=0.074, d2=0.092 g=0.099\n",
            ">1074, d1=0.034, d2=0.089 g=0.165\n",
            ">1075, d1=0.036, d2=0.071 g=0.194\n",
            ">1076, d1=0.077, d2=0.069 g=0.153\n",
            ">1077, d1=0.026, d2=0.055 g=0.251\n",
            ">1078, d1=0.031, d2=0.133 g=0.219\n",
            ">1079, d1=0.060, d2=0.098 g=0.161\n",
            ">1080, d1=0.040, d2=0.103 g=0.171\n",
            ">1081, d1=0.035, d2=0.103 g=0.293\n",
            ">1082, d1=0.053, d2=0.064 g=0.278\n",
            ">1083, d1=0.054, d2=0.060 g=0.172\n",
            ">1084, d1=0.039, d2=0.074 g=0.171\n",
            ">1085, d1=0.061, d2=0.077 g=0.147\n",
            ">1086, d1=0.030, d2=0.129 g=0.207\n",
            ">1087, d1=0.041, d2=0.136 g=0.081\n",
            ">1088, d1=0.038, d2=0.224 g=0.231\n",
            ">1089, d1=0.052, d2=0.150 g=0.106\n",
            ">1090, d1=0.044, d2=0.192 g=0.250\n",
            ">1091, d1=0.054, d2=0.162 g=0.145\n",
            ">1092, d1=0.039, d2=0.142 g=0.163\n",
            ">1093, d1=0.055, d2=0.068 g=0.198\n",
            ">1094, d1=0.047, d2=0.134 g=0.138\n",
            ">1095, d1=0.059, d2=0.081 g=0.162\n",
            ">1096, d1=0.028, d2=0.129 g=0.207\n",
            ">1097, d1=0.058, d2=0.105 g=0.184\n",
            ">1098, d1=0.046, d2=0.070 g=0.176\n",
            ">1099, d1=0.045, d2=0.074 g=0.268\n",
            ">1100, d1=0.050, d2=0.064 g=0.177\n",
            ">1101, d1=0.045, d2=0.120 g=0.235\n",
            ">1102, d1=0.106, d2=0.098 g=0.122\n",
            ">1103, d1=0.061, d2=0.146 g=0.276\n",
            ">1104, d1=0.044, d2=0.071 g=0.267\n",
            ">1105, d1=0.066, d2=0.076 g=0.246\n",
            ">1106, d1=0.046, d2=0.099 g=0.167\n",
            ">1107, d1=0.040, d2=0.120 g=0.171\n",
            ">1108, d1=0.065, d2=0.086 g=0.166\n",
            ">1109, d1=0.038, d2=0.106 g=0.300\n",
            ">1110, d1=0.047, d2=0.106 g=0.177\n",
            ">1111, d1=0.045, d2=0.046 g=0.222\n",
            ">1112, d1=0.065, d2=0.067 g=0.159\n",
            ">1113, d1=0.057, d2=0.090 g=0.097\n",
            ">1114, d1=0.050, d2=0.102 g=0.191\n",
            ">1115, d1=0.047, d2=0.041 g=0.200\n",
            ">1116, d1=0.056, d2=0.068 g=0.141\n",
            ">1117, d1=0.047, d2=0.070 g=0.187\n",
            ">1118, d1=0.050, d2=0.100 g=0.183\n",
            ">1119, d1=0.028, d2=0.098 g=0.129\n",
            ">1120, d1=0.046, d2=0.075 g=0.234\n",
            ">1121, d1=0.028, d2=0.105 g=0.214\n",
            ">1122, d1=0.050, d2=0.080 g=0.111\n",
            ">1123, d1=0.037, d2=0.097 g=0.213\n",
            ">1124, d1=0.066, d2=0.072 g=0.140\n",
            ">1125, d1=0.048, d2=0.103 g=0.130\n",
            ">1126, d1=0.043, d2=0.132 g=0.152\n",
            ">1127, d1=0.048, d2=0.057 g=0.220\n",
            ">1128, d1=0.049, d2=0.115 g=0.166\n",
            ">1129, d1=0.026, d2=0.075 g=0.101\n",
            ">1130, d1=0.034, d2=0.059 g=0.109\n",
            ">1131, d1=0.040, d2=0.100 g=0.145\n",
            ">1132, d1=0.052, d2=0.103 g=0.189\n",
            ">1133, d1=0.030, d2=0.070 g=0.242\n",
            ">1134, d1=0.051, d2=0.079 g=0.201\n",
            ">1135, d1=0.047, d2=0.105 g=0.341\n",
            ">1136, d1=0.041, d2=0.125 g=0.207\n",
            ">1137, d1=0.067, d2=0.078 g=0.143\n",
            ">1138, d1=0.053, d2=0.080 g=0.186\n",
            ">1139, d1=0.062, d2=0.141 g=0.164\n",
            ">1140, d1=0.050, d2=0.086 g=0.235\n",
            ">1141, d1=0.046, d2=0.109 g=0.118\n",
            ">1142, d1=0.067, d2=0.244 g=0.256\n",
            ">1143, d1=0.057, d2=0.101 g=0.182\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Saved generated_plot_001143.png and model_001143.h5\n",
            ">1144, d1=0.046, d2=0.131 g=0.251\n",
            ">1145, d1=0.032, d2=0.076 g=0.173\n",
            ">1146, d1=0.048, d2=0.131 g=0.255\n",
            ">1147, d1=0.107, d2=0.097 g=0.194\n",
            ">1148, d1=0.061, d2=0.086 g=0.255\n",
            ">1149, d1=0.040, d2=0.087 g=0.224\n",
            ">1150, d1=0.113, d2=0.084 g=0.327\n",
            ">1151, d1=0.055, d2=0.079 g=0.168\n",
            ">1152, d1=0.136, d2=0.045 g=0.168\n",
            ">1153, d1=0.038, d2=0.104 g=0.205\n",
            ">1154, d1=0.068, d2=0.156 g=0.214\n",
            ">1155, d1=0.043, d2=0.104 g=0.233\n",
            ">1156, d1=0.063, d2=0.104 g=0.188\n",
            ">1157, d1=0.033, d2=0.075 g=0.253\n",
            ">1158, d1=0.054, d2=0.104 g=0.178\n",
            ">1159, d1=0.082, d2=0.122 g=0.181\n",
            ">1160, d1=0.047, d2=0.106 g=0.231\n",
            ">1161, d1=0.026, d2=0.097 g=0.379\n",
            ">1162, d1=0.083, d2=0.106 g=0.134\n",
            ">1163, d1=0.059, d2=0.123 g=0.236\n",
            ">1164, d1=0.050, d2=0.126 g=0.221\n",
            ">1165, d1=0.067, d2=0.094 g=0.216\n",
            ">1166, d1=0.065, d2=0.092 g=0.250\n",
            ">1167, d1=0.077, d2=0.077 g=0.177\n",
            ">1168, d1=0.042, d2=0.134 g=0.261\n",
            ">1169, d1=0.118, d2=0.124 g=0.169\n",
            ">1170, d1=0.068, d2=0.093 g=0.117\n",
            ">1171, d1=0.086, d2=0.213 g=0.275\n",
            ">1172, d1=0.063, d2=0.104 g=0.377\n",
            ">1173, d1=0.044, d2=0.125 g=0.366\n",
            ">1174, d1=0.066, d2=0.076 g=0.397\n",
            ">1175, d1=0.040, d2=0.058 g=0.281\n",
            ">1176, d1=0.063, d2=0.084 g=0.244\n",
            ">1177, d1=0.050, d2=0.102 g=0.325\n",
            ">1178, d1=0.080, d2=0.107 g=0.223\n",
            ">1179, d1=0.039, d2=0.113 g=0.361\n",
            ">1180, d1=0.138, d2=0.037 g=0.360\n",
            ">1181, d1=0.033, d2=0.076 g=0.602\n",
            ">1182, d1=0.034, d2=0.065 g=0.455\n",
            ">1183, d1=0.043, d2=0.088 g=0.409\n",
            ">1184, d1=0.044, d2=0.105 g=0.149\n",
            ">1185, d1=0.055, d2=0.132 g=0.417\n",
            ">1186, d1=0.069, d2=0.094 g=0.430\n",
            ">1187, d1=0.048, d2=0.124 g=0.481\n",
            ">1188, d1=0.057, d2=0.089 g=0.592\n",
            ">1189, d1=0.038, d2=0.062 g=0.409\n",
            ">1190, d1=0.039, d2=0.138 g=0.380\n",
            ">1191, d1=0.052, d2=0.055 g=0.589\n",
            ">1192, d1=0.062, d2=0.040 g=0.438\n",
            ">1193, d1=0.070, d2=0.109 g=0.480\n",
            ">1194, d1=0.061, d2=0.075 g=0.439\n",
            ">1195, d1=0.061, d2=0.124 g=0.246\n",
            ">1196, d1=0.083, d2=0.165 g=0.438\n",
            ">1197, d1=0.071, d2=0.077 g=0.308\n",
            ">1198, d1=0.073, d2=0.128 g=0.300\n",
            ">1199, d1=0.049, d2=0.086 g=0.442\n",
            ">1200, d1=0.063, d2=0.081 g=0.443\n",
            ">1201, d1=0.035, d2=0.106 g=0.394\n",
            ">1202, d1=0.040, d2=0.056 g=0.379\n",
            ">1203, d1=0.059, d2=0.127 g=0.476\n",
            ">1204, d1=0.078, d2=0.111 g=0.228\n",
            ">1205, d1=0.024, d2=0.259 g=0.688\n",
            ">1206, d1=0.126, d2=0.203 g=0.296\n",
            ">1207, d1=0.076, d2=0.303 g=0.424\n",
            ">1208, d1=0.065, d2=0.173 g=0.320\n",
            ">1209, d1=0.055, d2=0.202 g=0.297\n",
            ">1210, d1=0.050, d2=0.095 g=0.340\n",
            ">1211, d1=0.085, d2=0.155 g=0.406\n",
            ">1212, d1=0.028, d2=0.116 g=0.580\n",
            ">1213, d1=0.044, d2=0.110 g=0.221\n",
            ">1214, d1=0.050, d2=0.314 g=0.533\n",
            ">1215, d1=0.083, d2=0.153 g=0.340\n",
            ">1216, d1=0.054, d2=0.129 g=0.254\n",
            ">1217, d1=0.039, d2=0.135 g=0.639\n",
            ">1218, d1=0.092, d2=0.169 g=0.144\n",
            ">1219, d1=0.127, d2=0.087 g=0.178\n",
            ">1220, d1=0.051, d2=0.081 g=0.291\n",
            ">1221, d1=0.038, d2=0.153 g=0.188\n",
            ">1222, d1=0.057, d2=0.128 g=0.257\n",
            ">1223, d1=0.078, d2=0.099 g=0.281\n",
            ">1224, d1=0.028, d2=0.093 g=0.324\n",
            ">1225, d1=0.067, d2=0.076 g=0.186\n",
            ">1226, d1=0.051, d2=0.123 g=0.233\n",
            ">1227, d1=0.037, d2=0.067 g=0.172\n",
            ">1228, d1=0.022, d2=0.107 g=0.224\n",
            ">1229, d1=0.056, d2=0.131 g=0.168\n",
            ">1230, d1=0.049, d2=0.207 g=0.287\n",
            ">1231, d1=0.046, d2=0.172 g=0.178\n",
            ">1232, d1=0.055, d2=0.176 g=0.256\n",
            ">1233, d1=0.045, d2=0.095 g=0.244\n",
            ">1234, d1=0.117, d2=0.225 g=0.301\n",
            ">1235, d1=0.062, d2=0.159 g=0.222\n",
            ">1236, d1=0.043, d2=0.168 g=0.170\n",
            ">1237, d1=0.040, d2=0.075 g=0.269\n",
            ">1238, d1=0.068, d2=0.101 g=0.204\n",
            ">1239, d1=0.053, d2=0.171 g=0.293\n",
            ">1240, d1=0.066, d2=0.142 g=0.261\n",
            ">1241, d1=0.042, d2=0.095 g=0.180\n",
            ">1242, d1=0.031, d2=0.164 g=0.224\n",
            ">1243, d1=0.056, d2=0.153 g=0.143\n",
            ">1244, d1=0.061, d2=0.115 g=0.175\n",
            ">1245, d1=0.050, d2=0.114 g=0.295\n",
            ">1246, d1=0.039, d2=0.081 g=0.185\n",
            ">1247, d1=0.074, d2=0.073 g=0.089\n",
            ">1248, d1=0.055, d2=0.173 g=0.189\n",
            ">1249, d1=0.118, d2=0.091 g=0.096\n",
            ">1250, d1=0.091, d2=0.114 g=0.263\n",
            ">1251, d1=0.074, d2=0.124 g=0.134\n",
            ">1252, d1=0.040, d2=0.202 g=0.200\n",
            ">1253, d1=0.038, d2=0.170 g=0.160\n",
            ">1254, d1=0.029, d2=0.117 g=0.120\n",
            ">1255, d1=0.032, d2=0.110 g=0.183\n",
            ">1256, d1=0.095, d2=0.090 g=0.096\n",
            ">1257, d1=0.079, d2=0.118 g=0.149\n",
            ">1258, d1=0.081, d2=0.136 g=0.253\n",
            ">1259, d1=0.065, d2=0.094 g=0.153\n",
            ">1260, d1=0.068, d2=0.126 g=0.130\n",
            ">1261, d1=0.048, d2=0.081 g=0.170\n",
            ">1262, d1=0.046, d2=0.109 g=0.122\n",
            ">1263, d1=0.061, d2=0.090 g=0.178\n",
            ">1264, d1=0.055, d2=0.055 g=0.156\n",
            ">1265, d1=0.024, d2=0.070 g=0.140\n",
            ">1266, d1=0.046, d2=0.078 g=0.080\n",
            ">1267, d1=0.033, d2=0.131 g=0.191\n",
            ">1268, d1=0.032, d2=0.134 g=0.185\n",
            ">1269, d1=0.060, d2=0.111 g=0.104\n",
            ">1270, d1=0.032, d2=0.089 g=0.174\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Saved generated_plot_001270.png and model_001270.h5\n",
            ">1271, d1=0.071, d2=0.096 g=0.175\n",
            ">1272, d1=0.050, d2=0.080 g=0.174\n",
            ">1273, d1=0.037, d2=0.134 g=0.279\n",
            ">1274, d1=0.028, d2=0.118 g=0.057\n",
            ">1275, d1=0.036, d2=0.161 g=0.126\n",
            ">1276, d1=0.021, d2=0.074 g=0.291\n",
            ">1277, d1=0.075, d2=0.147 g=0.222\n",
            ">1278, d1=0.039, d2=0.087 g=0.133\n",
            ">1279, d1=0.074, d2=0.100 g=0.111\n",
            ">1280, d1=0.077, d2=0.206 g=0.314\n",
            ">1281, d1=0.067, d2=0.136 g=0.150\n",
            ">1282, d1=0.112, d2=0.102 g=0.087\n",
            ">1283, d1=0.026, d2=0.099 g=0.190\n",
            ">1284, d1=0.057, d2=0.068 g=0.235\n",
            ">1285, d1=0.030, d2=0.171 g=0.093\n",
            ">1286, d1=0.015, d2=0.226 g=0.205\n",
            ">1287, d1=0.061, d2=0.090 g=0.225\n",
            ">1288, d1=0.033, d2=0.095 g=0.097\n",
            ">1289, d1=0.043, d2=0.099 g=0.175\n",
            ">1290, d1=0.040, d2=0.125 g=0.070\n",
            ">1291, d1=0.063, d2=0.277 g=0.241\n",
            ">1292, d1=0.081, d2=0.128 g=0.235\n",
            ">1293, d1=0.041, d2=0.076 g=0.230\n",
            ">1294, d1=0.042, d2=0.084 g=0.212\n",
            ">1295, d1=0.042, d2=0.101 g=0.133\n",
            ">1296, d1=0.061, d2=0.073 g=0.148\n",
            ">1297, d1=0.037, d2=0.069 g=0.124\n",
            ">1298, d1=0.023, d2=0.113 g=0.069\n",
            ">1299, d1=0.068, d2=0.199 g=0.312\n",
            ">1300, d1=0.125, d2=0.132 g=0.122\n",
            ">1301, d1=0.036, d2=0.109 g=0.182\n",
            ">1302, d1=0.062, d2=0.055 g=0.201\n",
            ">1303, d1=0.043, d2=0.099 g=0.143\n",
            ">1304, d1=0.082, d2=0.092 g=0.081\n",
            ">1305, d1=0.063, d2=0.094 g=0.160\n",
            ">1306, d1=0.046, d2=0.074 g=0.100\n",
            ">1307, d1=0.021, d2=0.100 g=0.072\n",
            ">1308, d1=0.040, d2=0.120 g=0.157\n",
            ">1309, d1=0.047, d2=0.109 g=0.124\n",
            ">1310, d1=0.028, d2=0.086 g=0.076\n",
            ">1311, d1=0.028, d2=0.081 g=0.237\n",
            ">1312, d1=0.064, d2=0.096 g=0.171\n",
            ">1313, d1=0.024, d2=0.086 g=0.203\n",
            ">1314, d1=0.043, d2=0.069 g=0.232\n",
            ">1315, d1=0.049, d2=0.094 g=0.120\n",
            ">1316, d1=0.037, d2=0.150 g=0.356\n",
            ">1317, d1=0.069, d2=0.148 g=0.122\n",
            ">1318, d1=0.028, d2=0.288 g=0.230\n",
            ">1319, d1=0.067, d2=0.121 g=0.142\n",
            ">1320, d1=0.081, d2=0.125 g=0.101\n",
            ">1321, d1=0.057, d2=0.135 g=0.124\n",
            ">1322, d1=0.041, d2=0.107 g=0.179\n",
            ">1323, d1=0.060, d2=0.154 g=0.192\n",
            ">1324, d1=0.040, d2=0.185 g=0.087\n",
            ">1325, d1=0.094, d2=0.091 g=0.110\n",
            ">1326, d1=0.067, d2=0.100 g=0.117\n",
            ">1327, d1=0.033, d2=0.088 g=0.252\n",
            ">1328, d1=0.076, d2=0.094 g=0.130\n",
            ">1329, d1=0.027, d2=0.216 g=0.189\n",
            ">1330, d1=0.056, d2=0.161 g=0.203\n",
            ">1331, d1=0.047, d2=0.094 g=0.166\n",
            ">1332, d1=0.033, d2=0.061 g=0.185\n",
            ">1333, d1=0.038, d2=0.094 g=0.079\n",
            ">1334, d1=0.057, d2=0.073 g=0.122\n",
            ">1335, d1=0.029, d2=0.095 g=0.181\n",
            ">1336, d1=0.025, d2=0.097 g=0.118\n",
            ">1337, d1=0.027, d2=0.108 g=0.072\n",
            ">1338, d1=0.041, d2=0.130 g=0.152\n",
            ">1339, d1=0.049, d2=0.115 g=0.082\n",
            ">1340, d1=0.041, d2=0.057 g=0.095\n",
            ">1341, d1=0.035, d2=0.088 g=0.116\n",
            ">1342, d1=0.033, d2=0.158 g=0.123\n",
            ">1343, d1=0.083, d2=0.082 g=0.174\n",
            ">1344, d1=0.043, d2=0.068 g=0.348\n",
            ">1345, d1=0.042, d2=0.177 g=0.098\n",
            ">1346, d1=0.052, d2=0.343 g=0.251\n",
            ">1347, d1=0.173, d2=0.162 g=0.117\n",
            ">1348, d1=0.279, d2=0.062 g=0.110\n",
            ">1349, d1=0.077, d2=0.157 g=0.119\n",
            ">1350, d1=0.064, d2=0.086 g=0.149\n",
            ">1351, d1=0.033, d2=0.126 g=0.099\n",
            ">1352, d1=0.044, d2=0.221 g=0.287\n",
            ">1353, d1=0.053, d2=0.171 g=0.114\n",
            ">1354, d1=0.078, d2=0.137 g=0.074\n",
            ">1355, d1=0.027, d2=0.073 g=0.086\n",
            ">1356, d1=0.067, d2=0.090 g=0.090\n",
            ">1357, d1=0.083, d2=0.155 g=0.214\n",
            ">1358, d1=0.087, d2=0.047 g=0.156\n",
            ">1359, d1=0.036, d2=0.135 g=0.244\n",
            ">1360, d1=0.039, d2=0.133 g=0.293\n",
            ">1361, d1=0.101, d2=0.072 g=0.153\n",
            ">1362, d1=0.071, d2=0.128 g=0.094\n",
            ">1363, d1=0.037, d2=0.100 g=0.094\n",
            ">1364, d1=0.050, d2=0.101 g=0.162\n",
            ">1365, d1=0.051, d2=0.092 g=0.063\n",
            ">1366, d1=0.032, d2=0.157 g=0.136\n",
            ">1367, d1=0.031, d2=0.091 g=0.202\n",
            ">1368, d1=0.053, d2=0.073 g=0.150\n",
            ">1369, d1=0.040, d2=0.079 g=0.115\n",
            ">1370, d1=0.020, d2=0.129 g=0.148\n",
            ">1371, d1=0.094, d2=0.066 g=0.143\n",
            ">1372, d1=0.070, d2=0.121 g=0.113\n",
            ">1373, d1=0.020, d2=0.089 g=0.123\n",
            ">1374, d1=0.041, d2=0.082 g=0.113\n",
            ">1375, d1=0.099, d2=0.133 g=0.156\n",
            ">1376, d1=0.084, d2=0.140 g=0.126\n",
            ">1377, d1=0.053, d2=0.114 g=0.133\n",
            ">1378, d1=0.050, d2=0.146 g=0.121\n",
            ">1379, d1=0.058, d2=0.059 g=0.121\n",
            ">1380, d1=0.051, d2=0.084 g=0.201\n",
            ">1381, d1=0.064, d2=0.102 g=0.096\n",
            ">1382, d1=0.038, d2=0.166 g=0.257\n",
            ">1383, d1=0.087, d2=0.079 g=0.168\n",
            ">1384, d1=0.047, d2=0.156 g=0.222\n",
            ">1385, d1=0.042, d2=0.103 g=0.147\n",
            ">1386, d1=0.061, d2=0.109 g=0.200\n",
            ">1387, d1=0.064, d2=0.101 g=0.150\n",
            ">1388, d1=0.029, d2=0.077 g=0.239\n",
            ">1389, d1=0.105, d2=0.066 g=0.079\n",
            ">1390, d1=0.050, d2=0.328 g=0.391\n",
            ">1391, d1=0.126, d2=0.186 g=0.150\n",
            ">1392, d1=0.076, d2=0.144 g=0.213\n",
            ">1393, d1=0.030, d2=0.134 g=0.200\n",
            ">1394, d1=0.097, d2=0.057 g=0.111\n",
            ">1395, d1=0.029, d2=0.095 g=0.092\n",
            ">1396, d1=0.025, d2=0.062 g=0.092\n",
            ">1397, d1=0.038, d2=0.085 g=0.076\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Saved generated_plot_001397.png and model_001397.h5\n",
            ">1398, d1=0.037, d2=0.149 g=0.108\n",
            ">1399, d1=0.082, d2=0.091 g=0.137\n",
            ">1400, d1=0.051, d2=0.071 g=0.219\n",
            ">1401, d1=0.035, d2=0.082 g=0.136\n",
            ">1402, d1=0.086, d2=0.166 g=0.109\n",
            ">1403, d1=0.080, d2=0.086 g=0.117\n",
            ">1404, d1=0.053, d2=0.103 g=0.122\n",
            ">1405, d1=0.092, d2=0.121 g=0.149\n",
            ">1406, d1=0.057, d2=0.117 g=0.124\n",
            ">1407, d1=0.027, d2=0.122 g=0.159\n",
            ">1408, d1=0.068, d2=0.106 g=0.137\n",
            ">1409, d1=0.112, d2=0.105 g=0.151\n",
            ">1410, d1=0.109, d2=0.130 g=0.175\n",
            ">1411, d1=0.076, d2=0.148 g=0.139\n",
            ">1412, d1=0.036, d2=0.187 g=0.138\n",
            ">1413, d1=0.031, d2=0.133 g=0.315\n",
            ">1414, d1=0.223, d2=0.189 g=0.130\n",
            ">1415, d1=0.046, d2=0.066 g=0.162\n",
            ">1416, d1=0.057, d2=0.097 g=0.126\n",
            ">1417, d1=0.044, d2=0.129 g=0.108\n",
            ">1418, d1=0.036, d2=0.119 g=0.218\n",
            ">1419, d1=0.037, d2=0.094 g=0.351\n",
            ">1420, d1=0.147, d2=0.131 g=0.186\n",
            ">1421, d1=0.084, d2=0.083 g=0.198\n",
            ">1422, d1=0.102, d2=0.152 g=0.142\n",
            ">1423, d1=0.061, d2=0.169 g=0.187\n",
            ">1424, d1=0.062, d2=0.138 g=0.408\n",
            ">1425, d1=0.154, d2=0.148 g=0.256\n",
            ">1426, d1=0.061, d2=0.153 g=0.200\n",
            ">1427, d1=0.088, d2=0.074 g=0.136\n",
            ">1428, d1=0.057, d2=0.125 g=0.224\n",
            ">1429, d1=0.101, d2=0.126 g=0.151\n",
            ">1430, d1=0.058, d2=0.180 g=0.348\n",
            ">1431, d1=0.110, d2=0.203 g=0.184\n",
            ">1432, d1=0.080, d2=0.211 g=0.509\n",
            ">1433, d1=0.132, d2=0.269 g=0.168\n",
            ">1434, d1=0.065, d2=0.404 g=0.239\n",
            ">1435, d1=0.073, d2=0.190 g=0.249\n",
            ">1436, d1=0.046, d2=0.233 g=0.316\n",
            ">1437, d1=0.060, d2=0.152 g=0.160\n",
            ">1438, d1=0.150, d2=0.155 g=0.326\n",
            ">1439, d1=0.161, d2=0.291 g=0.473\n",
            ">1440, d1=0.179, d2=0.159 g=0.146\n",
            ">1441, d1=0.130, d2=0.154 g=0.382\n",
            ">1442, d1=0.114, d2=0.241 g=0.198\n",
            ">1443, d1=0.031, d2=0.151 g=0.401\n",
            ">1444, d1=0.110, d2=0.162 g=0.346\n",
            ">1445, d1=0.045, d2=0.159 g=0.385\n",
            ">1446, d1=0.189, d2=0.253 g=0.317\n",
            ">1447, d1=0.063, d2=0.178 g=0.162\n",
            ">1448, d1=0.048, d2=0.395 g=1.418\n",
            ">1449, d1=0.192, d2=0.680 g=0.458\n",
            ">1450, d1=0.367, d2=1.104 g=2.247\n",
            ">1451, d1=0.552, d2=3.375 g=8.274\n",
            ">1452, d1=0.829, d2=17.122 g=70.128\n",
            ">1453, d1=3.010, d2=35.769 g=5.418\n",
            ">1454, d1=8.455, d2=7.234 g=1.483\n",
            ">1455, d1=1.798, d2=12.922 g=3.173\n",
            ">1456, d1=2.103, d2=4.017 g=0.872\n",
            ">1457, d1=1.259, d2=3.319 g=1.009\n",
            ">1458, d1=1.763, d2=0.655 g=0.386\n",
            ">1459, d1=0.495, d2=1.169 g=0.435\n",
            ">1460, d1=0.857, d2=0.504 g=0.409\n",
            ">1461, d1=0.762, d2=0.406 g=0.432\n",
            ">1462, d1=0.655, d2=0.304 g=0.493\n",
            ">1463, d1=0.427, d2=0.200 g=0.556\n",
            ">1464, d1=0.220, d2=0.266 g=0.426\n",
            ">1465, d1=0.175, d2=0.189 g=0.247\n",
            ">1466, d1=0.210, d2=0.260 g=0.148\n",
            ">1467, d1=0.208, d2=0.147 g=0.168\n",
            ">1468, d1=0.144, d2=0.254 g=0.178\n",
            ">1469, d1=0.083, d2=0.202 g=0.130\n",
            ">1470, d1=0.171, d2=0.299 g=0.103\n",
            ">1471, d1=0.106, d2=0.166 g=0.093\n",
            ">1472, d1=0.107, d2=0.140 g=0.064\n",
            ">1473, d1=0.136, d2=0.242 g=0.168\n",
            ">1474, d1=0.159, d2=0.240 g=0.159\n",
            ">1475, d1=0.127, d2=0.409 g=0.337\n",
            ">1476, d1=0.130, d2=0.511 g=0.182\n",
            ">1477, d1=0.161, d2=0.378 g=0.260\n",
            ">1478, d1=0.079, d2=0.231 g=0.100\n",
            ">1479, d1=0.099, d2=0.310 g=0.233\n",
            ">1480, d1=0.091, d2=0.222 g=0.172\n",
            ">1481, d1=0.061, d2=0.206 g=0.182\n",
            ">1482, d1=0.063, d2=0.071 g=0.237\n",
            ">1483, d1=0.070, d2=0.166 g=0.310\n",
            ">1484, d1=0.085, d2=0.078 g=0.216\n",
            ">1485, d1=0.140, d2=0.150 g=0.393\n",
            ">1486, d1=0.082, d2=0.161 g=0.139\n",
            ">1487, d1=0.068, d2=0.426 g=0.707\n",
            ">1488, d1=0.119, d2=0.412 g=0.207\n",
            ">1489, d1=0.065, d2=0.729 g=0.638\n",
            ">1490, d1=0.262, d2=0.114 g=0.333\n",
            ">1491, d1=0.160, d2=0.405 g=0.617\n",
            ">1492, d1=0.193, d2=0.121 g=0.484\n",
            ">1493, d1=0.068, d2=0.263 g=0.936\n",
            ">1494, d1=0.163, d2=0.084 g=0.464\n",
            ">1495, d1=0.160, d2=0.189 g=0.693\n",
            ">1496, d1=0.256, d2=0.234 g=0.680\n",
            ">1497, d1=0.449, d2=0.134 g=0.698\n",
            ">1498, d1=0.385, d2=0.104 g=0.559\n",
            ">1499, d1=0.301, d2=0.106 g=0.727\n",
            ">1500, d1=0.305, d2=0.255 g=0.827\n",
            ">1501, d1=0.211, d2=0.137 g=1.052\n",
            ">1502, d1=0.206, d2=0.188 g=0.631\n",
            ">1503, d1=0.225, d2=0.206 g=0.758\n",
            ">1504, d1=0.286, d2=0.133 g=0.698\n",
            ">1505, d1=0.280, d2=0.298 g=0.913\n",
            ">1506, d1=0.274, d2=0.102 g=0.917\n",
            ">1507, d1=0.198, d2=0.094 g=0.551\n",
            ">1508, d1=0.115, d2=0.126 g=0.721\n",
            ">1509, d1=0.137, d2=0.093 g=0.768\n",
            ">1510, d1=0.145, d2=0.133 g=0.691\n",
            ">1511, d1=0.093, d2=0.151 g=0.799\n",
            ">1512, d1=0.155, d2=0.130 g=0.648\n",
            ">1513, d1=0.145, d2=0.085 g=0.676\n",
            ">1514, d1=0.133, d2=0.142 g=0.599\n",
            ">1515, d1=0.109, d2=0.066 g=0.773\n",
            ">1516, d1=0.159, d2=0.111 g=0.624\n",
            ">1517, d1=0.094, d2=0.084 g=0.545\n",
            ">1518, d1=0.147, d2=0.109 g=0.547\n",
            ">1519, d1=0.172, d2=0.187 g=0.561\n",
            ">1520, d1=0.122, d2=0.107 g=0.655\n",
            ">1521, d1=0.148, d2=0.146 g=0.699\n",
            ">1522, d1=0.122, d2=0.073 g=0.578\n",
            ">1523, d1=0.180, d2=0.141 g=0.330\n",
            ">1524, d1=0.109, d2=0.176 g=0.371\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Saved generated_plot_001524.png and model_001524.h5\n",
            ">1525, d1=0.106, d2=0.094 g=0.431\n",
            ">1526, d1=0.057, d2=0.120 g=0.338\n",
            ">1527, d1=0.091, d2=0.197 g=0.534\n",
            ">1528, d1=0.146, d2=0.121 g=0.280\n",
            ">1529, d1=0.072, d2=0.129 g=0.376\n",
            ">1530, d1=0.089, d2=0.126 g=0.430\n",
            ">1531, d1=0.081, d2=0.108 g=0.301\n",
            ">1532, d1=0.057, d2=0.120 g=0.142\n",
            ">1533, d1=0.097, d2=0.104 g=0.157\n",
            ">1534, d1=0.067, d2=0.139 g=0.227\n",
            ">1535, d1=0.076, d2=0.106 g=0.157\n",
            ">1536, d1=0.105, d2=0.145 g=0.167\n",
            ">1537, d1=0.097, d2=0.088 g=0.135\n",
            ">1538, d1=0.072, d2=0.103 g=0.147\n",
            ">1539, d1=0.032, d2=0.113 g=0.151\n",
            ">1540, d1=0.060, d2=0.144 g=0.150\n",
            ">1541, d1=0.048, d2=0.079 g=0.176\n",
            ">1542, d1=0.073, d2=0.116 g=0.158\n",
            ">1543, d1=0.058, d2=0.156 g=0.219\n",
            ">1544, d1=0.078, d2=0.142 g=0.163\n",
            ">1545, d1=0.065, d2=0.133 g=0.247\n",
            ">1546, d1=0.082, d2=0.114 g=0.123\n",
            ">1547, d1=0.097, d2=0.134 g=0.176\n",
            ">1548, d1=0.056, d2=0.170 g=0.114\n",
            ">1549, d1=0.046, d2=0.075 g=0.135\n",
            ">1550, d1=0.065, d2=0.132 g=0.154\n",
            ">1551, d1=0.066, d2=0.086 g=0.098\n",
            ">1552, d1=0.037, d2=0.123 g=0.175\n",
            ">1553, d1=0.059, d2=0.064 g=0.122\n",
            ">1554, d1=0.044, d2=0.115 g=0.099\n",
            ">1555, d1=0.052, d2=0.215 g=0.164\n",
            ">1556, d1=0.094, d2=0.113 g=0.166\n",
            ">1557, d1=0.063, d2=0.133 g=0.124\n",
            ">1558, d1=0.059, d2=0.079 g=0.085\n",
            ">1559, d1=0.046, d2=0.099 g=0.075\n",
            ">1560, d1=0.050, d2=0.118 g=0.129\n",
            ">1561, d1=0.057, d2=0.078 g=0.140\n",
            ">1562, d1=0.087, d2=0.110 g=0.176\n",
            ">1563, d1=0.040, d2=0.203 g=0.094\n",
            ">1564, d1=0.048, d2=0.217 g=0.142\n",
            ">1565, d1=0.084, d2=0.136 g=0.113\n",
            ">1566, d1=0.055, d2=0.148 g=0.142\n",
            ">1567, d1=0.053, d2=0.164 g=0.095\n",
            ">1568, d1=0.054, d2=0.084 g=0.150\n",
            ">1569, d1=0.093, d2=0.193 g=0.097\n",
            ">1570, d1=0.129, d2=0.310 g=0.144\n",
            ">1571, d1=0.040, d2=0.145 g=0.119\n",
            ">1572, d1=0.020, d2=0.145 g=0.145\n",
            ">1573, d1=0.041, d2=0.164 g=0.235\n",
            ">1574, d1=0.086, d2=0.083 g=0.131\n",
            ">1575, d1=0.061, d2=0.084 g=0.108\n",
            ">1576, d1=0.035, d2=0.068 g=0.113\n",
            ">1577, d1=0.045, d2=0.125 g=0.152\n",
            ">1578, d1=0.020, d2=0.086 g=0.160\n",
            ">1579, d1=0.054, d2=0.127 g=0.103\n",
            ">1580, d1=0.033, d2=0.088 g=0.212\n",
            ">1581, d1=0.100, d2=0.109 g=0.182\n",
            ">1582, d1=0.044, d2=0.132 g=0.088\n",
            ">1583, d1=0.032, d2=0.141 g=0.221\n",
            ">1584, d1=0.047, d2=0.103 g=0.125\n",
            ">1585, d1=0.030, d2=0.085 g=0.127\n",
            ">1586, d1=0.038, d2=0.038 g=0.077\n",
            ">1587, d1=0.042, d2=0.106 g=0.098\n",
            ">1588, d1=0.072, d2=0.248 g=0.179\n",
            ">1589, d1=0.033, d2=0.122 g=0.188\n",
            ">1590, d1=0.065, d2=0.178 g=0.198\n",
            ">1591, d1=0.082, d2=0.099 g=0.138\n",
            ">1592, d1=0.036, d2=0.110 g=0.105\n",
            ">1593, d1=0.033, d2=0.097 g=0.149\n",
            ">1594, d1=0.069, d2=0.124 g=0.171\n",
            ">1595, d1=0.033, d2=0.089 g=0.115\n",
            ">1596, d1=0.020, d2=0.125 g=0.153\n",
            ">1597, d1=0.034, d2=0.106 g=0.128\n",
            ">1598, d1=0.052, d2=0.094 g=0.126\n",
            ">1599, d1=0.042, d2=0.055 g=0.200\n",
            ">1600, d1=0.080, d2=0.081 g=0.150\n",
            ">1601, d1=0.041, d2=0.121 g=0.258\n",
            ">1602, d1=0.091, d2=0.057 g=0.212\n",
            ">1603, d1=0.067, d2=0.073 g=0.170\n",
            ">1604, d1=0.028, d2=0.087 g=0.180\n",
            ">1605, d1=0.053, d2=0.104 g=0.280\n",
            ">1606, d1=0.060, d2=0.133 g=0.101\n",
            ">1607, d1=0.091, d2=0.156 g=0.205\n",
            ">1608, d1=0.140, d2=0.077 g=0.138\n",
            ">1609, d1=0.067, d2=0.121 g=0.240\n",
            ">1610, d1=0.077, d2=0.111 g=0.151\n",
            ">1611, d1=0.045, d2=0.134 g=0.160\n",
            ">1612, d1=0.057, d2=0.100 g=0.248\n",
            ">1613, d1=0.040, d2=0.161 g=0.244\n",
            ">1614, d1=0.026, d2=0.107 g=0.121\n",
            ">1615, d1=0.048, d2=0.109 g=0.176\n",
            ">1616, d1=0.064, d2=0.118 g=0.074\n",
            ">1617, d1=0.040, d2=0.223 g=0.190\n",
            ">1618, d1=0.048, d2=0.106 g=0.219\n",
            ">1619, d1=0.043, d2=0.098 g=0.115\n",
            ">1620, d1=0.060, d2=0.152 g=0.342\n",
            ">1621, d1=0.156, d2=0.103 g=0.116\n",
            ">1622, d1=0.139, d2=0.080 g=0.310\n",
            ">1623, d1=0.162, d2=0.090 g=0.163\n",
            ">1624, d1=0.101, d2=0.077 g=0.134\n",
            ">1625, d1=0.083, d2=0.138 g=0.160\n",
            ">1626, d1=0.026, d2=0.095 g=0.153\n",
            ">1627, d1=0.038, d2=0.078 g=0.143\n",
            ">1628, d1=0.077, d2=0.098 g=0.160\n",
            ">1629, d1=0.080, d2=0.117 g=0.317\n",
            ">1630, d1=0.120, d2=0.204 g=0.109\n",
            ">1631, d1=0.110, d2=0.156 g=0.164\n",
            ">1632, d1=0.174, d2=0.152 g=0.101\n",
            ">1633, d1=0.204, d2=0.114 g=0.241\n",
            ">1634, d1=0.166, d2=0.053 g=0.132\n",
            ">1635, d1=0.053, d2=0.144 g=0.138\n",
            ">1636, d1=0.037, d2=0.129 g=0.160\n",
            ">1637, d1=0.028, d2=0.134 g=0.124\n",
            ">1638, d1=0.038, d2=0.131 g=0.273\n",
            ">1639, d1=0.052, d2=0.131 g=0.144\n",
            ">1640, d1=0.139, d2=0.150 g=0.165\n",
            ">1641, d1=0.069, d2=0.171 g=0.212\n",
            ">1642, d1=0.030, d2=0.104 g=0.291\n",
            ">1643, d1=0.094, d2=0.061 g=0.173\n",
            ">1644, d1=0.058, d2=0.141 g=0.372\n",
            ">1645, d1=0.078, d2=0.094 g=0.231\n",
            ">1646, d1=0.134, d2=0.349 g=0.411\n",
            ">1647, d1=0.105, d2=0.132 g=0.359\n",
            ">1648, d1=0.127, d2=0.143 g=0.314\n",
            ">1649, d1=0.085, d2=0.119 g=0.319\n",
            ">1650, d1=0.087, d2=0.136 g=0.336\n",
            ">1651, d1=0.056, d2=0.147 g=0.399\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Saved generated_plot_001651.png and model_001651.h5\n",
            ">1652, d1=0.172, d2=0.274 g=0.484\n",
            ">1653, d1=0.130, d2=0.167 g=0.537\n",
            ">1654, d1=0.123, d2=0.223 g=0.443\n",
            ">1655, d1=0.068, d2=0.144 g=0.242\n",
            ">1656, d1=0.089, d2=0.293 g=0.423\n",
            ">1657, d1=0.222, d2=0.258 g=0.690\n",
            ">1658, d1=0.210, d2=0.171 g=0.229\n",
            ">1659, d1=0.146, d2=0.131 g=0.240\n",
            ">1660, d1=0.165, d2=0.144 g=0.307\n",
            ">1661, d1=0.129, d2=0.193 g=0.183\n",
            ">1662, d1=0.066, d2=0.116 g=0.153\n",
            ">1663, d1=0.093, d2=0.253 g=0.384\n",
            ">1664, d1=0.163, d2=0.139 g=0.310\n",
            ">1665, d1=0.056, d2=0.282 g=0.115\n",
            ">1666, d1=0.114, d2=0.171 g=0.122\n",
            ">1667, d1=0.114, d2=0.155 g=0.132\n",
            ">1668, d1=0.081, d2=0.146 g=0.185\n",
            ">1669, d1=0.041, d2=0.122 g=0.132\n",
            ">1670, d1=0.054, d2=0.142 g=0.124\n",
            ">1671, d1=0.069, d2=0.101 g=0.120\n",
            ">1672, d1=0.061, d2=0.143 g=0.140\n",
            ">1673, d1=0.058, d2=0.074 g=0.132\n",
            ">1674, d1=0.037, d2=0.101 g=0.148\n",
            ">1675, d1=0.048, d2=0.163 g=0.290\n",
            ">1676, d1=0.045, d2=0.234 g=0.075\n",
            ">1677, d1=0.143, d2=0.235 g=0.564\n",
            ">1678, d1=0.413, d2=0.130 g=0.103\n",
            ">1679, d1=0.215, d2=0.099 g=0.106\n",
            ">1680, d1=0.069, d2=0.127 g=0.156\n",
            ">1681, d1=0.107, d2=0.097 g=0.116\n",
            ">1682, d1=0.063, d2=0.312 g=0.241\n",
            ">1683, d1=0.180, d2=0.364 g=0.278\n",
            ">1684, d1=0.346, d2=0.203 g=0.120\n",
            ">1685, d1=0.160, d2=0.125 g=0.754\n",
            ">1686, d1=0.176, d2=0.277 g=1.834\n",
            ">1687, d1=0.478, d2=0.564 g=0.697\n",
            ">1688, d1=0.447, d2=0.222 g=0.684\n",
            ">1689, d1=0.081, d2=0.313 g=1.136\n",
            ">1690, d1=0.103, d2=0.328 g=0.436\n",
            ">1691, d1=0.291, d2=0.114 g=0.255\n",
            ">1692, d1=0.074, d2=0.231 g=0.467\n",
            ">1693, d1=0.157, d2=0.081 g=0.104\n",
            ">1694, d1=0.085, d2=0.104 g=0.114\n",
            ">1695, d1=0.170, d2=0.045 g=0.076\n",
            ">1696, d1=0.074, d2=0.064 g=0.176\n",
            ">1697, d1=0.033, d2=0.110 g=0.070\n",
            ">1698, d1=0.072, d2=0.232 g=0.671\n",
            ">1699, d1=0.182, d2=0.312 g=0.413\n",
            ">1700, d1=0.319, d2=0.761 g=2.024\n",
            ">1701, d1=1.116, d2=0.664 g=1.312\n",
            ">1702, d1=0.967, d2=1.422 g=2.424\n",
            ">1703, d1=1.298, d2=0.842 g=1.151\n",
            ">1704, d1=0.771, d2=0.311 g=0.219\n",
            ">1705, d1=0.276, d2=0.424 g=0.305\n",
            ">1706, d1=0.091, d2=0.499 g=0.367\n",
            ">1707, d1=0.182, d2=0.289 g=0.234\n",
            ">1708, d1=0.326, d2=0.185 g=0.252\n",
            ">1709, d1=0.242, d2=0.079 g=0.125\n",
            ">1710, d1=0.070, d2=0.300 g=0.154\n",
            ">1711, d1=0.101, d2=0.367 g=0.215\n",
            ">1712, d1=0.110, d2=0.277 g=0.262\n",
            ">1713, d1=0.124, d2=0.256 g=0.158\n",
            ">1714, d1=0.144, d2=0.177 g=0.184\n",
            ">1715, d1=0.199, d2=0.069 g=0.096\n",
            ">1716, d1=0.108, d2=0.071 g=0.104\n",
            ">1717, d1=0.084, d2=0.076 g=0.102\n",
            ">1718, d1=0.061, d2=0.122 g=0.127\n",
            ">1719, d1=0.041, d2=0.060 g=0.063\n",
            ">1720, d1=0.055, d2=0.048 g=0.070\n",
            ">1721, d1=0.030, d2=0.053 g=0.063\n",
            ">1722, d1=0.020, d2=0.077 g=0.115\n",
            ">1723, d1=0.077, d2=0.036 g=0.063\n",
            ">1724, d1=0.094, d2=0.072 g=0.086\n",
            ">1725, d1=0.060, d2=0.069 g=0.075\n",
            ">1726, d1=0.047, d2=0.176 g=0.142\n",
            ">1727, d1=0.077, d2=0.183 g=0.108\n",
            ">1728, d1=0.054, d2=0.187 g=0.106\n",
            ">1729, d1=0.184, d2=0.119 g=0.144\n",
            ">1730, d1=0.126, d2=0.095 g=0.133\n",
            ">1731, d1=0.047, d2=0.077 g=0.071\n",
            ">1732, d1=0.024, d2=0.096 g=0.065\n",
            ">1733, d1=0.041, d2=0.076 g=0.076\n",
            ">1734, d1=0.057, d2=0.084 g=0.057\n",
            ">1735, d1=0.062, d2=0.041 g=0.083\n",
            ">1736, d1=0.047, d2=0.044 g=0.090\n",
            ">1737, d1=0.057, d2=0.140 g=0.098\n",
            ">1738, d1=0.108, d2=0.101 g=0.115\n",
            ">1739, d1=0.080, d2=0.101 g=0.130\n",
            ">1740, d1=0.067, d2=0.194 g=0.329\n",
            ">1741, d1=0.127, d2=0.114 g=0.248\n",
            ">1742, d1=0.047, d2=0.224 g=0.759\n",
            ">1743, d1=0.284, d2=0.158 g=0.656\n",
            ">1744, d1=0.168, d2=0.196 g=0.930\n",
            ">1745, d1=0.208, d2=0.115 g=0.393\n",
            ">1746, d1=0.105, d2=0.270 g=1.368\n",
            ">1747, d1=0.294, d2=0.100 g=0.941\n",
            ">1748, d1=0.148, d2=0.115 g=0.751\n",
            ">1749, d1=0.118, d2=0.209 g=1.288\n",
            ">1750, d1=0.129, d2=0.126 g=0.923\n",
            ">1751, d1=0.146, d2=0.205 g=1.541\n",
            ">1752, d1=0.248, d2=0.095 g=0.629\n",
            ">1753, d1=0.060, d2=0.140 g=0.941\n",
            ">1754, d1=0.072, d2=0.096 g=1.252\n",
            ">1755, d1=0.159, d2=0.072 g=0.717\n",
            ">1756, d1=0.174, d2=0.072 g=0.689\n",
            ">1757, d1=0.070, d2=0.150 g=0.938\n",
            ">1758, d1=0.136, d2=0.083 g=0.352\n",
            ">1759, d1=0.131, d2=0.189 g=0.960\n",
            ">1760, d1=0.224, d2=0.121 g=0.664\n",
            ">1761, d1=0.077, d2=0.131 g=0.386\n",
            ">1762, d1=0.045, d2=0.218 g=0.689\n",
            ">1763, d1=0.037, d2=0.167 g=0.822\n",
            ">1764, d1=0.098, d2=0.077 g=0.166\n",
            ">1765, d1=0.116, d2=0.161 g=0.610\n",
            ">1766, d1=0.233, d2=0.274 g=1.095\n",
            ">1767, d1=0.068, d2=0.721 g=0.230\n",
            ">1768, d1=0.733, d2=0.311 g=0.208\n",
            ">1769, d1=0.255, d2=0.186 g=0.191\n",
            ">1770, d1=0.311, d2=0.143 g=0.195\n",
            ">1771, d1=0.299, d2=0.243 g=0.907\n",
            ">1772, d1=0.047, d2=0.149 g=0.465\n",
            ">1773, d1=0.338, d2=1.476 g=1.596\n",
            ">1774, d1=0.918, d2=0.403 g=0.361\n",
            ">1775, d1=0.225, d2=0.593 g=1.857\n",
            ">1776, d1=0.296, d2=1.727 g=1.215\n",
            ">1777, d1=1.557, d2=0.263 g=1.099\n",
            ">1778, d1=0.401, d2=0.323 g=0.397\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Saved generated_plot_001778.png and model_001778.h5\n",
            ">1779, d1=0.336, d2=0.342 g=0.463\n",
            ">1780, d1=0.367, d2=0.126 g=0.190\n",
            ">1781, d1=0.197, d2=0.108 g=0.212\n",
            ">1782, d1=0.093, d2=0.139 g=0.332\n",
            ">1783, d1=0.143, d2=0.225 g=0.223\n",
            ">1784, d1=0.078, d2=0.309 g=0.283\n",
            ">1785, d1=0.207, d2=0.240 g=0.381\n",
            ">1786, d1=0.093, d2=0.156 g=0.255\n",
            ">1787, d1=0.064, d2=0.365 g=1.018\n",
            ">1788, d1=0.120, d2=0.350 g=0.177\n",
            ">1789, d1=0.203, d2=0.314 g=0.629\n",
            ">1790, d1=0.225, d2=0.154 g=0.230\n",
            ">1791, d1=0.051, d2=0.148 g=0.442\n",
            ">1792, d1=0.060, d2=0.122 g=0.373\n",
            ">1793, d1=0.044, d2=0.128 g=0.188\n",
            ">1794, d1=0.040, d2=0.175 g=0.337\n",
            ">1795, d1=0.030, d2=0.146 g=0.232\n",
            ">1796, d1=0.060, d2=0.164 g=0.334\n",
            ">1797, d1=0.054, d2=0.146 g=0.159\n",
            ">1798, d1=0.041, d2=0.104 g=0.126\n",
            ">1799, d1=0.070, d2=0.140 g=0.339\n",
            ">1800, d1=0.140, d2=0.177 g=0.377\n",
            ">1801, d1=0.113, d2=0.149 g=0.495\n",
            ">1802, d1=0.038, d2=0.089 g=0.203\n",
            ">1803, d1=0.041, d2=0.143 g=0.682\n",
            ">1804, d1=0.168, d2=0.138 g=0.165\n",
            ">1805, d1=0.170, d2=0.164 g=0.779\n",
            ">1806, d1=0.285, d2=0.198 g=0.204\n",
            ">1807, d1=0.322, d2=0.238 g=0.456\n",
            ">1808, d1=0.357, d2=0.274 g=0.374\n",
            ">1809, d1=0.072, d2=0.179 g=0.217\n",
            ">1810, d1=0.082, d2=0.115 g=0.230\n",
            ">1811, d1=0.022, d2=0.089 g=0.430\n",
            ">1812, d1=0.081, d2=0.187 g=0.133\n",
            ">1813, d1=0.084, d2=0.178 g=0.585\n",
            ">1814, d1=0.141, d2=0.195 g=0.174\n",
            ">1815, d1=0.130, d2=0.135 g=0.130\n",
            ">1816, d1=0.072, d2=0.189 g=0.196\n",
            ">1817, d1=0.068, d2=0.110 g=0.111\n",
            ">1818, d1=0.046, d2=0.120 g=0.221\n",
            ">1819, d1=0.087, d2=0.167 g=0.383\n",
            ">1820, d1=0.061, d2=0.184 g=0.102\n",
            ">1821, d1=0.079, d2=0.220 g=0.348\n",
            ">1822, d1=0.182, d2=0.157 g=0.220\n",
            ">1823, d1=0.101, d2=0.121 g=0.226\n",
            ">1824, d1=0.045, d2=0.083 g=0.099\n",
            ">1825, d1=0.073, d2=0.136 g=0.136\n",
            ">1826, d1=0.108, d2=0.175 g=0.127\n",
            ">1827, d1=0.080, d2=0.149 g=0.314\n",
            ">1828, d1=0.095, d2=0.146 g=0.128\n",
            ">1829, d1=0.095, d2=0.210 g=0.192\n",
            ">1830, d1=0.040, d2=0.118 g=0.195\n",
            ">1831, d1=0.036, d2=0.198 g=0.131\n",
            ">1832, d1=0.058, d2=0.104 g=0.186\n",
            ">1833, d1=0.077, d2=0.152 g=0.164\n",
            ">1834, d1=0.029, d2=0.128 g=0.178\n",
            ">1835, d1=0.016, d2=0.139 g=0.266\n",
            ">1836, d1=0.024, d2=0.084 g=0.182\n",
            ">1837, d1=0.031, d2=0.137 g=0.445\n",
            ">1838, d1=0.108, d2=0.134 g=0.108\n",
            ">1839, d1=0.206, d2=0.098 g=0.143\n",
            ">1840, d1=0.145, d2=0.148 g=0.209\n",
            ">1841, d1=0.046, d2=0.161 g=0.244\n",
            ">1842, d1=0.072, d2=0.236 g=0.280\n",
            ">1843, d1=0.040, d2=0.451 g=0.342\n",
            ">1844, d1=0.388, d2=0.270 g=0.493\n",
            ">1845, d1=0.922, d2=0.204 g=0.326\n",
            ">1846, d1=0.722, d2=0.576 g=0.136\n",
            ">1847, d1=0.056, d2=0.760 g=0.831\n",
            ">1848, d1=0.559, d2=0.902 g=1.327\n",
            ">1849, d1=1.832, d2=0.577 g=0.809\n",
            ">1850, d1=1.902, d2=0.183 g=0.565\n",
            ">1851, d1=0.571, d2=0.563 g=0.161\n",
            ">1852, d1=0.195, d2=0.447 g=0.395\n",
            ">1853, d1=0.170, d2=0.246 g=0.138\n",
            ">1854, d1=0.116, d2=0.336 g=0.849\n",
            ">1855, d1=0.242, d2=1.226 g=1.524\n",
            ">1856, d1=1.062, d2=0.213 g=0.236\n",
            ">1857, d1=0.183, d2=0.207 g=0.540\n",
            ">1858, d1=0.082, d2=0.109 g=0.113\n",
            ">1859, d1=0.154, d2=0.281 g=0.194\n",
            ">1860, d1=0.174, d2=0.443 g=2.133\n",
            ">1861, d1=0.256, d2=0.278 g=0.146\n",
            ">1862, d1=0.205, d2=0.489 g=1.314\n",
            ">1863, d1=0.558, d2=0.166 g=0.102\n",
            ">1864, d1=0.145, d2=0.290 g=1.032\n",
            ">1865, d1=0.207, d2=0.161 g=0.148\n",
            ">1866, d1=0.071, d2=0.158 g=0.389\n",
            ">1867, d1=0.055, d2=0.076 g=0.303\n",
            ">1868, d1=0.074, d2=0.290 g=0.826\n",
            ">1869, d1=0.151, d2=0.237 g=0.135\n",
            ">1870, d1=0.157, d2=0.231 g=0.704\n",
            ">1871, d1=0.219, d2=0.283 g=0.133\n",
            ">1872, d1=0.336, d2=0.321 g=0.690\n",
            ">1873, d1=0.583, d2=0.111 g=0.328\n",
            ">1874, d1=0.184, d2=0.163 g=0.258\n",
            ">1875, d1=0.136, d2=0.141 g=0.170\n",
            ">1876, d1=0.066, d2=0.294 g=0.655\n",
            ">1877, d1=0.078, d2=0.170 g=0.262\n",
            ">1878, d1=0.097, d2=0.123 g=0.238\n",
            ">1879, d1=0.165, d2=0.128 g=0.272\n",
            ">1880, d1=0.122, d2=0.161 g=0.128\n",
            ">1881, d1=0.048, d2=0.325 g=0.748\n",
            ">1882, d1=0.213, d2=0.247 g=0.126\n",
            ">1883, d1=0.208, d2=0.199 g=0.565\n",
            ">1884, d1=0.241, d2=0.143 g=0.147\n",
            ">1885, d1=0.334, d2=0.163 g=0.685\n",
            ">1886, d1=0.280, d2=0.218 g=0.201\n",
            ">1887, d1=0.197, d2=0.159 g=0.136\n",
            ">1888, d1=0.064, d2=0.302 g=0.286\n",
            ">1889, d1=0.154, d2=0.153 g=0.108\n",
            ">1890, d1=0.365, d2=0.097 g=0.297\n",
            ">1891, d1=0.143, d2=0.158 g=0.928\n",
            ">1892, d1=0.164, d2=0.220 g=0.631\n",
            ">1893, d1=0.228, d2=0.360 g=0.462\n",
            ">1894, d1=0.198, d2=0.630 g=0.448\n",
            ">1895, d1=0.092, d2=1.210 g=3.276\n",
            ">1896, d1=0.137, d2=1.163 g=0.909\n",
            ">1897, d1=0.568, d2=1.455 g=4.399\n",
            ">1898, d1=1.145, d2=3.167 g=4.693\n",
            ">1899, d1=1.766, d2=4.482 g=4.115\n",
            ">1900, d1=2.667, d2=3.046 g=1.800\n",
            ">1901, d1=1.567, d2=4.658 g=4.687\n",
            ">1902, d1=1.390, d2=5.495 g=2.072\n",
            ">1903, d1=2.234, d2=10.034 g=12.396\n",
            ">1904, d1=3.661, d2=15.847 g=3.880\n",
            ">1905, d1=3.454, d2=14.851 g=6.346\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Saved generated_plot_001905.png and model_001905.h5\n",
            ">1906, d1=3.355, d2=4.048 g=0.235\n",
            ">1907, d1=2.266, d2=6.553 g=9.490\n",
            ">1908, d1=4.041, d2=4.996 g=2.667\n",
            ">1909, d1=2.855, d2=10.057 g=11.294\n",
            ">1910, d1=3.292, d2=12.151 g=6.338\n",
            ">1911, d1=1.654, d2=15.356 g=8.636\n",
            ">1912, d1=0.975, d2=13.280 g=2.247\n",
            ">1913, d1=1.547, d2=10.351 g=3.262\n",
            ">1914, d1=2.327, d2=3.426 g=0.345\n",
            ">1915, d1=2.058, d2=4.023 g=2.205\n",
            ">1916, d1=1.351, d2=1.069 g=0.311\n",
            ">1917, d1=0.611, d2=3.649 g=4.815\n",
            ">1918, d1=1.029, d2=4.053 g=1.240\n",
            ">1919, d1=0.484, d2=12.960 g=15.169\n",
            ">1920, d1=1.328, d2=20.229 g=3.161\n",
            ">1921, d1=3.083, d2=24.544 g=9.850\n",
            ">1922, d1=4.250, d2=10.793 g=0.554\n",
            ">1923, d1=1.960, d2=13.184 g=5.643\n",
            ">1924, d1=0.910, d2=1.648 g=2.451\n",
            ">1925, d1=1.166, d2=5.228 g=4.195\n",
            ">1926, d1=1.863, d2=0.358 g=2.057\n",
            ">1927, d1=1.722, d2=2.064 g=6.740\n",
            ">1928, d1=1.320, d2=1.168 g=0.229\n",
            ">1929, d1=0.481, d2=2.741 g=3.923\n",
            ">1930, d1=1.422, d2=1.227 g=0.379\n",
            ">1931, d1=0.567, d2=3.618 g=3.487\n",
            ">1932, d1=1.609, d2=0.997 g=0.258\n",
            ">1933, d1=1.000, d2=3.553 g=3.387\n",
            ">1934, d1=1.466, d2=0.769 g=0.878\n",
            ">1935, d1=0.644, d2=1.350 g=2.614\n",
            ">1936, d1=1.114, d2=0.714 g=0.483\n",
            ">1937, d1=1.291, d2=1.265 g=2.057\n",
            ">1938, d1=0.940, d2=0.239 g=1.070\n",
            ">1939, d1=0.389, d2=0.786 g=1.573\n",
            ">1940, d1=0.888, d2=0.359 g=1.390\n",
            ">1941, d1=1.073, d2=0.347 g=1.172\n",
            ">1942, d1=1.071, d2=0.492 g=0.678\n",
            ">1943, d1=0.909, d2=0.830 g=0.875\n",
            ">1944, d1=0.595, d2=0.304 g=0.565\n",
            ">1945, d1=0.554, d2=0.534 g=0.609\n",
            ">1946, d1=0.422, d2=0.422 g=0.603\n",
            ">1947, d1=0.722, d2=1.076 g=0.733\n",
            ">1948, d1=1.074, d2=0.380 g=0.870\n",
            ">1949, d1=1.153, d2=0.713 g=0.598\n",
            ">1950, d1=0.524, d2=0.599 g=0.952\n",
            ">1951, d1=0.597, d2=0.348 g=0.765\n",
            ">1952, d1=0.689, d2=0.751 g=0.879\n",
            ">1953, d1=0.823, d2=0.438 g=0.815\n",
            ">1954, d1=0.662, d2=0.401 g=0.570\n",
            ">1955, d1=0.220, d2=0.350 g=0.664\n",
            ">1956, d1=0.543, d2=0.275 g=0.377\n",
            ">1957, d1=0.155, d2=0.407 g=0.758\n",
            ">1958, d1=0.406, d2=0.161 g=0.443\n",
            ">1959, d1=0.305, d2=0.274 g=0.413\n",
            ">1960, d1=0.289, d2=0.325 g=0.279\n",
            ">1961, d1=0.414, d2=0.264 g=0.292\n",
            ">1962, d1=0.320, d2=0.394 g=0.595\n",
            ">1963, d1=0.400, d2=0.367 g=0.482\n",
            ">1964, d1=0.573, d2=0.291 g=0.398\n",
            ">1965, d1=0.473, d2=0.693 g=0.443\n",
            ">1966, d1=0.343, d2=0.273 g=0.473\n",
            ">1967, d1=0.261, d2=0.274 g=0.481\n",
            ">1968, d1=0.597, d2=0.448 g=0.346\n",
            ">1969, d1=0.346, d2=0.355 g=0.433\n",
            ">1970, d1=0.681, d2=0.578 g=0.484\n",
            ">1971, d1=0.255, d2=0.160 g=0.348\n",
            ">1972, d1=0.169, d2=0.241 g=0.544\n",
            ">1973, d1=0.377, d2=0.255 g=0.390\n",
            ">1974, d1=0.472, d2=0.339 g=0.249\n",
            ">1975, d1=0.339, d2=0.443 g=0.324\n",
            ">1976, d1=0.365, d2=0.238 g=0.407\n",
            ">1977, d1=0.323, d2=0.199 g=0.190\n",
            ">1978, d1=0.152, d2=0.194 g=0.466\n",
            ">1979, d1=0.247, d2=0.239 g=0.357\n",
            ">1980, d1=0.190, d2=0.084 g=0.233\n",
            ">1981, d1=0.213, d2=0.365 g=0.309\n",
            ">1982, d1=0.100, d2=0.080 g=0.428\n",
            ">1983, d1=0.434, d2=0.153 g=0.159\n",
            ">1984, d1=0.170, d2=0.122 g=0.139\n",
            ">1985, d1=0.203, d2=0.122 g=0.232\n",
            ">1986, d1=0.195, d2=0.135 g=0.194\n",
            ">1987, d1=0.139, d2=0.093 g=0.167\n",
            ">1988, d1=0.112, d2=0.142 g=0.161\n",
            ">1989, d1=0.101, d2=0.082 g=0.215\n",
            ">1990, d1=0.075, d2=0.130 g=0.123\n",
            ">1991, d1=0.095, d2=0.059 g=0.252\n",
            ">1992, d1=0.141, d2=0.075 g=0.066\n",
            ">1993, d1=0.068, d2=0.162 g=0.270\n",
            ">1994, d1=0.128, d2=0.074 g=0.130\n",
            ">1995, d1=0.121, d2=0.087 g=0.156\n",
            ">1996, d1=0.092, d2=0.058 g=0.119\n",
            ">1997, d1=0.089, d2=0.138 g=0.217\n",
            ">1998, d1=0.119, d2=0.091 g=0.125\n",
            ">1999, d1=0.082, d2=0.070 g=0.106\n",
            ">2000, d1=0.070, d2=0.041 g=0.140\n",
            ">2001, d1=0.088, d2=0.055 g=0.121\n",
            ">2002, d1=0.078, d2=0.094 g=0.113\n",
            ">2003, d1=0.057, d2=0.044 g=0.109\n",
            ">2004, d1=0.095, d2=0.088 g=0.256\n",
            ">2005, d1=0.081, d2=0.064 g=0.099\n",
            ">2006, d1=0.069, d2=0.104 g=0.230\n",
            ">2007, d1=0.095, d2=0.063 g=0.154\n",
            ">2008, d1=0.077, d2=0.072 g=0.185\n",
            ">2009, d1=0.061, d2=0.057 g=0.180\n",
            ">2010, d1=0.069, d2=0.077 g=0.103\n",
            ">2011, d1=0.059, d2=0.065 g=0.136\n",
            ">2012, d1=0.080, d2=0.077 g=0.099\n",
            ">2013, d1=0.119, d2=0.133 g=0.131\n",
            ">2014, d1=0.030, d2=0.087 g=0.149\n",
            ">2015, d1=0.100, d2=0.128 g=0.167\n",
            ">2016, d1=0.085, d2=0.066 g=0.149\n",
            ">2017, d1=0.067, d2=0.085 g=0.086\n",
            ">2018, d1=0.083, d2=0.081 g=0.114\n",
            ">2019, d1=0.082, d2=0.111 g=0.155\n",
            ">2020, d1=0.060, d2=0.049 g=0.220\n",
            ">2021, d1=0.090, d2=0.106 g=0.153\n",
            ">2022, d1=0.069, d2=0.063 g=0.185\n",
            ">2023, d1=0.082, d2=0.066 g=0.136\n",
            ">2024, d1=0.048, d2=0.084 g=0.155\n",
            ">2025, d1=0.058, d2=0.044 g=0.245\n",
            ">2026, d1=0.081, d2=0.069 g=0.102\n",
            ">2027, d1=0.086, d2=0.061 g=0.164\n",
            ">2028, d1=0.083, d2=0.046 g=0.162\n",
            ">2029, d1=0.041, d2=0.048 g=0.149\n",
            ">2030, d1=0.051, d2=0.105 g=0.182\n",
            ">2031, d1=0.094, d2=0.077 g=0.154\n",
            ">2032, d1=0.105, d2=0.036 g=0.168\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Saved generated_plot_002032.png and model_002032.h5\n",
            ">2033, d1=0.067, d2=0.073 g=0.185\n",
            ">2034, d1=0.096, d2=0.053 g=0.131\n",
            ">2035, d1=0.095, d2=0.101 g=0.242\n",
            ">2036, d1=0.079, d2=0.036 g=0.103\n",
            ">2037, d1=0.063, d2=0.116 g=0.234\n",
            ">2038, d1=0.059, d2=0.088 g=0.251\n",
            ">2039, d1=0.068, d2=0.089 g=0.198\n",
            ">2040, d1=0.090, d2=0.070 g=0.130\n",
            ">2041, d1=0.045, d2=0.109 g=0.193\n",
            ">2042, d1=0.068, d2=0.061 g=0.225\n",
            ">2043, d1=0.090, d2=0.036 g=0.117\n",
            ">2044, d1=0.067, d2=0.115 g=0.224\n",
            ">2045, d1=0.103, d2=0.059 g=0.212\n",
            ">2046, d1=0.075, d2=0.064 g=0.182\n",
            ">2047, d1=0.095, d2=0.060 g=0.165\n",
            ">2048, d1=0.073, d2=0.045 g=0.181\n",
            ">2049, d1=0.066, d2=0.083 g=0.210\n",
            ">2050, d1=0.055, d2=0.059 g=0.289\n",
            ">2051, d1=0.080, d2=0.043 g=0.193\n",
            ">2052, d1=0.082, d2=0.094 g=0.196\n",
            ">2053, d1=0.078, d2=0.046 g=0.275\n",
            ">2054, d1=0.040, d2=0.037 g=0.212\n",
            ">2055, d1=0.096, d2=0.092 g=0.209\n",
            ">2056, d1=0.111, d2=0.065 g=0.217\n",
            ">2057, d1=0.053, d2=0.089 g=0.381\n",
            ">2058, d1=0.083, d2=0.034 g=0.305\n",
            ">2059, d1=0.073, d2=0.048 g=0.349\n",
            ">2060, d1=0.107, d2=0.068 g=0.254\n",
            ">2061, d1=0.065, d2=0.036 g=0.310\n",
            ">2062, d1=0.082, d2=0.070 g=0.166\n",
            ">2063, d1=0.087, d2=0.189 g=0.298\n",
            ">2064, d1=0.084, d2=0.042 g=0.376\n",
            ">2065, d1=0.048, d2=0.076 g=0.243\n",
            ">2066, d1=0.070, d2=0.040 g=0.266\n",
            ">2067, d1=0.116, d2=0.150 g=0.187\n",
            ">2068, d1=0.033, d2=0.054 g=0.498\n",
            ">2069, d1=0.150, d2=0.096 g=0.256\n",
            ">2070, d1=0.085, d2=0.047 g=0.349\n",
            ">2071, d1=0.157, d2=0.086 g=0.140\n",
            ">2072, d1=0.068, d2=0.044 g=0.215\n",
            ">2073, d1=0.088, d2=0.086 g=0.383\n",
            ">2074, d1=0.061, d2=0.051 g=0.290\n",
            ">2075, d1=0.030, d2=0.049 g=0.263\n",
            ">2076, d1=0.049, d2=0.083 g=0.286\n",
            ">2077, d1=0.077, d2=0.097 g=0.264\n",
            ">2078, d1=0.076, d2=0.069 g=0.280\n",
            ">2079, d1=0.052, d2=0.103 g=0.427\n",
            ">2080, d1=0.107, d2=0.057 g=0.269\n",
            ">2081, d1=0.031, d2=0.082 g=0.302\n",
            ">2082, d1=0.090, d2=0.133 g=0.315\n",
            ">2083, d1=0.084, d2=0.113 g=0.351\n",
            ">2084, d1=0.041, d2=0.130 g=0.543\n",
            ">2085, d1=0.326, d2=0.189 g=0.247\n",
            ">2086, d1=0.093, d2=0.179 g=0.525\n",
            ">2087, d1=0.208, d2=0.181 g=0.516\n",
            ">2088, d1=0.088, d2=0.140 g=0.588\n",
            ">2089, d1=0.147, d2=0.128 g=0.460\n",
            ">2090, d1=0.107, d2=0.199 g=0.789\n",
            ">2091, d1=0.161, d2=0.141 g=0.592\n",
            ">2092, d1=0.122, d2=0.143 g=0.550\n",
            ">2093, d1=0.165, d2=0.191 g=0.319\n",
            ">2094, d1=0.091, d2=0.253 g=0.547\n",
            ">2095, d1=0.199, d2=0.256 g=0.472\n",
            ">2096, d1=0.075, d2=0.060 g=0.347\n",
            ">2097, d1=0.132, d2=0.138 g=0.232\n",
            ">2098, d1=0.095, d2=0.126 g=0.191\n",
            ">2099, d1=0.117, d2=0.225 g=0.218\n",
            ">2100, d1=0.113, d2=0.093 g=0.103\n",
            ">2101, d1=0.097, d2=0.144 g=0.173\n",
            ">2102, d1=0.086, d2=0.133 g=0.101\n",
            ">2103, d1=0.088, d2=0.151 g=0.104\n",
            ">2104, d1=0.074, d2=0.091 g=0.094\n",
            ">2105, d1=0.043, d2=0.071 g=0.086\n",
            ">2106, d1=0.090, d2=0.108 g=0.066\n",
            ">2107, d1=0.127, d2=0.068 g=0.062\n",
            ">2108, d1=0.061, d2=0.051 g=0.045\n",
            ">2109, d1=0.048, d2=0.091 g=0.077\n",
            ">2110, d1=0.058, d2=0.062 g=0.051\n",
            ">2111, d1=0.077, d2=0.065 g=0.066\n",
            ">2112, d1=0.030, d2=0.043 g=0.075\n",
            ">2113, d1=0.036, d2=0.072 g=0.046\n",
            ">2114, d1=0.039, d2=0.054 g=0.067\n",
            ">2115, d1=0.045, d2=0.076 g=0.064\n",
            ">2116, d1=0.059, d2=0.079 g=0.055\n",
            ">2117, d1=0.046, d2=0.067 g=0.052\n",
            ">2118, d1=0.052, d2=0.093 g=0.074\n",
            ">2119, d1=0.052, d2=0.052 g=0.065\n",
            ">2120, d1=0.041, d2=0.115 g=0.103\n",
            ">2121, d1=0.072, d2=0.058 g=0.089\n",
            ">2122, d1=0.037, d2=0.050 g=0.049\n",
            ">2123, d1=0.049, d2=0.052 g=0.061\n",
            ">2124, d1=0.069, d2=0.085 g=0.107\n",
            ">2125, d1=0.068, d2=0.053 g=0.063\n",
            ">2126, d1=0.047, d2=0.075 g=0.069\n",
            ">2127, d1=0.054, d2=0.051 g=0.076\n",
            ">2128, d1=0.046, d2=0.064 g=0.086\n",
            ">2129, d1=0.045, d2=0.080 g=0.078\n",
            ">2130, d1=0.052, d2=0.053 g=0.067\n",
            ">2131, d1=0.052, d2=0.053 g=0.086\n",
            ">2132, d1=0.073, d2=0.050 g=0.095\n",
            ">2133, d1=0.093, d2=0.059 g=0.108\n",
            ">2134, d1=0.034, d2=0.066 g=0.082\n",
            ">2135, d1=0.028, d2=0.048 g=0.152\n",
            ">2136, d1=0.075, d2=0.045 g=0.054\n",
            ">2137, d1=0.047, d2=0.035 g=0.072\n",
            ">2138, d1=0.070, d2=0.082 g=0.116\n",
            ">2139, d1=0.023, d2=0.090 g=0.044\n",
            ">2140, d1=0.103, d2=0.094 g=0.048\n",
            ">2141, d1=0.064, d2=0.151 g=0.055\n",
            ">2142, d1=0.049, d2=0.057 g=0.062\n",
            ">2143, d1=0.046, d2=0.044 g=0.052\n",
            ">2144, d1=0.045, d2=0.064 g=0.082\n",
            ">2145, d1=0.040, d2=0.075 g=0.109\n",
            ">2146, d1=0.047, d2=0.071 g=0.107\n",
            ">2147, d1=0.101, d2=0.034 g=0.099\n",
            ">2148, d1=0.066, d2=0.062 g=0.061\n",
            ">2149, d1=0.043, d2=0.068 g=0.054\n",
            ">2150, d1=0.089, d2=0.049 g=0.175\n",
            ">2151, d1=0.109, d2=0.046 g=0.071\n",
            ">2152, d1=0.048, d2=0.036 g=0.069\n",
            ">2153, d1=0.028, d2=0.056 g=0.072\n",
            ">2154, d1=0.032, d2=0.086 g=0.063\n",
            ">2155, d1=0.049, d2=0.053 g=0.095\n",
            ">2156, d1=0.050, d2=0.069 g=0.109\n",
            ">2157, d1=0.035, d2=0.087 g=0.105\n",
            ">2158, d1=0.096, d2=0.061 g=0.159\n",
            ">2159, d1=0.033, d2=0.069 g=0.070\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Saved generated_plot_002159.png and model_002159.h5\n",
            ">2160, d1=0.053, d2=0.200 g=0.233\n",
            ">2161, d1=0.121, d2=0.095 g=0.098\n",
            ">2162, d1=0.086, d2=0.171 g=0.150\n",
            ">2163, d1=0.063, d2=0.047 g=0.125\n",
            ">2164, d1=0.044, d2=0.098 g=0.119\n",
            ">2165, d1=0.052, d2=0.088 g=0.196\n",
            ">2166, d1=0.062, d2=0.061 g=0.111\n",
            ">2167, d1=0.036, d2=0.128 g=0.195\n",
            ">2168, d1=0.042, d2=0.154 g=0.114\n",
            ">2169, d1=0.035, d2=0.297 g=0.202\n",
            ">2170, d1=0.240, d2=0.120 g=0.088\n",
            ">2171, d1=0.156, d2=0.196 g=0.394\n",
            ">2172, d1=0.094, d2=0.349 g=0.174\n",
            ">2173, d1=0.047, d2=0.586 g=0.374\n",
            ">2174, d1=0.079, d2=0.395 g=0.177\n",
            ">2175, d1=0.053, d2=0.646 g=0.747\n",
            ">2176, d1=0.228, d2=0.199 g=0.208\n",
            ">2177, d1=0.171, d2=0.272 g=0.361\n",
            ">2178, d1=0.093, d2=0.151 g=0.198\n",
            ">2179, d1=0.089, d2=0.190 g=0.390\n",
            ">2180, d1=0.098, d2=0.060 g=0.146\n",
            ">2181, d1=0.078, d2=0.077 g=0.070\n",
            ">2182, d1=0.053, d2=0.069 g=0.088\n",
            ">2183, d1=0.035, d2=0.089 g=0.092\n",
            ">2184, d1=0.042, d2=0.072 g=0.082\n",
            ">2185, d1=0.042, d2=0.170 g=0.225\n",
            ">2186, d1=0.062, d2=0.188 g=0.107\n",
            ">2187, d1=0.063, d2=0.384 g=0.378\n",
            ">2188, d1=0.129, d2=0.309 g=0.172\n",
            ">2189, d1=0.224, d2=0.349 g=0.233\n",
            ">2190, d1=0.339, d2=0.097 g=0.096\n",
            ">2191, d1=0.039, d2=0.214 g=0.194\n",
            ">2192, d1=0.073, d2=0.268 g=0.064\n",
            ">2193, d1=0.096, d2=0.299 g=0.262\n",
            ">2194, d1=0.135, d2=0.080 g=0.241\n",
            ">2195, d1=0.067, d2=0.096 g=0.085\n",
            ">2196, d1=0.077, d2=0.077 g=0.093\n",
            ">2197, d1=0.046, d2=0.060 g=0.069\n",
            ">2198, d1=0.027, d2=0.066 g=0.144\n",
            ">2199, d1=0.033, d2=0.067 g=0.072\n",
            ">2200, d1=0.057, d2=0.082 g=0.117\n",
            ">2201, d1=0.031, d2=0.111 g=0.246\n",
            ">2202, d1=0.087, d2=0.068 g=0.100\n",
            ">2203, d1=0.083, d2=0.045 g=0.226\n",
            ">2204, d1=0.067, d2=0.049 g=0.168\n",
            ">2205, d1=0.057, d2=0.062 g=0.227\n",
            ">2206, d1=0.045, d2=0.045 g=0.096\n",
            ">2207, d1=0.038, d2=0.083 g=0.210\n",
            ">2208, d1=0.145, d2=0.068 g=0.167\n",
            ">2209, d1=0.059, d2=0.093 g=0.105\n",
            ">2210, d1=0.036, d2=0.097 g=0.136\n",
            ">2211, d1=0.054, d2=0.077 g=0.079\n",
            ">2212, d1=0.062, d2=0.107 g=0.134\n",
            ">2213, d1=0.054, d2=0.055 g=0.181\n",
            ">2214, d1=0.046, d2=0.095 g=0.262\n",
            ">2215, d1=0.062, d2=0.053 g=0.240\n",
            ">2216, d1=0.052, d2=0.058 g=0.131\n",
            ">2217, d1=0.024, d2=0.075 g=0.122\n",
            ">2218, d1=0.038, d2=0.036 g=0.085\n",
            ">2219, d1=0.046, d2=0.079 g=0.200\n",
            ">2220, d1=0.079, d2=0.064 g=0.152\n",
            ">2221, d1=0.035, d2=0.146 g=0.530\n",
            ">2222, d1=0.055, d2=0.114 g=0.088\n",
            ">2223, d1=0.066, d2=0.221 g=0.326\n",
            ">2224, d1=0.068, d2=0.127 g=0.099\n",
            ">2225, d1=0.049, d2=0.316 g=0.921\n",
            ">2226, d1=0.069, d2=0.207 g=0.228\n",
            ">2227, d1=0.063, d2=0.582 g=1.375\n",
            ">2228, d1=0.128, d2=0.484 g=0.155\n",
            ">2229, d1=0.232, d2=0.507 g=0.765\n",
            ">2230, d1=0.206, d2=0.176 g=0.130\n",
            ">2231, d1=0.105, d2=0.262 g=1.296\n",
            ">2232, d1=0.152, d2=0.067 g=0.626\n",
            ">2233, d1=0.099, d2=0.336 g=1.219\n",
            ">2234, d1=0.359, d2=0.400 g=0.138\n",
            ">2235, d1=0.301, d2=0.181 g=0.348\n",
            ">2236, d1=0.087, d2=0.132 g=0.608\n",
            ">2237, d1=0.162, d2=0.182 g=0.803\n",
            ">2238, d1=0.121, d2=0.094 g=0.504\n",
            ">2239, d1=0.140, d2=0.153 g=0.360\n",
            ">2240, d1=0.097, d2=0.247 g=0.529\n",
            ">2241, d1=0.065, d2=0.217 g=0.233\n",
            ">2242, d1=0.080, d2=0.348 g=0.793\n",
            ">2243, d1=0.147, d2=0.171 g=0.722\n",
            ">2244, d1=0.098, d2=0.150 g=0.106\n",
            ">2245, d1=0.104, d2=0.213 g=0.815\n",
            ">2246, d1=0.139, d2=0.143 g=0.927\n",
            ">2247, d1=0.119, d2=0.054 g=0.661\n",
            ">2248, d1=0.091, d2=0.088 g=0.149\n",
            ">2249, d1=0.149, d2=0.313 g=0.993\n",
            ">2250, d1=0.126, d2=0.040 g=0.876\n",
            ">2251, d1=0.152, d2=0.030 g=0.744\n",
            ">2252, d1=0.106, d2=0.062 g=0.515\n",
            ">2253, d1=0.074, d2=0.096 g=0.723\n",
            ">2254, d1=0.132, d2=0.059 g=0.654\n",
            ">2255, d1=0.100, d2=0.047 g=0.327\n",
            ">2256, d1=0.052, d2=0.077 g=0.586\n",
            ">2257, d1=0.073, d2=0.035 g=0.635\n",
            ">2258, d1=0.057, d2=0.067 g=0.274\n",
            ">2259, d1=0.086, d2=0.211 g=1.014\n",
            ">2260, d1=0.068, d2=0.252 g=0.190\n",
            ">2261, d1=0.099, d2=0.398 g=0.805\n",
            ">2262, d1=0.274, d2=0.178 g=0.624\n",
            ">2263, d1=0.086, d2=0.144 g=0.197\n",
            ">2264, d1=0.053, d2=0.436 g=0.932\n",
            ">2265, d1=0.120, d2=0.255 g=0.813\n",
            ">2266, d1=0.156, d2=0.348 g=1.053\n",
            ">2267, d1=0.530, d2=0.178 g=0.213\n",
            ">2268, d1=0.386, d2=0.173 g=0.463\n",
            ">2269, d1=0.099, d2=0.103 g=0.676\n",
            ">2270, d1=0.039, d2=0.074 g=0.581\n",
            ">2271, d1=0.082, d2=0.150 g=0.590\n",
            ">2272, d1=0.078, d2=0.065 g=0.346\n",
            ">2273, d1=0.071, d2=0.138 g=0.636\n",
            ">2274, d1=0.070, d2=0.081 g=0.371\n",
            ">2275, d1=0.054, d2=0.147 g=0.388\n",
            ">2276, d1=0.055, d2=0.043 g=0.280\n",
            ">2277, d1=0.069, d2=0.125 g=0.340\n",
            ">2278, d1=0.061, d2=0.066 g=0.252\n",
            ">2279, d1=0.043, d2=0.137 g=0.362\n",
            ">2280, d1=0.067, d2=0.052 g=0.331\n",
            ">2281, d1=0.080, d2=0.091 g=0.218\n",
            ">2282, d1=0.086, d2=0.124 g=0.300\n",
            ">2283, d1=0.030, d2=0.068 g=0.404\n",
            ">2284, d1=0.045, d2=0.054 g=0.134\n",
            ">2285, d1=0.036, d2=0.115 g=0.316\n",
            ">2286, d1=0.097, d2=0.099 g=0.325\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Saved generated_plot_002286.png and model_002286.h5\n",
            ">2287, d1=0.139, d2=0.088 g=0.093\n",
            ">2288, d1=0.066, d2=0.071 g=0.112\n",
            ">2289, d1=0.094, d2=0.054 g=0.093\n",
            ">2290, d1=0.062, d2=0.074 g=0.107\n",
            ">2291, d1=0.042, d2=0.047 g=0.080\n",
            ">2292, d1=0.045, d2=0.040 g=0.129\n",
            ">2293, d1=0.068, d2=0.047 g=0.067\n",
            ">2294, d1=0.050, d2=0.053 g=0.104\n",
            ">2295, d1=0.094, d2=0.085 g=0.080\n",
            ">2296, d1=0.050, d2=0.068 g=0.109\n",
            ">2297, d1=0.036, d2=0.105 g=0.076\n",
            ">2298, d1=0.043, d2=0.070 g=0.082\n",
            ">2299, d1=0.057, d2=0.091 g=0.063\n",
            ">2300, d1=0.112, d2=0.075 g=0.073\n",
            ">2301, d1=0.037, d2=0.065 g=0.085\n",
            ">2302, d1=0.055, d2=0.163 g=0.079\n",
            ">2303, d1=0.031, d2=0.133 g=0.093\n",
            ">2304, d1=0.027, d2=0.117 g=0.070\n",
            ">2305, d1=0.034, d2=0.081 g=0.074\n",
            ">2306, d1=0.026, d2=0.062 g=0.086\n",
            ">2307, d1=0.025, d2=0.043 g=0.094\n",
            ">2308, d1=0.036, d2=0.088 g=0.086\n",
            ">2309, d1=0.044, d2=0.097 g=0.079\n",
            ">2310, d1=0.094, d2=0.051 g=0.064\n",
            ">2311, d1=0.105, d2=0.069 g=0.100\n",
            ">2312, d1=0.032, d2=0.068 g=0.064\n",
            ">2313, d1=0.030, d2=0.073 g=0.095\n",
            ">2314, d1=0.030, d2=0.055 g=0.079\n",
            ">2315, d1=0.040, d2=0.132 g=0.088\n",
            ">2316, d1=0.047, d2=0.120 g=0.067\n",
            ">2317, d1=0.037, d2=0.132 g=0.054\n",
            ">2318, d1=0.042, d2=0.082 g=0.084\n",
            ">2319, d1=0.029, d2=0.071 g=0.064\n",
            ">2320, d1=0.037, d2=0.061 g=0.124\n",
            ">2321, d1=0.050, d2=0.029 g=0.139\n",
            ">2322, d1=0.120, d2=0.106 g=0.090\n",
            ">2323, d1=0.091, d2=0.102 g=0.089\n",
            ">2324, d1=0.044, d2=0.149 g=0.191\n",
            ">2325, d1=0.058, d2=0.092 g=0.072\n",
            ">2326, d1=0.037, d2=0.107 g=0.126\n",
            ">2327, d1=0.030, d2=0.082 g=0.070\n",
            ">2328, d1=0.053, d2=0.132 g=0.119\n",
            ">2329, d1=0.024, d2=0.034 g=0.140\n",
            ">2330, d1=0.044, d2=0.098 g=0.189\n",
            ">2331, d1=0.030, d2=0.094 g=0.080\n",
            ">2332, d1=0.029, d2=0.111 g=0.132\n",
            ">2333, d1=0.023, d2=0.054 g=0.160\n",
            ">2334, d1=0.037, d2=0.078 g=0.086\n",
            ">2335, d1=0.025, d2=0.072 g=0.117\n",
            ">2336, d1=0.034, d2=0.057 g=0.142\n",
            ">2337, d1=0.036, d2=0.060 g=0.099\n",
            ">2338, d1=0.031, d2=0.101 g=0.082\n",
            ">2339, d1=0.030, d2=0.081 g=0.086\n",
            ">2340, d1=0.043, d2=0.070 g=0.142\n",
            ">2341, d1=0.039, d2=0.058 g=0.106\n",
            ">2342, d1=0.025, d2=0.095 g=0.203\n",
            ">2343, d1=0.038, d2=0.044 g=0.172\n",
            ">2344, d1=0.040, d2=0.038 g=0.053\n",
            ">2345, d1=0.033, d2=0.196 g=0.301\n",
            ">2346, d1=0.171, d2=0.076 g=0.200\n",
            ">2347, d1=0.292, d2=0.077 g=0.158\n",
            ">2348, d1=0.329, d2=0.151 g=0.095\n",
            ">2349, d1=0.180, d2=0.127 g=0.066\n",
            ">2350, d1=0.063, d2=0.218 g=0.158\n",
            ">2351, d1=0.051, d2=0.164 g=0.076\n",
            ">2352, d1=0.048, d2=0.132 g=0.120\n",
            ">2353, d1=0.088, d2=0.064 g=0.075\n",
            ">2354, d1=0.061, d2=0.101 g=0.345\n",
            ">2355, d1=0.165, d2=0.049 g=0.125\n",
            ">2356, d1=0.147, d2=0.105 g=0.337\n",
            ">2357, d1=0.351, d2=0.162 g=0.130\n",
            ">2358, d1=0.137, d2=0.061 g=0.263\n",
            ">2359, d1=0.135, d2=0.155 g=0.325\n",
            ">2360, d1=0.062, d2=0.104 g=0.262\n",
            ">2361, d1=0.056, d2=0.073 g=0.178\n",
            ">2362, d1=0.044, d2=0.191 g=0.451\n",
            ">2363, d1=0.113, d2=0.068 g=0.354\n",
            ">2364, d1=0.094, d2=0.127 g=0.230\n",
            ">2365, d1=0.110, d2=0.135 g=0.166\n",
            ">2366, d1=0.077, d2=0.101 g=0.223\n",
            ">2367, d1=0.140, d2=0.194 g=0.304\n",
            ">2368, d1=0.087, d2=0.079 g=0.240\n",
            ">2369, d1=0.110, d2=0.300 g=0.728\n",
            ">2370, d1=0.090, d2=0.219 g=1.112\n",
            ">2371, d1=0.422, d2=0.686 g=1.439\n",
            ">2372, d1=0.338, d2=0.264 g=0.769\n",
            ">2373, d1=0.399, d2=0.609 g=0.770\n",
            ">2374, d1=0.216, d2=0.393 g=2.422\n",
            ">2375, d1=0.468, d2=0.638 g=0.412\n",
            ">2376, d1=0.631, d2=1.272 g=3.750\n",
            ">2377, d1=1.580, d2=0.061 g=0.590\n",
            ">2378, d1=0.835, d2=0.079 g=0.987\n",
            ">2379, d1=0.591, d2=1.031 g=4.225\n",
            ">2380, d1=0.406, d2=0.997 g=0.239\n",
            ">2381, d1=0.843, d2=2.018 g=6.659\n",
            ">2382, d1=2.040, d2=1.409 g=0.913\n",
            ">2383, d1=1.207, d2=2.134 g=3.611\n",
            ">2384, d1=1.493, d2=0.961 g=0.291\n",
            ">2385, d1=0.756, d2=1.759 g=2.090\n",
            ">2386, d1=0.883, d2=0.286 g=0.378\n",
            ">2387, d1=0.316, d2=0.949 g=1.207\n",
            ">2388, d1=0.365, d2=0.171 g=0.486\n",
            ">2389, d1=0.249, d2=0.494 g=0.892\n",
            ">2390, d1=0.608, d2=0.280 g=0.466\n",
            ">2391, d1=0.330, d2=0.102 g=0.288\n",
            ">2392, d1=0.148, d2=0.332 g=0.489\n",
            ">2393, d1=0.464, d2=0.152 g=0.254\n",
            ">2394, d1=0.145, d2=0.064 g=0.262\n",
            ">2395, d1=0.100, d2=0.180 g=0.336\n",
            ">2396, d1=0.140, d2=0.055 g=0.305\n",
            ">2397, d1=0.143, d2=0.139 g=0.279\n",
            ">2398, d1=0.145, d2=0.106 g=0.420\n",
            ">2399, d1=0.171, d2=0.129 g=0.449\n",
            ">2400, d1=0.084, d2=0.044 g=0.454\n",
            ">2401, d1=0.114, d2=0.110 g=0.392\n",
            ">2402, d1=0.097, d2=0.149 g=0.534\n",
            ">2403, d1=0.105, d2=0.063 g=0.321\n",
            ">2404, d1=0.114, d2=0.192 g=0.541\n",
            ">2405, d1=0.149, d2=0.123 g=0.437\n",
            ">2406, d1=0.142, d2=0.125 g=0.497\n",
            ">2407, d1=0.170, d2=0.085 g=0.467\n",
            ">2408, d1=0.140, d2=0.117 g=0.312\n",
            ">2409, d1=0.108, d2=0.141 g=0.570\n",
            ">2410, d1=0.278, d2=0.117 g=0.355\n",
            ">2411, d1=0.143, d2=0.092 g=0.378\n",
            ">2412, d1=0.083, d2=0.075 g=0.378\n",
            ">2413, d1=0.081, d2=0.062 g=0.363\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Saved generated_plot_002413.png and model_002413.h5\n",
            ">2414, d1=0.174, d2=0.093 g=0.225\n",
            ">2415, d1=0.159, d2=0.089 g=0.533\n",
            ">2416, d1=0.175, d2=0.126 g=0.364\n",
            ">2417, d1=0.142, d2=0.084 g=0.331\n",
            ">2418, d1=0.156, d2=0.052 g=0.618\n",
            ">2419, d1=0.289, d2=0.118 g=0.137\n",
            ">2420, d1=0.059, d2=0.193 g=0.491\n",
            ">2421, d1=0.184, d2=0.057 g=0.433\n",
            ">2422, d1=0.240, d2=0.166 g=0.257\n",
            ">2423, d1=0.115, d2=0.056 g=0.477\n",
            ">2424, d1=0.176, d2=0.130 g=0.233\n",
            ">2425, d1=0.106, d2=0.106 g=0.322\n",
            ">2426, d1=0.088, d2=0.057 g=0.257\n",
            ">2427, d1=0.109, d2=0.097 g=0.291\n",
            ">2428, d1=0.087, d2=0.069 g=0.308\n",
            ">2429, d1=0.097, d2=0.059 g=0.197\n",
            ">2430, d1=0.074, d2=0.130 g=0.339\n",
            ">2431, d1=0.160, d2=0.199 g=0.345\n",
            ">2432, d1=0.147, d2=0.071 g=0.220\n",
            ">2433, d1=0.087, d2=0.065 g=0.426\n",
            ">2434, d1=0.153, d2=0.178 g=0.342\n",
            ">2435, d1=0.208, d2=0.212 g=0.411\n",
            ">2436, d1=0.260, d2=0.175 g=0.406\n",
            ">2437, d1=0.132, d2=0.224 g=0.313\n",
            ">2438, d1=0.086, d2=0.088 g=0.260\n",
            ">2439, d1=0.190, d2=0.086 g=0.323\n",
            ">2440, d1=0.075, d2=0.144 g=0.374\n",
            ">2441, d1=0.199, d2=0.208 g=0.337\n",
            ">2442, d1=0.092, d2=0.061 g=0.380\n",
            ">2443, d1=0.118, d2=0.164 g=0.288\n",
            ">2444, d1=0.132, d2=0.112 g=0.356\n",
            ">2445, d1=0.110, d2=0.187 g=0.257\n",
            ">2446, d1=0.056, d2=0.069 g=0.255\n",
            ">2447, d1=0.092, d2=0.084 g=0.342\n",
            ">2448, d1=0.069, d2=0.040 g=0.334\n",
            ">2449, d1=0.151, d2=0.114 g=0.169\n",
            ">2450, d1=0.059, d2=0.047 g=0.199\n",
            ">2451, d1=0.049, d2=0.098 g=0.323\n",
            ">2452, d1=0.054, d2=0.074 g=0.197\n",
            ">2453, d1=0.054, d2=0.044 g=0.244\n",
            ">2454, d1=0.048, d2=0.061 g=0.214\n",
            ">2455, d1=0.058, d2=0.073 g=0.301\n",
            ">2456, d1=0.051, d2=0.041 g=0.223\n",
            ">2457, d1=0.076, d2=0.067 g=0.340\n",
            ">2458, d1=0.092, d2=0.068 g=0.253\n",
            ">2459, d1=0.065, d2=0.073 g=0.207\n",
            ">2460, d1=0.052, d2=0.038 g=0.295\n",
            ">2461, d1=0.092, d2=0.071 g=0.207\n",
            ">2462, d1=0.063, d2=0.144 g=0.307\n",
            ">2463, d1=0.135, d2=0.084 g=0.255\n",
            ">2464, d1=0.101, d2=0.079 g=0.345\n",
            ">2465, d1=0.195, d2=0.163 g=0.106\n",
            ">2466, d1=0.095, d2=0.081 g=0.398\n",
            ">2467, d1=0.278, d2=0.289 g=0.303\n",
            ">2468, d1=0.108, d2=0.134 g=0.487\n",
            ">2469, d1=0.189, d2=0.183 g=0.370\n",
            ">2470, d1=0.167, d2=0.179 g=0.383\n",
            ">2471, d1=0.184, d2=0.238 g=0.475\n",
            ">2472, d1=0.222, d2=0.144 g=0.422\n",
            ">2473, d1=0.109, d2=0.120 g=0.354\n",
            ">2474, d1=0.164, d2=0.167 g=0.441\n",
            ">2475, d1=0.180, d2=0.179 g=0.288\n",
            ">2476, d1=0.108, d2=0.109 g=0.496\n",
            ">2477, d1=0.201, d2=0.164 g=0.254\n",
            ">2478, d1=0.213, d2=0.099 g=0.644\n",
            ">2479, d1=0.351, d2=0.160 g=0.229\n",
            ">2480, d1=0.241, d2=0.089 g=0.391\n",
            ">2481, d1=0.230, d2=0.149 g=0.303\n",
            ">2482, d1=0.139, d2=0.081 g=0.275\n",
            ">2483, d1=0.185, d2=0.247 g=0.214\n",
            ">2484, d1=0.150, d2=0.134 g=0.376\n",
            ">2485, d1=0.115, d2=0.068 g=0.226\n",
            ">2486, d1=0.136, d2=0.225 g=0.330\n",
            ">2487, d1=0.108, d2=0.072 g=0.287\n",
            ">2488, d1=0.125, d2=0.171 g=0.362\n",
            ">2489, d1=0.112, d2=0.115 g=0.499\n",
            ">2490, d1=0.104, d2=0.095 g=0.323\n",
            ">2491, d1=0.187, d2=0.101 g=0.214\n",
            ">2492, d1=0.127, d2=0.218 g=0.418\n",
            ">2493, d1=0.169, d2=0.101 g=0.158\n",
            ">2494, d1=0.139, d2=0.058 g=0.422\n",
            ">2495, d1=0.241, d2=0.140 g=0.227\n",
            ">2496, d1=0.096, d2=0.135 g=0.626\n",
            ">2497, d1=0.199, d2=0.174 g=0.334\n",
            ">2498, d1=0.149, d2=0.141 g=0.313\n",
            ">2499, d1=0.197, d2=0.342 g=0.578\n",
            ">2500, d1=0.244, d2=0.130 g=0.244\n",
            ">2501, d1=0.196, d2=0.111 g=0.508\n",
            ">2502, d1=0.264, d2=0.215 g=0.363\n",
            ">2503, d1=0.183, d2=0.185 g=0.419\n",
            ">2504, d1=0.167, d2=0.172 g=0.438\n",
            ">2505, d1=0.138, d2=0.119 g=0.264\n",
            ">2506, d1=0.105, d2=0.130 g=0.432\n",
            ">2507, d1=0.151, d2=0.101 g=0.238\n",
            ">2508, d1=0.179, d2=0.234 g=0.312\n",
            ">2509, d1=0.142, d2=0.241 g=0.390\n",
            ">2510, d1=0.371, d2=0.292 g=0.246\n",
            ">2511, d1=0.158, d2=0.190 g=0.516\n",
            ">2512, d1=0.291, d2=0.147 g=0.216\n",
            ">2513, d1=0.182, d2=0.109 g=0.479\n",
            ">2514, d1=0.374, d2=0.199 g=0.184\n",
            ">2515, d1=0.268, d2=0.217 g=0.326\n",
            ">2516, d1=0.254, d2=0.264 g=0.253\n",
            ">2517, d1=0.239, d2=0.122 g=0.196\n",
            ">2518, d1=0.214, d2=0.326 g=0.427\n",
            ">2519, d1=0.214, d2=0.112 g=0.244\n",
            ">2520, d1=0.112, d2=0.044 g=0.134\n",
            ">2521, d1=0.196, d2=0.121 g=0.214\n",
            ">2522, d1=0.275, d2=0.164 g=0.110\n",
            ">2523, d1=0.158, d2=0.100 g=0.276\n",
            ">2524, d1=0.268, d2=0.263 g=0.116\n",
            ">2525, d1=0.126, d2=0.146 g=0.453\n",
            ">2526, d1=0.318, d2=0.138 g=0.164\n",
            ">2527, d1=0.163, d2=0.079 g=0.170\n",
            ">2528, d1=0.174, d2=0.090 g=0.186\n",
            ">2529, d1=0.103, d2=0.056 g=0.171\n",
            ">2530, d1=0.138, d2=0.161 g=0.240\n",
            ">2531, d1=0.256, d2=0.274 g=0.177\n",
            ">2532, d1=0.114, d2=0.058 g=0.217\n",
            ">2533, d1=0.212, d2=0.222 g=0.309\n",
            ">2534, d1=0.227, d2=0.109 g=0.169\n",
            ">2535, d1=0.111, d2=0.167 g=0.302\n",
            ">2536, d1=0.247, d2=0.143 g=0.191\n",
            ">2537, d1=0.170, d2=0.099 g=0.269\n",
            ">2538, d1=0.177, d2=0.121 g=0.160\n",
            ">2539, d1=0.155, d2=0.353 g=0.239\n",
            ">2540, d1=0.260, d2=0.206 g=0.266\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Saved generated_plot_002540.png and model_002540.h5\n",
            "Saved plot_line_plot_loss.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8Tft6gAXgz_"
      },
      "source": [
        "Generate Images Using Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "Zlh0cxgeXjg5",
        "outputId": "022e4852-4558-4014-97d0-bef85bfa9be7"
      },
      "source": [
        "# example of loading the generator model and generating images\n",
        "from keras.models import load_model\n",
        "from numpy.random import randn\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# generate points in latent space as input for the generator\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "\t# generate points in the latent space\n",
        "\tx_input = randn(latent_dim * n_samples)\n",
        "\t# reshape into a batch of inputs for the network\n",
        "\tx_input = x_input.reshape(n_samples, latent_dim)\n",
        "\treturn x_input\n",
        "\n",
        "# create a plot of generated images (reversed grayscale)\n",
        "def plot_generated(examples, n):\n",
        "\t# plot images\n",
        "\tfor i in range(n * n):\n",
        "\t\t# define subplot\n",
        "\t\tpyplot.subplot(n, n, 1 + i)\n",
        "\t\t# turn off axis\n",
        "\t\tpyplot.axis('off')\n",
        "\t\t# plot raw pixel data\n",
        "\t\tpyplot.imshow(examples[i, :, :, 0], cmap='gray_r')\n",
        "\tpyplot.show()\n",
        "\n",
        "# load model\n",
        "model = load_model('model_002540.h5')\n",
        "# generate images\n",
        "latent_points = generate_latent_points(100, 100)\n",
        "# generate images\n",
        "X = model.predict(latent_points)\n",
        "# plot the result\n",
        "plot_generated(X, 10)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 100 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "vv9vn3eXbyq9",
        "outputId": "78c582e4-5f62-412a-d2e1-3843854bded5"
      },
      "source": [
        "pyplot.figure(1)\n",
        "pyplot.plot(d1_hist, label='d-real loss')\n",
        "pyplot.plot(d2_hist, label='d-fake loss')\n",
        "pyplot.plot(g_hist, label='gen loss')\n",
        "pyplot.legend()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fb833b53890>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaqfoglfdKwx"
      },
      "source": [
        "As we can see from the loss graph and the generated car images from the trained generator - this is the worst of the three models (the other two being my DCGAN and VGG GAN using transfer learning)\n",
        "\n",
        "The loss of generator and discriminator is not converging at all.\n",
        "\n",
        "The generated images are pure noise.\n",
        "\n",
        "The Least Squares Generative Adversarial Network, or LSGAN for short, is an extension to the GAN architecture proposed by Xudong Mao, et al. in their 2016 paper titled “Least Squares Generative Adversarial Networks.” The LSGAN is a modification to the GAN architecture that changes the loss function for the discriminator from binary cross entropy to a least squares loss.\n",
        "\n",
        "The motivation for this change is that the least squares loss will penalize generated images based on their distance from the decision boundary. This will provide a strong gradient signal for generated images that are very different or far from the existing data and address the problem of saturated loss.\n",
        "\n",
        "As it turns out, this type of GAN is even worse, and requires more fine tuning which could not be done due to time constraints."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQ2WwRZJgJhH"
      },
      "source": [
        "#Question 2 - Part 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e27_KaVhgSPQ"
      },
      "source": [
        "The student applied the sufficiently large median blurring filter to remove noise from the original images given by the researcher. \n",
        "\n",
        "Since the kernel/filter was large,original images were shrinked. Padding was done to retain the size of the original image. Now, the student has a batch of low resolution images and he wants to scale them upto the original HD image size (size is known).\n",
        "\n",
        "**SRGANs can be used in this scenario**\n",
        "\n",
        "Inspired from: https://paperswithcode.com/method/srgan\n",
        "\n",
        "Super-Resolution Generative Adversarial Network, or SRGAN, is a Generative Adversarial Network (GAN) that can generate super-resolution images from low-resolution images, with finer details and higher quality.\n",
        "\n",
        "SRGAN performs the challenging task of estimating a highresolution (HR) image from its low-resolution (LR) counterpart is referred to as super-resolution (SR). To achieve a photo-realistic effect in high resolution images, the network uses a perceptual loss function which consists of an adversarial loss and a content loss. It also uses a deep residual network to protect the minor details from getting lost in the down sampling process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMQfeOfdgSgG"
      },
      "source": [
        "#Question 2 - Part 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_6DX9rqgTfk"
      },
      "source": [
        "In this problem for skin matching, we do not have paired images of regular bears and pandas that can be used. A different set of images of bears and pandas is available. This problem may be handled by:\n",
        "\n",
        "1. CGANS\n",
        "2. CycleGAN\n",
        "\n",
        "CGANs require a large dataset. Moreoever, a CGAN learns by figuring out the mapping of image X to image Y, and then is able to apply this mapping function on previously unseen data. Since, a CGAN requires a paired set of images for pandas and bears, which we do not have, it cannot be used.\n",
        "\n",
        "The CycleGAN is a technique that involves the automatic training of image-to-image translation models without paired examples. The models are trained in an unsupervised manner using a collection of images from the source and target domain that do not need to be related in any way.\n",
        "\n",
        "Inspired from: https://machinelearningmastery.com/what-is-cyclegan/#:~:text=The%20CycleGAN%20is%20a%20technique,be%20related%20in%20any%20way.\n",
        "\n",
        "A CycleGAN is able to perform unpaired image-to-image translation by using a network of two discriminators and two generators. CycleGANs also learn mapping of image X to image Y, however they don't need the images to be exact same copies of each other with stylistic difference, as long as images are from the same domain.\n",
        "\n",
        "Hence CycleGANs are the way to go for this problem!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyNe0pT4gTsd"
      },
      "source": [
        "##Question 2 - Part 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxU98KY8gXbr"
      },
      "source": [
        "The daughter wants to turn her family photos to a painting style of a famous painter to impress her mother. Two GANS may be used for this purpose:\n",
        "\n",
        "1. CycleGAN\n",
        "2. Style transfer GAN\n",
        "\n",
        "A CycleGAN may work as it needs Van Gogh paintings and family photos at input. And those images do not have to be exact copy of one another. So a CycleGAN seems to work too.\n",
        "\n",
        "However, I feel that a Style transfer GAN is a more suitable choice.\n",
        "\n",
        "Style transfer is the task of changing the style of an image in one domain to the style of an image in another domain.\n",
        "\n",
        "Inspired from: https://paperswithcode.com/task/style-transfer\n",
        "\n",
        "It gives the option of masking which means more control over how much style is transferred on the input image unlike CycleGAN. \n",
        "\n",
        "The Style Transfer GAN uses generator network based on VGG-based CNN encoder-decoder using skip connections to transmit minor details to the output image. The discriminator is a patch based model which calculated the loss of an image in patches.\n",
        "\n",
        "For training the Style transfer GAN, Behance dataset which is a large scale dataset of artistic images with category labels and styles can be used. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idOHZSokgXv-"
      },
      "source": [
        "#Question 3 - Bonus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSPHIITOgZOE"
      },
      "source": [
        "The idea of an LSTM in the DC-GAN was inspired from: https://arxiv.org/pdf/1806.03027.pdf\n",
        "\n",
        "For this particular problem, I have two things in mind for the architecture:\n",
        "\n",
        "1. CNN for DC-GAN\n",
        "2. LSTM for series prediction or for next image prediction in the discriminator.\n",
        "\n",
        "Preprocessing: \n",
        "\n",
        "It would be really very important for a machine learning researcher or a programmer to first remove all the noise as well as distortion present within the video data by enhancing their contrast so that only that information that is required for the training of the model would be present within the video data\n",
        "and there would be no noise within the data and hence the training, as well as the convergence of the model, becomes faster and more efficient.\n",
        "\n",
        "The frames would be extracted from the videos present within the dataset and then these frames would be processed for the texture as well as appearances by making use of the libraries such as OpenCV, and cv2 of Python, or the image processing toolbox by MATLAB. Once these frames are extracted and preprocessed properly, a dataset would be prepared of these frames to train the models. \n",
        "\n",
        "These methods of preprocessing would include the stretching of the contrast within the images so that the objects within the image can be clearly identied, smoothing the image by filtering it so that there is uniformity within the image and the noise is removed from it, and so on.\n",
        "\n",
        "Architecture:\n",
        "\n",
        "A CNN and LSTM would have to be used alongside the GANs to better process the visual data in the discriminator section of the model where the model would try to differentiate between which frame is a fighting scene and which is not. \n",
        "\n",
        "Therefore, there has to be a combined CNN-LSTM-GAN model that has to be deployed in order to predict the frames perfectly using this visual data.\n",
        "\n",
        "Our Proposed Model:\n",
        "\n",
        "Input -> LSTM -> Generator -> CNN Discriminator \n",
        "\n",
        "The final output will be by the generator. It will be trained by feedback from LSTM and CNN.\n",
        "\n",
        "Before the generator, an LSTM network structure enables learned semantics to correlate more closely with high-level visual features of images, which gives the generator more flexibility to add details to improve the visual quality of the synthesized images. The generator would make use of the ReLU activation function to get a better calculation of the gradients during the training phase in its neural layer while it would use the tanh function in its output layer.\n",
        "The discriminator is supposed to use the Leaky ReLU activation function to reduce the chances of vanishing gradient during the training phase.\n",
        "\n",
        "The generator would make use of the fractionally stridden convolutional layers in place of the pooling layers to perform the feature extraction. The discriminator would make use of the stridden convolutional layers in place of the pooling layers for the enhanced feature extraction from the data.\n",
        "\n"
      ]
    }
  ]
}